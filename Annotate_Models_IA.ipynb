{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: emoji in c:\\users\\kikoo\\appdata\\roaming\\python\\python312\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kikoo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install emoji pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID Post",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comments",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Sentiments",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "418e823b-b853-454a-a1c7-0eeec1ecb903",
       "rows": [
        [
         "0",
         "1",
         "Samir Bekhouche",
         null,
         "Neutre"
        ],
        [
         "1",
         "1",
         "Yanise Yanise",
         "ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู ุจุฏุฃุช ุชููุต ุดูู ุดููุง ูู 100 ุฏุฌ ุฅูู 75ุฏุฌ ู ุจุนุฏูุง ุฅูู 50 ุฏุฌ ู ุจุนุฏูุง ุฅูู 25 ุฏุฌ !!!!!!!!!!! ุงูู ุฐูุจุช ูุฒูููุชู ุชุงุนู ุุุุ!!!!!!\n ูู ุฃุชููู ุจูุง ู ูู ุงุชุตู ุจูุง ู ููุณ ูู ุฎุงุตูุฉ ุฑูุชู ุงุฐู ุงูู ุฐูุจ ูุงููุ!ุ!ุ!ุ\n ู ุตุงุฑ ููุณ ุงูุดูุก ูุน ุฃุฎู!!!!!!!!!!!!\n ูุงูุฐุง ูุงุจุฏ ูู ุงุณุชุฑุฌุงุนู",
         "Negatif"
        ],
        [
         "2",
         "1",
         "Jj Kie",
         "ูู ุนุงู ู ุงูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "3",
         "1",
         "Sakou Younes",
         "ูู ุนุงู ูุฃูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "4",
         "1",
         "ุฑุงูู ูุนุงูู",
         "ูู ุนุงู ูุญูุง ุจุฎูุฑ",
         "Positif"
        ],
        [
         "5",
         "1",
         "Wahab Ziadi",
         "ูู ุนุงู ูุญูุง ุจุฎูุฑ",
         "Positif"
        ],
        [
         "6",
         "1",
         "ุฃุญูุฏ ููุฑุงุณ",
         "๐ฅฐ",
         "Positif"
        ],
        [
         "7",
         "1",
         "ูุฑูุงู ุณูุฏูู ุณูุฏูู ูุฑูุงู",
         "ูู ุนุงู ูุฃูุชู ุจุฎูุฑ ูุฃุชููุง ุฑุฏ ุนูุง ุฃุณุฅูุชู ุนูุง ูุญุงุต ููู ุนุงู ูุฃูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "8",
         "1",
         "Mostefa Merabti",
         "Happy New year",
         "Positif"
        ],
        [
         "9",
         "1",
         "ูููุฏ ุจุฑู",
         "ูุงุด ุนุฑูุถ ูุฏู ุฑู ูู 2024",
         "Neutre"
        ],
        [
         "10",
         "1",
         "Aymen Aymen",
         "ุชุญูุง ุฌูุฒู",
         "Positif"
        ],
        [
         "11",
         "1",
         "Maram Akram",
         "Bonne annรฉe ร tous",
         "Positif"
        ],
        [
         "12",
         "1",
         "Plako Platr Ba 13",
         "๐",
         "Neutre"
        ],
        [
         "13",
         "1",
         "Lina Sami",
         "ูููู ูุญูู ุนุฑูุถ ุฌูุฒู ุณุจูุณูุงู ุจุงู ูุฑุฌุนูุง ูุงููุฉ ุจุฒุงู",
         "Neutre"
        ],
        [
         "14",
         "1",
         "Yakoub Boussebsi",
         "ุณูุฉ ุณุนูุฏุฉ ูุฑุฌุนููุง 6h",
         "Positif"
        ],
        [
         "15",
         "1",
         "Hamza Othmani",
         "ุจุฏุงูุฉ ุณูุฉ ุณูุฆุฉ ุฌุฏุงุ ููุฏ ุซู ูุทุน ุฎุทู ุถููุ ู ูุตูุญุฉ ุงูุฒุจุงุฆู ูุง ุชุฑุฏุ ุนูุจ",
         "Negatif"
        ],
        [
         "16",
         "1",
         "RED ROSE",
         "๐น๐น๐น๐น",
         "Positif"
        ],
        [
         "17",
         "1",
         "Mohamed Mellak",
         "ุนุงู ุณุนูุฏ 2024",
         "Positif"
        ],
        [
         "18",
         "1",
         "Naseraddein Hamada",
         null,
         "Neutre"
        ],
        [
         "19",
         "1",
         "Saber Zem",
         "ุฃูุง ูุดุชุฑู ุฏูุน ุจุนุฏู ุชู ุชุฒููุฏู ุจุฎุฏูุฉ chirpix ุฏูู ุนููู ูู 2 ุฏูุณูุจุฑ 2023ุ ูุนูุฏ ุงูุงุทูุงุน ุนูู ูุงุชูุฑุฉ ุดูุฑ ุฌุงููู ูุฌุฏุช ูุจูุบ 740.00 ุฏุฌ ุฒุงุฆุฏ ุนู ุงููุงุชูุฑุฉ ูุนูุฏ ุงูุงุณุชูุณุงุฑ ุนูุฏ ุฎุฏูุฉ ุงูุฒุจุงุฆู ูุงู ุจุณุจุจ chirpixุ ุนููุง ุฃููู ูู ุฃุทูุจ ูุฐู ุงูุฎุฏูุฉ ุฃุจุฏุง ุุุุุุุ",
         "Neutre"
        ],
        [
         "20",
         "1",
         "ุฌูุนูุฉ ุงูุญู ุฃุจูุงุก ุงูุบุฏ ูุนูุงุถุงุช -ูุตุฑ ุงูุฃุจุทุงู-",
         "ูุญูุทูู ุนููุง ุงูุง ูุฑูุชูุง ( ูุฑูุฉ ูุนูุงุถุงุช ) ุงูุชุงุจุนุฉ ูุจูุฏูุฉ ูุตุฑ ุงูุฃุจุทุงู ุฏุงุฆุฑุฉ ุนูู ูููุงู ููุงูุฉ ุณุทูู ุงู ุดุจูุฉ ุงูุงูุชุฑูุช ุฌูุฒู ุชูุนุฏู ุชูุงูุง ูู ูุฑูุชูุง.ูุฑุฌู ูููู ุงูุฌุงุฏ ุญู ููุฐู ุงููุดููุฉ",
         "Negatif"
        ],
        [
         "21",
         "1",
         "Sรm Fรrรh Mehimdร",
         "ูู ูุฑุฉ ุชุณุฑููุง 50ุฏุฌ ุุุุ ุนูุงุด ูุงู ุชุฎูููุง ูุจุฏููุง ุงูุฎุท ๐ฅด๐ฅด๐ฅด",
         "Negatif"
        ],
        [
         "22",
         "1",
         "ลรลรh ลฤhรฏr",
         "ูู ุนุงู ูุงูุชู ุจุงูู ุฎูุฑ โฃ๏ธโฃ๏ธ",
         "Positif"
        ],
        [
         "23",
         "1",
         "Sofiane Sofiane",
         "ุนูุงู ุฏูุชููู 50 ุฏุฌ ูู ูุฑุฉ ุฑุงูู ุฏูุฑููุงูู",
         "Negatif"
        ],
        [
         "24",
         "1",
         "Lamine Jseb",
         "ูุงุด ุจูู ุงูุฑูุฒู ุงููููุุ ูุงูุงุด ุงูุชุฑูุช ููุฐ 3 ุณุงุนุงุช",
         "Negatif"
        ],
        [
         "25",
         "1",
         "ใใฆใณใ ใณใฉใคใ",
         "ุจูุฏ ููุงุณุจุฉ ุชุจุฑุนู ุนูููุง ุจ ุงูุชุฑูุช๐",
         "Neutre"
        ],
        [
         "26",
         "1",
         "Bnamer Boutayeb",
         "ุฑูููู ุงุจูููุงุณูู ูุชุงุนูู",
         "Negatif"
        ],
        [
         "27",
         "1",
         "ใใใ ใฅ ใฅ",
         "ุฏูุฑูููุง ูุด ุญุงุฌุฉ ูุชุน ูููููุณููู",
         "Neutre"
        ],
        [
         "28",
         "1",
         "ูููุด ุณููุฑ",
         "ููุงูุด ูููููุณู ๐๐",
         "Negatif"
        ],
        [
         "29",
         "1",
         "Fati Fati",
         "ูู 2006 ุฑุงูู ูุดุชุงุฑูู ูุนุงูู ูุงุด ููุงุฑ ูุฑุญููุง ุจูุฏูู ๐",
         "Neutre"
        ],
        [
         "30",
         "1",
         "Sofiane Renault Medea",
         "ุจุทูุกุฉ",
         "Negatif"
        ],
        [
         "31",
         "1",
         "Sifadine Mehdi",
         "ุฑูุฒู ูุดุจูู ูุฑูุญ ู ูุฌู ุ",
         "Negatif"
        ],
        [
         "32",
         "1",
         "Aรฑdลeรค Aรฑdลeรค",
         "ููุชุงู ุชุฑุฏูููุง ุฑูุฒู๐คง",
         "Negatif"
        ],
        [
         "33",
         "1",
         "Nabil Issam",
         "ุฑูฺจูููุง ุฑุจ ุฑูุฒู",
         "Negatif"
        ],
        [
         "34",
         "1",
         "Abdo Gros",
         "Malheureusement le rรฉseau รฉtait coupรฉ men 17h ! Hata dok bach wala en plus c'est en niveau d'Alger yahsra les autres wilaya !! Ni excuses ni rien! Mais bon en souhaitant une amรฉlioration cette annรฉe nchlh",
         "Negatif"
        ],
        [
         "35",
         "2",
         "Djezzy",
         "ูุฑุญุจุงู\n ูุฑุฌู ุงูุชูุงุตู ูุนูุง ูู ุงูุฎุงุต ุญุชู ูุชููู ูู ูุณุงุนุฏุชูู\n ุดูุฑุงู ( ุณููุฑุฉ .ู ) ูู ุฌุงุฒู",
         "Neutre"
        ],
        [
         "36",
         "2",
         "Abdelghani Tahtah",
         "ูุงูู ูู ุงูููุฏ ูุชุงุน ุณูููู ... ุุ",
         "Neutre"
        ],
        [
         "37",
         "2",
         "ุฃุญูุฏ ููุฑุงุณ",
         "ูููุญ",
         "Positif"
        ],
        [
         "38",
         "2",
         "ลล ลล",
         "ูููุงู ูุณูู ุนุดุฑุงูุงู",
         "Neutre"
        ],
        [
         "39",
         "2",
         "Houhou Ben Medani",
         null,
         "Neutre"
        ],
        [
         "40",
         "2",
         "Riad BM",
         "ุดููู ูุจุนุซูู 2 ุฌูุบุง ๐๐",
         "Neutre"
        ],
        [
         "41",
         "2",
         "Amine Boudiaf",
         "ุฑุฌุนููุง ุนุฑูุถ ุงูุชูุงุฒ ูู ูุญูุชููุง ููุง",
         "Negatif"
        ],
        [
         "42",
         "2",
         "ุฒูู ุงูุฏูู ุงุจู ุงูุจูุงุฏู",
         "ุฃูุฏ ูุนุฑูุฉ ููููุฉ ุณุฑูุฉ ุฑุตูุฏู ุ\n ุงูุฑุฌุงุก ุงูุชูุถูุญ \n ูู ุฑูููู ูู ุฌูุฒู ุฏุงุฆูุง ูุง ุงุฌุฏ ุงูุฑุตูุฏ Djezzy",
         "Negatif"
        ],
        [
         "43",
         "2",
         "Amani Amina",
         "ููู ุฑูู ุฎุฏูุฉ ุณููู",
         "Neutre"
        ],
        [
         "44",
         "2",
         "ุงูุนุฑุจู ููุงูู",
         "ูููู ูุนุฑู ุนูุงุด ุชููุตู ูู ุงูุฑุตูุฏ \n ูุงููู ุงูุนุธูู ุนูุจ ุนูุจ ุนูุจ \n ุชููููุณู 50 ุงูู ุบุฏูุฉ ุชููู 20 ุงูู ุนูุจ\n ุญุณุจูุง ุงููู ููุนู ุงููููู.",
         "Negatif"
        ],
        [
         "45",
         "2",
         "Yassine Madrid",
         "ูู ูุถููู ุดุฑูุช ุดุฑูุญุฉ ุฌูุฒู ุฌุฏูุฏุฉ ูููุงู ูุฃูุชููููุง ูุน ุงูุนูู ูููุง 60g ุงูุชุฑูุช ู 7000 ููุงููุงุช",
         "Neutre"
        ],
        [
         "46",
         "2",
         "Aoudjia Aimen",
         "ูุดุจูู ุชุทุจูู ุญุงุจุณ ุงู ุฑููููู ูุฑููููู ุงูุฑูุฒู ุฑุงูุง ูุนุงููู 2024 ูุฑูุฒู ููุช ูู ุญุงูุง ูุงููู ูุง ููููุง ูููููุชุด ุนูุงู ุฑุงูุง ูุงูุนุงูู ุงูุซุงูุซ (ุงูุณุจุจ ุงููุญูุฏ ูุง ุบูุฑู ูู ูุฎูููุง ูุงูุนุงูู ุงูุซุงูุซ ุงูู ููุงุด ุนุงูู ุฑุงุจุน ุงู ุฎุงูุณ)",
         "Negatif"
        ],
        [
         "47",
         "2",
         "ุตุงุญุจุฉ ุงูุณุนุงุฏุฉ",
         "ุนูุงุจููุง ูููุชู ููููููุณูู ุชุฏููู",
         "Negatif"
        ],
        [
         "48",
         "2",
         "ุนุงุฆุดุฉ ุตุฏููุฉ",
         "Djezzy ูู ูุถููู ุฃุฑูุฏ ุชูุทูุน ุงูุดุฑูุญุฉ ูุชูุงุณุจ ุงููุงุชู..ููู ูุฐุง ุบูุฑ ูููู ูุน ุดุฑูุญุชู ุงูุญุงููุฉ ูู ูููู ุงุณุชุจุฏุงููุง ูุน ุฃุฎุฑู ูุงุจูุฉ ูุชูุทูุน ูุน ุดุฑุท ุงูุงุญุชูุงุธ ุจุฑููู ุงูุญุงูู..",
         "Neutre"
        ],
        [
         "49",
         "2",
         "Youcef Mellah",
         "ุฑุงูุง ูุณููู 150 ูุดูุฑ ู ูููููุณููู ุฑุจู ูุฌูุจ ูููู ุชูุถูุญ",
         "Negatif"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4129
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Post</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Samir Bekhouche</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yanise Yanise</td>\n",
       "      <td>ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jj Kie</td>\n",
       "      <td>ูู ุนุงู ู ุงูุชู ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sakou Younes</td>\n",
       "      <td>ูู ุนุงู ูุฃูุชู ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ุฑุงูู ูุนุงูู</td>\n",
       "      <td>ูู ุนุงู ูุญูุง ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>183</td>\n",
       "      <td>ฤนรฃ Rรตsรซ รb</td>\n",
       "      <td>โค๏ธโค๏ธ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>183</td>\n",
       "      <td>ูุณูุงุช ูุงุฏุฆุฉ</td>\n",
       "      <td>๐๐๐๐</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>183</td>\n",
       "      <td>ููู ูููุงุด ุบูุฑู</td>\n",
       "      <td>โคโคโคโคโคโค๐น</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>183</td>\n",
       "      <td>ุณุนูุฏู ุฑุถุง</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>183</td>\n",
       "      <td>ุฌูุจูู ููุช ููุช</td>\n",
       "      <td>โค๏ธโค๏ธโค๏ธโค๏ธ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4129 rows ร 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Post        User Name  \\\n",
       "0           1  Samir Bekhouche   \n",
       "1           1    Yanise Yanise   \n",
       "2           1           Jj Kie   \n",
       "3           1     Sakou Younes   \n",
       "4           1       ุฑุงูู ูุนุงูู   \n",
       "...       ...              ...   \n",
       "4124      183       ฤนรฃ Rรตsรซ รb   \n",
       "4125      183      ูุณูุงุช ูุงุฏุฆุฉ   \n",
       "4126      183   ููู ูููุงุด ุบูุฑู   \n",
       "4127      183        ุณุนูุฏู ุฑุถุง   \n",
       "4128      183    ุฌูุจูู ููุช ููุช   \n",
       "\n",
       "                                               Comments Sentiments  \n",
       "0                                                   NaN     Neutre  \n",
       "1     ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู...    Negatif  \n",
       "2                                    ูู ุนุงู ู ุงูุชู ุจุฎูุฑ    Positif  \n",
       "3                                     ูู ุนุงู ูุฃูุชู ุจุฎูุฑ    Positif  \n",
       "4                                      ูู ุนุงู ูุญูุง ุจุฎูุฑ    Positif  \n",
       "...                                                 ...        ...  \n",
       "4124                                               โค๏ธโค๏ธ    Positif  \n",
       "4125                                               ๐๐๐๐    Positif  \n",
       "4126                                            โคโคโคโคโคโค๐น    Positif  \n",
       "4127                                                NaN     Neutre  \n",
       "4128                                           โค๏ธโค๏ธโค๏ธโค๏ธ    Positif  \n",
       "\n",
       "[4129 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger les fichiers Excel\n",
    "comments_df = pd.read_excel('Data/Comments.xlsx')\n",
    "\n",
    "# Afficher DataFrame \"Comments\"\n",
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Contents",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Lien Post",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Nb Like",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Love",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Care",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Wow",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Sad",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Angry",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Haha",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "82502164-6493-4eeb-9ba1-d2fb1699420c",
       "rows": [
        [
         "0",
         "1",
         "ุฌุงุฒู ุชุชูููู ููู ุณูุฉ ุณุนูุฏุฉ๐ฅฐ\n#DJEZZY #HAPPY_NEW_YEAR_2024",
         "https://www.facebook.com/djezzy/posts/788227516669599?ref=embed_post",
         "272",
         "45",
         "0",
         "1",
         "1",
         "76",
         "14",
         "Djezzy",
         "2024-01-01 00:00:00"
        ],
        [
         "1",
         "2",
         "ุฑุงู en panne ู ุฎุตู ุฑุตูุฏ ุ\nูุน ุฎุฏูุฉ Tranquilo ุชุงุน Djezzy ููุด ุณุงูู๐\n#ุฌุงุฒู #Astuces_ุณุงููุฉ",
         "https://www.facebook.com/watch/?v=1068829281022985&ref=sharing",
         "255",
         "28",
         "0",
         "1",
         "0",
         "12",
         "31",
         "Djezzy",
         "2024-01-04 00:00:00"
        ],
        [
         "2",
         "3",
         "It's Time To be a legend",
         "https://www.facebook.com/djezzy/posts/392564993435969:392564993435969?ref=embed_post",
         "257",
         "51",
         "2",
         "0",
         "0",
         "2",
         "8",
         "Djezzy",
         "2024-01-10 00:00:00"
        ],
        [
         "3",
         "4",
         "Djezzy vous souhaite Yennayer amervuh!  โดฐโตโตโดปโดณโดฐโต โดฐโตโดปโดณโดฐโตฃ 2974\n ! ุฌุงุฒู ุชูุฏู ููู ุฃุญุฑู ุงูุชูุงูู ุจููุงุณุจุฉ ุงูุณูุฉ ุงูุฃูุงุฒูุบูุฉ ุงูุฌุฏูุฏุฉ\n#DJEZZY #Yennayer_2974",
         "https://www.facebook.com/share/p/19UDNBoQ1k/",
         "621",
         "231",
         "10",
         "3",
         "0",
         "1",
         "300",
         "Djezzy",
         "2024-01-11 00:00:00"
        ],
        [
         "4",
         "5",
         "ูุฑูุจุงู ...",
         "https://www.facebook.com/share/v/12B9LZySBRe/",
         "288",
         "49",
         "4",
         "0",
         "0",
         "3",
         "24",
         "Djezzy",
         "2024-01-12 00:00:00"
        ],
        [
         "5",
         "6",
         "ู ููุงููุงุช ุบูุฑ ูุญุฏูุฏุฉ ูุญู ุฌููุน ุดุจูุงุช ุงูููุงู ู ุงูุซุงุจุช.\nุจู 2500ุฏุฌ ููุท !\n#ูุชุง_ูู_ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/v/15R9u8sYHg/",
         "564",
         "157",
         "24",
         "0",
         "0",
         "7",
         "73",
         "Djezzy",
         "2024-01-13 00:00:00"
        ],
        [
         "6",
         "7",
         "ูุน ุฌุงุฒู LEGEND\nุฅุณุชูุฏ ูู ููุงููุงุช ูุฌุงููุฉ ูุญู ูู ุดุจูุงุช ุงูููุงู ู ุงูุซุงุจุช !\nูุญุฌู ุงูุชุฑูุช ูุตู ุฅูู ุบุงูุฉ 100 ุฌูุบุง !\nุฅูุชุดููุง ูุฒุงูุง ุงูุนุฑุถ ุงูุฌุฏูุฏ DJEZZY LEGEND ุนูู ๐ https://ms.spr.ly/6188iUry6\n#ูุชุง_ูู_ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/djezzy/posts/797321975760153?ref=embed_post",
         "438",
         "31",
         "5",
         "0",
         "0",
         "26",
         "52",
         "Djezzy",
         "2024-01-14 00:00:00"
        ],
        [
         "7",
         "8",
         "ุชูุชุน ุจุงูููุงููุงุช ุงููุฌุงููุฉ ูุญู ุฌููุน ุดุจูุงุช ุงูุฌูุงู๐ฑ ูุงูุซุงุจุช  โ๏ธ ูุงุณุชูุฏ ูู 70ุฌูุบุง ุจ2000 ุฏุฌ ููุท !\nุงุณุชูุดู ูู ุงููููุฒุงุช ุนูู ๐https://ms.spr.ly/6187iUx8v \n#ูุชุง_ูู_ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/djezzy/posts/797937005698650?ref=embed_post",
         "428",
         "23",
         "4",
         "1",
         "1",
         "5",
         "52",
         "Djezzy",
         "2024-01-15 00:00:00"
        ],
        [
         "8",
         "9",
         "ูุน DJEZZY LEGEND ุงูุช ูู ุงูู LEGEND \nุจู 2000ุฏุฌ !\nุชุญุตููุง ุนูู 70Go ุงูุชุฑูุชุ ููุงููุงุช ุบูุฑ ูุญุฏูุฏุฉ ูุญู ุฌููุน ุดุจูุงุช ุงูุซุงุจุช ู ุงูููุงู ! \nุฅูุชุดููุง ูุฒุงูุง DJEZZY LEGEND ุนูู ๐ https://ms.spr.ly/6183isCkU \n#ูุชุง_ูู_ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/v/12BG5K7FV8K/",
         "323",
         "37",
         "5",
         "0",
         "1",
         "2",
         "9",
         "Djezzy",
         "2024-01-20 00:00:00"
        ],
        [
         "9",
         "10",
         "GOAL Algeria VS Burkina Faso Football ",
         "https://www.facebook.com/watch/?v=1346282365905418&ref=sharing",
         "170",
         "26",
         "1",
         "1",
         "0",
         "4",
         "2",
         "Djezzy",
         "2024-01-20 00:00:00"
        ],
        [
         "10",
         "11",
         "ูุน  PACK 3AYLA ูุชุฑุงุทู ุญุชู Match โฝ  \nุงุณุชูุงุฏ ูู Modem 4G ู 150GO ุงูุชุฑูุช ููุฏุฉ 6 ุฃุดูุฑ ุจ9990ุฏุฌ ๐คฉ\nูุน PACK 3AYLA SUPPORTY \n ูุฑููู ูุน ุนุงููุชู๐ช\nููุฒูุฏ ูู ุงููุนูููุงุช ุฒูุฑูุง ูููุนูุง ๐๐ป\n https://bit.ly/Djezzy-Pack3ayla\n#Djezzy #Match #3ayla",
         "https://www.facebook.com/watch/?v=1387729078503230&ref=sharing",
         "130",
         "8",
         "1",
         "1",
         "1",
         "2",
         "31",
         "Djezzy",
         "2024-01-23 00:00:00"
        ],
        [
         "11",
         "12",
         "ูุน ZUNI SPORT  ุนูู DJEZZY APP ๐ฒ ุชุงุจุน ููุงุนูุฏ ู ูุชุงุฆุฌ ุงููุจุงุฑูุงุช ูุญุธุฉ ุจูุญุธุฉ โฝ ๐ \nุญููู ุงูุชุทุจูู ุงูุขู ๐ https://ms.spr.ly/6181gi6y3\n#Djezzy_App #ZUNI_SPORT #Max_Foot",
         "https://www.facebook.com/share/p/13tcBA3rkg/",
         "189",
         "16",
         "3",
         "0",
         "0",
         "3",
         "11",
         "Djezzy",
         "2024-01-27 00:00:00"
        ],
        [
         "12",
         "13",
         "ุงูููู ูู ุงูููู ุงูุนุงููู ูุญูุงูุฉ ุงูุจูุงูุงุช. ุชุฐููุฑ ุฃุณุงุณู ุจุฃูููุฉ ุงูุญูุงุธ ุนูู ุฎุตูุตูุชู ุนูู ุงูุฅูุชุฑูุช. \nุญูุงูุฉ ุงูุจูุงูุงุช ุชูู ูู ูุงุญุฏ ููุง ๐ป๐ \nAujourd'hui, c'est la Journรฉe Mondiale de la Protection des Donnรฉes. Un rappel essentiel de l'importance de prรฉserver votre vie privรฉe en ligne. La protection des donnรฉes concerne chacun d'entre \nnous๐ป๐ \n#ProtectionDesDonnรฉes #ViePrivรฉeEnLigne #Djezzy",
         "https://www.facebook.com/share/p/15aRgkr5JS/",
         "161",
         "13",
         "2",
         "1",
         "0",
         "1",
         "11",
         "Djezzy",
         "2024-01-28 00:00:00"
        ],
        [
         "13",
         "14",
         "ุงุฎุชุจุฑ ูุนูููุงุชู ูู ูุฑุฉ ุงููุฏู โฝ๏ธ \n ูุญุงูู ุชููุฒ ุจูุณููุฉ ุดุฑุงุก ุจูููุฉ 100 ููููู ุณูุชูู ุฃุณุจูุนูุง ๐ค \nูุง ุนููู ุบูุฑ ุชุญููู DJEZZY APP ๐ฒ ุนูู ุงูุฑุงุจุท  ๐ https://ms.spr.ly/6181gi6y3\n#DJEZZY_APP #DJEZZY_WIN",
         "https://www.facebook.com/share/p/1AzBbfwqh1/",
         "229",
         "22",
         "5",
         "0",
         "0",
         "2",
         "9",
         "Djezzy",
         "2024-01-30 00:00:00"
        ],
        [
         "14",
         "15",
         "ุฃุฎุจุงุฑ ูุญููุฉ ุ ุซูุงููุฉ ุ ุฑูุงุถูุฉ โฝ\nูุน  DJEZZY SCOOP ๐ฃ ููููุชู ุญุชู ุฎุจุฑ ! \n ููุงุดุชุฑุงู ุฅุชุตู ุนูู 404 ุฃู ุฃุฑุณู SMS ุงูู ููุณ ุงูุฑูู\n#Djezzy_Scoop #Max_News",
         "https://www.facebook.com/share/p/13yNkR5JW2/",
         "150",
         "7",
         "0",
         "0",
         "0",
         "1",
         "11",
         "Djezzy",
         "2024-01-31 00:00:00"
        ],
        [
         "15",
         "16",
         "ุดููู ูููู ูุนุฑู Le code ุจุงุด ููุชููู Double Appel ุ\n#ุฌุงุฒู #Astuces_ุณุงููุฉ",
         "https://www.facebook.com/watch/?v=1497445130819223&ref=sharing",
         "325",
         "33",
         "4",
         "0",
         "0",
         "5",
         "6",
         "Djezzy",
         "2024-02-01 00:00:00"
        ],
        [
         "16",
         "17",
         "ูููุงุด ุชุชูุงุฏู ุชููู ุงูุฎุท ุฏูุงูู ๐ค ุ\nุชุงุจุน ุงูุญู ูู ุงูููุฏูู ๐ \n#ุฌุงุฒู #Astuces_ุณุงููุฉ",
         "https://www.facebook.com/watch/?v=408877615031858&rdid=nscweaDh1ie6K7G0",
         "161",
         "18",
         "2",
         "0",
         "0",
         "3",
         "10",
         "Djezzy",
         "2024-02-15 00:00:00"
        ],
        [
         "17",
         "18",
         "ูู ุฑุงููู , ูุงุฐ ุงููุฑุฉ ุนูุงุด ุฌููุง ๐",
         "https://www.facebook.com/share/v/1CVK8AkWr6/",
         "202",
         "24",
         "2",
         "1",
         "0",
         "5",
         "18",
         "Djezzy",
         "2024-02-18 00:00:00"
        ],
        [
         "18",
         "19",
         "ุงูุถููุง ุฅูููุง  ๐ถโ ูู ูุจุงุฏุฑุฉ ุงูุจุณูุฉ WALK for ุ ููุฑุณู ุงูุจุณูุฉ ูุน ุจุนุถ ูู ูู ุฎุทูุฉ.\nุญูููุง  DJEZZY APP ๐ฑ ู ุญูููุง ุฎุทูุงุชูู ุฅูู ุชุจุฑุนุงุช ูููุฉ ุฑูุถุงู  ๐ \nุฑุงุจุท ุงูุชุญููู ๐ https://ms.spr.ly/6181gi6y3\n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉWalk4",
         "https://www.facebook.com/share/p/14kGTVBiaXU/",
         "177",
         "19",
         "3",
         "0",
         "0",
         "13",
         "3",
         "Djezzy",
         "2024-02-19 00:00:00"
        ],
        [
         "19",
         "20",
         "ุจุงุด ููุฑุญู ุงููุงุณ ูู ูุฐุง ุฑูุถุงู ๐ ู ูุฑุณููุง ุงูุจุณูุฉ ุนูู ูุฌูู ุงูุตุงูููู ๐ \nููุง ููุดูุง ูุน ุจุนุถ ู ูุชุจุฑุนูุง ุจุฎุทูุงุชูุง ุนูู DJEZZY APP ๐ฃ ๐ฒ \nุฑุงุจุท ุงูุชุญููู  ๐ https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/19nVrLQmjV/",
         "173",
         "17",
         "5",
         "0",
         "0",
         "0",
         "2",
         "Djezzy",
         "2024-02-20 00:00:00"
        ],
        [
         "20",
         "21",
         "ุดุงุฑู ูู ุชุญุฏู ุงููุดู ๐ถโโ๏ธ ูุน ุตุญุงุจู ู ุณุฌู ุฎุทูุงุชู ูู ููุฏูู ู ุฃูุดุฑูุง ุนูู ุตูุญุชู ุ ุทุงฺจู DJEEZY ูุน ูุงุดุชุงุบ\n #ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉWalk4\nุฃุญุณู ููุฏูู  ุฑุงุญ ูุจุฑุทุงุฌูููุง ุนุจุฑ ุตูุญุชูุง ๐ช \nุฑุงุจุท ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/p/1ESi1iAD8L/",
         "299",
         "34",
         "3",
         "2",
         "1",
         "6",
         "52",
         "Djezzy",
         "2024-02-21 00:00:00"
        ],
        [
         "21",
         "22",
         "ุฎุทูุฉ ุณุงููุฉ ุจููุงุณุจุฉ ุดูุฑ ุฑูุถุงู ุงููุฑูู ๐ \n#ุฌุงุฒู #Astuces_ุณุงููุฉ #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉWalk4",
         "https://www.facebook.com/share/v/19dwGJKfjm/",
         "181",
         "23",
         "3",
         "0",
         "0",
         "4",
         "1",
         "Djezzy",
         "2024-02-22 00:00:00"
        ],
        [
         "22",
         "23",
         "ุทุงฺจู ุตุงุญุจู  ููุดู ุจุงูุฒุฑุจุฉ ๐ถโโ๏ธ ๐โโ๏ธ\n#ุฌุงุฒู  #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉWalk4",
         "https://www.facebook.com/share/p/14KAHkwsXF/",
         "201",
         "23",
         "3",
         "0",
         "2",
         "4",
         "58",
         "Djezzy",
         "2024-02-23 00:00:00"
        ],
        [
         "23",
         "24",
         "ูู ูุงุญุฏ ููุชุจููุง ูู ุงูุชุนูููุงุช ุดุญุงู ูู ุฎุทูุฉ ูุดุงูุง ุนูู Djezzy App ๐ฃ ๐ถโโ๏ธ ๐ฑ \nูุฏุฑู ุดููู ุฑุงุญ ูููู ๐ Le champion  ุ\n #ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉWalk4",
         "https://www.facebook.com/share/p/18BbsUNDKa/",
         "204",
         "18",
         "3",
         "0",
         "0",
         "3",
         "26",
         "Djezzy",
         "2024-02-24 00:00:00"
        ],
        [
         "24",
         "25",
         "ุงูุจุณูุฉ WALK FOR ๐ถโโ๏ธ ูุงุฒุงููุง ูุชูุงุตูุฉ ๐ฃ\n ุทุงฺจู ุตุงุญุจู ูู ูุงุฒุงู ูุงุดุงุฑูุด ูุนุงูุง \n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉWalk4",
         "https://www.facebook.com/share/v/17cPeTM5qo/",
         "111",
         "20",
         "0",
         "0",
         "0",
         "5",
         "9",
         "Djezzy",
         "2024-02-26 00:00:00"
        ],
        [
         "25",
         "26",
         "ูุดุงุฑููุง ูุนุงูู  TOP 10 ุชุน ุงูุจุณูุฉ Walk for\nุฅูุถููุง ุฅูููุงุ ูุงุฒููุง ูุชูุงุตููู ูู ุฃุฌู ุฑุณู ุงูุจุณูุฉ ูุน ุจุนุถ.\n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉWalk4",
         "https://www.facebook.com/share/p/1BYQb7q2cL/",
         "185",
         "17",
         "1",
         "0",
         "0",
         "4",
         "10",
         "Djezzy",
         "2024-02-27 00:00:00"
        ],
        [
         "26",
         "27",
         "๐ถโ ูุจุงุฏุฑุฉ ุงูุจุณูุฉ  WALK for ูุงุฒุงููุง ูุชูุงุตูุฉ  ุ ุฎุทูุงุชูุง ุฑุงุญ ุชูุฑูุญ ุจุฒุงู ูุงุณ \nุญูููุง  DJEZZY APP ๐ฑ ู ุญูููุง ุฎุทูุงุชูู ุฅูู ุชุจุฑุนุงุช ูููุฉ ุฑูุถุงู  ๐ \nุฑุงุจุท ุงูุชุญููู ๐ https://ms.spr.ly/6181gi6y3\n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉWalk4",
         "https://www.facebook.com/share/p/18KCQQmfLL/",
         "228",
         "30",
         "2",
         "0",
         "1",
         "3",
         "6",
         "Djezzy",
         "2024-02-29 00:00:00"
        ],
        [
         "27",
         "28",
         "ู ููุฃุณุจูุน ุงูุซุงูู โ๏ธ ุงูุจุณูุฉ WALK FOR ูุงุฒุงููุง ูุชูุงุตูุฉ ุจูุฌุงุญ ุจูุถู ุฎุทูุงุชูู ๐ฃ\n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/v/12AywsCXXA3/",
         "128",
         "20",
         "0",
         "0",
         "0",
         "2",
         "4",
         "Djezzy",
         "2024-03-04 00:00:00"
        ],
        [
         "28",
         "29",
         "ูุดุงุฑููุง ูุนุงูู   ๐ถโโ๏ธ ๐ฃ The best walkers  ููุฃุณุจูุน ุงูุซุงูู โ๏ธ \nุฅูุถููุง ุฅูููุง ูู ุฃุฌู ุฑุณู ุงูุจุณูุฉ ูุน ุจุนุถ ูู ูุฐุง ุฑูุถุงู \n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉWalk4",
         "https://www.facebook.com/share/p/1Azzo8rf7E/",
         "167",
         "19",
         "0",
         "0",
         "0",
         "1",
         "2",
         "Djezzy",
         "2024-03-06 00:00:00"
        ],
        [
         "29",
         "30",
         "ูุฎุชุชู ูุจุงุฏุฑุฉ ุงูุจุณูุฉ WALK FOR ุจุฃูุซุฑ ูู 821 ููููู ุฎุทูุฉ ๐ช ๐ฃ\nุดูุฑุงู ุนูู ูุดุงุฑูุชูู ู ุฏุนููู ุงููููู ๐ ูุน ุจุนุถ ุตูุนูุง ุงูุจุณูุฉ ๐\n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉWalk4",
         "https://www.facebook.com/watch/?v=3419181848374064&rdid=OpVtNNOSdxW0g2eO",
         "110",
         "23",
         "1",
         "0",
         "0",
         "1",
         "1",
         "Djezzy",
         "2024-03-10 00:00:00"
        ],
        [
         "30",
         "31",
         "ุจุงุด ุชููู ูุดููุฑ ูุงุฒููู ุจุฒูุงู ุงูุชุฑูุช ๐คฉ\nู ุจุงุด ุชููู ุฃุณุทูุฑุฉ ูุงุฒููู DJEZZY LEGEND ๐\nุงูุชุดููุง ุชูุงุตูู ุงูุนุฑุถ ุนูู ๐ https://bit.ly/3uW7xsl",
         "https://www.facebook.com/share/v/15kQvgwaYH/",
         "89",
         "15",
         "2",
         "0",
         "0",
         "1",
         "13",
         "Djezzy",
         "2024-03-11 00:00:00"
        ],
        [
         "31",
         "32",
         "ุญููู DJEZZY APP ู ุดุงุฑู ูู ูุณุงุจูุฉ ุนูุฑุฉ RANATI ูุดุฎุตูู ๐\nุฑุงุจุท ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/18BXF4DAnq/",
         "131",
         "37",
         "0",
         "0",
         "0",
         "0",
         "1",
         "Djezzy",
         "2024-03-11 00:00:00"
        ],
        [
         "32",
         "33",
         "ูุฐุง ุฑูุถุงู ุงููุฑุญุฉ ุฏูุจู ๐X2 ุนูู DJEZZY APP ๐ฑ  \nุฑุงุจุท ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/1FyzpbnWBQ/",
         "106",
         "30",
         "1",
         "1",
         "0",
         "2",
         "0",
         "Djezzy",
         "2024-03-12 00:00:00"
        ],
        [
         "33",
         "34",
         "ูุน DJEZZY APP ุฏูุจูู ูุฑุญุชู ๐คฉ ู ุงูุงูุชุฑูุช ุฏูุงูู โ๏ธ \nุฑุงุจุท ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/17z9TWBMWj/",
         "132",
         "20",
         "2",
         "0",
         "0",
         "2",
         "2",
         "Djezzy",
         "2024-03-13 00:00:00"
        ],
        [
         "34",
         "35",
         "ุจุงุด ุฏูุฑ ูุญุชูู ุฃุณุทูุฑู ูุงุฒููู ุนุฑุถ ุฃุณุทูุฑู ๐ \nุงูุชุดููุง ุงูุชูุงุตูู   ๐ https://ms.spr.ly/6187cis3P\nูุน DJEZZY LEGEND ุงูุช ูู ุงูุฃุณุทูุฑุฉ  ๐",
         "https://www.facebook.com/share/p/1NTLjuLH4q/",
         "179",
         "22",
         "0",
         "1",
         "0",
         "3",
         "31",
         "Djezzy",
         "2024-03-14 00:00:00"
        ],
        [
         "35",
         "36",
         "ูุงูู ููุตููุง  SMS ๐ฒ ุจูู ุฑุจุญูุง ูู ูุณุงุจูุงุช ู ุญูุง ูุงุดุงุฑููุงุด ูููุง !\nูููุงุด ูุชูุงุฏููุง  ุ\n#ุฌุงุฒู #Astuces_ุณุงููุฉ #ุฑูุถุงู2024",
         "https://www.facebook.com/share/v/1Ax3tK3yQf/",
         "71",
         "13",
         "1",
         "0",
         "0",
         "2",
         "0",
         "Djezzy",
         "2024-03-14 00:00:00"
        ],
        [
         "36",
         "37",
         "ุงูุชุฑูุช โ 2  ููุฏุฉ ุฃุณุจูุน !\nุญููู Djezzy App ู ุงุณุชูุชุน ุจ10 ุฌูุบุง ููู ุนุฑุถ ุชุงุน 300 ุฏุฌ \nุฑุงุจุท ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3\n#ุฌุงุฒู #ุฏูุจู_ุฃูุชุฑูุช #ุฑูุถุงู2024_ุฌุงุฒู_APP",
         "https://www.facebook.com/share/v/1QvSNe3qr6/",
         "86",
         "16",
         "2",
         "0",
         "0",
         "8",
         "3",
         "Djezzy",
         "2024-03-17 00:00:00"
        ],
        [
         "37",
         "38",
         "ููููุชู Doubleโ 2 ู ุฃูุฑุญ Doubleโ 2 ูุน ุงูุชุฑูุช  Double โ 2\nุญููู ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3\n#ุฌุงุฒู #ุฏูุจู_ุฃูุชุฑูุช #ุฑูุถุงู2024_ุฌุงุฒู_APP",
         "https://www.facebook.com/share/p/19cMcLv6sd/",
         "139",
         "18",
         "0",
         "0",
         "0",
         "4",
         "2",
         "Djezzy",
         "2024-03-17 00:00:00"
        ],
        [
         "38",
         "39",
         "ูุน ุนุฑุถ ุฌุงุฒู LEGEND MAX ุงูุฌุฏูุฏุ ุงุณุชูุฏ ูู ููุงููุงุช ุบูุฑ ูุญุฏูุฏุฉ ูุญู ุฌููุน ุงูุดุจูุงุช ุงููุทููุฉ ูุญุฏู ุฃูุตู ูู ุงูุงูุชุฑูุช !\nูููุฒูุฏ ูู ุงูุชูุงุตูู : https://ms.spr.ly/6186cUdNk\n#ุฌุงุฒู #ูุชุงููููุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/p/1Gxhnote12/",
         "163",
         "31",
         "1",
         "0",
         "0",
         "2",
         "1",
         "Djezzy",
         "2024-03-22 00:00:00"
        ],
        [
         "39",
         "40",
         "ูุน DJEZZY APP ุฃุจูู ุฏุงููุงู Connectรฉ ุจDouble \n  ุงุณุชูุชุน ุจ10 ุฌูุบุง ููุฏุฉ ุฃุณุจูุน  ุจ300 ุฏุฌ ููุท ! \nุฑุงุจุท ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3\n#ุฌุงุฒู #ุฏูุจู_ุฃูุชุฑูุช #ุฑูุถุงู2024_ุฌุงุฒู_APP",
         "https://www.facebook.com/share/v/19THVFCcWA/",
         "64",
         "18",
         "0",
         "0",
         "0",
         "2",
         "2",
         "Djezzy",
         "2024-03-23 00:00:00"
        ],
        [
         "40",
         "41",
         "\nุนูุฏู LEGEND MAXุ\nBIEN SรR QUE ุงูุช ุงุณุทูุฑุฉ ๐",
         "https://www.facebook.com/share/v/1EZyVsxH3S/",
         "91",
         "20",
         "0",
         "1",
         "0",
         "0",
         "6",
         "Djezzy",
         "2024-03-25 00:00:00"
        ],
        [
         "41",
         "42",
         "ุจุงูุดุฑุงูุฉ ูุน ุงููุดุงูุฉ ุงูุฅุณูุงููุฉ ุงูุฌุฒุงุฆุฑูุฉุ ุฌุงุฒู ุชุดุงุฑููู ุงูุฃุฌูุงุก ุงูุชุถุงูููุฉ ูู ูุทุนู ููุฌ ุงูุงู ูุงูุด ุจุจูุฏูุฉ ุงูุดุฑุงูุฉ.\nุชุชููุฒ ูุฐู ุงููุจุงุฏุฑุฉ ุจูุณุงููุฉ ุงููุดุงููู ูู ูุฎุชูู ุงูุฃุนูุงุฑ  ูู ุงุฏุฎุงู ุงููุฑุญุฉ ูุฑุณู ุงูุจุณูุฉ ุนูู ูุฌูู ุงููุงุตุฏูู ู ุงูุนุงุจุฑูู ูู ูู ููุงู.\nูู ูุฐุง ุฑูุถุงู ูุฑุณูู ุงูุจุณูุฉ  ูุน ุจุนุถ ๐ค \nููุฌ ูฑูุงู ูุงูุด ุงููุดุงูุฉ ุงูุฅุณูุงููุฉ ุงูุฌุฒุงุฆุฑูุฉ \n #ุฌุงุฒู #ูุงุฆุฏุฉ_ุงูุจุณูุฉ #ุงููุดุงูุฉ_ุงูุฅุณูุงููุฉ_ุงูุฌุฒุงุฆุฑูุฉ",
         "https://www.facebook.com/share/v/1Dcy3GKWLV/",
         "65",
         "28",
         "3",
         "0",
         "0",
         "0",
         "0",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "42",
         "43",
         "ุชุงุจุนูุง ุงูุงุญุฏุงุซ ุงููุชููุนุฉ ูู ุญููุฉ ุงูููู ูู ุดุจู ุญุตุฉ 2 ูู ูุฐุง ุฑูุถุงู ๐ \nุดุงูุฏูุง  ุงูุญููุฉ ูุงููุฉ ุนูู ๐  https://youtu.be/iarIxuw3n40\n#ุฌุงุฒู #ุดุจู_ุญุตุฉ2 #ุฑูุถุงู2024",
         "https://www.facebook.com/share/v/196vTS7ztN/",
         "49",
         "17",
         "2",
         "0",
         "0",
         "0",
         "1",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "43",
         "44",
         "ูุน  LEGEND MAX ุงุณุชูุฏ ูู ููุงููุงุช ุบูุฑ ูุญุฏูุฏุฉ ูุญู ุฌููุน ุงูุดุจูุงุช ุงููุทููุฉ ู ุงูMax  ุชุงุน ุงูุงูุชุฑูุช ๐ \nูููุฒูุฏ ูู ุงูุชูุงุตูู : https://ms.spr.ly/6186cUdNk\n#ุฌุงุฒู #ูุชุง_ูู_ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/p/15N1wg8V2N/",
         "133",
         "20",
         "4",
         "2",
         "0",
         "5",
         "4",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "44",
         "45",
         "ูุชููุชุด ุงูุนุฑุถ ูู ูุฐุง ุฑูุถุงู ๐ \nุญููู ุ ุงูุชููู ุ ู ุฏูุจูู โ๏ธ \nูุฐุง ูุงูู ุนูู ๐ https://ms.spr.ly/6181gi6y3\n#ุฌุงุฒู #ุฏูุจู_ุฃูุชุฑูุช #ุฑูุถุงู2024_ุฌุงุฒู_APP",
         "https://www.facebook.com/share/v/19HbnWWpMa/",
         "37",
         "15",
         "1",
         "0",
         "0",
         "4",
         "0",
         "Djezzy",
         "2024-03-28 00:00:00"
        ],
        [
         "45",
         "46",
         "ุชุงุจุนูุง ุญููุฉ ุงูููู ูู ุดุจู ุญุตุฉ ูุน ูุฑุงุฏ ู ุฃุฑูุงู ๐ฌ\nููุดุงูุฏุฉ ุงูุญููุฉ ูุงููุฉ ๐ https://youtu.be/SqxB8u6ui-4",
         "https://www.facebook.com/share/v/1AewF1ZDSN/",
         "35",
         "16",
         "1",
         "0",
         "0",
         "0",
         "0",
         "Djezzy",
         "2024-03-28 00:00:00"
        ],
        [
         "46",
         "47",
         "ุฃูู ุดูุฑ Super Fans ุชุงุนูุง ุุดูุฑุง ุนูู ูุญุจุชูู ู ููุงุฆูู ูููุง ู ุชูุงุนููู ุงูุฏุงุฆู ูุนุงูุง ๐ฅฐ๐๐ป๐\nุตุญ ุณุญูุฑูู ๐",
         "https://www.facebook.com/share/v/15Z5g8V2Cs/",
         "76",
         "33",
         "5",
         "0",
         "0",
         "1",
         "0",
         "Djezzy",
         "2024-03-29 00:00:00"
        ],
        [
         "47",
         "48",
         "ุชุญุจ ุฏูุฑ ุจุฒุงู LES STORIES ุ les REELS ุ Les PHOTOS ุบูุฑ DJEZZY LEGEND ูู ุชุฎุฑุฌ ุนููู , 100 GO ุฅูุชุฑูุช ู ุงูุช ูููู ๐ \nูููุฒูุฏ ูู ุงูุชูุงุตูู : https://ms.spr.ly/6186cUdNk\n#ุฌุงุฒู #ูุชุง_ูู_ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/v/19aWCgdZW3/",
         "133",
         "20",
         "2",
         "0",
         "0",
         "2",
         "7",
         "Djezzy",
         "2024-03-30 00:00:00"
        ],
        [
         "48",
         "49",
         "ูุชููุง ุนุดุงู ุงูุฃูุนุงุจ ุงูุฅููุชุฑูููุฉ ๐ฎ๐น๏ธ ุชุญุจู ุชูุถูู ููุช ุดุจุงุจ ูุนูุงุ๐ฏ \nุฎููุช ูููู  #MobiliStore  ุนูุดูุง ูุชุนุฉ ุงูุฃูุนุงุจ ูููุง  ๐๐๐\n#ููุจูููุณ #ูุนุง_ูุตูุน_ุงููุณุชูุจู",
         "https://www.facebook.com/share/p/18K8JuwacB/",
         "399",
         "38",
         "8",
         "0",
         "0",
         "1",
         "2",
         "Mobilis",
         "2024-01-04 00:00:00"
        ],
        [
         "49",
         "50",
         "ูุฑุนุฉ ุงูุฏูุฑูู ุงูู32 ูุงูู16 ููุฃุณ ุงูุฌุฒุงุฆุฑ ุงูุทุจุนุฉ 59 ๐โฝ๐ฉ๐ฟ\nุชุชุงุจุนูููุง ููู ุงูุฃุญุฏ 7 ุฌุงููู 2024 ุนูู ุงูุณุงุนุฉ 17:30โณ\n#ููุจูููุณ #ุงูุฑุงุนู_ูุงูุดุฑูู_ุงูุฑุณูู_ููุฃุณ_ุงูุฌุฒุงุฆุฑ\n#ูุนุง_ูุตูุน_ุงููุณุชูุจู",
         "https://www.facebook.com/share/p/15Y99MUo3z/",
         "612",
         "61",
         "7",
         "0",
         "0",
         "1",
         "0",
         "Mobilis",
         "2024-01-06 00:00:00"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 183
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Contents</th>\n",
       "      <th>Lien Post</th>\n",
       "      <th>Nb Like</th>\n",
       "      <th>Nb Love</th>\n",
       "      <th>Nb Care</th>\n",
       "      <th>Nb Wow</th>\n",
       "      <th>Nb Sad</th>\n",
       "      <th>Nb Angry</th>\n",
       "      <th>Nb Haha</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ุฌุงุฒู ุชุชูููู ููู ุณูุฉ ุณุนูุฏุฉ๐ฅฐ\\n#DJEZZY #HAPPY_NEW...</td>\n",
       "      <td>https://www.facebook.com/djezzy/posts/78822751...</td>\n",
       "      <td>272</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>14</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ุฑุงู en panne ู ุฎุตู ุฑุตูุฏ ุ\\nูุน ุฎุฏูุฉ Tranquilo ุช...</td>\n",
       "      <td>https://www.facebook.com/watch/?v=106882928102...</td>\n",
       "      <td>255</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>It's Time To be a legend</td>\n",
       "      <td>https://www.facebook.com/djezzy/posts/39256499...</td>\n",
       "      <td>257</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Djezzy vous souhaite Yennayer amervuh!  โดฐโตโตโดปโดณโดฐ...</td>\n",
       "      <td>https://www.facebook.com/share/p/19UDNBoQ1k/</td>\n",
       "      <td>621</td>\n",
       "      <td>231</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ูุฑูุจุงู ...</td>\n",
       "      <td>https://www.facebook.com/share/v/12B9LZySBRe/</td>\n",
       "      <td>288</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>179</td>\n",
       "      <td>ุฅุซุงุฑุฉ ุงูุฃูุนุงุจ ุชุชุนุงุด ูุน ุงูุฃุญุจุงุจุ ุฎุงุตุฉ ูู Ooredo...</td>\n",
       "      <td>https://www.facebook.com/share/p/1KGHZQuXex/</td>\n",
       "      <td>208</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>ูุน Ooredoo ุฏููุง ุฑุงุจุญูู !\\nูุฌูุฏูุง ููู ุญุงุฌุฉ ุฌุฏูุฏ...</td>\n",
       "      <td>https://www.facebook.com/share/v/1Bc7FtdDPx/</td>\n",
       "      <td>625</td>\n",
       "      <td>125</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>ุนุดูุง ูุน ุจุนุถ ุฃุฌูุงุก ุฑูุถุงููุฉ ุฑุงุฆุนุฉ ูู ุฎูุงู ุงูุฅูุทุง...</td>\n",
       "      <td>https://www.facebook.com/reel/954679512980806</td>\n",
       "      <td>280</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>182</td>\n",
       "      <td>ุถุงุนููุง ุงุดุชุฑุงู ุงูุฅูุชุฑูุช ุงูุฎุงุต ุจูู ุฎูุงู ุดูุฑ ุฑูุถุง...</td>\n",
       "      <td>https://www.facebook.com/watch/?v=193245186050...</td>\n",
       "      <td>148</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>183</td>\n",
       "      <td>ุฃูุชู ูู ุนุดุงู ุงูุณูููุง ุงูุนุฑุจูุฉุ ุญููููุง ุงูุชุทุจูู ุด...</td>\n",
       "      <td>https://www.facebook.com/OoredooDZ/posts/44139...</td>\n",
       "      <td>215</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows ร 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                           Contents  \\\n",
       "0      1  ุฌุงุฒู ุชุชูููู ููู ุณูุฉ ุณุนูุฏุฉ๐ฅฐ\\n#DJEZZY #HAPPY_NEW...   \n",
       "1      2  ุฑุงู en panne ู ุฎุตู ุฑุตูุฏ ุ\\nูุน ุฎุฏูุฉ Tranquilo ุช...   \n",
       "2      3                           It's Time To be a legend   \n",
       "3      4  Djezzy vous souhaite Yennayer amervuh!  โดฐโตโตโดปโดณโดฐ...   \n",
       "4      5                                         ูุฑูุจุงู ...   \n",
       "..   ...                                                ...   \n",
       "178  179  ุฅุซุงุฑุฉ ุงูุฃูุนุงุจ ุชุชุนุงุด ูุน ุงูุฃุญุจุงุจุ ุฎุงุตุฉ ูู Ooredo...   \n",
       "179  180  ูุน Ooredoo ุฏููุง ุฑุงุจุญูู !\\nูุฌูุฏูุง ููู ุญุงุฌุฉ ุฌุฏูุฏ...   \n",
       "180  181  ุนุดูุง ูุน ุจุนุถ ุฃุฌูุงุก ุฑูุถุงููุฉ ุฑุงุฆุนุฉ ูู ุฎูุงู ุงูุฅูุทุง...   \n",
       "181  182  ุถุงุนููุง ุงุดุชุฑุงู ุงูุฅูุชุฑูุช ุงูุฎุงุต ุจูู ุฎูุงู ุดูุฑ ุฑูุถุง...   \n",
       "182  183  ุฃูุชู ูู ุนุดุงู ุงูุณูููุง ุงูุนุฑุจูุฉุ ุญููููุง ุงูุชุทุจูู ุด...   \n",
       "\n",
       "                                             Lien Post  Nb Like  Nb Love  \\\n",
       "0    https://www.facebook.com/djezzy/posts/78822751...      272       45   \n",
       "1    https://www.facebook.com/watch/?v=106882928102...      255       28   \n",
       "2    https://www.facebook.com/djezzy/posts/39256499...      257       51   \n",
       "3         https://www.facebook.com/share/p/19UDNBoQ1k/      621      231   \n",
       "4        https://www.facebook.com/share/v/12B9LZySBRe/      288       49   \n",
       "..                                                 ...      ...      ...   \n",
       "178       https://www.facebook.com/share/p/1KGHZQuXex/      208       46   \n",
       "179       https://www.facebook.com/share/v/1Bc7FtdDPx/      625      125   \n",
       "180      https://www.facebook.com/reel/954679512980806      280       40   \n",
       "181  https://www.facebook.com/watch/?v=193245186050...      148       35   \n",
       "182  https://www.facebook.com/OoredooDZ/posts/44139...      215       46   \n",
       "\n",
       "     Nb Care  Nb Wow  Nb Sad  Nb Angry  Nb Haha  Company       Date  \n",
       "0          0       1       1        76       14   Djezzy 2024-01-01  \n",
       "1          0       1       0        12       31   Djezzy 2024-01-04  \n",
       "2          2       0       0         2        8   Djezzy 2024-01-10  \n",
       "3         10       3       0         1      300   Djezzy 2024-01-11  \n",
       "4          4       0       0         3       24   Djezzy 2024-01-12  \n",
       "..       ...     ...     ...       ...      ...      ...        ...  \n",
       "178        6       0       0         0        1  Ooredoo 2024-03-26  \n",
       "179       14       0       1         1        1  Ooredoo 2024-03-27  \n",
       "180        7       1       1         0        0  Ooredoo 2024-03-28  \n",
       "181        3       0       0         2        0  Ooredoo 2024-03-28  \n",
       "182        5       0       0         1        0  Ooredoo 2024-03-30  \n",
       "\n",
       "[183 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger les fichiers Excel\n",
    "posts_df = pd.read_excel('Data/Posts.xlsx')\n",
    "\n",
    "# Afficher DataFrame \"Posts\"\n",
    "posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID Post",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comments",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Sentiments",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6771f1ba-c19e-41a2-ab60-942f17344545",
       "rows": [
        [
         "0",
         "1",
         "Samir Bekhouche",
         null,
         "Neutre"
        ],
        [
         "1",
         "1",
         "Yanise Yanise",
         "ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู ุจุฏุฃุช ุชููุต ุดูู ุดููุง ูู 100 ุฏุฌ ุฅูู 75ุฏุฌ ู ุจุนุฏูุง ุฅูู 50 ุฏุฌ ู ุจุนุฏูุง ุฅูู 25 ุฏุฌ !!!!!!!!!!! ุงูู ุฐูุจุช ูุฒูููุชู ุชุงุนู ุุุุ!!!!!!\n ูู ุฃุชููู ุจูุง ู ูู ุงุชุตู ุจูุง ู ููุณ ูู ุฎุงุตูุฉ ุฑูุชู ุงุฐู ุงูู ุฐูุจ ูุงููุ!ุ!ุ!ุ\n ู ุตุงุฑ ููุณ ุงูุดูุก ูุน ุฃุฎู!!!!!!!!!!!!\n ูุงูุฐุง ูุงุจุฏ ูู ุงุณุชุฑุฌุงุนู",
         "Negatif"
        ],
        [
         "2",
         "1",
         "Jj Kie",
         "ูู ุนุงู ู ุงูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "3",
         "1",
         "Sakou Younes",
         "ูู ุนุงู ูุฃูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "4",
         "1",
         "ุฑุงูู ูุนุงูู",
         "ูู ุนุงู ูุญูุง ุจุฎูุฑ",
         "Positif"
        ],
        [
         "5",
         "1",
         "Wahab Ziadi",
         "ูู ุนุงู ูุญูุง ุจุฎูุฑ",
         "Positif"
        ],
        [
         "6",
         "1",
         "ุฃุญูุฏ ููุฑุงุณ",
         "๐ฅฐ",
         "Positif"
        ],
        [
         "7",
         "1",
         "ูุฑูุงู ุณูุฏูู ุณูุฏูู ูุฑูุงู",
         "ูู ุนุงู ูุฃูุชู ุจุฎูุฑ ูุฃุชููุง ุฑุฏ ุนูุง ุฃุณุฅูุชู ุนูุง ูุญุงุต ููู ุนุงู ูุฃูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "8",
         "1",
         "Mostefa Merabti",
         "Happy New year",
         "Positif"
        ],
        [
         "9",
         "1",
         "ูููุฏ ุจุฑู",
         "ูุงุด ุนุฑูุถ ูุฏู ุฑู ูู 2024",
         "Neutre"
        ],
        [
         "10",
         "1",
         "Aymen Aymen",
         "ุชุญูุง ุฌูุฒู",
         "Positif"
        ],
        [
         "11",
         "1",
         "Maram Akram",
         "Bonne annรฉe ร tous",
         "Positif"
        ],
        [
         "12",
         "1",
         "Plako Platr Ba 13",
         "๐",
         "Neutre"
        ],
        [
         "13",
         "1",
         "Lina Sami",
         "ูููู ูุญูู ุนุฑูุถ ุฌูุฒู ุณุจูุณูุงู ุจุงู ูุฑุฌุนูุง ูุงููุฉ ุจุฒุงู",
         "Neutre"
        ],
        [
         "14",
         "1",
         "Yakoub Boussebsi",
         "ุณูุฉ ุณุนูุฏุฉ ูุฑุฌุนููุง 6h",
         "Positif"
        ],
        [
         "15",
         "1",
         "Hamza Othmani",
         "ุจุฏุงูุฉ ุณูุฉ ุณูุฆุฉ ุฌุฏุงุ ููุฏ ุซู ูุทุน ุฎุทู ุถููุ ู ูุตูุญุฉ ุงูุฒุจุงุฆู ูุง ุชุฑุฏุ ุนูุจ",
         "Negatif"
        ],
        [
         "16",
         "1",
         "RED ROSE",
         "๐น๐น๐น๐น",
         "Positif"
        ],
        [
         "17",
         "1",
         "Mohamed Mellak",
         "ุนุงู ุณุนูุฏ 2024",
         "Positif"
        ],
        [
         "18",
         "1",
         "Naseraddein Hamada",
         null,
         "Neutre"
        ],
        [
         "19",
         "1",
         "Saber Zem",
         "ุฃูุง ูุดุชุฑู ุฏูุน ุจุนุฏู ุชู ุชุฒููุฏู ุจุฎุฏูุฉ chirpix ุฏูู ุนููู ูู 2 ุฏูุณูุจุฑ 2023ุ ูุนูุฏ ุงูุงุทูุงุน ุนูู ูุงุชูุฑุฉ ุดูุฑ ุฌุงููู ูุฌุฏุช ูุจูุบ 740.00 ุฏุฌ ุฒุงุฆุฏ ุนู ุงููุงุชูุฑุฉ ูุนูุฏ ุงูุงุณุชูุณุงุฑ ุนูุฏ ุฎุฏูุฉ ุงูุฒุจุงุฆู ูุงู ุจุณุจุจ chirpixุ ุนููุง ุฃููู ูู ุฃุทูุจ ูุฐู ุงูุฎุฏูุฉ ุฃุจุฏุง ุุุุุุุ",
         "Neutre"
        ],
        [
         "20",
         "1",
         "ุฌูุนูุฉ ุงูุญู ุฃุจูุงุก ุงูุบุฏ ูุนูุงุถุงุช -ูุตุฑ ุงูุฃุจุทุงู-",
         "ูุญูุทูู ุนููุง ุงูุง ูุฑูุชูุง ( ูุฑูุฉ ูุนูุงุถุงุช ) ุงูุชุงุจุนุฉ ูุจูุฏูุฉ ูุตุฑ ุงูุฃุจุทุงู ุฏุงุฆุฑุฉ ุนูู ูููุงู ููุงูุฉ ุณุทูู ุงู ุดุจูุฉ ุงูุงูุชุฑูุช ุฌูุฒู ุชูุนุฏู ุชูุงูุง ูู ูุฑูุชูุง.ูุฑุฌู ูููู ุงูุฌุงุฏ ุญู ููุฐู ุงููุดููุฉ",
         "Negatif"
        ],
        [
         "21",
         "1",
         "Sรm Fรrรh Mehimdร",
         "ูู ูุฑุฉ ุชุณุฑููุง 50ุฏุฌ ุุุุ ุนูุงุด ูุงู ุชุฎูููุง ูุจุฏููุง ุงูุฎุท ๐ฅด๐ฅด๐ฅด",
         "Negatif"
        ],
        [
         "22",
         "1",
         "ลรลรh ลฤhรฏr",
         "ูู ุนุงู ูุงูุชู ุจุงูู ุฎูุฑ โฃ๏ธโฃ๏ธ",
         "Positif"
        ],
        [
         "23",
         "1",
         "Sofiane Sofiane",
         "ุนูุงู ุฏูุชููู 50 ุฏุฌ ูู ูุฑุฉ ุฑุงูู ุฏูุฑููุงูู",
         "Negatif"
        ],
        [
         "24",
         "1",
         "Lamine Jseb",
         "ูุงุด ุจูู ุงูุฑูุฒู ุงููููุุ ูุงูุงุด ุงูุชุฑูุช ููุฐ 3 ุณุงุนุงุช",
         "Negatif"
        ],
        [
         "25",
         "1",
         "ใใฆใณใ ใณใฉใคใ",
         "ุจูุฏ ููุงุณุจุฉ ุชุจุฑุนู ุนูููุง ุจ ุงูุชุฑูุช๐",
         "Neutre"
        ],
        [
         "26",
         "1",
         "Bnamer Boutayeb",
         "ุฑูููู ุงุจูููุงุณูู ูุชุงุนูู",
         "Negatif"
        ],
        [
         "27",
         "1",
         "ใใใ ใฅ ใฅ",
         "ุฏูุฑูููุง ูุด ุญุงุฌุฉ ูุชุน ูููููุณููู",
         "Neutre"
        ],
        [
         "28",
         "1",
         "ูููุด ุณููุฑ",
         "ููุงูุด ูููููุณู ๐๐",
         "Negatif"
        ],
        [
         "29",
         "1",
         "Fati Fati",
         "ูู 2006 ุฑุงูู ูุดุชุงุฑูู ูุนุงูู ูุงุด ููุงุฑ ูุฑุญููุง ุจูุฏูู ๐",
         "Neutre"
        ],
        [
         "30",
         "1",
         "Sofiane Renault Medea",
         "ุจุทูุกุฉ",
         "Negatif"
        ],
        [
         "31",
         "1",
         "Sifadine Mehdi",
         "ุฑูุฒู ูุดุจูู ูุฑูุญ ู ูุฌู ุ",
         "Negatif"
        ],
        [
         "32",
         "1",
         "Aรฑdลeรค Aรฑdลeรค",
         "ููุชุงู ุชุฑุฏูููุง ุฑูุฒู๐คง",
         "Negatif"
        ],
        [
         "33",
         "1",
         "Nabil Issam",
         "ุฑูฺจูููุง ุฑุจ ุฑูุฒู",
         "Negatif"
        ],
        [
         "34",
         "1",
         "Abdo Gros",
         "Malheureusement le rรฉseau รฉtait coupรฉ men 17h ! Hata dok bach wala en plus c'est en niveau d'Alger yahsra les autres wilaya !! Ni excuses ni rien! Mais bon en souhaitant une amรฉlioration cette annรฉe nchlh",
         "Negatif"
        ],
        [
         "36",
         "2",
         "Abdelghani Tahtah",
         "ูุงูู ูู ุงูููุฏ ูุชุงุน ุณูููู ... ุุ",
         "Neutre"
        ],
        [
         "37",
         "2",
         "ุฃุญูุฏ ููุฑุงุณ",
         "ูููุญ",
         "Positif"
        ],
        [
         "38",
         "2",
         "ลล ลล",
         "ูููุงู ูุณูู ุนุดุฑุงูุงู",
         "Neutre"
        ],
        [
         "39",
         "2",
         "Houhou Ben Medani",
         null,
         "Neutre"
        ],
        [
         "40",
         "2",
         "Riad BM",
         "ุดููู ูุจุนุซูู 2 ุฌูุบุง ๐๐",
         "Neutre"
        ],
        [
         "41",
         "2",
         "Amine Boudiaf",
         "ุฑุฌุนููุง ุนุฑูุถ ุงูุชูุงุฒ ูู ูุญูุชููุง ููุง",
         "Negatif"
        ],
        [
         "42",
         "2",
         "ุฒูู ุงูุฏูู ุงุจู ุงูุจูุงุฏู",
         "ุฃูุฏ ูุนุฑูุฉ ููููุฉ ุณุฑูุฉ ุฑุตูุฏู ุ\n ุงูุฑุฌุงุก ุงูุชูุถูุญ \n ูู ุฑูููู ูู ุฌูุฒู ุฏุงุฆูุง ูุง ุงุฌุฏ ุงูุฑุตูุฏ Djezzy",
         "Negatif"
        ],
        [
         "43",
         "2",
         "Amani Amina",
         "ููู ุฑูู ุฎุฏูุฉ ุณููู",
         "Neutre"
        ],
        [
         "44",
         "2",
         "ุงูุนุฑุจู ููุงูู",
         "ูููู ูุนุฑู ุนูุงุด ุชููุตู ูู ุงูุฑุตูุฏ \n ูุงููู ุงูุนุธูู ุนูุจ ุนูุจ ุนูุจ \n ุชููููุณู 50 ุงูู ุบุฏูุฉ ุชููู 20 ุงูู ุนูุจ\n ุญุณุจูุง ุงููู ููุนู ุงููููู.",
         "Negatif"
        ],
        [
         "45",
         "2",
         "Yassine Madrid",
         "ูู ูุถููู ุดุฑูุช ุดุฑูุญุฉ ุฌูุฒู ุฌุฏูุฏุฉ ูููุงู ูุฃูุชููููุง ูุน ุงูุนูู ูููุง 60g ุงูุชุฑูุช ู 7000 ููุงููุงุช",
         "Neutre"
        ],
        [
         "46",
         "2",
         "Aoudjia Aimen",
         "ูุดุจูู ุชุทุจูู ุญุงุจุณ ุงู ุฑููููู ูุฑููููู ุงูุฑูุฒู ุฑุงูุง ูุนุงููู 2024 ูุฑูุฒู ููุช ูู ุญุงูุง ูุงููู ูุง ููููุง ูููููุชุด ุนูุงู ุฑุงูุง ูุงูุนุงูู ุงูุซุงูุซ (ุงูุณุจุจ ุงููุญูุฏ ูุง ุบูุฑู ูู ูุฎูููุง ูุงูุนุงูู ุงูุซุงูุซ ุงูู ููุงุด ุนุงูู ุฑุงุจุน ุงู ุฎุงูุณ)",
         "Negatif"
        ],
        [
         "47",
         "2",
         "ุตุงุญุจุฉ ุงูุณุนุงุฏุฉ",
         "ุนูุงุจููุง ูููุชู ููููููุณูู ุชุฏููู",
         "Negatif"
        ],
        [
         "48",
         "2",
         "ุนุงุฆุดุฉ ุตุฏููุฉ",
         "Djezzy ูู ูุถููู ุฃุฑูุฏ ุชูุทูุน ุงูุดุฑูุญุฉ ูุชูุงุณุจ ุงููุงุชู..ููู ูุฐุง ุบูุฑ ูููู ูุน ุดุฑูุญุชู ุงูุญุงููุฉ ูู ูููู ุงุณุชุจุฏุงููุง ูุน ุฃุฎุฑู ูุงุจูุฉ ูุชูุทูุน ูุน ุดุฑุท ุงูุงุญุชูุงุธ ุจุฑููู ุงูุญุงูู..",
         "Neutre"
        ],
        [
         "49",
         "2",
         "Youcef Mellah",
         "ุฑุงูุง ูุณููู 150 ูุดูุฑ ู ูููููุณููู ุฑุจู ูุฌูุจ ูููู ุชูุถูุญ",
         "Negatif"
        ],
        [
         "50",
         "2",
         "Mar Lyn",
         "ุชุฎุฏูู ุงูุฌูุนุฉ ุ",
         "Neutre"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4104
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Post</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Samir Bekhouche</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yanise Yanise</td>\n",
       "      <td>ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jj Kie</td>\n",
       "      <td>ูู ุนุงู ู ุงูุชู ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sakou Younes</td>\n",
       "      <td>ูู ุนุงู ูุฃูุชู ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ุฑุงูู ูุนุงูู</td>\n",
       "      <td>ูู ุนุงู ูุญูุง ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>183</td>\n",
       "      <td>ฤนรฃ Rรตsรซ รb</td>\n",
       "      <td>โค๏ธโค๏ธ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>183</td>\n",
       "      <td>ูุณูุงุช ูุงุฏุฆุฉ</td>\n",
       "      <td>๐๐๐๐</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>183</td>\n",
       "      <td>ููู ูููุงุด ุบูุฑู</td>\n",
       "      <td>โคโคโคโคโคโค๐น</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>183</td>\n",
       "      <td>ุณุนูุฏู ุฑุถุง</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>183</td>\n",
       "      <td>ุฌูุจูู ููุช ููุช</td>\n",
       "      <td>โค๏ธโค๏ธโค๏ธโค๏ธ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4104 rows ร 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Post        User Name  \\\n",
       "0           1  Samir Bekhouche   \n",
       "1           1    Yanise Yanise   \n",
       "2           1           Jj Kie   \n",
       "3           1     Sakou Younes   \n",
       "4           1       ุฑุงูู ูุนุงูู   \n",
       "...       ...              ...   \n",
       "4124      183       ฤนรฃ Rรตsรซ รb   \n",
       "4125      183      ูุณูุงุช ูุงุฏุฆุฉ   \n",
       "4126      183   ููู ูููุงุด ุบูุฑู   \n",
       "4127      183        ุณุนูุฏู ุฑุถุง   \n",
       "4128      183    ุฌูุจูู ููุช ููุช   \n",
       "\n",
       "                                               Comments Sentiments  \n",
       "0                                                   NaN     Neutre  \n",
       "1     ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู...    Negatif  \n",
       "2                                    ูู ุนุงู ู ุงูุชู ุจุฎูุฑ    Positif  \n",
       "3                                     ูู ุนุงู ูุฃูุชู ุจุฎูุฑ    Positif  \n",
       "4                                      ูู ุนุงู ูุญูุง ุจุฎูุฑ    Positif  \n",
       "...                                                 ...        ...  \n",
       "4124                                               โค๏ธโค๏ธ    Positif  \n",
       "4125                                               ๐๐๐๐    Positif  \n",
       "4126                                            โคโคโคโคโคโค๐น    Positif  \n",
       "4127                                                NaN     Neutre  \n",
       "4128                                           โค๏ธโค๏ธโค๏ธโค๏ธ    Positif  \n",
       "\n",
       "[4104 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppression des lignes oรน \"User Name\" est \"Djezzy\", \"Mobilis\" ou \"Ooredoo\"\n",
    "comments_df = comments_df[~comments_df[\"User Name\"].isin([\"Djezzy\", \"Mobilis\", \"Ooredoo Algรฉrie\"])]\n",
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID Post",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comments",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiments",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "36b6352d-9b75-4bf4-a9c5-92ba458e7589",
       "rows": [
        [
         "1",
         "1",
         "Yanise Yanise",
         "ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู ุจุฏุฃุช ุชููุต ุดูู ุดููุง ูู 100 ุฏุฌ ุฅูู 75ุฏุฌ ู ุจุนุฏูุง ุฅูู 50 ุฏุฌ ู ุจุนุฏูุง ุฅูู 25 ุฏุฌ !!!!!!!!!!! ุงูู ุฐูุจุช ูุฒูููุชู ุชุงุนู ุุุุ!!!!!!\n ูู ุฃุชููู ุจูุง ู ูู ุงุชุตู ุจูุง ู ููุณ ูู ุฎุงุตูุฉ ุฑูุชู ุงุฐู ุงูู ุฐูุจ ูุงููุ!ุ!ุ!ุ\n ู ุตุงุฑ ููุณ ุงูุดูุก ูุน ุฃุฎู!!!!!!!!!!!!\n ูุงูุฐุง ูุงุจุฏ ูู ุงุณุชุฑุฌุงุนู",
         "Negatif"
        ],
        [
         "2",
         "1",
         "Jj Kie",
         "ูู ุนุงู ู ุงูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "3",
         "1",
         "Sakou Younes",
         "ูู ุนุงู ูุฃูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "4",
         "1",
         "ุฑุงูู ูุนุงูู",
         "ูู ุนุงู ูุญูุง ุจุฎูุฑ",
         "Positif"
        ],
        [
         "5",
         "1",
         "Wahab Ziadi",
         "ูู ุนุงู ูุญูุง ุจุฎูุฑ",
         "Positif"
        ],
        [
         "6",
         "1",
         "ุฃุญูุฏ ููุฑุงุณ",
         "๐ฅฐ",
         "Positif"
        ],
        [
         "7",
         "1",
         "ูุฑูุงู ุณูุฏูู ุณูุฏูู ูุฑูุงู",
         "ูู ุนุงู ูุฃูุชู ุจุฎูุฑ ูุฃุชููุง ุฑุฏ ุนูุง ุฃุณุฅูุชู ุนูุง ูุญุงุต ููู ุนุงู ูุฃูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "8",
         "1",
         "Mostefa Merabti",
         "Happy New year",
         "Positif"
        ],
        [
         "9",
         "1",
         "ูููุฏ ุจุฑู",
         "ูุงุด ุนุฑูุถ ูุฏู ุฑู ูู 2024",
         "Neutre"
        ],
        [
         "10",
         "1",
         "Aymen Aymen",
         "ุชุญูุง ุฌูุฒู",
         "Positif"
        ],
        [
         "11",
         "1",
         "Maram Akram",
         "Bonne annรฉe ร tous",
         "Positif"
        ],
        [
         "12",
         "1",
         "Plako Platr Ba 13",
         "๐",
         "Neutre"
        ],
        [
         "13",
         "1",
         "Lina Sami",
         "ูููู ูุญูู ุนุฑูุถ ุฌูุฒู ุณุจูุณูุงู ุจุงู ูุฑุฌุนูุง ูุงููุฉ ุจุฒุงู",
         "Neutre"
        ],
        [
         "14",
         "1",
         "Yakoub Boussebsi",
         "ุณูุฉ ุณุนูุฏุฉ ูุฑุฌุนููุง 6h",
         "Positif"
        ],
        [
         "15",
         "1",
         "Hamza Othmani",
         "ุจุฏุงูุฉ ุณูุฉ ุณูุฆุฉ ุฌุฏุงุ ููุฏ ุซู ูุทุน ุฎุทู ุถููุ ู ูุตูุญุฉ ุงูุฒุจุงุฆู ูุง ุชุฑุฏุ ุนูุจ",
         "Negatif"
        ],
        [
         "16",
         "1",
         "RED ROSE",
         "๐น๐น๐น๐น",
         "Positif"
        ],
        [
         "17",
         "1",
         "Mohamed Mellak",
         "ุนุงู ุณุนูุฏ 2024",
         "Positif"
        ],
        [
         "19",
         "1",
         "Saber Zem",
         "ุฃูุง ูุดุชุฑู ุฏูุน ุจุนุฏู ุชู ุชุฒููุฏู ุจุฎุฏูุฉ chirpix ุฏูู ุนููู ูู 2 ุฏูุณูุจุฑ 2023ุ ูุนูุฏ ุงูุงุทูุงุน ุนูู ูุงุชูุฑุฉ ุดูุฑ ุฌุงููู ูุฌุฏุช ูุจูุบ 740.00 ุฏุฌ ุฒุงุฆุฏ ุนู ุงููุงุชูุฑุฉ ูุนูุฏ ุงูุงุณุชูุณุงุฑ ุนูุฏ ุฎุฏูุฉ ุงูุฒุจุงุฆู ูุงู ุจุณุจุจ chirpixุ ุนููุง ุฃููู ูู ุฃุทูุจ ูุฐู ุงูุฎุฏูุฉ ุฃุจุฏุง ุุุุุุุ",
         "Neutre"
        ],
        [
         "20",
         "1",
         "ุฌูุนูุฉ ุงูุญู ุฃุจูุงุก ุงูุบุฏ ูุนูุงุถุงุช -ูุตุฑ ุงูุฃุจุทุงู-",
         "ูุญูุทูู ุนููุง ุงูุง ูุฑูุชูุง ( ูุฑูุฉ ูุนูุงุถุงุช ) ุงูุชุงุจุนุฉ ูุจูุฏูุฉ ูุตุฑ ุงูุฃุจุทุงู ุฏุงุฆุฑุฉ ุนูู ูููุงู ููุงูุฉ ุณุทูู ุงู ุดุจูุฉ ุงูุงูุชุฑูุช ุฌูุฒู ุชูุนุฏู ุชูุงูุง ูู ูุฑูุชูุง.ูุฑุฌู ูููู ุงูุฌุงุฏ ุญู ููุฐู ุงููุดููุฉ",
         "Negatif"
        ],
        [
         "21",
         "1",
         "Sรm Fรrรh Mehimdร",
         "ูู ูุฑุฉ ุชุณุฑููุง 50ุฏุฌ ุุุุ ุนูุงุด ูุงู ุชุฎูููุง ูุจุฏููุง ุงูุฎุท ๐ฅด๐ฅด๐ฅด",
         "Negatif"
        ],
        [
         "22",
         "1",
         "ลรลรh ลฤhรฏr",
         "ูู ุนุงู ูุงูุชู ุจุงูู ุฎูุฑ โฃ๏ธโฃ๏ธ",
         "Positif"
        ],
        [
         "23",
         "1",
         "Sofiane Sofiane",
         "ุนูุงู ุฏูุชููู 50 ุฏุฌ ูู ูุฑุฉ ุฑุงูู ุฏูุฑููุงูู",
         "Negatif"
        ],
        [
         "24",
         "1",
         "Lamine Jseb",
         "ูุงุด ุจูู ุงูุฑูุฒู ุงููููุุ ูุงูุงุด ุงูุชุฑูุช ููุฐ 3 ุณุงุนุงุช",
         "Negatif"
        ],
        [
         "25",
         "1",
         "ใใฆใณใ ใณใฉใคใ",
         "ุจูุฏ ููุงุณุจุฉ ุชุจุฑุนู ุนูููุง ุจ ุงูุชุฑูุช๐",
         "Neutre"
        ],
        [
         "26",
         "1",
         "Bnamer Boutayeb",
         "ุฑูููู ุงุจูููุงุณูู ูุชุงุนูู",
         "Negatif"
        ],
        [
         "27",
         "1",
         "ใใใ ใฅ ใฅ",
         "ุฏูุฑูููุง ูุด ุญุงุฌุฉ ูุชุน ูููููุณููู",
         "Neutre"
        ],
        [
         "28",
         "1",
         "ูููุด ุณููุฑ",
         "ููุงูุด ูููููุณู ๐๐",
         "Negatif"
        ],
        [
         "29",
         "1",
         "Fati Fati",
         "ูู 2006 ุฑุงูู ูุดุชุงุฑูู ูุนุงูู ูุงุด ููุงุฑ ูุฑุญููุง ุจูุฏูู ๐",
         "Neutre"
        ],
        [
         "30",
         "1",
         "Sofiane Renault Medea",
         "ุจุทูุกุฉ",
         "Negatif"
        ],
        [
         "31",
         "1",
         "Sifadine Mehdi",
         "ุฑูุฒู ูุดุจูู ูุฑูุญ ู ูุฌู ุ",
         "Negatif"
        ],
        [
         "32",
         "1",
         "Aรฑdลeรค Aรฑdลeรค",
         "ููุชุงู ุชุฑุฏูููุง ุฑูุฒู๐คง",
         "Negatif"
        ],
        [
         "33",
         "1",
         "Nabil Issam",
         "ุฑูฺจูููุง ุฑุจ ุฑูุฒู",
         "Negatif"
        ],
        [
         "34",
         "1",
         "Abdo Gros",
         "Malheureusement le rรฉseau รฉtait coupรฉ men 17h ! Hata dok bach wala en plus c'est en niveau d'Alger yahsra les autres wilaya !! Ni excuses ni rien! Mais bon en souhaitant une amรฉlioration cette annรฉe nchlh",
         "Negatif"
        ],
        [
         "36",
         "2",
         "Abdelghani Tahtah",
         "ูุงูู ูู ุงูููุฏ ูุชุงุน ุณูููู ... ุุ",
         "Neutre"
        ],
        [
         "37",
         "2",
         "ุฃุญูุฏ ููุฑุงุณ",
         "ูููุญ",
         "Positif"
        ],
        [
         "38",
         "2",
         "ลล ลล",
         "ูููุงู ูุณูู ุนุดุฑุงูุงู",
         "Neutre"
        ],
        [
         "40",
         "2",
         "Riad BM",
         "ุดููู ูุจุนุซูู 2 ุฌูุบุง ๐๐",
         "Neutre"
        ],
        [
         "41",
         "2",
         "Amine Boudiaf",
         "ุฑุฌุนููุง ุนุฑูุถ ุงูุชูุงุฒ ูู ูุญูุชููุง ููุง",
         "Negatif"
        ],
        [
         "42",
         "2",
         "ุฒูู ุงูุฏูู ุงุจู ุงูุจูุงุฏู",
         "ุฃูุฏ ูุนุฑูุฉ ููููุฉ ุณุฑูุฉ ุฑุตูุฏู ุ\n ุงูุฑุฌุงุก ุงูุชูุถูุญ \n ูู ุฑูููู ูู ุฌูุฒู ุฏุงุฆูุง ูุง ุงุฌุฏ ุงูุฑุตูุฏ Djezzy",
         "Negatif"
        ],
        [
         "43",
         "2",
         "Amani Amina",
         "ููู ุฑูู ุฎุฏูุฉ ุณููู",
         "Neutre"
        ],
        [
         "44",
         "2",
         "ุงูุนุฑุจู ููุงูู",
         "ูููู ูุนุฑู ุนูุงุด ุชููุตู ูู ุงูุฑุตูุฏ \n ูุงููู ุงูุนุธูู ุนูุจ ุนูุจ ุนูุจ \n ุชููููุณู 50 ุงูู ุบุฏูุฉ ุชููู 20 ุงูู ุนูุจ\n ุญุณุจูุง ุงููู ููุนู ุงููููู.",
         "Negatif"
        ],
        [
         "45",
         "2",
         "Yassine Madrid",
         "ูู ูุถููู ุดุฑูุช ุดุฑูุญุฉ ุฌูุฒู ุฌุฏูุฏุฉ ูููุงู ูุฃูุชููููุง ูุน ุงูุนูู ูููุง 60g ุงูุชุฑูุช ู 7000 ููุงููุงุช",
         "Neutre"
        ],
        [
         "46",
         "2",
         "Aoudjia Aimen",
         "ูุดุจูู ุชุทุจูู ุญุงุจุณ ุงู ุฑููููู ูุฑููููู ุงูุฑูุฒู ุฑุงูุง ูุนุงููู 2024 ูุฑูุฒู ููุช ูู ุญุงูุง ูุงููู ูุง ููููุง ูููููุชุด ุนูุงู ุฑุงูุง ูุงูุนุงูู ุงูุซุงูุซ (ุงูุณุจุจ ุงููุญูุฏ ูุง ุบูุฑู ูู ูุฎูููุง ูุงูุนุงูู ุงูุซุงูุซ ุงูู ููุงุด ุนุงูู ุฑุงุจุน ุงู ุฎุงูุณ)",
         "Negatif"
        ],
        [
         "47",
         "2",
         "ุตุงุญุจุฉ ุงูุณุนุงุฏุฉ",
         "ุนูุงุจููุง ูููุชู ููููููุณูู ุชุฏููู",
         "Negatif"
        ],
        [
         "48",
         "2",
         "ุนุงุฆุดุฉ ุตุฏููุฉ",
         "Djezzy ูู ูุถููู ุฃุฑูุฏ ุชูุทูุน ุงูุดุฑูุญุฉ ูุชูุงุณุจ ุงููุงุชู..ููู ูุฐุง ุบูุฑ ูููู ูุน ุดุฑูุญุชู ุงูุญุงููุฉ ูู ูููู ุงุณุชุจุฏุงููุง ูุน ุฃุฎุฑู ูุงุจูุฉ ูุชูุทูุน ูุน ุดุฑุท ุงูุงุญุชูุงุธ ุจุฑููู ุงูุญุงูู..",
         "Neutre"
        ],
        [
         "49",
         "2",
         "Youcef Mellah",
         "ุฑุงูุง ูุณููู 150 ูุดูุฑ ู ูููููุณููู ุฑุจู ูุฌูุจ ูููู ุชูุถูุญ",
         "Negatif"
        ],
        [
         "50",
         "2",
         "Mar Lyn",
         "ุชุฎุฏูู ุงูุฌูุนุฉ ุ",
         "Neutre"
        ],
        [
         "51",
         "2",
         "Oussama Chabane",
         "ุงูุญู",
         "Neutre"
        ],
        [
         "52",
         "2",
         "Sifoune Soufyane",
         "ูู ุงูุฑูู 455 ุฎุงุต ุจูู ูููุงุฐุง ูุชุตู ุจู",
         "Neutre"
        ],
        [
         "53",
         "2",
         "Mohamed Rakmouche",
         "ุทุฑููุฉ ูููุณู ูู ุฌูุฒู ุงูู ุฌูุฒู",
         "Neutre"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3924
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Post</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yanise Yanise</td>\n",
       "      <td>ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jj Kie</td>\n",
       "      <td>ูู ุนุงู ู ุงูุชู ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sakou Younes</td>\n",
       "      <td>ูู ุนุงู ูุฃูุชู ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ุฑุงูู ูุนุงูู</td>\n",
       "      <td>ูู ุนุงู ูุญูุง ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Wahab Ziadi</td>\n",
       "      <td>ูู ุนุงู ูุญูุง ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>183</td>\n",
       "      <td>ูุฑ ุณููู '</td>\n",
       "      <td>๐ฉท๐ฉท๐ฉท๐ฉท๐ฉท๐ฉท</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>183</td>\n",
       "      <td>ฤนรฃ Rรตsรซ รb</td>\n",
       "      <td>โค๏ธโค๏ธ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>183</td>\n",
       "      <td>ูุณูุงุช ูุงุฏุฆุฉ</td>\n",
       "      <td>๐๐๐๐</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>183</td>\n",
       "      <td>ููู ูููุงุด ุบูุฑู</td>\n",
       "      <td>โคโคโคโคโคโค๐น</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>183</td>\n",
       "      <td>ุฌูุจูู ููุช ููุช</td>\n",
       "      <td>โค๏ธโค๏ธโค๏ธโค๏ธ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3924 rows ร 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Post       User Name  \\\n",
       "1           1   Yanise Yanise   \n",
       "2           1          Jj Kie   \n",
       "3           1    Sakou Younes   \n",
       "4           1      ุฑุงูู ูุนุงูู   \n",
       "5           1     Wahab Ziadi   \n",
       "...       ...             ...   \n",
       "4123      183      ูุฑ ุณููู '   \n",
       "4124      183      ฤนรฃ Rรตsรซ รb   \n",
       "4125      183     ูุณูุงุช ูุงุฏุฆุฉ   \n",
       "4126      183  ููู ูููุงุด ุบูุฑู   \n",
       "4128      183   ุฌูุจูู ููุช ููุช   \n",
       "\n",
       "                                               Comments Sentiments  \n",
       "1     ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู...    Negatif  \n",
       "2                                    ูู ุนุงู ู ุงูุชู ุจุฎูุฑ    Positif  \n",
       "3                                     ูู ุนุงู ูุฃูุชู ุจุฎูุฑ    Positif  \n",
       "4                                      ูู ุนุงู ูุญูุง ุจุฎูุฑ    Positif  \n",
       "5                                      ูู ุนุงู ูุญูุง ุจุฎูุฑ    Positif  \n",
       "...                                                 ...        ...  \n",
       "4123                                             ๐ฉท๐ฉท๐ฉท๐ฉท๐ฉท๐ฉท    Positif  \n",
       "4124                                               โค๏ธโค๏ธ    Positif  \n",
       "4125                                               ๐๐๐๐    Positif  \n",
       "4126                                            โคโคโคโคโคโค๐น    Positif  \n",
       "4128                                           โค๏ธโค๏ธโค๏ธโค๏ธ    Positif  \n",
       "\n",
       "[3924 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = comments_df.dropna(subset=[\"Comments\"])\n",
    "comments_df = comments_df[comments_df[\"Comments\"].str.strip() != \"\"]\n",
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID Post",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comments",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiments",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1d8b1ba0-3669-40f2-8fb2-38ef9a5a96d5",
       "rows": [
        [
         "1",
         "1",
         "Yanise Yanise",
         "ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู ุจุฏุฃุช ุชููุต ุดูู ุดููุง ูู 100 ุฏุฌ ุฅูู 75ุฏุฌ ู ุจุนุฏูุง ุฅูู 50 ุฏุฌ ู ุจุนุฏูุง ุฅูู 25 ุฏุฌ !!!!!!!!!!! ุงูู ุฐูุจุช ูุฒูููุชู ุชุงุนู ุุุุ!!!!!!\n ูู ุฃุชููู ุจูุง ู ูู ุงุชุตู ุจูุง ู ููุณ ูู ุฎุงุตูุฉ ุฑูุชู ุงุฐู ุงูู ุฐูุจ ูุงููุ!ุ!ุ!ุ\n ู ุตุงุฑ ููุณ ุงูุดูุก ูุน ุฃุฎู!!!!!!!!!!!!\n ูุงูุฐุง ูุงุจุฏ ูู ุงุณุชุฑุฌุงุนู",
         "Negatif"
        ],
        [
         "2",
         "1",
         "Jj Kie",
         "ูู ุนุงู ู ุงูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "3",
         "1",
         "Sakou Younes",
         "ูู ุนุงู ูุฃูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "4",
         "1",
         "ุฑุงูู ูุนุงูู",
         "ูู ุนุงู ูุญูุง ุจุฎูุฑ",
         "Positif"
        ],
        [
         "6",
         "1",
         "ุฃุญูุฏ ููุฑุงุณ",
         "๐ฅฐ",
         "Positif"
        ],
        [
         "7",
         "1",
         "ูุฑูุงู ุณูุฏูู ุณูุฏูู ูุฑูุงู",
         "ูู ุนุงู ูุฃูุชู ุจุฎูุฑ ูุฃุชููุง ุฑุฏ ุนูุง ุฃุณุฅูุชู ุนูุง ูุญุงุต ููู ุนุงู ูุฃูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "8",
         "1",
         "Mostefa Merabti",
         "Happy New year",
         "Positif"
        ],
        [
         "9",
         "1",
         "ูููุฏ ุจุฑู",
         "ูุงุด ุนุฑูุถ ูุฏู ุฑู ูู 2024",
         "Neutre"
        ],
        [
         "10",
         "1",
         "Aymen Aymen",
         "ุชุญูุง ุฌูุฒู",
         "Positif"
        ],
        [
         "11",
         "1",
         "Maram Akram",
         "Bonne annรฉe ร tous",
         "Positif"
        ],
        [
         "12",
         "1",
         "Plako Platr Ba 13",
         "๐",
         "Neutre"
        ],
        [
         "13",
         "1",
         "Lina Sami",
         "ูููู ูุญูู ุนุฑูุถ ุฌูุฒู ุณุจูุณูุงู ุจุงู ูุฑุฌุนูุง ูุงููุฉ ุจุฒุงู",
         "Neutre"
        ],
        [
         "14",
         "1",
         "Yakoub Boussebsi",
         "ุณูุฉ ุณุนูุฏุฉ ูุฑุฌุนููุง 6h",
         "Positif"
        ],
        [
         "15",
         "1",
         "Hamza Othmani",
         "ุจุฏุงูุฉ ุณูุฉ ุณูุฆุฉ ุฌุฏุงุ ููุฏ ุซู ูุทุน ุฎุทู ุถููุ ู ูุตูุญุฉ ุงูุฒุจุงุฆู ูุง ุชุฑุฏุ ุนูุจ",
         "Negatif"
        ],
        [
         "16",
         "1",
         "RED ROSE",
         "๐น๐น๐น๐น",
         "Positif"
        ],
        [
         "17",
         "1",
         "Mohamed Mellak",
         "ุนุงู ุณุนูุฏ 2024",
         "Positif"
        ],
        [
         "19",
         "1",
         "Saber Zem",
         "ุฃูุง ูุดุชุฑู ุฏูุน ุจุนุฏู ุชู ุชุฒููุฏู ุจุฎุฏูุฉ chirpix ุฏูู ุนููู ูู 2 ุฏูุณูุจุฑ 2023ุ ูุนูุฏ ุงูุงุทูุงุน ุนูู ูุงุชูุฑุฉ ุดูุฑ ุฌุงููู ูุฌุฏุช ูุจูุบ 740.00 ุฏุฌ ุฒุงุฆุฏ ุนู ุงููุงุชูุฑุฉ ูุนูุฏ ุงูุงุณุชูุณุงุฑ ุนูุฏ ุฎุฏูุฉ ุงูุฒุจุงุฆู ูุงู ุจุณุจุจ chirpixุ ุนููุง ุฃููู ูู ุฃุทูุจ ูุฐู ุงูุฎุฏูุฉ ุฃุจุฏุง ุุุุุุุ",
         "Neutre"
        ],
        [
         "20",
         "1",
         "ุฌูุนูุฉ ุงูุญู ุฃุจูุงุก ุงูุบุฏ ูุนูุงุถุงุช -ูุตุฑ ุงูุฃุจุทุงู-",
         "ูุญูุทูู ุนููุง ุงูุง ูุฑูุชูุง ( ูุฑูุฉ ูุนูุงุถุงุช ) ุงูุชุงุจุนุฉ ูุจูุฏูุฉ ูุตุฑ ุงูุฃุจุทุงู ุฏุงุฆุฑุฉ ุนูู ูููุงู ููุงูุฉ ุณุทูู ุงู ุดุจูุฉ ุงูุงูุชุฑูุช ุฌูุฒู ุชูุนุฏู ุชูุงูุง ูู ูุฑูุชูุง.ูุฑุฌู ูููู ุงูุฌุงุฏ ุญู ููุฐู ุงููุดููุฉ",
         "Negatif"
        ],
        [
         "21",
         "1",
         "Sรm Fรrรh Mehimdร",
         "ูู ูุฑุฉ ุชุณุฑููุง 50ุฏุฌ ุุุุ ุนูุงุด ูุงู ุชุฎูููุง ูุจุฏููุง ุงูุฎุท ๐ฅด๐ฅด๐ฅด",
         "Negatif"
        ],
        [
         "22",
         "1",
         "ลรลรh ลฤhรฏr",
         "ูู ุนุงู ูุงูุชู ุจุงูู ุฎูุฑ โฃ๏ธโฃ๏ธ",
         "Positif"
        ],
        [
         "23",
         "1",
         "Sofiane Sofiane",
         "ุนูุงู ุฏูุชููู 50 ุฏุฌ ูู ูุฑุฉ ุฑุงูู ุฏูุฑููุงูู",
         "Negatif"
        ],
        [
         "24",
         "1",
         "Lamine Jseb",
         "ูุงุด ุจูู ุงูุฑูุฒู ุงููููุุ ูุงูุงุด ุงูุชุฑูุช ููุฐ 3 ุณุงุนุงุช",
         "Negatif"
        ],
        [
         "25",
         "1",
         "ใใฆใณใ ใณใฉใคใ",
         "ุจูุฏ ููุงุณุจุฉ ุชุจุฑุนู ุนูููุง ุจ ุงูุชุฑูุช๐",
         "Neutre"
        ],
        [
         "26",
         "1",
         "Bnamer Boutayeb",
         "ุฑูููู ุงุจูููุงุณูู ูุชุงุนูู",
         "Negatif"
        ],
        [
         "27",
         "1",
         "ใใใ ใฅ ใฅ",
         "ุฏูุฑูููุง ูุด ุญุงุฌุฉ ูุชุน ูููููุณููู",
         "Neutre"
        ],
        [
         "28",
         "1",
         "ูููุด ุณููุฑ",
         "ููุงูุด ูููููุณู ๐๐",
         "Negatif"
        ],
        [
         "29",
         "1",
         "Fati Fati",
         "ูู 2006 ุฑุงูู ูุดุชุงุฑูู ูุนุงูู ูุงุด ููุงุฑ ูุฑุญููุง ุจูุฏูู ๐",
         "Neutre"
        ],
        [
         "30",
         "1",
         "Sofiane Renault Medea",
         "ุจุทูุกุฉ",
         "Negatif"
        ],
        [
         "31",
         "1",
         "Sifadine Mehdi",
         "ุฑูุฒู ูุดุจูู ูุฑูุญ ู ูุฌู ุ",
         "Negatif"
        ],
        [
         "32",
         "1",
         "Aรฑdลeรค Aรฑdลeรค",
         "ููุชุงู ุชุฑุฏูููุง ุฑูุฒู๐คง",
         "Negatif"
        ],
        [
         "33",
         "1",
         "Nabil Issam",
         "ุฑูฺจูููุง ุฑุจ ุฑูุฒู",
         "Negatif"
        ],
        [
         "34",
         "1",
         "Abdo Gros",
         "Malheureusement le rรฉseau รฉtait coupรฉ men 17h ! Hata dok bach wala en plus c'est en niveau d'Alger yahsra les autres wilaya !! Ni excuses ni rien! Mais bon en souhaitant une amรฉlioration cette annรฉe nchlh",
         "Negatif"
        ],
        [
         "36",
         "2",
         "Abdelghani Tahtah",
         "ูุงูู ูู ุงูููุฏ ูุชุงุน ุณูููู ... ุุ",
         "Neutre"
        ],
        [
         "37",
         "2",
         "ุฃุญูุฏ ููุฑุงุณ",
         "ูููุญ",
         "Positif"
        ],
        [
         "38",
         "2",
         "ลล ลล",
         "ูููุงู ูุณูู ุนุดุฑุงูุงู",
         "Neutre"
        ],
        [
         "40",
         "2",
         "Riad BM",
         "ุดููู ูุจุนุซูู 2 ุฌูุบุง ๐๐",
         "Neutre"
        ],
        [
         "41",
         "2",
         "Amine Boudiaf",
         "ุฑุฌุนููุง ุนุฑูุถ ุงูุชูุงุฒ ูู ูุญูุชููุง ููุง",
         "Negatif"
        ],
        [
         "42",
         "2",
         "ุฒูู ุงูุฏูู ุงุจู ุงูุจูุงุฏู",
         "ุฃูุฏ ูุนุฑูุฉ ููููุฉ ุณุฑูุฉ ุฑุตูุฏู ุ\n ุงูุฑุฌุงุก ุงูุชูุถูุญ \n ูู ุฑูููู ูู ุฌูุฒู ุฏุงุฆูุง ูุง ุงุฌุฏ ุงูุฑุตูุฏ Djezzy",
         "Negatif"
        ],
        [
         "43",
         "2",
         "Amani Amina",
         "ููู ุฑูู ุฎุฏูุฉ ุณููู",
         "Neutre"
        ],
        [
         "44",
         "2",
         "ุงูุนุฑุจู ููุงูู",
         "ูููู ูุนุฑู ุนูุงุด ุชููุตู ูู ุงูุฑุตูุฏ \n ูุงููู ุงูุนุธูู ุนูุจ ุนูุจ ุนูุจ \n ุชููููุณู 50 ุงูู ุบุฏูุฉ ุชููู 20 ุงูู ุนูุจ\n ุญุณุจูุง ุงููู ููุนู ุงููููู.",
         "Negatif"
        ],
        [
         "45",
         "2",
         "Yassine Madrid",
         "ูู ูุถููู ุดุฑูุช ุดุฑูุญุฉ ุฌูุฒู ุฌุฏูุฏุฉ ูููุงู ูุฃูุชููููุง ูุน ุงูุนูู ูููุง 60g ุงูุชุฑูุช ู 7000 ููุงููุงุช",
         "Neutre"
        ],
        [
         "46",
         "2",
         "Aoudjia Aimen",
         "ูุดุจูู ุชุทุจูู ุญุงุจุณ ุงู ุฑููููู ูุฑููููู ุงูุฑูุฒู ุฑุงูุง ูุนุงููู 2024 ูุฑูุฒู ููุช ูู ุญุงูุง ูุงููู ูุง ููููุง ูููููุชุด ุนูุงู ุฑุงูุง ูุงูุนุงูู ุงูุซุงูุซ (ุงูุณุจุจ ุงููุญูุฏ ูุง ุบูุฑู ูู ูุฎูููุง ูุงูุนุงูู ุงูุซุงูุซ ุงูู ููุงุด ุนุงูู ุฑุงุจุน ุงู ุฎุงูุณ)",
         "Negatif"
        ],
        [
         "47",
         "2",
         "ุตุงุญุจุฉ ุงูุณุนุงุฏุฉ",
         "ุนูุงุจููุง ูููุชู ููููููุณูู ุชุฏููู",
         "Negatif"
        ],
        [
         "48",
         "2",
         "ุนุงุฆุดุฉ ุตุฏููุฉ",
         "Djezzy ูู ูุถููู ุฃุฑูุฏ ุชูุทูุน ุงูุดุฑูุญุฉ ูุชูุงุณุจ ุงููุงุชู..ููู ูุฐุง ุบูุฑ ูููู ูุน ุดุฑูุญุชู ุงูุญุงููุฉ ูู ูููู ุงุณุชุจุฏุงููุง ูุน ุฃุฎุฑู ูุงุจูุฉ ูุชูุทูุน ูุน ุดุฑุท ุงูุงุญุชูุงุธ ุจุฑููู ุงูุญุงูู..",
         "Neutre"
        ],
        [
         "49",
         "2",
         "Youcef Mellah",
         "ุฑุงูุง ูุณููู 150 ูุดูุฑ ู ูููููุณููู ุฑุจู ูุฌูุจ ูููู ุชูุถูุญ",
         "Negatif"
        ],
        [
         "50",
         "2",
         "Mar Lyn",
         "ุชุฎุฏูู ุงูุฌูุนุฉ ุ",
         "Neutre"
        ],
        [
         "51",
         "2",
         "Oussama Chabane",
         "ุงูุญู",
         "Neutre"
        ],
        [
         "52",
         "2",
         "Sifoune Soufyane",
         "ูู ุงูุฑูู 455 ุฎุงุต ุจูู ูููุงุฐุง ูุชุตู ุจู",
         "Neutre"
        ],
        [
         "53",
         "2",
         "Mohamed Rakmouche",
         "ุทุฑููุฉ ูููุณู ูู ุฌูุฒู ุงูู ุฌูุฒู",
         "Neutre"
        ],
        [
         "54",
         "2",
         "ลธรตn รs",
         "ุฑูฺจูู ุฑูุฒู ุฑุญูุฉ ุนูู ูุงูุฏููู",
         "Negatif"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3826
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Post</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yanise Yanise</td>\n",
       "      <td>ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jj Kie</td>\n",
       "      <td>ูู ุนุงู ู ุงูุชู ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sakou Younes</td>\n",
       "      <td>ูู ุนุงู ูุฃูุชู ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ุฑุงูู ูุนุงูู</td>\n",
       "      <td>ูู ุนุงู ูุญูุง ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>ุฃุญูุฏ ููุฑุงุณ</td>\n",
       "      <td>๐ฅฐ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>183</td>\n",
       "      <td>ูุฑ ุณููู '</td>\n",
       "      <td>๐ฉท๐ฉท๐ฉท๐ฉท๐ฉท๐ฉท</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>183</td>\n",
       "      <td>ฤนรฃ Rรตsรซ รb</td>\n",
       "      <td>โค๏ธโค๏ธ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>183</td>\n",
       "      <td>ูุณูุงุช ูุงุฏุฆุฉ</td>\n",
       "      <td>๐๐๐๐</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>183</td>\n",
       "      <td>ููู ูููุงุด ุบูุฑู</td>\n",
       "      <td>โคโคโคโคโคโค๐น</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>183</td>\n",
       "      <td>ุฌูุจูู ููุช ููุช</td>\n",
       "      <td>โค๏ธโค๏ธโค๏ธโค๏ธ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3826 rows ร 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Post       User Name  \\\n",
       "1           1   Yanise Yanise   \n",
       "2           1          Jj Kie   \n",
       "3           1    Sakou Younes   \n",
       "4           1      ุฑุงูู ูุนุงูู   \n",
       "6           1      ุฃุญูุฏ ููุฑุงุณ   \n",
       "...       ...             ...   \n",
       "4123      183      ูุฑ ุณููู '   \n",
       "4124      183      ฤนรฃ Rรตsรซ รb   \n",
       "4125      183     ูุณูุงุช ูุงุฏุฆุฉ   \n",
       "4126      183  ููู ูููุงุด ุบูุฑู   \n",
       "4128      183   ุฌูุจูู ููุช ููุช   \n",
       "\n",
       "                                               Comments Sentiments  \n",
       "1     ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู...    Negatif  \n",
       "2                                    ูู ุนุงู ู ุงูุชู ุจุฎูุฑ    Positif  \n",
       "3                                     ูู ุนุงู ูุฃูุชู ุจุฎูุฑ    Positif  \n",
       "4                                      ูู ุนุงู ูุญูุง ุจุฎูุฑ    Positif  \n",
       "6                                                     ๐ฅฐ    Positif  \n",
       "...                                                 ...        ...  \n",
       "4123                                             ๐ฉท๐ฉท๐ฉท๐ฉท๐ฉท๐ฉท    Positif  \n",
       "4124                                               โค๏ธโค๏ธ    Positif  \n",
       "4125                                               ๐๐๐๐    Positif  \n",
       "4126                                            โคโคโคโคโคโค๐น    Positif  \n",
       "4128                                           โค๏ธโค๏ธโค๏ธโค๏ธ    Positif  \n",
       "\n",
       "[3826 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = comments_df.loc[comments_df[\"Comments\"].shift() != comments_df[\"Comments\"]]\n",
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kikoo\\AppData\\Local\\Temp\\ipykernel_17412\\1392052614.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comments_df[\"Comments\"] = comments_df[\"Comments\"].apply(normalize_arabic)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncomments_df[\"Comments\"] = comments_df[\"Comments\"].apply(replace_emojis)\\nposts_df[\"Contents\"] = posts_df[\"Contents\"].apply(replace_emojis)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_arabic(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"ฺฏ\", \"ู\", text)\n",
    "    text = re.sub(\"ฺญ\", \"ู\", text)\n",
    "    text = re.sub(\"ฺค\", \"ู\", text)\n",
    "    text = re.sub(\"ฺจ\", \"ู\", text)\n",
    "    text = re.sub(\"ูพ\", \"ุจ\", text)\n",
    "    text = re.sub(\"รฉ\", \"e\", text)\n",
    "    text = re.sub(\"รช\", \"e\", text)\n",
    "    text = re.sub(\"รซ\", \"e\", text)\n",
    "    text = re.sub(\"รง\", \"c\", text)\n",
    "    text = re.sub(\"ร\", \"a\", text)\n",
    "    text = re.sub(\"รข\", \"a\", text)\n",
    "    text = re.sub(\"รค\", \"a\", text)\n",
    "    text = re.sub(\"รฎ\", \"i\", text)\n",
    "    text = re.sub(\"รฏ\", \"a\", text)\n",
    "    text = re.sub(\"รฆ\", \"ae\", text)\n",
    "    text = re.sub(\"ล\", \"oe\", text)\n",
    "    return text\n",
    "\"\"\"\n",
    "def replace_emojis(text):\n",
    "    emojis = {\n",
    "        \"\\U0001F601\": \"ูุฑุญ\",\n",
    "        \"\\U0001F602\": \"ูุฑุญ\",\n",
    "        \"\\U0001F603\": \"ูุฑุญ\",\n",
    "        \"\\U0001F604\": \"ูุฑุญ\",\n",
    "        \"\\U0001F606\": \"ูุฑุญ\",\n",
    "        \"\\U0001F607\": \"ูุฑุญ\",\n",
    "        \"\\U0001F60D\": \"ุญุจ\",\n",
    "        \"\\U0001F618\": \"ุญุจ\",\n",
    "        \"\\U0001F619\": \"ุญุจ\",\n",
    "        \"\\U0001F61A\": \"ุญุจ\",\n",
    "        \"\\U0001F61E\": \"ุญุฒู\",\n",
    "        \"\\U0001F61F\": \"ุญุฒู\",\n",
    "        \"\\U0001F620\": \"ุบุถุจ\",\n",
    "        \"\\U0001F621\": \"ุบุถุจ\",\n",
    "        \"\\U0001F92C\": \"ุบุถุจ\",\n",
    "        \"\\U0001F636\": \"ุตูุช\",\n",
    "        \"\\U0001F637\": \"ูุฑุถ\",\n",
    "        \"\\U0001F638\": \"ูุฑุญ\",\n",
    "        \"\\U0001F639\": \"ุถุญู\",\n",
    "        \"\\U0001F63B\": \"ุญุจ\",\n",
    "        \"\\U0001F63C\": \"ูุฑุญ\",\n",
    "        \"\\U0001F63D\": \"ุญุจ\",\n",
    "        \"\\U0001F63E\": \"ุบุถุจ\",\n",
    "        \"\\U0001F63F\": \"ุญุฒู\",\n",
    "        \"\\U0001F640\": \"ุญุฒู\",\n",
    "        \"\\U0001F641\": \"ุญุฒู\",\n",
    "        \"\\U0001F64B\": \"ุชุญูุฉ\",\n",
    "        \"\\U0001F64E\": \"ุญุฒู\",\n",
    "        \"\\U0001FA79\": \"ุญุจ\",\n",
    "        \"\\U0001F970\": \"ุฅุนุฌุงุจ\",\n",
    "        \"\\U00002764\": \"ุญุจ\",\n",
    "        \"\\U0001F495\": \"ุญุจ\",\n",
    "        \"\\U0001F339\": \"ุญุจ\",\n",
    "    }\n",
    "    for emoji, arabic_equivalent in emojis.items():\n",
    "        # Ajouter un espace aprรจs chaque remplacement\n",
    "        text = re.sub(emoji, f\" {arabic_equivalent} \", text)\n",
    "    return text.strip()\n",
    "\"\"\"\n",
    "\n",
    "# Appliquer la normalisation\n",
    "comments_df[\"Comments\"] = comments_df[\"Comments\"].apply(normalize_arabic)\n",
    "posts_df[\"Contents\"] = posts_df[\"Contents\"].apply(normalize_arabic)\n",
    "\n",
    "\"\"\"\n",
    "comments_df[\"Comments\"] = comments_df[\"Comments\"].apply(replace_emojis)\n",
    "posts_df[\"Contents\"] = posts_df[\"Contents\"].apply(replace_emojis)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID Post",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comments",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiments",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4c7e3ca2-5058-4189-9d1d-8487c0f0afc3",
       "rows": [
        [
         "1",
         "1",
         "Yanise Yanise",
         "ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู ุจุฏุฃุช ุชููุต ุดูู ุดููุง ูู 100 ุฏุฌ ุฅูู 75ุฏุฌ ู ุจุนุฏูุง ุฅูู 50 ุฏุฌ ู ุจุนุฏูุง ุฅูู 25 ุฏุฌ !!!!!!!!!!! ุงูู ุฐูุจุช ูุฒูููุชู ุชุงุนู ุุุุ!!!!!!\n ูู ุฃุชููู ุจูุง ู ูู ุงุชุตู ุจูุง ู ููุณ ูู ุฎุงุตูุฉ ุฑูุชู ุงุฐู ุงูู ุฐูุจ ูุงููุ!ุ!ุ!ุ\n ู ุตุงุฑ ููุณ ุงูุดูุก ูุน ุฃุฎู!!!!!!!!!!!!\n ูุงูุฐุง ูุงุจุฏ ูู ุงุณุชุฑุฌุงุนู",
         "Negatif"
        ],
        [
         "2",
         "1",
         "Jj Kie",
         "ูู ุนุงู ู ุงูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "3",
         "1",
         "Sakou Younes",
         "ูู ุนุงู ูุฃูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "4",
         "1",
         "ุฑุงูู ูุนุงูู",
         "ูู ุนุงู ูุญูุง ุจุฎูุฑ",
         "Positif"
        ],
        [
         "6",
         "1",
         "ุฃุญูุฏ ููุฑุงุณ",
         "๐ฅฐ",
         "Positif"
        ],
        [
         "7",
         "1",
         "ูุฑูุงู ุณูุฏูู ุณูุฏูู ูุฑูุงู",
         "ูู ุนุงู ูุฃูุชู ุจุฎูุฑ ูุฃุชููุง ุฑุฏ ุนูุง ุฃุณุฅูุชู ุนูุง ูุญุงุต ููู ุนุงู ูุฃูุชู ุจุฎูุฑ",
         "Positif"
        ],
        [
         "8",
         "1",
         "Mostefa Merabti",
         "happy new year",
         "Positif"
        ],
        [
         "9",
         "1",
         "ูููุฏ ุจุฑู",
         "ูุงุด ุนุฑูุถ ูุฏู ุฑู ูู 2024",
         "Neutre"
        ],
        [
         "10",
         "1",
         "Aymen Aymen",
         "ุชุญูุง ุฌูุฒู",
         "Positif"
        ],
        [
         "11",
         "1",
         "Maram Akram",
         "bonne annee a tous",
         "Positif"
        ],
        [
         "12",
         "1",
         "Plako Platr Ba 13",
         "๐",
         "Neutre"
        ],
        [
         "13",
         "1",
         "Lina Sami",
         "ูููู ูุญูู ุนุฑูุถ ุฌูุฒู ุณุจูุณูุงู ุจุงู ูุฑุฌุนูุง ูุงููุฉ ุจุฒุงู",
         "Neutre"
        ],
        [
         "14",
         "1",
         "Yakoub Boussebsi",
         "ุณูุฉ ุณุนูุฏุฉ ูุฑุฌุนููุง 6h",
         "Positif"
        ],
        [
         "15",
         "1",
         "Hamza Othmani",
         "ุจุฏุงูุฉ ุณูุฉ ุณูุฆุฉ ุฌุฏุงุ ููุฏ ุซู ูุทุน ุฎุทู ุถููุ ู ูุตูุญุฉ ุงูุฒุจุงุฆู ูุง ุชุฑุฏุ ุนูุจ",
         "Negatif"
        ],
        [
         "16",
         "1",
         "RED ROSE",
         "๐น๐น๐น๐น",
         "Positif"
        ],
        [
         "17",
         "1",
         "Mohamed Mellak",
         "ุนุงู ุณุนูุฏ 2024",
         "Positif"
        ],
        [
         "19",
         "1",
         "Saber Zem",
         "ุฃูุง ูุดุชุฑู ุฏูุน ุจุนุฏู ุชู ุชุฒููุฏู ุจุฎุฏูุฉ chirpix ุฏูู ุนููู ูู 2 ุฏูุณูุจุฑ 2023ุ ูุนูุฏ ุงูุงุทูุงุน ุนูู ูุงุชูุฑุฉ ุดูุฑ ุฌุงููู ูุฌุฏุช ูุจูุบ 740.00 ุฏุฌ ุฒุงุฆุฏ ุนู ุงููุงุชูุฑุฉ ูุนูุฏ ุงูุงุณุชูุณุงุฑ ุนูุฏ ุฎุฏูุฉ ุงูุฒุจุงุฆู ูุงู ุจุณุจุจ chirpixุ ุนููุง ุฃููู ูู ุฃุทูุจ ูุฐู ุงูุฎุฏูุฉ ุฃุจุฏุง ุุุุุุุ",
         "Neutre"
        ],
        [
         "20",
         "1",
         "ุฌูุนูุฉ ุงูุญู ุฃุจูุงุก ุงูุบุฏ ูุนูุงุถุงุช -ูุตุฑ ุงูุฃุจุทุงู-",
         "ูุญูุทูู ุนููุง ุงูุง ูุฑูุชูุง ( ูุฑูุฉ ูุนูุงุถุงุช ) ุงูุชุงุจุนุฉ ูุจูุฏูุฉ ูุตุฑ ุงูุฃุจุทุงู ุฏุงุฆุฑุฉ ุนูู ูููุงู ููุงูุฉ ุณุทูู ุงู ุดุจูุฉ ุงูุงูุชุฑูุช ุฌูุฒู ุชูุนุฏู ุชูุงูุง ูู ูุฑูุชูุง.ูุฑุฌู ูููู ุงูุฌุงุฏ ุญู ููุฐู ุงููุดููุฉ",
         "Negatif"
        ],
        [
         "21",
         "1",
         "Sรm Fรrรh Mehimdร",
         "ูู ูุฑุฉ ุชุณุฑููุง 50ุฏุฌ ุุุุ ุนูุงุด ูุงู ุชุฎูููุง ูุจุฏููุง ุงูุฎุท ๐ฅด๐ฅด๐ฅด",
         "Negatif"
        ],
        [
         "22",
         "1",
         "ลรลรh ลฤhรฏr",
         "ูู ุนุงู ูุงูุชู ุจุงูู ุฎูุฑ โฃ๏ธโฃ๏ธ",
         "Positif"
        ],
        [
         "23",
         "1",
         "Sofiane Sofiane",
         "ุนูุงู ุฏูุชููู 50 ุฏุฌ ูู ูุฑุฉ ุฑุงูู ุฏูุฑููุงูู",
         "Negatif"
        ],
        [
         "24",
         "1",
         "Lamine Jseb",
         "ูุงุด ุจูู ุงูุฑูุฒู ุงููููุุ ูุงูุงุด ุงูุชุฑูุช ููุฐ 3 ุณุงุนุงุช",
         "Negatif"
        ],
        [
         "25",
         "1",
         "ใใฆใณใ ใณใฉใคใ",
         "ุจูุฏ ููุงุณุจุฉ ุชุจุฑุนู ุนูููุง ุจ ุงูุชุฑูุช๐",
         "Neutre"
        ],
        [
         "26",
         "1",
         "Bnamer Boutayeb",
         "ุฑูููู ุงุจูููุงุณูู ูุชุงุนูู",
         "Negatif"
        ],
        [
         "27",
         "1",
         "ใใใ ใฅ ใฅ",
         "ุฏูุฑูููุง ูุด ุญุงุฌุฉ ูุชุน ูููููุณููู",
         "Neutre"
        ],
        [
         "28",
         "1",
         "ูููุด ุณููุฑ",
         "ููุงูุด ูููููุณู ๐๐",
         "Negatif"
        ],
        [
         "29",
         "1",
         "Fati Fati",
         "ูู 2006 ุฑุงูู ูุดุชุงุฑูู ูุนุงูู ูุงุด ููุงุฑ ูุฑุญููุง ุจูุฏูู ๐",
         "Neutre"
        ],
        [
         "30",
         "1",
         "Sofiane Renault Medea",
         "ุจุทูุกุฉ",
         "Negatif"
        ],
        [
         "31",
         "1",
         "Sifadine Mehdi",
         "ุฑูุฒู ูุดุจูู ูุฑูุญ ู ูุฌู ุ",
         "Negatif"
        ],
        [
         "32",
         "1",
         "Aรฑdลeรค Aรฑdลeรค",
         "ููุชุงู ุชุฑุฏูููุง ุฑูุฒู๐คง",
         "Negatif"
        ],
        [
         "33",
         "1",
         "Nabil Issam",
         "ุฑูููููุง ุฑุจ ุฑูุฒู",
         "Negatif"
        ],
        [
         "34",
         "1",
         "Abdo Gros",
         "malheureusement le reseau etait coupe men 17h ! hata dok bach wala en plus c'est en niveau d'alger yahsra les autres wilaya !! ni excuses ni rien! mais bon en souhaitant une amelioration cette annee nchlh",
         "Negatif"
        ],
        [
         "36",
         "2",
         "Abdelghani Tahtah",
         "ูุงูู ูู ุงูููุฏ ูุชุงุน ุณูููู ... ุุ",
         "Neutre"
        ],
        [
         "37",
         "2",
         "ุฃุญูุฏ ููุฑุงุณ",
         "ูููุญ",
         "Positif"
        ],
        [
         "38",
         "2",
         "ลล ลล",
         "ูููุงู ูุณูู ุนุดุฑุงูุงู",
         "Neutre"
        ],
        [
         "40",
         "2",
         "Riad BM",
         "ุดููู ูุจุนุซูู 2 ุฌูุบุง ๐๐",
         "Neutre"
        ],
        [
         "41",
         "2",
         "Amine Boudiaf",
         "ุฑุฌุนููุง ุนุฑูุถ ุงูุชูุงุฒ ูู ูุญูุชููุง ููุง",
         "Negatif"
        ],
        [
         "42",
         "2",
         "ุฒูู ุงูุฏูู ุงุจู ุงูุจูุงุฏู",
         "ุฃูุฏ ูุนุฑูุฉ ููููุฉ ุณุฑูุฉ ุฑุตูุฏู ุ\n ุงูุฑุฌุงุก ุงูุชูุถูุญ \n ูู ุฑูููู ูู ุฌูุฒู ุฏุงุฆูุง ูุง ุงุฌุฏ ุงูุฑุตูุฏ djezzy",
         "Negatif"
        ],
        [
         "43",
         "2",
         "Amani Amina",
         "ููู ุฑูู ุฎุฏูุฉ ุณููู",
         "Neutre"
        ],
        [
         "44",
         "2",
         "ุงูุนุฑุจู ููุงูู",
         "ูููู ูุนุฑู ุนูุงุด ุชููุตู ูู ุงูุฑุตูุฏ \n ูุงููู ุงูุนุธูู ุนูุจ ุนูุจ ุนูุจ \n ุชููููุณู 50 ุงูู ุบุฏูุฉ ุชููู 20 ุงูู ุนูุจ\n ุญุณุจูุง ุงููู ููุนู ุงููููู.",
         "Negatif"
        ],
        [
         "45",
         "2",
         "Yassine Madrid",
         "ูู ูุถููู ุดุฑูุช ุดุฑูุญุฉ ุฌูุฒู ุฌุฏูุฏุฉ ูููุงู ูุฃูุชููููุง ูุน ุงูุนูู ูููุง 60g ุงูุชุฑูุช ู 7000 ููุงููุงุช",
         "Neutre"
        ],
        [
         "46",
         "2",
         "Aoudjia Aimen",
         "ูุดุจูู ุชุทุจูู ุญุงุจุณ ุงู ุฑููููู ูุฑููููู ุงูุฑูุฒู ุฑุงูุง ูุนุงููู 2024 ูุฑูุฒู ููุช ูู ุญุงูุง ูุงููู ูุง ููููุง ูููููุชุด ุนูุงู ุฑุงูุง ูุงูุนุงูู ุงูุซุงูุซ (ุงูุณุจุจ ุงููุญูุฏ ูุง ุบูุฑู ูู ูุฎูููุง ูุงูุนุงูู ุงูุซุงูุซ ุงูู ููุงุด ุนุงูู ุฑุงุจุน ุงู ุฎุงูุณ)",
         "Negatif"
        ],
        [
         "47",
         "2",
         "ุตุงุญุจุฉ ุงูุณุนุงุฏุฉ",
         "ุนูุงุจููุง ูููุชู ููููููุณูู ุชุฏููู",
         "Negatif"
        ],
        [
         "48",
         "2",
         "ุนุงุฆุดุฉ ุตุฏููุฉ",
         "djezzy ูู ูุถููู ุฃุฑูุฏ ุชูุทูุน ุงูุดุฑูุญุฉ ูุชูุงุณุจ ุงููุงุชู..ููู ูุฐุง ุบูุฑ ูููู ูุน ุดุฑูุญุชู ุงูุญุงููุฉ ูู ูููู ุงุณุชุจุฏุงููุง ูุน ุฃุฎุฑู ูุงุจูุฉ ูุชูุทูุน ูุน ุดุฑุท ุงูุงุญุชูุงุธ ุจุฑููู ุงูุญุงูู..",
         "Neutre"
        ],
        [
         "49",
         "2",
         "Youcef Mellah",
         "ุฑุงูุง ูุณููู 150 ูุดูุฑ ู ูููููุณููู ุฑุจู ูุฌูุจ ูููู ุชูุถูุญ",
         "Negatif"
        ],
        [
         "50",
         "2",
         "Mar Lyn",
         "ุชุฎุฏูู ุงูุฌูุนุฉ ุ",
         "Neutre"
        ],
        [
         "51",
         "2",
         "Oussama Chabane",
         "ุงูุญู",
         "Neutre"
        ],
        [
         "52",
         "2",
         "Sifoune Soufyane",
         "ูู ุงูุฑูู 455 ุฎุงุต ุจูู ูููุงุฐุง ูุชุตู ุจู",
         "Neutre"
        ],
        [
         "53",
         "2",
         "Mohamed Rakmouche",
         "ุทุฑููุฉ ูููุณู ูู ุฌูุฒู ุงูู ุฌูุฒู",
         "Neutre"
        ],
        [
         "54",
         "2",
         "ลธรตn รs",
         "ุฑูููู ุฑูุฒู ุฑุญูุฉ ุนูู ูุงูุฏููู",
         "Negatif"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3826
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Post</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yanise Yanise</td>\n",
       "      <td>ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jj Kie</td>\n",
       "      <td>ูู ุนุงู ู ุงูุชู ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sakou Younes</td>\n",
       "      <td>ูู ุนุงู ูุฃูุชู ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ุฑุงูู ูุนุงูู</td>\n",
       "      <td>ูู ุนุงู ูุญูุง ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>ุฃุญูุฏ ููุฑุงุณ</td>\n",
       "      <td>๐ฅฐ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>183</td>\n",
       "      <td>ูุฑ ุณููู '</td>\n",
       "      <td>๐ฉท๐ฉท๐ฉท๐ฉท๐ฉท๐ฉท</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>183</td>\n",
       "      <td>ฤนรฃ Rรตsรซ รb</td>\n",
       "      <td>โค๏ธโค๏ธ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>183</td>\n",
       "      <td>ูุณูุงุช ูุงุฏุฆุฉ</td>\n",
       "      <td>๐๐๐๐</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>183</td>\n",
       "      <td>ููู ูููุงุด ุบูุฑู</td>\n",
       "      <td>โคโคโคโคโคโค๐น</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>183</td>\n",
       "      <td>ุฌูุจูู ููุช ููุช</td>\n",
       "      <td>โค๏ธโค๏ธโค๏ธโค๏ธ</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3826 rows ร 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Post       User Name  \\\n",
       "1           1   Yanise Yanise   \n",
       "2           1          Jj Kie   \n",
       "3           1    Sakou Younes   \n",
       "4           1      ุฑุงูู ูุนุงูู   \n",
       "6           1      ุฃุญูุฏ ููุฑุงุณ   \n",
       "...       ...             ...   \n",
       "4123      183      ูุฑ ุณููู '   \n",
       "4124      183      ฤนรฃ Rรตsรซ รb   \n",
       "4125      183     ูุณูุงุช ูุงุฏุฆุฉ   \n",
       "4126      183  ููู ูููุงุด ุบูุฑู   \n",
       "4128      183   ุฌูุจูู ููุช ููุช   \n",
       "\n",
       "                                               Comments Sentiments  \n",
       "1     ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ููููุณูุช 100 ุฏุฌ ู...    Negatif  \n",
       "2                                    ูู ุนุงู ู ุงูุชู ุจุฎูุฑ    Positif  \n",
       "3                                     ูู ุนุงู ูุฃูุชู ุจุฎูุฑ    Positif  \n",
       "4                                      ูู ุนุงู ูุญูุง ุจุฎูุฑ    Positif  \n",
       "6                                                     ๐ฅฐ    Positif  \n",
       "...                                                 ...        ...  \n",
       "4123                                             ๐ฉท๐ฉท๐ฉท๐ฉท๐ฉท๐ฉท    Positif  \n",
       "4124                                               โค๏ธโค๏ธ    Positif  \n",
       "4125                                               ๐๐๐๐    Positif  \n",
       "4126                                            โคโคโคโคโคโค๐น    Positif  \n",
       "4128                                           โค๏ธโค๏ธโค๏ธโค๏ธ    Positif  \n",
       "\n",
       "[3826 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Contents",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Lien Post",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Nb Like",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Love",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Care",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Wow",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Sad",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Angry",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Haha",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cfbcef3b-130c-4ea0-8867-59969cd73b7a",
       "rows": [
        [
         "0",
         "1",
         "ุฌุงุฒู ุชุชูููู ููู ุณูุฉ ุณุนูุฏุฉ๐ฅฐ\n#djezzy #happy_new_year_2024",
         "https://www.facebook.com/djezzy/posts/788227516669599?ref=embed_post",
         "272",
         "45",
         "0",
         "1",
         "1",
         "76",
         "14",
         "Djezzy",
         "2024-01-01 00:00:00"
        ],
        [
         "1",
         "2",
         "ุฑุงู en panne ู ุฎุตู ุฑุตูุฏ ุ\nูุน ุฎุฏูุฉ tranquilo ุชุงุน djezzy ููุด ุณุงูู๐\n#ุฌุงุฒู #astuces_ุณุงููุฉ",
         "https://www.facebook.com/watch/?v=1068829281022985&ref=sharing",
         "255",
         "28",
         "0",
         "1",
         "0",
         "12",
         "31",
         "Djezzy",
         "2024-01-04 00:00:00"
        ],
        [
         "2",
         "3",
         "it's time to be a legend",
         "https://www.facebook.com/djezzy/posts/392564993435969:392564993435969?ref=embed_post",
         "257",
         "51",
         "2",
         "0",
         "0",
         "2",
         "8",
         "Djezzy",
         "2024-01-10 00:00:00"
        ],
        [
         "3",
         "4",
         "djezzy vous souhaite yennayer amervuh!  โดฐโตโตโดปโดณโดฐโต โดฐโตโดปโดณโดฐโตฃ 2974\n ! ุฌุงุฒู ุชูุฏู ููู ุฃุญุฑู ุงูุชูุงูู ุจููุงุณุจุฉ ุงูุณูุฉ ุงูุฃูุงุฒูุบูุฉ ุงูุฌุฏูุฏุฉ\n#djezzy #yennayer_2974",
         "https://www.facebook.com/share/p/19UDNBoQ1k/",
         "621",
         "231",
         "10",
         "3",
         "0",
         "1",
         "300",
         "Djezzy",
         "2024-01-11 00:00:00"
        ],
        [
         "4",
         "5",
         "ูุฑูุจุงู ...",
         "https://www.facebook.com/share/v/12B9LZySBRe/",
         "288",
         "49",
         "4",
         "0",
         "0",
         "3",
         "24",
         "Djezzy",
         "2024-01-12 00:00:00"
        ],
        [
         "5",
         "6",
         "ู ููุงููุงุช ุบูุฑ ูุญุฏูุฏุฉ ูุญู ุฌููุน ุดุจูุงุช ุงูููุงู ู ุงูุซุงุจุช.\nุจู 2500ุฏุฌ ููุท !\n#ูุชุง_ูู_ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/v/15R9u8sYHg/",
         "564",
         "157",
         "24",
         "0",
         "0",
         "7",
         "73",
         "Djezzy",
         "2024-01-13 00:00:00"
        ],
        [
         "6",
         "7",
         "ูุน ุฌุงุฒู legend\nุฅุณุชูุฏ ูู ููุงููุงุช ูุฌุงููุฉ ูุญู ูู ุดุจูุงุช ุงูููุงู ู ุงูุซุงุจุช !\nูุญุฌู ุงูุชุฑูุช ูุตู ุฅูู ุบุงูุฉ 100 ุฌูุบุง !\nุฅูุชุดููุง ูุฒุงูุง ุงูุนุฑุถ ุงูุฌุฏูุฏ djezzy legend ุนูู ๐ https://ms.spr.ly/6188iury6\n#ูุชุง_ูู_ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/djezzy/posts/797321975760153?ref=embed_post",
         "438",
         "31",
         "5",
         "0",
         "0",
         "26",
         "52",
         "Djezzy",
         "2024-01-14 00:00:00"
        ],
        [
         "7",
         "8",
         "ุชูุชุน ุจุงูููุงููุงุช ุงููุฌุงููุฉ ูุญู ุฌููุน ุดุจูุงุช ุงูุฌูุงู๐ฑ ูุงูุซุงุจุช  โ๏ธ ูุงุณุชูุฏ ูู 70ุฌูุบุง ุจ2000 ุฏุฌ ููุท !\nุงุณุชูุดู ูู ุงููููุฒุงุช ุนูู ๐https://ms.spr.ly/6187iux8v \n#ูุชุง_ูู_ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/djezzy/posts/797937005698650?ref=embed_post",
         "428",
         "23",
         "4",
         "1",
         "1",
         "5",
         "52",
         "Djezzy",
         "2024-01-15 00:00:00"
        ],
        [
         "8",
         "9",
         "ูุน djezzy legend ุงูุช ูู ุงูู legend \nุจู 2000ุฏุฌ !\nุชุญุตููุง ุนูู 70go ุงูุชุฑูุชุ ููุงููุงุช ุบูุฑ ูุญุฏูุฏุฉ ูุญู ุฌููุน ุดุจูุงุช ุงูุซุงุจุช ู ุงูููุงู ! \nุฅูุชุดููุง ูุฒุงูุง djezzy legend ุนูู ๐ https://ms.spr.ly/6183iscku \n#ูุชุง_ูู_ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/v/12BG5K7FV8K/",
         "323",
         "37",
         "5",
         "0",
         "1",
         "2",
         "9",
         "Djezzy",
         "2024-01-20 00:00:00"
        ],
        [
         "9",
         "10",
         "goal algeria vs burkina faso football ",
         "https://www.facebook.com/watch/?v=1346282365905418&ref=sharing",
         "170",
         "26",
         "1",
         "1",
         "0",
         "4",
         "2",
         "Djezzy",
         "2024-01-20 00:00:00"
        ],
        [
         "10",
         "11",
         "ูุน  pack 3ayla ูุชุฑุงุทู ุญุชู match โฝ  \nุงุณุชูุงุฏ ูู modem 4g ู 150go ุงูุชุฑูุช ููุฏุฉ 6 ุฃุดูุฑ ุจ9990ุฏุฌ ๐คฉ\nูุน pack 3ayla supporty \n ูุฑููู ูุน ุนุงููุชู๐ช\nููุฒูุฏ ูู ุงููุนูููุงุช ุฒูุฑูุง ูููุนูุง ๐๐ป\n https://bit.ly/djezzy-pack3ayla\n#djezzy #match #3ayla",
         "https://www.facebook.com/watch/?v=1387729078503230&ref=sharing",
         "130",
         "8",
         "1",
         "1",
         "1",
         "2",
         "31",
         "Djezzy",
         "2024-01-23 00:00:00"
        ],
        [
         "11",
         "12",
         "ูุน zuni sport  ุนูู djezzy app ๐ฒ ุชุงุจุน ููุงุนูุฏ ู ูุชุงุฆุฌ ุงููุจุงุฑูุงุช ูุญุธุฉ ุจูุญุธุฉ โฝ ๐ \nุญููู ุงูุชุทุจูู ุงูุขู ๐ https://ms.spr.ly/6181gi6y3\n#djezzy_app #zuni_sport #max_foot",
         "https://www.facebook.com/share/p/13tcBA3rkg/",
         "189",
         "16",
         "3",
         "0",
         "0",
         "3",
         "11",
         "Djezzy",
         "2024-01-27 00:00:00"
        ],
        [
         "12",
         "13",
         "ุงูููู ูู ุงูููู ุงูุนุงููู ูุญูุงูุฉ ุงูุจูุงูุงุช. ุชุฐููุฑ ุฃุณุงุณู ุจุฃูููุฉ ุงูุญูุงุธ ุนูู ุฎุตูุตูุชู ุนูู ุงูุฅูุชุฑูุช. \nุญูุงูุฉ ุงูุจูุงูุงุช ุชูู ูู ูุงุญุฏ ููุง ๐ป๐ \naujourd'hui, c'est la journee mondiale de la protection des donnees. un rappel essentiel de l'importance de preserver votre vie privee en ligne. la protection des donnees concerne chacun d'entre \nnous๐ป๐ \n#protectiondesdonnees #viepriveeenligne #djezzy",
         "https://www.facebook.com/share/p/15aRgkr5JS/",
         "161",
         "13",
         "2",
         "1",
         "0",
         "1",
         "11",
         "Djezzy",
         "2024-01-28 00:00:00"
        ],
        [
         "13",
         "14",
         "ุงุฎุชุจุฑ ูุนูููุงุชู ูู ูุฑุฉ ุงููุฏู โฝ๏ธ \n ูุญุงูู ุชููุฒ ุจูุณููุฉ ุดุฑุงุก ุจูููุฉ 100 ููููู ุณูุชูู ุฃุณุจูุนูุง ๐ค \nูุง ุนููู ุบูุฑ ุชุญููู djezzy app ๐ฒ ุนูู ุงูุฑุงุจุท  ๐ https://ms.spr.ly/6181gi6y3\n#djezzy_app #djezzy_win",
         "https://www.facebook.com/share/p/1AzBbfwqh1/",
         "229",
         "22",
         "5",
         "0",
         "0",
         "2",
         "9",
         "Djezzy",
         "2024-01-30 00:00:00"
        ],
        [
         "14",
         "15",
         "ุฃุฎุจุงุฑ ูุญููุฉ ุ ุซูุงููุฉ ุ ุฑูุงุถูุฉ โฝ\nูุน  djezzy scoop ๐ฃ ููููุชู ุญุชู ุฎุจุฑ ! \n ููุงุดุชุฑุงู ุฅุชุตู ุนูู 404 ุฃู ุฃุฑุณู sms ุงูู ููุณ ุงูุฑูู\n#djezzy_scoop #max_news",
         "https://www.facebook.com/share/p/13yNkR5JW2/",
         "150",
         "7",
         "0",
         "0",
         "0",
         "1",
         "11",
         "Djezzy",
         "2024-01-31 00:00:00"
        ],
        [
         "15",
         "16",
         "ุดููู ูููู ูุนุฑู le code ุจุงุด ููุชููู double appel ุ\n#ุฌุงุฒู #astuces_ุณุงููุฉ",
         "https://www.facebook.com/watch/?v=1497445130819223&ref=sharing",
         "325",
         "33",
         "4",
         "0",
         "0",
         "5",
         "6",
         "Djezzy",
         "2024-02-01 00:00:00"
        ],
        [
         "16",
         "17",
         "ูููุงุด ุชุชูุงุฏู ุชููู ุงูุฎุท ุฏูุงูู ๐ค ุ\nุชุงุจุน ุงูุญู ูู ุงูููุฏูู ๐ \n#ุฌุงุฒู #astuces_ุณุงููุฉ",
         "https://www.facebook.com/watch/?v=408877615031858&rdid=nscweaDh1ie6K7G0",
         "161",
         "18",
         "2",
         "0",
         "0",
         "3",
         "10",
         "Djezzy",
         "2024-02-15 00:00:00"
        ],
        [
         "17",
         "18",
         "ูู ุฑุงููู , ูุงุฐ ุงููุฑุฉ ุนูุงุด ุฌููุง ๐",
         "https://www.facebook.com/share/v/1CVK8AkWr6/",
         "202",
         "24",
         "2",
         "1",
         "0",
         "5",
         "18",
         "Djezzy",
         "2024-02-18 00:00:00"
        ],
        [
         "18",
         "19",
         "ุงูุถููุง ุฅูููุง  ๐ถโ ูู ูุจุงุฏุฑุฉ ุงูุจุณูุฉ walk for ุ ููุฑุณู ุงูุจุณูุฉ ูุน ุจุนุถ ูู ูู ุฎุทูุฉ.\nุญูููุง  djezzy app ๐ฑ ู ุญูููุง ุฎุทูุงุชูู ุฅูู ุชุจุฑุนุงุช ูููุฉ ุฑูุถุงู  ๐ \nุฑุงุจุท ุงูุชุญููู ๐ https://ms.spr.ly/6181gi6y3\n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/p/14kGTVBiaXU/",
         "177",
         "19",
         "3",
         "0",
         "0",
         "13",
         "3",
         "Djezzy",
         "2024-02-19 00:00:00"
        ],
        [
         "19",
         "20",
         "ุจุงุด ููุฑุญู ุงููุงุณ ูู ูุฐุง ุฑูุถุงู ๐ ู ูุฑุณููุง ุงูุจุณูุฉ ุนูู ูุฌูู ุงูุตุงูููู ๐ \nููุง ููุดูุง ูุน ุจุนุถ ู ูุชุจุฑุนูุง ุจุฎุทูุงุชูุง ุนูู djezzy app ๐ฃ ๐ฒ \nุฑุงุจุท ุงูุชุญููู  ๐ https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/19nVrLQmjV/",
         "173",
         "17",
         "5",
         "0",
         "0",
         "0",
         "2",
         "Djezzy",
         "2024-02-20 00:00:00"
        ],
        [
         "20",
         "21",
         "ุดุงุฑู ูู ุชุญุฏู ุงููุดู ๐ถโโ๏ธ ูุน ุตุญุงุจู ู ุณุฌู ุฎุทูุงุชู ูู ููุฏูู ู ุฃูุดุฑูุง ุนูู ุตูุญุชู ุ ุทุงูู djeezy ูุน ูุงุดุชุงุบ\n #ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉwalk4\nุฃุญุณู ููุฏูู  ุฑุงุญ ูุจุฑุทุงุฌูููุง ุนุจุฑ ุตูุญุชูุง ๐ช \nุฑุงุจุท ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/p/1ESi1iAD8L/",
         "299",
         "34",
         "3",
         "2",
         "1",
         "6",
         "52",
         "Djezzy",
         "2024-02-21 00:00:00"
        ],
        [
         "21",
         "22",
         "ุฎุทูุฉ ุณุงููุฉ ุจููุงุณุจุฉ ุดูุฑ ุฑูุถุงู ุงููุฑูู ๐ \n#ุฌุงุฒู #astuces_ุณุงููุฉ #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/v/19dwGJKfjm/",
         "181",
         "23",
         "3",
         "0",
         "0",
         "4",
         "1",
         "Djezzy",
         "2024-02-22 00:00:00"
        ],
        [
         "22",
         "23",
         "ุทุงูู ุตุงุญุจู  ููุดู ุจุงูุฒุฑุจุฉ ๐ถโโ๏ธ ๐โโ๏ธ\n#ุฌุงุฒู  #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/p/14KAHkwsXF/",
         "201",
         "23",
         "3",
         "0",
         "2",
         "4",
         "58",
         "Djezzy",
         "2024-02-23 00:00:00"
        ],
        [
         "23",
         "24",
         "ูู ูุงุญุฏ ููุชุจููุง ูู ุงูุชุนูููุงุช ุดุญุงู ูู ุฎุทูุฉ ูุดุงูุง ุนูู djezzy app ๐ฃ ๐ถโโ๏ธ ๐ฑ \nูุฏุฑู ุดููู ุฑุงุญ ูููู ๐ le champion  ุ\n #ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/p/18BbsUNDKa/",
         "204",
         "18",
         "3",
         "0",
         "0",
         "3",
         "26",
         "Djezzy",
         "2024-02-24 00:00:00"
        ],
        [
         "24",
         "25",
         "ุงูุจุณูุฉ walk for ๐ถโโ๏ธ ูุงุฒุงููุง ูุชูุงุตูุฉ ๐ฃ\n ุทุงูู ุตุงุญุจู ูู ูุงุฒุงู ูุงุดุงุฑูุด ูุนุงูุง \n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/v/17cPeTM5qo/",
         "111",
         "20",
         "0",
         "0",
         "0",
         "5",
         "9",
         "Djezzy",
         "2024-02-26 00:00:00"
        ],
        [
         "25",
         "26",
         "ูุดุงุฑููุง ูุนุงูู  top 10 ุชุน ุงูุจุณูุฉ walk for\nุฅูุถููุง ุฅูููุงุ ูุงุฒููุง ูุชูุงุตููู ูู ุฃุฌู ุฑุณู ุงูุจุณูุฉ ูุน ุจุนุถ.\n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/p/1BYQb7q2cL/",
         "185",
         "17",
         "1",
         "0",
         "0",
         "4",
         "10",
         "Djezzy",
         "2024-02-27 00:00:00"
        ],
        [
         "26",
         "27",
         "๐ถโ ูุจุงุฏุฑุฉ ุงูุจุณูุฉ  walk for ูุงุฒุงููุง ูุชูุงุตูุฉ  ุ ุฎุทูุงุชูุง ุฑุงุญ ุชูุฑูุญ ุจุฒุงู ูุงุณ \nุญูููุง  djezzy app ๐ฑ ู ุญูููุง ุฎุทูุงุชูู ุฅูู ุชุจุฑุนุงุช ูููุฉ ุฑูุถุงู  ๐ \nุฑุงุจุท ุงูุชุญููู ๐ https://ms.spr.ly/6181gi6y3\n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/p/18KCQQmfLL/",
         "228",
         "30",
         "2",
         "0",
         "1",
         "3",
         "6",
         "Djezzy",
         "2024-02-29 00:00:00"
        ],
        [
         "27",
         "28",
         "ู ููุฃุณุจูุน ุงูุซุงูู โ๏ธ ุงูุจุณูุฉ walk for ูุงุฒุงููุง ูุชูุงุตูุฉ ุจูุฌุงุญ ุจูุถู ุฎุทูุงุชูู ๐ฃ\n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/v/12AywsCXXA3/",
         "128",
         "20",
         "0",
         "0",
         "0",
         "2",
         "4",
         "Djezzy",
         "2024-03-04 00:00:00"
        ],
        [
         "28",
         "29",
         "ูุดุงุฑููุง ูุนุงูู   ๐ถโโ๏ธ ๐ฃ the best walkers  ููุฃุณุจูุน ุงูุซุงูู โ๏ธ \nุฅูุถููุง ุฅูููุง ูู ุฃุฌู ุฑุณู ุงูุจุณูุฉ ูุน ุจุนุถ ูู ูุฐุง ุฑูุถุงู \n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/p/1Azzo8rf7E/",
         "167",
         "19",
         "0",
         "0",
         "0",
         "1",
         "2",
         "Djezzy",
         "2024-03-06 00:00:00"
        ],
        [
         "29",
         "30",
         "ูุฎุชุชู ูุจุงุฏุฑุฉ ุงูุจุณูุฉ walk for ุจุฃูุซุฑ ูู 821 ููููู ุฎุทูุฉ ๐ช ๐ฃ\nุดูุฑุงู ุนูู ูุดุงุฑูุชูู ู ุฏุนููู ุงููููู ๐ ูุน ุจุนุถ ุตูุนูุง ุงูุจุณูุฉ ๐\n#ุฌุงุฒู #ููุฉ_ุฑูุถุงู #ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/watch/?v=3419181848374064&rdid=OpVtNNOSdxW0g2eO",
         "110",
         "23",
         "1",
         "0",
         "0",
         "1",
         "1",
         "Djezzy",
         "2024-03-10 00:00:00"
        ],
        [
         "30",
         "31",
         "ุจุงุด ุชููู ูุดููุฑ ูุงุฒููู ุจุฒูุงู ุงูุชุฑูุช ๐คฉ\nู ุจุงุด ุชููู ุฃุณุทูุฑุฉ ูุงุฒููู djezzy legend ๐\nุงูุชุดููุง ุชูุงุตูู ุงูุนุฑุถ ุนูู ๐ https://bit.ly/3uw7xsl",
         "https://www.facebook.com/share/v/15kQvgwaYH/",
         "89",
         "15",
         "2",
         "0",
         "0",
         "1",
         "13",
         "Djezzy",
         "2024-03-11 00:00:00"
        ],
        [
         "31",
         "32",
         "ุญููู djezzy app ู ุดุงุฑู ูู ูุณุงุจูุฉ ุนูุฑุฉ ranati ูุดุฎุตูู ๐\nุฑุงุจุท ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/18BXF4DAnq/",
         "131",
         "37",
         "0",
         "0",
         "0",
         "0",
         "1",
         "Djezzy",
         "2024-03-11 00:00:00"
        ],
        [
         "32",
         "33",
         "ูุฐุง ุฑูุถุงู ุงููุฑุญุฉ ุฏูุจู ๐x2 ุนูู djezzy app ๐ฑ  \nุฑุงุจุท ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/1FyzpbnWBQ/",
         "106",
         "30",
         "1",
         "1",
         "0",
         "2",
         "0",
         "Djezzy",
         "2024-03-12 00:00:00"
        ],
        [
         "33",
         "34",
         "ูุน djezzy app ุฏูุจูู ูุฑุญุชู ๐คฉ ู ุงูุงูุชุฑูุช ุฏูุงูู โ๏ธ \nุฑุงุจุท ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/17z9TWBMWj/",
         "132",
         "20",
         "2",
         "0",
         "0",
         "2",
         "2",
         "Djezzy",
         "2024-03-13 00:00:00"
        ],
        [
         "34",
         "35",
         "ุจุงุด ุฏูุฑ ูุญุชูู ุฃุณุทูุฑู ูุงุฒููู ุนุฑุถ ุฃุณุทูุฑู ๐ \nุงูุชุดููุง ุงูุชูุงุตูู   ๐ https://ms.spr.ly/6187cis3p\nูุน djezzy legend ุงูุช ูู ุงูุฃุณุทูุฑุฉ  ๐",
         "https://www.facebook.com/share/p/1NTLjuLH4q/",
         "179",
         "22",
         "0",
         "1",
         "0",
         "3",
         "31",
         "Djezzy",
         "2024-03-14 00:00:00"
        ],
        [
         "35",
         "36",
         "ูุงูู ููุตููุง  sms ๐ฒ ุจูู ุฑุจุญูุง ูู ูุณุงุจูุงุช ู ุญูุง ูุงุดุงุฑููุงุด ูููุง !\nูููุงุด ูุชูุงุฏููุง  ุ\n#ุฌุงุฒู #astuces_ุณุงููุฉ #ุฑูุถุงู2024",
         "https://www.facebook.com/share/v/1Ax3tK3yQf/",
         "71",
         "13",
         "1",
         "0",
         "0",
         "2",
         "0",
         "Djezzy",
         "2024-03-14 00:00:00"
        ],
        [
         "36",
         "37",
         "ุงูุชุฑูุช โ 2  ููุฏุฉ ุฃุณุจูุน !\nุญููู djezzy app ู ุงุณุชูุชุน ุจ10 ุฌูุบุง ููู ุนุฑุถ ุชุงุน 300 ุฏุฌ \nุฑุงุจุท ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3\n#ุฌุงุฒู #ุฏูุจู_ุฃูุชุฑูุช #ุฑูุถุงู2024_ุฌุงุฒู_app",
         "https://www.facebook.com/share/v/1QvSNe3qr6/",
         "86",
         "16",
         "2",
         "0",
         "0",
         "8",
         "3",
         "Djezzy",
         "2024-03-17 00:00:00"
        ],
        [
         "37",
         "38",
         "ููููุชู doubleโ 2 ู ุฃูุฑุญ doubleโ 2 ูุน ุงูุชุฑูุช  double โ 2\nุญููู ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3\n#ุฌุงุฒู #ุฏูุจู_ุฃูุชุฑูุช #ุฑูุถุงู2024_ุฌุงุฒู_app",
         "https://www.facebook.com/share/p/19cMcLv6sd/",
         "139",
         "18",
         "0",
         "0",
         "0",
         "4",
         "2",
         "Djezzy",
         "2024-03-17 00:00:00"
        ],
        [
         "38",
         "39",
         "ูุน ุนุฑุถ ุฌุงุฒู legend max ุงูุฌุฏูุฏุ ุงุณุชูุฏ ูู ููุงููุงุช ุบูุฑ ูุญุฏูุฏุฉ ูุญู ุฌููุน ุงูุดุจูุงุช ุงููุทููุฉ ูุญุฏู ุฃูุตู ูู ุงูุงูุชุฑูุช !\nูููุฒูุฏ ูู ุงูุชูุงุตูู : https://ms.spr.ly/6186cudnk\n#ุฌุงุฒู #ูุชุงููููุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/p/1Gxhnote12/",
         "163",
         "31",
         "1",
         "0",
         "0",
         "2",
         "1",
         "Djezzy",
         "2024-03-22 00:00:00"
        ],
        [
         "39",
         "40",
         "ูุน djezzy app ุฃุจูู ุฏุงููุงู connecte ุจdouble \n  ุงุณุชูุชุน ุจ10 ุฌูุบุง ููุฏุฉ ุฃุณุจูุน  ุจ300 ุฏุฌ ููุท ! \nุฑุงุจุท ุงูุชุทุจูู๐ https://ms.spr.ly/6181gi6y3\n#ุฌุงุฒู #ุฏูุจู_ุฃูุชุฑูุช #ุฑูุถุงู2024_ุฌุงุฒู_app",
         "https://www.facebook.com/share/v/19THVFCcWA/",
         "64",
         "18",
         "0",
         "0",
         "0",
         "2",
         "2",
         "Djezzy",
         "2024-03-23 00:00:00"
        ],
        [
         "40",
         "41",
         "\nุนูุฏู legend maxุ\nbien sรปr que ุงูุช ุงุณุทูุฑุฉ ๐",
         "https://www.facebook.com/share/v/1EZyVsxH3S/",
         "91",
         "20",
         "0",
         "1",
         "0",
         "0",
         "6",
         "Djezzy",
         "2024-03-25 00:00:00"
        ],
        [
         "41",
         "42",
         "ุจุงูุดุฑุงูุฉ ูุน ุงููุดุงูุฉ ุงูุฅุณูุงููุฉ ุงูุฌุฒุงุฆุฑูุฉุ ุฌุงุฒู ุชุดุงุฑููู ุงูุฃุฌูุงุก ุงูุชุถุงูููุฉ ูู ูุทุนู ููุฌ ุงูุงู ูุงูุด ุจุจูุฏูุฉ ุงูุดุฑุงูุฉ.\nุชุชููุฒ ูุฐู ุงููุจุงุฏุฑุฉ ุจูุณุงููุฉ ุงููุดุงููู ูู ูุฎุชูู ุงูุฃุนูุงุฑ  ูู ุงุฏุฎุงู ุงููุฑุญุฉ ูุฑุณู ุงูุจุณูุฉ ุนูู ูุฌูู ุงููุงุตุฏูู ู ุงูุนุงุจุฑูู ูู ูู ููุงู.\nูู ูุฐุง ุฑูุถุงู ูุฑุณูู ุงูุจุณูุฉ  ูุน ุจุนุถ ๐ค \nููุฌ ูฑูุงู ูุงูุด ุงููุดุงูุฉ ุงูุฅุณูุงููุฉ ุงูุฌุฒุงุฆุฑูุฉ \n #ุฌุงุฒู #ูุงุฆุฏุฉ_ุงูุจุณูุฉ #ุงููุดุงูุฉ_ุงูุฅุณูุงููุฉ_ุงูุฌุฒุงุฆุฑูุฉ",
         "https://www.facebook.com/share/v/1Dcy3GKWLV/",
         "65",
         "28",
         "3",
         "0",
         "0",
         "0",
         "0",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "42",
         "43",
         "ุชุงุจุนูุง ุงูุงุญุฏุงุซ ุงููุชููุนุฉ ูู ุญููุฉ ุงูููู ูู ุดุจู ุญุตุฉ 2 ูู ูุฐุง ุฑูุถุงู ๐ \nุดุงูุฏูุง  ุงูุญููุฉ ูุงููุฉ ุนูู ๐  https://youtu.be/iarixuw3n40\n#ุฌุงุฒู #ุดุจู_ุญุตุฉ2 #ุฑูุถุงู2024",
         "https://www.facebook.com/share/v/196vTS7ztN/",
         "49",
         "17",
         "2",
         "0",
         "0",
         "0",
         "1",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "43",
         "44",
         "ูุน  legend max ุงุณุชูุฏ ูู ููุงููุงุช ุบูุฑ ูุญุฏูุฏุฉ ูุญู ุฌููุน ุงูุดุจูุงุช ุงููุทููุฉ ู ุงูmax  ุชุงุน ุงูุงูุชุฑูุช ๐ \nูููุฒูุฏ ูู ุงูุชูุงุตูู : https://ms.spr.ly/6186cudnk\n#ุฌุงุฒู #ูุชุง_ูู_ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/p/15N1wg8V2N/",
         "133",
         "20",
         "4",
         "2",
         "0",
         "5",
         "4",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "44",
         "45",
         "ูุชููุชุด ุงูุนุฑุถ ูู ูุฐุง ุฑูุถุงู ๐ \nุญููู ุ ุงูุชููู ุ ู ุฏูุจูู โ๏ธ \nูุฐุง ูุงูู ุนูู ๐ https://ms.spr.ly/6181gi6y3\n#ุฌุงุฒู #ุฏูุจู_ุฃูุชุฑูุช #ุฑูุถุงู2024_ุฌุงุฒู_app",
         "https://www.facebook.com/share/v/19HbnWWpMa/",
         "37",
         "15",
         "1",
         "0",
         "0",
         "4",
         "0",
         "Djezzy",
         "2024-03-28 00:00:00"
        ],
        [
         "45",
         "46",
         "ุชุงุจุนูุง ุญููุฉ ุงูููู ูู ุดุจู ุญุตุฉ ูุน ูุฑุงุฏ ู ุฃุฑูุงู ๐ฌ\nููุดุงูุฏุฉ ุงูุญููุฉ ูุงููุฉ ๐ https://youtu.be/sqxb8u6ui-4",
         "https://www.facebook.com/share/v/1AewF1ZDSN/",
         "35",
         "16",
         "1",
         "0",
         "0",
         "0",
         "0",
         "Djezzy",
         "2024-03-28 00:00:00"
        ],
        [
         "46",
         "47",
         "ุฃูู ุดูุฑ super fans ุชุงุนูุง ุุดูุฑุง ุนูู ูุญุจุชูู ู ููุงุฆูู ูููุง ู ุชูุงุนููู ุงูุฏุงุฆู ูุนุงูุง ๐ฅฐ๐๐ป๐\nุตุญ ุณุญูุฑูู ๐",
         "https://www.facebook.com/share/v/15Z5g8V2Cs/",
         "76",
         "33",
         "5",
         "0",
         "0",
         "1",
         "0",
         "Djezzy",
         "2024-03-29 00:00:00"
        ],
        [
         "47",
         "48",
         "ุชุญุจ ุฏูุฑ ุจุฒุงู les stories ุ les reels ุ les photos ุบูุฑ djezzy legend ูู ุชุฎุฑุฌ ุนููู , 100 go ุฅูุชุฑูุช ู ุงูุช ูููู ๐ \nูููุฒูุฏ ูู ุงูุชูุงุตูู : https://ms.spr.ly/6186cudnk\n#ุฌุงุฒู #ูุชุง_ูู_ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/v/19aWCgdZW3/",
         "133",
         "20",
         "2",
         "0",
         "0",
         "2",
         "7",
         "Djezzy",
         "2024-03-30 00:00:00"
        ],
        [
         "48",
         "49",
         "ูุชููุง ุนุดุงู ุงูุฃูุนุงุจ ุงูุฅููุชุฑูููุฉ ๐ฎ๐น๏ธ ุชุญุจู ุชูุถูู ููุช ุดุจุงุจ ูุนูุงุ๐ฏ \nุฎููุช ูููู  #mobilistore  ุนูุดูุง ูุชุนุฉ ุงูุฃูุนุงุจ ูููุง  ๐๐๐\n#ููุจูููุณ #ูุนุง_ูุตูุน_ุงููุณุชูุจู",
         "https://www.facebook.com/share/p/18K8JuwacB/",
         "399",
         "38",
         "8",
         "0",
         "0",
         "1",
         "2",
         "Mobilis",
         "2024-01-04 00:00:00"
        ],
        [
         "49",
         "50",
         "ูุฑุนุฉ ุงูุฏูุฑูู ุงูู32 ูุงูู16 ููุฃุณ ุงูุฌุฒุงุฆุฑ ุงูุทุจุนุฉ 59 ๐โฝ๐ฉ๐ฟ\nุชุชุงุจุนูููุง ููู ุงูุฃุญุฏ 7 ุฌุงููู 2024 ุนูู ุงูุณุงุนุฉ 17:30โณ\n#ููุจูููุณ #ุงูุฑุงุนู_ูุงูุดุฑูู_ุงูุฑุณูู_ููุฃุณ_ุงูุฌุฒุงุฆุฑ\n#ูุนุง_ูุตูุน_ุงููุณุชูุจู",
         "https://www.facebook.com/share/p/15Y99MUo3z/",
         "612",
         "61",
         "7",
         "0",
         "0",
         "1",
         "0",
         "Mobilis",
         "2024-01-06 00:00:00"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 183
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Contents</th>\n",
       "      <th>Lien Post</th>\n",
       "      <th>Nb Like</th>\n",
       "      <th>Nb Love</th>\n",
       "      <th>Nb Care</th>\n",
       "      <th>Nb Wow</th>\n",
       "      <th>Nb Sad</th>\n",
       "      <th>Nb Angry</th>\n",
       "      <th>Nb Haha</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ุฌุงุฒู ุชุชูููู ููู ุณูุฉ ุณุนูุฏุฉ๐ฅฐ\\n#djezzy #happy_new...</td>\n",
       "      <td>https://www.facebook.com/djezzy/posts/78822751...</td>\n",
       "      <td>272</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>14</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ุฑุงู en panne ู ุฎุตู ุฑุตูุฏ ุ\\nูุน ุฎุฏูุฉ tranquilo ุช...</td>\n",
       "      <td>https://www.facebook.com/watch/?v=106882928102...</td>\n",
       "      <td>255</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>it's time to be a legend</td>\n",
       "      <td>https://www.facebook.com/djezzy/posts/39256499...</td>\n",
       "      <td>257</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>djezzy vous souhaite yennayer amervuh!  โดฐโตโตโดปโดณโดฐ...</td>\n",
       "      <td>https://www.facebook.com/share/p/19UDNBoQ1k/</td>\n",
       "      <td>621</td>\n",
       "      <td>231</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ูุฑูุจุงู ...</td>\n",
       "      <td>https://www.facebook.com/share/v/12B9LZySBRe/</td>\n",
       "      <td>288</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>179</td>\n",
       "      <td>ุฅุซุงุฑุฉ ุงูุฃูุนุงุจ ุชุชุนุงุด ูุน ุงูุฃุญุจุงุจุ ุฎุงุตุฉ ูู ooredo...</td>\n",
       "      <td>https://www.facebook.com/share/p/1KGHZQuXex/</td>\n",
       "      <td>208</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>ูุน ooredoo ุฏููุง ุฑุงุจุญูู !\\nูุฌูุฏูุง ููู ุญุงุฌุฉ ุฌุฏูุฏ...</td>\n",
       "      <td>https://www.facebook.com/share/v/1Bc7FtdDPx/</td>\n",
       "      <td>625</td>\n",
       "      <td>125</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>ุนุดูุง ูุน ุจุนุถ ุฃุฌูุงุก ุฑูุถุงููุฉ ุฑุงุฆุนุฉ ูู ุฎูุงู ุงูุฅูุทุง...</td>\n",
       "      <td>https://www.facebook.com/reel/954679512980806</td>\n",
       "      <td>280</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>182</td>\n",
       "      <td>ุถุงุนููุง ุงุดุชุฑุงู ุงูุฅูุชุฑูุช ุงูุฎุงุต ุจูู ุฎูุงู ุดูุฑ ุฑูุถุง...</td>\n",
       "      <td>https://www.facebook.com/watch/?v=193245186050...</td>\n",
       "      <td>148</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>183</td>\n",
       "      <td>ุฃูุชู ูู ุนุดุงู ุงูุณูููุง ุงูุนุฑุจูุฉุ ุญููููุง ุงูุชุทุจูู ุด...</td>\n",
       "      <td>https://www.facebook.com/OoredooDZ/posts/44139...</td>\n",
       "      <td>215</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows ร 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                           Contents  \\\n",
       "0      1  ุฌุงุฒู ุชุชูููู ููู ุณูุฉ ุณุนูุฏุฉ๐ฅฐ\\n#djezzy #happy_new...   \n",
       "1      2  ุฑุงู en panne ู ุฎุตู ุฑุตูุฏ ุ\\nูุน ุฎุฏูุฉ tranquilo ุช...   \n",
       "2      3                           it's time to be a legend   \n",
       "3      4  djezzy vous souhaite yennayer amervuh!  โดฐโตโตโดปโดณโดฐ...   \n",
       "4      5                                         ูุฑูุจุงู ...   \n",
       "..   ...                                                ...   \n",
       "178  179  ุฅุซุงุฑุฉ ุงูุฃูุนุงุจ ุชุชุนุงุด ูุน ุงูุฃุญุจุงุจุ ุฎุงุตุฉ ูู ooredo...   \n",
       "179  180  ูุน ooredoo ุฏููุง ุฑุงุจุญูู !\\nูุฌูุฏูุง ููู ุญุงุฌุฉ ุฌุฏูุฏ...   \n",
       "180  181  ุนุดูุง ูุน ุจุนุถ ุฃุฌูุงุก ุฑูุถุงููุฉ ุฑุงุฆุนุฉ ูู ุฎูุงู ุงูุฅูุทุง...   \n",
       "181  182  ุถุงุนููุง ุงุดุชุฑุงู ุงูุฅูุชุฑูุช ุงูุฎุงุต ุจูู ุฎูุงู ุดูุฑ ุฑูุถุง...   \n",
       "182  183  ุฃูุชู ูู ุนุดุงู ุงูุณูููุง ุงูุนุฑุจูุฉุ ุญููููุง ุงูุชุทุจูู ุด...   \n",
       "\n",
       "                                             Lien Post  Nb Like  Nb Love  \\\n",
       "0    https://www.facebook.com/djezzy/posts/78822751...      272       45   \n",
       "1    https://www.facebook.com/watch/?v=106882928102...      255       28   \n",
       "2    https://www.facebook.com/djezzy/posts/39256499...      257       51   \n",
       "3         https://www.facebook.com/share/p/19UDNBoQ1k/      621      231   \n",
       "4        https://www.facebook.com/share/v/12B9LZySBRe/      288       49   \n",
       "..                                                 ...      ...      ...   \n",
       "178       https://www.facebook.com/share/p/1KGHZQuXex/      208       46   \n",
       "179       https://www.facebook.com/share/v/1Bc7FtdDPx/      625      125   \n",
       "180      https://www.facebook.com/reel/954679512980806      280       40   \n",
       "181  https://www.facebook.com/watch/?v=193245186050...      148       35   \n",
       "182  https://www.facebook.com/OoredooDZ/posts/44139...      215       46   \n",
       "\n",
       "     Nb Care  Nb Wow  Nb Sad  Nb Angry  Nb Haha  Company       Date  \n",
       "0          0       1       1        76       14   Djezzy 2024-01-01  \n",
       "1          0       1       0        12       31   Djezzy 2024-01-04  \n",
       "2          2       0       0         2        8   Djezzy 2024-01-10  \n",
       "3         10       3       0         1      300   Djezzy 2024-01-11  \n",
       "4          4       0       0         3       24   Djezzy 2024-01-12  \n",
       "..       ...     ...     ...       ...      ...      ...        ...  \n",
       "178        6       0       0         0        1  Ooredoo 2024-03-26  \n",
       "179       14       0       1         1        1  Ooredoo 2024-03-27  \n",
       "180        7       1       1         0        0  Ooredoo 2024-03-28  \n",
       "181        3       0       0         2        0  Ooredoo 2024-03-28  \n",
       "182        5       0       0         1        0  Ooredoo 2024-03-30  \n",
       "\n",
       "[183 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = emoji.replace_emoji(text, replace=\" \")  # Supprimer les emojis\n",
    "    text = re.sub(r'http\\S+ | htps\\S+', \" \", str(text))  # Supprimer les hyperliens\n",
    "    text = re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+))', \" \", str(text))  # Supprimer les URL\n",
    "    text = re.sub(r'@\\S+', '', str(text))  # Supprimer les mots commenรงant par @\n",
    "    text = text.replace(\"_\", \" \").replace(\"#\", \"\")  # Supprimer # et _\n",
    "    text = text.replace(\"'\", \" \")  # Supprimer '\n",
    "    text = re.sub(r'\\. | , | ุ | ุ', \" \", text)  # Supprimer les ponctuations\n",
    "    \n",
    "    # Supprimer les mots rรฉservรฉs\n",
    "    text = re.sub(r'\\bRT\\b | \\bRetweeted\\b', \" \", text)\n",
    "\n",
    "    # Supprimer tout caractรจre spรฉcial sauf l'alphabet arabe et latin\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\u0600-\\u06FF\\s]', \" \", text)\n",
    "        \n",
    "    # Supprimer les voyelles courtes arabes (ุญุฑูุงุช)\n",
    "    harakat = \"[\\u064B-\\u0652]\"  # Comprend\n",
    "    text = re.sub(harakat, '', text)\n",
    "\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\", text)  # Supprimer les caractรจres consรฉcutifs en double\n",
    "    text = text.replace('\\n', \" \").replace('/', \" \")  # Supprimer sauts de ligne et /\n",
    "    text = re.sub(r'[^\\w\\s]', \" \", text)  # Supprimer les caractรจres spรฉciaux\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "comments_df[\"Comments\"] = comments_df[\"Comments\"].apply(clean_text)\n",
    "posts_df[\"Contents\"] = posts_df[\"Contents\"].apply(clean_text)\n",
    "\n",
    "# Remplacer les valeurs nulles par une chaรฎne vide\n",
    "comments_df[\"Comments\"] = comments_df[\"Comments\"].fillna('')\n",
    "posts_df[\"Contents\"] = posts_df[\"Contents\"].fillna('')\n",
    "\n",
    "comments_df = comments_df.dropna(subset=[\"Comments\"])\n",
    "comments_df = comments_df[comments_df[\"Comments\"].str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID Post",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comments",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiments",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment_Predicted",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f1be4f68-c8f3-402f-8eb5-71d6e49875ad",
       "rows": [
        [
         "1",
         "1",
         "Yanise Yanise",
         "ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ุชุนุจุฆุฉ 100 ุฏุฌ ู ุจุฏุฃุช ุชููุต ูููู ูููู ูู 100 ุฏุฌ ุฅูู 75ุฏุฌ ู ุจุนุฏูุง ุฅูู 50 ุฏุฌ ู ุจุนุฏูุง ุฅูู 25 ุฏุฌ ุงูู ุฐูุจุช ุฑุตูุฏ ุชุงุนู    ูู ุฃุชููู ุจูุง ู ูู ุงุชุตู ุจูุง ู ููุณ ูู ุฎุงุตูุฉ ุฑูุชู ุงุฐู ุงูู ุฐูุจ ูุงูู        ู ุตุงุฑ ููุณ ุงูุดูุก ูุน ุฃุฎู  ูุงูุฐุง ูุงุจุฏ ูู ุงุณุชุฑุฌุงุนู",
         "Negatif",
         "Negatif"
        ],
        [
         "2",
         "1",
         "Jj Kie",
         "ูู ุนุงู ู ุงูุชู ุจุฎูุฑ",
         "Positif",
         "Positif"
        ],
        [
         "3",
         "1",
         "Sakou Younes",
         "ูู ุนุงู ูุฃูุชู ุจุฎูุฑ",
         "Positif",
         "Neutre"
        ],
        [
         "4",
         "1",
         "ุฑุงูู ูุนุงูู",
         "ูู ุนุงู ูุญูุง ุจุฎูุฑ",
         "Positif",
         "Positif"
        ],
        [
         "7",
         "1",
         "ูุฑูุงู ุณูุฏูู ุณูุฏูู ูุฑูุงู",
         "ูู ุนุงู ูุฃูุชู ุจุฎูุฑ ูุฃุชููุง ุฑุฏ ููุงุฐุง ุงุณุฆูุฉ ููุงุฐุง ูุญุงุต ููู ุนุงู ูุฃูุชู ุจุฎูุฑ",
         "Positif",
         "Neutre"
        ],
        [
         "8",
         "1",
         "Mostefa Merabti",
         "ุณุนูุฏุฉ ุฌุฏูุฏุฉ ุณูุฉ",
         "Positif",
         "Positif"
        ],
        [
         "9",
         "1",
         "ูููุฏ ุจุฑู",
         "ุฃู ุนุฑูุถ ูุฏู ุฑู ูู 2024",
         "Neutre",
         "Neutre"
        ],
        [
         "10",
         "1",
         "Aymen Aymen",
         "ุชุญูุง ุฌุงุฒู",
         "Positif",
         "Positif"
        ],
        [
         "11",
         "1",
         "Maram Akram",
         "bonne annee a tous",
         "Positif",
         "Positif"
        ],
        [
         "13",
         "1",
         "Lina Sami",
         "ูููู ูุญูู ุนุฑูุถ ุฌุงุฒู ูููุฑุฏ ููู ูุฑุฌุนูุง ูุงููุฉ ูุซูุฑุง",
         "Neutre",
         "Positif"
        ],
        [
         "14",
         "1",
         "Yakoub Boussebsi",
         "ุณูุฉ ุณุนูุฏุฉ ูุฑุฌุนููุง 6h",
         "Positif",
         "Positif"
        ],
        [
         "15",
         "1",
         "Hamza Othmani",
         "ุจุฏุงูุฉ ุณูุฉ ุณูุฆุฉ ุฌุฏุง  ููุฏ ุซู ูุทุน ุดุจูุฉ ุถูู  ู ูุตูุญุฉ ุงูุฒุจุงุฆู ูุง ุชุฑุฏ  ุนูุจ",
         "Negatif",
         "Negatif"
        ],
        [
         "17",
         "1",
         "Mohamed Mellak",
         "ุนุงู ุณุนูุฏ 2024",
         "Positif",
         "Positif"
        ],
        [
         "19",
         "1",
         "Saber Zem",
         "ุฃูุง ูุดุชุฑู ุฏูุน ุจุนุฏู ุชู ุชุฒููุฏู ุจุฎุฏูุฉ chirpix ุฏูู ุนููู ูู 2 ุฏูุณูุจุฑ 2023  ูุนูุฏ ุงูุงุทูุงุน ุนูู ูุงุชูุฑุฉ ุดูุฑ ุฌุงููู ูุฌุฏุช ูุจูุบ 740 00 ุฏุฌ ุฒุงุฆุฏ ุนู ุงููุงุชูุฑุฉ ูุนูุฏ ุงูุงุณุชูุณุงุฑ ุนูุฏ ุฎุฏูุฉ ุงูุฒุจุงุฆู ูุงู ุจุณุจุจ chirpix  ุนููุง ุฃููู ูู ุฃุทูุจ ูุฐู ุงูุฎุฏูุฉ ุฃุจุฏุง",
         "Neutre",
         "Negatif"
        ],
        [
         "20",
         "1",
         "ุฌูุนูุฉ ุงูุญู ุฃุจูุงุก ุงูุบุฏ ูุนูุงุถุงุช -ูุตุฑ ุงูุฃุจุทุงู-",
         "ูุญูุทูู ุนููุง ุงูุง ูุฑูุชูุง ูุฑูุฉ ูุนูุงุถุงุช ุงูุชุงุจุนุฉ ูุจูุฏูุฉ ูุตุฑ ุงูุฃุจุทุงู ุฏุงุฆุฑุฉ ุนูู ูููุงู ููุงูุฉ ุณุทูู ุงู ุดุจูุฉ ุงูุชุฑูุช ุฌุงุฒู ุชูุนุฏู ุชูุงูุง ูู ูุฑูุชูุง ูุฑุฌู ูููู ุงูุฌุงุฏ ุญู ููุฐู ุงููุดููุฉ",
         "Negatif",
         "Negatif"
        ],
        [
         "21",
         "1",
         "Sรm Fรrรh Mehimdร",
         "ูู ูุฑุฉ ุชุณุฑููุง 50ุฏุฌ   ููุงุฐุง ูุงู ุชุฎูููุง ูุจุฏููุง ุงูุฎุท",
         "Negatif",
         "Negatif"
        ],
        [
         "22",
         "1",
         "ลรลรh ลฤhรฏr",
         "ูู ุนุงู ูุงูุชู ุจุงูู ุฎูุฑ",
         "Positif",
         "Positif"
        ],
        [
         "23",
         "1",
         "Sofiane Sofiane",
         "ููุงุฐุง ุฏูุชููู 50 ุฏุฌ ูู ูุฑุฉ ุฑุงูู ุฏูุฑููุงูู",
         "Negatif",
         "Negatif"
        ],
        [
         "24",
         "1",
         "Lamine Jseb",
         "ูุงุฐุง ุจูู ุดุจูุฉ ุงูููู   ูุง ููุฌุฏ ุงูุชุฑูุช ููุฐ 3 ุณุงุนุงุช",
         "Negatif",
         "Negatif"
        ],
        [
         "25",
         "1",
         "ใใฆใณใ ใณใฉใคใ",
         "ุจูุฏ ููุงุณุจุฉ ุชุจุฑุน ุนูููุง ุจ ุงูุชุฑูุช",
         "Neutre",
         "Positif"
        ],
        [
         "26",
         "1",
         "Bnamer Boutayeb",
         "ุงุตูุญูุง ุชุทุจูู ูุชุงุนูู",
         "Negatif",
         "Negatif"
        ],
        [
         "27",
         "1",
         "ใใใ ใฅ ใฅ",
         "ุงูุนูู ููุง ุฃู ุดูุก ุฎุงุต ุจ ุงูุชุฑูุช",
         "Neutre",
         "Negatif"
        ],
        [
         "28",
         "1",
         "ูููุด ุณููุฑ",
         "ูุง ููุฌุฏ ุงูุชุฑูุช",
         "Negatif",
         "Negatif"
        ],
        [
         "29",
         "1",
         "Fati Fati",
         "ูู 2006 ุฑุงูู ูุดุงุฑูุฉ ูุนุงูู ุฃู ููุงุฑ ูุฑุญููุง ุจูุฏูู",
         "Neutre",
         "Positif"
        ],
        [
         "30",
         "1",
         "Sofiane Renault Medea",
         "ุจุทูุกุฉ",
         "Negatif",
         "Negatif"
        ],
        [
         "31",
         "1",
         "Sifadine Mehdi",
         "ุดุจูุฉ ูุง ุจู ูุฐูุจ ู ูุฃุชู",
         "Negatif",
         "Negatif"
        ],
        [
         "32",
         "1",
         "Aรฑdลeรค Aรฑdลeรค",
         "ูุชู ุชุฑุฏูู ุดุจูุฉ",
         "Negatif",
         "Positif"
        ],
        [
         "33",
         "1",
         "Nabil Issam",
         "ุฑูููููุง ุฑุจ ุดุจูุฉ",
         "Negatif",
         "Negatif"
        ],
        [
         "34",
         "1",
         "Abdo Gros",
         "malheureusement le reseau etait coupe men 17h hata maintenant pour wala ูู plus c est ูู niveau d alger yahsra les autres wilaya ni excuses ni rien  mais bon ูู souhaitant une amelioration cette annee incha allah",
         "Negatif",
         "Negatif"
        ],
        [
         "36",
         "2",
         "Abdelghani Tahtah",
         "ูุงูู ูู ุงูููุฏ ุฎุงุต ุจ ูุฑุถ",
         "Neutre",
         "Neutre"
        ],
        [
         "37",
         "2",
         "ุฃุญูุฏ ููุฑุงุณ",
         "ุฌูุฏ",
         "Positif",
         "Positif"
        ],
        [
         "38",
         "2",
         "ลล ลล",
         "ูููุงู ูุณูู ุนุดุฑุงูุงู",
         "Neutre",
         "Negatif"
        ],
        [
         "40",
         "2",
         "Riad BM",
         "ูู ูุจุนุซูู 2 ุฌูุบุง",
         "Neutre",
         "Negatif"
        ],
        [
         "41",
         "2",
         "Amine Boudiaf",
         "ุฑุฌุนููุง ุนุฑูุถ ุงูุชูุงุฒ ูู ูุฒุน ููุง",
         "Negatif",
         "Negatif"
        ],
        [
         "42",
         "2",
         "ุฒูู ุงูุฏูู ุงุจู ุงูุจูุงุฏู",
         "ุฃูุฏ ูุนุฑูุฉ ููููุฉ ุณุฑูุฉ ุฑุตูุฏู   ุงูุฑุฌุงุก ุงูุชูุถูุญ ูู ุฑูููู ูู ุฌุงุฒู ุฏุงุฆูุง ูุง ุงุฌุฏ ุงูุฑุตูุฏ djezzy",
         "Negatif",
         "Negatif"
        ],
        [
         "43",
         "2",
         "Amani Amina",
         "ููู ุฑูู ุฎุฏูุฉ ุณููู",
         "Neutre",
         "Negatif"
        ],
        [
         "44",
         "2",
         "ุงูุนุฑุจู ููุงูู",
         "ูููู ูุนุฑู ููุงุฐุง ุชููุตู ูู ุงูุฑุตูุฏ ูุงููู ุงูุนุธูู ุนูุจ ุนูุจ ุนูุจ ุชุนุจุฆุฉ 50 ุงูู ุบุฏุง ุชุฌุฏ 20 ุงูู ุนูุจ ุญุณุจูุง ุงููู ููุนู ุงููููู",
         "Negatif",
         "Negatif"
        ],
        [
         "45",
         "2",
         "Yassine Madrid",
         "ูู ูุถููู ุดุฑูุช ุดุฑูุญุฉ ุฌุงุฒู ุฌุฏูุฏุฉ ูููุงู ุชูุนูู ูุน ุงูุนูู ูููุง 60g ุงูุชุฑูุช ู 70 ููุงููุงุช",
         "Neutre",
         "Positif"
        ],
        [
         "46",
         "2",
         "Aoudjia Aimen",
         "ูุง ุจู ุชุทุจูู ุญุงุจุณ ุงู ุงุตูุญูุง ุงุตูุญูุง ุดุจูุฉ ูุญู ูุนุงููู 2024 ูุฑูุฒู ููุช ูู ุญุงูุง ูุงููู ูุง ููููุง ูููููุชุด ููุงุฐุง ูุญู ูุงูุนุงูู ุงูุซุงูุซ  ุงูุณุจุจ ุงููุญูุฏ ูุง ุบูุฑู ูู ูุฎูููุง ูุงูุนุงูู ุงูุซุงูุซ ุงูู ูุง ููุฌุฏ ุนุงูู ุฑุงุจุน ุงู ุฎุงูุณ",
         "Negatif",
         "Negatif"
        ],
        [
         "47",
         "2",
         "ุตุงุญุจุฉ ุงูุณุนุงุฏุฉ",
         "ุนูุงุจููุง ุงุตุจุญุชู ุชุนุจุฆุฉ ุชุฏููู",
         "Negatif",
         "Negatif"
        ],
        [
         "48",
         "2",
         "ุนุงุฆุดุฉ ุตุฏููุฉ",
         "djezzy ูู ูุถููู ุฃุฑูุฏ ุชูุทูุน ุงูุดุฑูุญุฉ ูุชูุงุณุจ ุงููุงุชู  ููู ูุฐุง ุงูุง ูููู ูุน ุดุฑูุญุชู ุงูุญุงููุฉ ูู ูููู ุงุณุชุจุฏุงููุง ูุน ุฃุฎุฑู ูุงุจูุฉ ูุชูุทูุน ูุน ุดุฑุท ุงูุงุญุชูุงุธ ุจุฑููู ุงูุญุงูู",
         "Neutre",
         "Positif"
        ],
        [
         "49",
         "2",
         "Youcef Mellah",
         "ูุญู ูุณููู 150 ูุดูุฑ ู ุงูุชุฑูุช ุฑุจู ูุฌูุจ ูููู ุชูุถูุญ",
         "Negatif",
         "Negatif"
        ],
        [
         "50",
         "2",
         "Mar Lyn",
         "ุชุฎุฏูู ุงูุฌูุนุฉ",
         "Neutre",
         "Neutre"
        ],
        [
         "51",
         "2",
         "Oussama Chabane",
         "ุงูุญู",
         "Neutre",
         "Positif"
        ],
        [
         "52",
         "2",
         "Sifoune Soufyane",
         "ูู ุงูุฑูู 455 ุฎุงุต ุจูู ูููุงุฐุง ูุชุตู ุจู",
         "Neutre",
         "Negatif"
        ],
        [
         "53",
         "2",
         "Mohamed Rakmouche",
         "ุทุฑููุฉ ูููุณู ูู ุฌุงุฒู ุฅูู ุฌุงุฒู",
         "Neutre",
         "Positif"
        ],
        [
         "54",
         "2",
         "ลธรตn รs",
         "ุงุตูุญูุง ุดุจูุฉ ุฑุญูุฉ ุนูู ูุงูุฏููู",
         "Negatif",
         "Negatif"
        ],
        [
         "55",
         "2",
         "Kh Khaled",
         "ุงุญุชุงุฌ ุฅูุชุฑูุช ุชูุดู ุนุงุฏู",
         "Neutre",
         "Neutre"
        ],
        [
         "56",
         "2",
         "Sid Ali Haciane",
         "ุดุจูุฉ ุฌุงุฒู ูุง ููุฌุฏ ูููุฏููู ูุง ููุฌุฏ",
         "Negatif",
         "Negatif"
        ],
        [
         "57",
         "2",
         "รyรตub ฤคaลni",
         "ุงุฑูุฏ ุทุฑุญ ุดููุง",
         "Negatif",
         "Negatif"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3469
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Post</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>Sentiment_Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yanise Yanise</td>\n",
       "      <td>ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ุชุนุจุฆุฉ 100 ุฏุฌ ู ุจุฏุฃ...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jj Kie</td>\n",
       "      <td>ูู ุนุงู ู ุงูุชู ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sakou Younes</td>\n",
       "      <td>ูู ุนุงู ูุฃูุชู ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Neutre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ุฑุงูู ูุนุงูู</td>\n",
       "      <td>ูู ุนุงู ูุญูุง ุจุฎูุฑ</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>ูุฑูุงู ุณูุฏูู ุณูุฏูู ูุฑูุงู</td>\n",
       "      <td>ูู ุนุงู ูุฃูุชู ุจุฎูุฑ ูุฃุชููุง ุฑุฏ ููุงุฐุง ุงุณุฆูุฉ ููุงุฐุง ...</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Neutre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4102</th>\n",
       "      <td>183</td>\n",
       "      <td>Kร Nรธ</td>\n",
       "      <td>ุงุตูุญูุง ุงูุชุฑูุช ุงูุง ุงูุนุงุจ ุฎุณุฑุช ูู ูู ุจุงุฑุทูุง ูู ุฃ...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105</th>\n",
       "      <td>183</td>\n",
       "      <td>Noรฉ Noรฉ</td>\n",
       "      <td>ุฑูุถุงู ูุฑูู</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>183</td>\n",
       "      <td>Kolรฉa Kolรฉa</td>\n",
       "      <td>ุฑูุถุงู ูุฑูู</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>183</td>\n",
       "      <td>Oussama Zhm</td>\n",
       "      <td>walah connexion ta3koum rahi t3ayi lyamat hado...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>183</td>\n",
       "      <td>B-m Lamine</td>\n",
       "      <td>ุณูุงู ุนูููู ุงูุฑูุฏู ุนูุฏู ูุดูู ูู ูุฑุฉ ุชุนุจุฆุฉ ูุฒุน ุฎ...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3469 rows ร 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Post                User Name  \\\n",
       "1           1            Yanise Yanise   \n",
       "2           1                   Jj Kie   \n",
       "3           1             Sakou Younes   \n",
       "4           1               ุฑุงูู ูุนุงูู   \n",
       "7           1  ูุฑูุงู ุณูุฏูู ุณูุฏูู ูุฑูุงู   \n",
       "...       ...                      ...   \n",
       "4102      183                    Kร Nรธ   \n",
       "4105      183                  Noรฉ Noรฉ   \n",
       "4114      183              Kolรฉa Kolรฉa   \n",
       "4120      183              Oussama Zhm   \n",
       "4122      183               B-m Lamine   \n",
       "\n",
       "                                               Comments Sentiments  \\\n",
       "1     ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ุชุนุจุฆุฉ 100 ุฏุฌ ู ุจุฏุฃ...    Negatif   \n",
       "2                                    ูู ุนุงู ู ุงูุชู ุจุฎูุฑ    Positif   \n",
       "3                                     ูู ุนุงู ูุฃูุชู ุจุฎูุฑ    Positif   \n",
       "4                                      ูู ุนุงู ูุญูุง ุจุฎูุฑ    Positif   \n",
       "7     ูู ุนุงู ูุฃูุชู ุจุฎูุฑ ูุฃุชููุง ุฑุฏ ููุงุฐุง ุงุณุฆูุฉ ููุงุฐุง ...    Positif   \n",
       "...                                                 ...        ...   \n",
       "4102  ุงุตูุญูุง ุงูุชุฑูุช ุงูุง ุงูุนุงุจ ุฎุณุฑุช ูู ูู ุจุงุฑุทูุง ูู ุฃ...    Negatif   \n",
       "4105                                         ุฑูุถุงู ูุฑูู    Positif   \n",
       "4114                                         ุฑูุถุงู ูุฑูู    Positif   \n",
       "4120  walah connexion ta3koum rahi t3ayi lyamat hado...    Negatif   \n",
       "4122  ุณูุงู ุนูููู ุงูุฑูุฏู ุนูุฏู ูุดูู ูู ูุฑุฉ ุชุนุจุฆุฉ ูุฒุน ุฎ...    Negatif   \n",
       "\n",
       "     Sentiment_Predicted  \n",
       "1                Negatif  \n",
       "2                Positif  \n",
       "3                 Neutre  \n",
       "4                Positif  \n",
       "7                 Neutre  \n",
       "...                  ...  \n",
       "4102             Negatif  \n",
       "4105             Positif  \n",
       "4114             Positif  \n",
       "4120             Negatif  \n",
       "4122             Negatif  \n",
       "\n",
       "[3469 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Contents",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Lien Post",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Nb Like",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Love",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Care",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Wow",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Sad",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Angry",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Haha",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e65b73ac-bdbe-438b-9b61-b54f4ff29fcc",
       "rows": [
        [
         "0",
         "1",
         "ุฌุงุฒู ุชุชููู ููู ุณูุฉ ุณุนูุฏุฉ  djezzy happy new year 2024",
         "https://www.facebook.com/djezzy/posts/788227516669599?ref=embed_post",
         "272",
         "45",
         "0",
         "1",
         "1",
         "76",
         "14",
         "Djezzy",
         "2024-01-01 00:00:00"
        ],
        [
         "1",
         "2",
         "ุฑุงู en panne ู ุฎุตู ุฑุตูุฏ ุ ูุน ุฎุฏูุฉ tranquilo ุชุงุน djezzy ููุด ุณุงูู  ุฌุงุฒู astuces ุณุงููุฉ",
         "https://www.facebook.com/watch/?v=1068829281022985&ref=sharing",
         "255",
         "28",
         "0",
         "1",
         "0",
         "12",
         "31",
         "Djezzy",
         "2024-01-04 00:00:00"
        ],
        [
         "2",
         "3",
         "it s time to be a legend",
         "https://www.facebook.com/djezzy/posts/392564993435969:392564993435969?ref=embed_post",
         "257",
         "51",
         "2",
         "0",
         "0",
         "2",
         "8",
         "Djezzy",
         "2024-01-10 00:00:00"
        ],
        [
         "3",
         "4",
         "djezzy vous souhaite yennayer amervuh!  โดฐโตโตโดปโดณโดฐโต โดฐโตโดปโดณโดฐโตฃ 2974  ! ุฌุงุฒู ุชูุฏู ููู ุฃุญุฑ ุงูุชูุงูู ุจููุงุณุจุฉ ุงูุณูุฉ ุงูุฃูุงุฒูุบูุฉ ุงูุฌุฏูุฏุฉ djezzy yennayer 2974",
         "https://www.facebook.com/share/p/19UDNBoQ1k/",
         "621",
         "231",
         "10",
         "3",
         "0",
         "1",
         "300",
         "Djezzy",
         "2024-01-11 00:00:00"
        ],
        [
         "4",
         "5",
         "ูุฑูุจุง .",
         "https://www.facebook.com/share/v/12B9LZySBRe/",
         "288",
         "49",
         "4",
         "0",
         "0",
         "3",
         "24",
         "Djezzy",
         "2024-01-12 00:00:00"
        ],
        [
         "5",
         "6",
         "ู ููุงููุงุช ุบูุฑ ูุญุฏูุฏุฉ ูุญู ุฌููุน ุดุจูุงุช ุงูููุงู ู ุงูุซุงุจุช. ุจู 2500ุฏุฌ ููุท ! ูุชุง ูู ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/v/15R9u8sYHg/",
         "564",
         "157",
         "24",
         "0",
         "0",
         "7",
         "73",
         "Djezzy",
         "2024-01-13 00:00:00"
        ],
        [
         "6",
         "7",
         "ูุน ุฌุงุฒู legend ุฅุณุชูุฏ ูู ููุงููุงุช ูุฌุงููุฉ ูุญู ูู ุดุจูุงุช ุงูููุงู ู ุงูุซุงุจุช ! ูุญุฌู ุงูุชุฑูุช ูุตู ุฅูู ุบุงูุฉ 100 ุฌูุบุง ! ุฅูุชุดููุง ูุฒุงูุง ุงูุนุฑุถ ุงูุฌุฏูุฏ djezzy legend ุนูู  ูุชุง ูู ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/djezzy/posts/797321975760153?ref=embed_post",
         "438",
         "31",
         "5",
         "0",
         "0",
         "26",
         "52",
         "Djezzy",
         "2024-01-14 00:00:00"
        ],
        [
         "7",
         "8",
         "ุชูุชุน ุจุงูููุงููุงุช ุงููุฌุงููุฉ ูุญู ุฌููุน ุดุจูุงุช ุงูุฌูุงู  ูุงูุซุงุจุช ูุงุณุชูุฏ ูู 70ุฌูุบุง ุจ20 ุฏุฌ ููุท ! ุงุณุชูุดู ูู ุงููููุฒุงุช ุนูู  ูุชุง ูู ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/djezzy/posts/797937005698650?ref=embed_post",
         "428",
         "23",
         "4",
         "1",
         "1",
         "5",
         "52",
         "Djezzy",
         "2024-01-15 00:00:00"
        ],
        [
         "8",
         "9",
         "ูุน djezzy legend ุงูุช ูู ุงูู legend  ุจู 20ุฏุฌ ! ุชุญุตููุง ุนูู 70go ุงูุชุฑูุชุ ููุงููุงุช ุบูุฑ ูุญุฏูุฏุฉ ูุญู ุฌููุน ุดุจูุงุช ุงูุซุงุจุช ู ุงูููุงู !  ุฅูุชุดููุง ูุฒุงูุง djezzy legend ุนูู  ูุชุง ูู ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/v/12BG5K7FV8K/",
         "323",
         "37",
         "5",
         "0",
         "1",
         "2",
         "9",
         "Djezzy",
         "2024-01-20 00:00:00"
        ],
        [
         "9",
         "10",
         "goal algeria vs burkina faso football",
         "https://www.facebook.com/watch/?v=1346282365905418&ref=sharing",
         "170",
         "26",
         "1",
         "1",
         "0",
         "4",
         "2",
         "Djezzy",
         "2024-01-20 00:00:00"
        ],
        [
         "10",
         "11",
         "ูุน  pack 3ayla ูุชุฑุงุทู ุญุชู match  ุงุณุชูุงุฏ ูู modem 4g ู 150go ุงูุชุฑูุช ููุฏุฉ 6 ุฃุดูุฑ ุจ90ุฏุฌ   ูุน pack 3ayla supporty   ูุฑููู ูุน ุนุงููุชู  ููุฒูุฏ ูู ุงููุนูููุงุช ุฒูุฑูุง ูููุนูุง      djezzy match 3ayla",
         "https://www.facebook.com/watch/?v=1387729078503230&ref=sharing",
         "130",
         "8",
         "1",
         "1",
         "1",
         "2",
         "31",
         "Djezzy",
         "2024-01-23 00:00:00"
        ],
        [
         "11",
         "12",
         "ูุน zuni sport  ุนูู djezzy app ุชุงุจุน ููุงุนูุฏ ู ูุชุงุฆุฌ ุงููุจุงุฑูุงุช ูุญุธุฉ ุจูุญุธุฉ  ุญูู ุงูุชุทุจูู ุงูุขู  djezzy app zuni sport max foot",
         "https://www.facebook.com/share/p/13tcBA3rkg/",
         "189",
         "16",
         "3",
         "0",
         "0",
         "3",
         "11",
         "Djezzy",
         "2024-01-27 00:00:00"
        ],
        [
         "12",
         "13",
         "ุงูููู ูู ุงูููู ุงูุนุงููู ูุญูุงูุฉ ุงูุจูุงูุงุช ุชุฐููุฑ ุฃุณุงุณู ุจุฃูููุฉ ุงูุญูุงุธ ุนูู ุฎุตูุตูุชู ุนูู ุงูุฅูุชุฑูุช  ุญูุงูุฉ ุงูุจูุงูุงุช ุชูู ูู ูุงุญุฏ ููุง  aujourd hui, c est la journee mondiale de la protection des donnees un rappel essentiel de l importance de preserver votre vie privee en ligne la protection des donnees concerne chacun d entre  nous  protectiondesdonnees vieprivenligne djezzy",
         "https://www.facebook.com/share/p/15aRgkr5JS/",
         "161",
         "13",
         "2",
         "1",
         "0",
         "1",
         "11",
         "Djezzy",
         "2024-01-28 00:00:00"
        ],
        [
         "13",
         "14",
         "ุงุฎุชุจุฑ ูุนูููุงุชู ูู ูุฑุฉ ุงููุฏู   ูุญุงูู ุชููุฒ ุจูุณููุฉ ุดุฑุงุก ุจูููุฉ 100 ููููู ุณูุชูู ุฃุณุจูุนูุง  ูุง ุนููู ุบูุฑ ุชุญูู djezzy app ุนูู ุงูุฑุงุจุท  djezzy app djezzy win",
         "https://www.facebook.com/share/p/1AzBbfwqh1/",
         "229",
         "22",
         "5",
         "0",
         "0",
         "2",
         "9",
         "Djezzy",
         "2024-01-30 00:00:00"
        ],
        [
         "14",
         "15",
         "ุฃุฎุจุงุฑ ูุญููุฉ ุซูุงููุฉ ุฑูุงุถูุฉ   ูุน  djezzy scoop ููููุชู ุญุชู ุฎุจุฑ !   ููุงุดุชุฑุงู ุฅุชุตู ุนูู 404 ุฃู ุฃุฑุณู sms ุงูู ููุณ ุงูุฑูู djezzy scoop max news",
         "https://www.facebook.com/share/p/13yNkR5JW2/",
         "150",
         "7",
         "0",
         "0",
         "0",
         "1",
         "11",
         "Djezzy",
         "2024-01-31 00:00:00"
        ],
        [
         "15",
         "16",
         "ุดููู ูููู ูุนุฑู le code ุจุงุด ููุชููู double appel ุ ุฌุงุฒู astuces ุณุงููุฉ",
         "https://www.facebook.com/watch/?v=1497445130819223&ref=sharing",
         "325",
         "33",
         "4",
         "0",
         "0",
         "5",
         "6",
         "Djezzy",
         "2024-02-01 00:00:00"
        ],
        [
         "16",
         "17",
         "ูููุงุด ุชุชูุงุฏู ุชููู ุงูุฎุท ุฏูุงูู ุ ุชุงุจุน ุงูุญู ูู ุงูููุฏูู  ุฌุงุฒู astuces ุณุงููุฉ",
         "https://www.facebook.com/watch/?v=408877615031858&rdid=nscweaDh1ie6K7G0",
         "161",
         "18",
         "2",
         "0",
         "0",
         "3",
         "10",
         "Djezzy",
         "2024-02-15 00:00:00"
        ],
        [
         "17",
         "18",
         "ูู ุฑุงููู ูุงุฐ ุงููุฑุฉ ุนูุงุด ุฌููุง",
         "https://www.facebook.com/share/v/1CVK8AkWr6/",
         "202",
         "24",
         "2",
         "1",
         "0",
         "5",
         "18",
         "Djezzy",
         "2024-02-18 00:00:00"
        ],
        [
         "18",
         "19",
         "ุงูุถููุง ุฅูููุง โ ูู ูุจุงุฏุฑุฉ ุงูุจุณูุฉ walk for  ููุฑุณู ุงูุจุณูุฉ ูุน ุจุนุถ ูู ูู ุฎุทูุฉ. ุญูููุง  djezzy app ู ุญูููุง ุฎุทูุงุชูู ุฅูู ุชุจุฑุนุงุช ูููุฉ ุฑูุถุงู  ุฑุงุจุท ุงูุชุญููู  ุฌุงุฒู ููุฉ ุฑูุถุงู ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/p/14kGTVBiaXU/",
         "177",
         "19",
         "3",
         "0",
         "0",
         "13",
         "3",
         "Djezzy",
         "2024-02-19 00:00:00"
        ],
        [
         "19",
         "20",
         "ุจุงุด ููุฑุญู ุงููุงุณ ูู ูุฐุง ุฑูุถุงู ู ูุฑุณููุง ุงูุจุณูุฉ ุนูู ูุฌูู ุงูุตุงูููู  ููุง ููุดูุง ูุน ุจุนุถ ู ูุชุจุฑุนูุง ุจุฎุทูุงุชูุง ุนูู djezzy app  ุฑุงุจุท ุงูุชุญููู",
         "https://www.facebook.com/share/v/19nVrLQmjV/",
         "173",
         "17",
         "5",
         "0",
         "0",
         "0",
         "2",
         "Djezzy",
         "2024-02-20 00:00:00"
        ],
        [
         "20",
         "21",
         "ุดุงุฑู ูู ุชุญุฏู ุงููุดู ูุน ุตุญุงุจู ู ุณุฌู ุฎุทูุงุชู ูู ููุฏูู ู ุฃูุดุฑูุง ุนูู ุตูุญุชู ุทุงูู djeezy ูุน ูุงุดุชุงุบ  ุฌุงุฒู ููุฉ ุฑูุถุงู ุงูุจุณูุฉwalk4 ุฃุญุณู ููุฏูู  ุฑุงุญ ูุจุฑุทุงุฌูููุง ุนุจุฑ ุตูุญุชูุง  ุฑุงุจุท ุงูุชุทุจูู",
         "https://www.facebook.com/share/p/1ESi1iAD8L/",
         "299",
         "34",
         "3",
         "2",
         "1",
         "6",
         "52",
         "Djezzy",
         "2024-02-21 00:00:00"
        ],
        [
         "21",
         "22",
         "ุฎุทูุฉ ุณุงููุฉ ุจููุงุณุจุฉ ุดูุฑ ุฑูุถุงู ุงููุฑูู  ุฌุงุฒู astuces ุณุงููุฉ ููุฉ ุฑูุถุงู ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/v/19dwGJKfjm/",
         "181",
         "23",
         "3",
         "0",
         "0",
         "4",
         "1",
         "Djezzy",
         "2024-02-22 00:00:00"
        ],
        [
         "22",
         "23",
         "ุทุงูู ุตุงุญุจู  ููุดู ุจุงูุฒุฑุจุฉ  ุฌุงุฒู  ููุฉ ุฑูุถุงู ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/p/14KAHkwsXF/",
         "201",
         "23",
         "3",
         "0",
         "2",
         "4",
         "58",
         "Djezzy",
         "2024-02-23 00:00:00"
        ],
        [
         "23",
         "24",
         "ูู ูุงุญุฏ ููุชุจููุง ูู ุงูุชุนูููุงุช ุดุญุงู ูู ุฎุทูุฉ ูุดุงูุง ุนูู djezzy app  ูุฏุฑู ุดููู ุฑุงุญ ูููู le champion  ุ  ุฌุงุฒู ููุฉ ุฑูุถุงู ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/p/18BbsUNDKa/",
         "204",
         "18",
         "3",
         "0",
         "0",
         "3",
         "26",
         "Djezzy",
         "2024-02-24 00:00:00"
        ],
        [
         "24",
         "25",
         "ุงูุจุณูุฉ walk for ูุงุฒุงููุง ูุชูุงุตูุฉ    ุทุงูู ุตุงุญุจู ูู ูุงุฒุงู ูุงุดุงุฑูุด ูุนุงูุง  ุฌุงุฒู ููุฉ ุฑูุถุงู ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/v/17cPeTM5qo/",
         "111",
         "20",
         "0",
         "0",
         "0",
         "5",
         "9",
         "Djezzy",
         "2024-02-26 00:00:00"
        ],
        [
         "25",
         "26",
         "ูุดุงุฑููุง ูุนุงูู  top 10 ุชุน ุงูุจุณูุฉ walk for ุฅูุถููุง ุฅูููุงุ ูุงุฒููุง ูุชูุงุตููู ูู ุฃุฌู ุฑุณู ุงูุจุณูุฉ ูุน ุจุนุถ. ุฌุงุฒู ููุฉ ุฑูุถุงู ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/p/1BYQb7q2cL/",
         "185",
         "17",
         "1",
         "0",
         "0",
         "4",
         "10",
         "Djezzy",
         "2024-02-27 00:00:00"
        ],
        [
         "26",
         "27",
         "โ ูุจุงุฏุฑุฉ ุงูุจุณูุฉ  walk for ูุงุฒุงููุง ูุชูุงุตูุฉ ุฎุทูุงุชูุง ุฑุงุญ ุชูุฑุญ ุจุฒุงู ูุงุณ  ุญูููุง  djezzy app ู ุญูููุง ุฎุทูุงุชูู ุฅูู ุชุจุฑุนุงุช ูููุฉ ุฑูุถุงู  ุฑุงุจุท ุงูุชุญููู  ุฌุงุฒู ููุฉ ุฑูุถุงู ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/p/18KCQQmfLL/",
         "228",
         "30",
         "2",
         "0",
         "1",
         "3",
         "6",
         "Djezzy",
         "2024-02-29 00:00:00"
        ],
        [
         "27",
         "28",
         "ู ููุฃุณุจูุน ุงูุซุงูู ุงูุจุณูุฉ walk for ูุงุฒุงููุง ูุชูุงุตูุฉ ุจูุฌุงุญ ุจูุถู ุฎุทูุงุชูู   ุฌุงุฒู ููุฉ ุฑูุถุงู ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/v/12AywsCXXA3/",
         "128",
         "20",
         "0",
         "0",
         "0",
         "2",
         "4",
         "Djezzy",
         "2024-03-04 00:00:00"
        ],
        [
         "28",
         "29",
         "ูุดุงุฑููุง ูุนุงูู the best walkers  ููุฃุณุจูุน ุงูุซุงูู  ุฅูุถููุง ุฅูููุง ูู ุฃุฌู ุฑุณู ุงูุจุณูุฉ ูุน ุจุนุถ ูู ูุฐุง ุฑูุถุงู  ุฌุงุฒู ููุฉ ุฑูุถุงู ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/share/p/1Azzo8rf7E/",
         "167",
         "19",
         "0",
         "0",
         "0",
         "1",
         "2",
         "Djezzy",
         "2024-03-06 00:00:00"
        ],
        [
         "29",
         "30",
         "ูุฎุชุชู ูุจุงุฏุฑุฉ ุงูุจุณูุฉ walk for ุจุฃูุซุฑ ูู 821 ููููู ุฎุทูุฉ  ุดูุฑุง ุนูู ูุดุงุฑูุชูู ู ุฏุนููู ุงูููู ูุน ุจุนุถ ุตูุนูุง ุงูุจุณูุฉ   ุฌุงุฒู ููุฉ ุฑูุถุงู ุงูุจุณูุฉwalk4",
         "https://www.facebook.com/watch/?v=3419181848374064&rdid=OpVtNNOSdxW0g2eO",
         "110",
         "23",
         "1",
         "0",
         "0",
         "1",
         "1",
         "Djezzy",
         "2024-03-10 00:00:00"
        ],
        [
         "30",
         "31",
         "ุจุงุด ุชููู ูุดููุฑ ูุงุฒููู ุจุฒุงู ุงูุชุฑูุช   ู ุจุงุด ุชููู ุฃุณุทูุฑุฉ ูุงุฒููู djezzy legend   ุงูุชุดููุง ุชูุงุตูู ุงูุนุฑุถ ุนูู",
         "https://www.facebook.com/share/v/15kQvgwaYH/",
         "89",
         "15",
         "2",
         "0",
         "0",
         "1",
         "13",
         "Djezzy",
         "2024-03-11 00:00:00"
        ],
        [
         "31",
         "32",
         "ุญูู djezzy app ู ุดุงุฑู ูู ูุณุงุจูุฉ ุนูุฑุฉ ranati ูุดุฎุตูู   ุฑุงุจุท ุงูุชุทุจูู",
         "https://www.facebook.com/share/v/18BXF4DAnq/",
         "131",
         "37",
         "0",
         "0",
         "0",
         "0",
         "1",
         "Djezzy",
         "2024-03-11 00:00:00"
        ],
        [
         "32",
         "33",
         "ูุฐุง ุฑูุถุงู ุงููุฑุญุฉ ุฏูุจู  x2 ุนูู djezzy app  ุฑุงุจุท ุงูุชุทุจูู",
         "https://www.facebook.com/share/v/1FyzpbnWBQ/",
         "106",
         "30",
         "1",
         "1",
         "0",
         "2",
         "0",
         "Djezzy",
         "2024-03-12 00:00:00"
        ],
        [
         "33",
         "34",
         "ูุน djezzy app ุฏูุจูู ูุฑุญุชู ู ุงูุงูุชุฑูุช ุฏูุงูู  ุฑุงุจุท ุงูุชุทุจูู",
         "https://www.facebook.com/share/v/17z9TWBMWj/",
         "132",
         "20",
         "2",
         "0",
         "0",
         "2",
         "2",
         "Djezzy",
         "2024-03-13 00:00:00"
        ],
        [
         "34",
         "35",
         "ุจุงุด ุฏูุฑ ูุญุชูู ุฃุณุทูุฑู ูุงุฒููู ุนุฑุถ ุฃุณุทูุฑู  ุงูุชุดููุง ุงูุชูุงุตูู  ูุน djezzy legend ุงูุช ูู ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/p/1NTLjuLH4q/",
         "179",
         "22",
         "0",
         "1",
         "0",
         "3",
         "31",
         "Djezzy",
         "2024-03-14 00:00:00"
        ],
        [
         "35",
         "36",
         "ูุงูู ููุตููุง  sms ุจูู ุฑุจุญูุง ูู ูุณุงุจูุงุช ู ุญูุง ูุงุดุงุฑููุงุด ูููุง ! ูููุงุด ูุชูุงุฏููุง  ุ ุฌุงุฒู astuces ุณุงููุฉ ุฑูุถุงู2024",
         "https://www.facebook.com/share/v/1Ax3tK3yQf/",
         "71",
         "13",
         "1",
         "0",
         "0",
         "2",
         "0",
         "Djezzy",
         "2024-03-14 00:00:00"
        ],
        [
         "36",
         "37",
         "ุงูุชุฑูุช 2  ููุฏุฉ ุฃุณุจูุน ! ุญูู djezzy app ู ุงุณุชูุชุน ุจ10 ุฌูุบุง ููู ุนุฑุถ ุชุงุน 300 ุฏุฌ  ุฑุงุจุท ุงูุชุทุจูู  ุฌุงุฒู ุฏูุจู ุฃูุชุฑูุช ุฑูุถุงู2024 ุฌุงุฒู app",
         "https://www.facebook.com/share/v/1QvSNe3qr6/",
         "86",
         "16",
         "2",
         "0",
         "0",
         "8",
         "3",
         "Djezzy",
         "2024-03-17 00:00:00"
        ],
        [
         "37",
         "38",
         "ููููุชู double  2 ู ุฃูุฑุญ double  2 ูุน ุงูุชุฑูุช  double 2 ุญูู ุงูุชุทุจูู  ุฌุงุฒู ุฏูุจู ุฃูุชุฑูุช ุฑูุถุงู2024 ุฌุงุฒู app",
         "https://www.facebook.com/share/p/19cMcLv6sd/",
         "139",
         "18",
         "0",
         "0",
         "0",
         "4",
         "2",
         "Djezzy",
         "2024-03-17 00:00:00"
        ],
        [
         "38",
         "39",
         "ูุน ุนุฑุถ ุฌุงุฒู legend max ุงูุฌุฏูุฏุ ุงุณุชูุฏ ูู ููุงููุงุช ุบูุฑ ูุญุฏูุฏุฉ ูุญู ุฌููุน ุงูุดุจูุงุช ุงููุทููุฉ ูุญุฏ ุฃูุตู ูู ุงูุงูุชุฑูุช ! ูููุฒูุฏ ูู ุงูุชูุงุตูู :   ุฌุงุฒู ูุชุงููููุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/p/1Gxhnote12/",
         "163",
         "31",
         "1",
         "0",
         "0",
         "2",
         "1",
         "Djezzy",
         "2024-03-22 00:00:00"
        ],
        [
         "39",
         "40",
         "ูุน djezzy app ุฃุจูู ุฏุงููุง connecte ุจdouble    ุงุณุชูุชุน ุจ10 ุฌูุบุง ููุฏุฉ ุฃุณุจูุน  ุจ300 ุฏุฌ ููุท !  ุฑุงุจุท ุงูุชุทุจูู  ุฌุงุฒู ุฏูุจู ุฃูุชุฑูุช ุฑูุถุงู2024 ุฌุงุฒู app",
         "https://www.facebook.com/share/v/19THVFCcWA/",
         "64",
         "18",
         "0",
         "0",
         "0",
         "2",
         "2",
         "Djezzy",
         "2024-03-23 00:00:00"
        ],
        [
         "40",
         "41",
         "ุนูุฏู legend maxุ bien sรปr que ุงูุช ุงุณุทูุฑุฉ",
         "https://www.facebook.com/share/v/1EZyVsxH3S/",
         "91",
         "20",
         "0",
         "1",
         "0",
         "0",
         "6",
         "Djezzy",
         "2024-03-25 00:00:00"
        ],
        [
         "41",
         "42",
         "ุจุงูุดุฑุงูุฉ ูุน ุงููุดุงูุฉ ุงูุฅุณูุงููุฉ ุงูุฌุฒุงุฆุฑูุฉุ ุฌุงุฒู ุชุดุงุฑููู ุงูุฃุฌูุงุก ุงูุชุถุงูููุฉ ูู ูุทุนู ููุฌ ุงูุงู ูุงูุด ุจุจูุฏูุฉ ุงูุดุฑุงูุฉ. ุชุชููุฒ ูุฐู ุงููุจุงุฏุฑุฉ ุจูุณุงููุฉ ุงููุดุงููู ูู ูุฎุชูู ุงูุฃุนูุงุฑ  ูู ุงุฏุฎุงู ุงููุฑุญุฉ ูุฑุณู ุงูุจุณูุฉ ุนูู ูุฌูู ุงููุงุตุฏูู ู ุงูุนุงุจุฑูู ูู ูู ููุงู. ูู ูุฐุง ุฑูุถุงู ูุฑุณูู ุงูุจุณูุฉ  ูุน ุจุนุถ  ููุฌ ูฑูุงู ูุงูุด ุงููุดุงูุฉ ุงูุฅุณูุงููุฉ ุงูุฌุฒุงุฆุฑูุฉ   ุฌุงุฒู ูุงุฆุฏุฉ ุงูุจุณูุฉ ุงููุดุงูุฉ ุงูุฅุณูุงููุฉ ุงูุฌุฒุงุฆุฑูุฉ",
         "https://www.facebook.com/share/v/1Dcy3GKWLV/",
         "65",
         "28",
         "3",
         "0",
         "0",
         "0",
         "0",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "42",
         "43",
         "ุชุงุจุนูุง ุงูุงุญุฏุงุซ ุงููุชููุนุฉ ูู ุญููุฉ ุงูููู ูู ุดุจู ุญุตุฉ 2 ูู ูุฐุง ุฑูุถุงู  ุดุงูุฏูุง  ุงูุญููุฉ ูุงููุฉ ุนูู  ุฌุงุฒู ุดุจู ุญุตุฉ2 ุฑูุถุงู2024",
         "https://www.facebook.com/share/v/196vTS7ztN/",
         "49",
         "17",
         "2",
         "0",
         "0",
         "0",
         "1",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "43",
         "44",
         "ูุน  legend max ุงุณุชูุฏ ูู ููุงููุงุช ุบูุฑ ูุญุฏูุฏุฉ ูุญู ุฌููุน ุงูุดุจูุงุช ุงููุทููุฉ ู ุงูmax  ุชุงุน ุงูุงูุชุฑูุช  ูููุฒูุฏ ูู ุงูุชูุงุตูู :   ุฌุงุฒู ูุชุง ูู ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/p/15N1wg8V2N/",
         "133",
         "20",
         "4",
         "2",
         "0",
         "5",
         "4",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "44",
         "45",
         "ูุชููุชุด ุงูุนุฑุถ ูู ูุฐุง ุฑูุถุงู  ุญูู ุงูุชููู ู ุฏูุจูู  ูุฐุง ูุงูู ุนูู  ุฌุงุฒู ุฏูุจู ุฃูุชุฑูุช ุฑูุถุงู2024 ุฌุงุฒู app",
         "https://www.facebook.com/share/v/19HbnWWpMa/",
         "37",
         "15",
         "1",
         "0",
         "0",
         "4",
         "0",
         "Djezzy",
         "2024-03-28 00:00:00"
        ],
        [
         "45",
         "46",
         "ุชุงุจุนูุง ุญููุฉ ุงูููู ูู ุดุจู ุญุตุฉ ูุน ูุฑุงุฏ ู ุฃุฑูุงู   ููุดุงูุฏุฉ ุงูุญููุฉ ูุงููุฉ",
         "https://www.facebook.com/share/v/1AewF1ZDSN/",
         "35",
         "16",
         "1",
         "0",
         "0",
         "0",
         "0",
         "Djezzy",
         "2024-03-28 00:00:00"
        ],
        [
         "46",
         "47",
         "ุฃูู ุดูุฑ super fans ุชุงุนูุง ุุดูุฑุง ุนูู ูุญุจุชูู ู ููุงุฆูู ูููุง ู ุชูุงุนููู ุงูุฏุงุฆู ูุนุงูุง  ุตุญ ุณุญูุฑูู",
         "https://www.facebook.com/share/v/15Z5g8V2Cs/",
         "76",
         "33",
         "5",
         "0",
         "0",
         "1",
         "0",
         "Djezzy",
         "2024-03-29 00:00:00"
        ],
        [
         "47",
         "48",
         "ุชุญุจ ุฏูุฑ ุจุฒุงู les stories les reels les photos ุบูุฑ djezzy legend ูู ุชุฎุฑุฌ ุนููู 100 go ุฅูุชุฑูุช ู ุงูุช ูููู  ูููุฒูุฏ ูู ุงูุชูุงุตูู :   ุฌุงุฒู ูุชุง ูู ุงูุฃุณุทูุฑุฉ",
         "https://www.facebook.com/share/v/19aWCgdZW3/",
         "133",
         "20",
         "2",
         "0",
         "0",
         "2",
         "7",
         "Djezzy",
         "2024-03-30 00:00:00"
        ],
        [
         "48",
         "49",
         "ูุชููุง ุนุดุงู ุงูุฃูุนุงุจ ุงูุฅููุชุฑูููุฉ ุชุญุจู ุชูุถูู ููุช ุดุจุงุจ ูุนูุงุ   ุฎููุช ูููู  mobilistore  ุนูุดูุง ูุชุนุฉ ุงูุฃูุนุงุจ ูููุง  ููุจูููุณ ูุนุง ูุตูุน ุงููุณุชูุจู",
         "https://www.facebook.com/share/p/18K8JuwacB/",
         "399",
         "38",
         "8",
         "0",
         "0",
         "1",
         "2",
         "Mobilis",
         "2024-01-04 00:00:00"
        ],
        [
         "49",
         "50",
         "ูุฑุนุฉ ุงูุฏูุฑูู ุงูู32 ูุงูู16 ููุฃุณ ุงูุฌุฒุงุฆุฑ ุงูุทุจุนุฉ 59  ุชุชุงุจุนูููุง ููู ุงูุฃุญุฏ 7 ุฌุงููู 2024 ุนูู ุงูุณุงุนุฉ 17:30  ููุจูููุณ ุงูุฑุงุนู ูุงูุดุฑูู ุงูุฑุณูู ููุฃุณ ุงูุฌุฒุงุฆุฑ ูุนุง ูุตูุน ุงููุณุชูุจู",
         "https://www.facebook.com/share/p/15Y99MUo3z/",
         "612",
         "61",
         "7",
         "0",
         "0",
         "1",
         "0",
         "Mobilis",
         "2024-01-06 00:00:00"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 183
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Contents</th>\n",
       "      <th>Lien Post</th>\n",
       "      <th>Nb Like</th>\n",
       "      <th>Nb Love</th>\n",
       "      <th>Nb Care</th>\n",
       "      <th>Nb Wow</th>\n",
       "      <th>Nb Sad</th>\n",
       "      <th>Nb Angry</th>\n",
       "      <th>Nb Haha</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ุฌุงุฒู ุชุชููู ููู ุณูุฉ ุณุนูุฏุฉ  djezzy happy new yea...</td>\n",
       "      <td>https://www.facebook.com/djezzy/posts/78822751...</td>\n",
       "      <td>272</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>14</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ุฑุงู en panne ู ุฎุตู ุฑุตูุฏ ุ ูุน ุฎุฏูุฉ tranquilo ุชุง...</td>\n",
       "      <td>https://www.facebook.com/watch/?v=106882928102...</td>\n",
       "      <td>255</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>it s time to be a legend</td>\n",
       "      <td>https://www.facebook.com/djezzy/posts/39256499...</td>\n",
       "      <td>257</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>djezzy vous souhaite yennayer amervuh!  โดฐโตโตโดปโดณโดฐ...</td>\n",
       "      <td>https://www.facebook.com/share/p/19UDNBoQ1k/</td>\n",
       "      <td>621</td>\n",
       "      <td>231</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ูุฑูุจุง .</td>\n",
       "      <td>https://www.facebook.com/share/v/12B9LZySBRe/</td>\n",
       "      <td>288</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>179</td>\n",
       "      <td>ุฅุซุงุฑุฉ ุงูุฃูุนุงุจ ุชุชุนุงุด ูุน ุงูุฃุญุจุงุจุ ุฎุงุตุฉ ูู ooredo...</td>\n",
       "      <td>https://www.facebook.com/share/p/1KGHZQuXex/</td>\n",
       "      <td>208</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>ูุน ooredoo ุฏููุง ุฑุงุจุญูู ! ูุฌุฏูุง ููู ุญุงุฌุฉ ุฌุฏูุฏุฉ ...</td>\n",
       "      <td>https://www.facebook.com/share/v/1Bc7FtdDPx/</td>\n",
       "      <td>625</td>\n",
       "      <td>125</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>ุนุดูุง ูุน ุจุนุถ ุฃุฌูุงุก ุฑูุถุงููุฉ ุฑุงุฆุนุฉ ูู ุฎูุงู ุงูุฅูุทุง...</td>\n",
       "      <td>https://www.facebook.com/reel/954679512980806</td>\n",
       "      <td>280</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>182</td>\n",
       "      <td>ุถุงุนููุง ุงุดุชุฑุงู ุงูุฅูุชุฑูุช ุงูุฎุงุต ุจูู ุฎูุงู ุดูุฑ ุฑูุถุง...</td>\n",
       "      <td>https://www.facebook.com/watch/?v=193245186050...</td>\n",
       "      <td>148</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>183</td>\n",
       "      <td>ุฃูุชู ูู ุนุดุงู ุงูุณูููุง ุงูุนุฑุจูุฉุ ุญูููุง ุงูุชุทุจูู ุดุง...</td>\n",
       "      <td>https://www.facebook.com/OoredooDZ/posts/44139...</td>\n",
       "      <td>215</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows ร 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                           Contents  \\\n",
       "0      1  ุฌุงุฒู ุชุชููู ููู ุณูุฉ ุณุนูุฏุฉ  djezzy happy new yea...   \n",
       "1      2  ุฑุงู en panne ู ุฎุตู ุฑุตูุฏ ุ ูุน ุฎุฏูุฉ tranquilo ุชุง...   \n",
       "2      3                           it s time to be a legend   \n",
       "3      4  djezzy vous souhaite yennayer amervuh!  โดฐโตโตโดปโดณโดฐ...   \n",
       "4      5                                            ูุฑูุจุง .   \n",
       "..   ...                                                ...   \n",
       "178  179  ุฅุซุงุฑุฉ ุงูุฃูุนุงุจ ุชุชุนุงุด ูุน ุงูุฃุญุจุงุจุ ุฎุงุตุฉ ูู ooredo...   \n",
       "179  180  ูุน ooredoo ุฏููุง ุฑุงุจุญูู ! ูุฌุฏูุง ููู ุญุงุฌุฉ ุฌุฏูุฏุฉ ...   \n",
       "180  181  ุนุดูุง ูุน ุจุนุถ ุฃุฌูุงุก ุฑูุถุงููุฉ ุฑุงุฆุนุฉ ูู ุฎูุงู ุงูุฅูุทุง...   \n",
       "181  182  ุถุงุนููุง ุงุดุชุฑุงู ุงูุฅูุชุฑูุช ุงูุฎุงุต ุจูู ุฎูุงู ุดูุฑ ุฑูุถุง...   \n",
       "182  183  ุฃูุชู ูู ุนุดุงู ุงูุณูููุง ุงูุนุฑุจูุฉุ ุญูููุง ุงูุชุทุจูู ุดุง...   \n",
       "\n",
       "                                             Lien Post  Nb Like  Nb Love  \\\n",
       "0    https://www.facebook.com/djezzy/posts/78822751...      272       45   \n",
       "1    https://www.facebook.com/watch/?v=106882928102...      255       28   \n",
       "2    https://www.facebook.com/djezzy/posts/39256499...      257       51   \n",
       "3         https://www.facebook.com/share/p/19UDNBoQ1k/      621      231   \n",
       "4        https://www.facebook.com/share/v/12B9LZySBRe/      288       49   \n",
       "..                                                 ...      ...      ...   \n",
       "178       https://www.facebook.com/share/p/1KGHZQuXex/      208       46   \n",
       "179       https://www.facebook.com/share/v/1Bc7FtdDPx/      625      125   \n",
       "180      https://www.facebook.com/reel/954679512980806      280       40   \n",
       "181  https://www.facebook.com/watch/?v=193245186050...      148       35   \n",
       "182  https://www.facebook.com/OoredooDZ/posts/44139...      215       46   \n",
       "\n",
       "     Nb Care  Nb Wow  Nb Sad  Nb Angry  Nb Haha  Company       Date  \n",
       "0          0       1       1        76       14   Djezzy 2024-01-01  \n",
       "1          0       1       0        12       31   Djezzy 2024-01-04  \n",
       "2          2       0       0         2        8   Djezzy 2024-01-10  \n",
       "3         10       3       0         1      300   Djezzy 2024-01-11  \n",
       "4          4       0       0         3       24   Djezzy 2024-01-12  \n",
       "..       ...     ...     ...       ...      ...      ...        ...  \n",
       "178        6       0       0         0        1  Ooredoo 2024-03-26  \n",
       "179       14       0       1         1        1  Ooredoo 2024-03-27  \n",
       "180        7       1       1         0        0  Ooredoo 2024-03-28  \n",
       "181        3       0       0         2        0  Ooredoo 2024-03-28  \n",
       "182        5       0       0         1        0  Ooredoo 2024-03-30  \n",
       "\n",
       "[183 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    \"mrc\": \"merci\",\n",
    "    \"num\": \"numรฉro\",\n",
    "    \"numro\": \"numรฉro\",\n",
    "    \"nn\": \"non\",\n",
    "    \"bn\": \"bonne\",\n",
    "    \"topp\": \"top\",\n",
    "    \"ุดูู\": \"ูููู\",\n",
    "    \"ุดููุง\": \"ูููู\",\n",
    "    \"ูุฒูููุชู\": \"ุฑุตูุฏ\",\n",
    "    \"ุญูุง\": \"ูุญู\",\n",
    "    \"ุฃุณุฅูุชู\": \"ุงุณุฆูุฉ\",\n",
    "    \"ุญุงุต\": \"ุฎุงุต\",\n",
    "    \"ูุฏุงู\": \"ุจูููุง\",\n",
    "    \"ุฑุงูุง\": \"ูุญู\",\n",
    "    \"ุจูู\": \"ุญุณู\",\n",
    "    \"ุชูุณ\": \"ุฌููุน\",\n",
    "    \"ุณุจูุณูุงู\": \"ูููุฑุฏ\",\n",
    "    \"ุณุจูุงู\": \"ูููุฑุฏ\",\n",
    "    \"ุจุงู\": \"ููู\",\n",
    "    \"ุฒุงู\": \"ูุซูุฑุง\",\n",
    "    \"ุจุฒุงู\": \"ูุซูุฑุง\",\n",
    "    \"ูุชููู\": \"ูุชููู\",\n",
    "    \"ูุธููู\": \"ูุถููู\",\n",
    "    \"ุถูู\": \"ุธูู\",\n",
    "    \"ุฑุฏู\": \"ุฑุฏ\",\n",
    "    \"ุนูุงุด\": \"ููุงุฐุง\",\n",
    "    \"ุนูุงู\": \"ููุงุฐุง\",\n",
    "    \"ุนูุง\": \"ููุงุฐุง\",\n",
    "    \"ูุฐ\": \"ูุฐุง\",\n",
    "    \"ุชุจุฑุนู\": \"ุชุจุฑุน\",\n",
    "    \"ุงุจูููุงุณูู\": \"ุชุทุจูู\",\n",
    "    \"ุฃุจูููุงุณููู\": \"ุชุทุจูู\",\n",
    "    \"ุฃุจูููุงุณูู\": \"ุชุทุจูู\",\n",
    "    \"ุงูุฎุงุต ุจูู\": \"ูุชุงุนูู\",\n",
    "    \"ุฏูุฑูููุง\": \"ุงูุนูู ููุง\",\n",
    "    \"ุฏูุฑู\": \"ุงูุนูู\",\n",
    "    \"ูุญุง\": \"ูุฒุน\",\n",
    "    \"ุฏูุฑ\": \"ุงูุนู\",\n",
    "    \"ุญุงุฌุฉ\": \"ุดูุก\",\n",
    "    \"ูุชุน\": \"ุฎุงุต ุจ\",\n",
    "    \"ุชุงุน\": \"ุฎุงุต ุจ\",\n",
    "    \"ุชุน\": \"ุฎุงุต ุจ\",\n",
    "    \"ุฌุงูุจููู\": \"ุฑุฏ ุนูู\",\n",
    "    \"ูุดุชุงุฑูู\": \"ูุดุงุฑูุฉ\",\n",
    "    \"ุฑุญู\": \"ุงุฐูุจู\",\n",
    "    \"ูุฐู\": \"ูุฐู\",\n",
    "    \"ูุฑูุญ\": \"ูุฐูุจ\",\n",
    "    \"ูุฌู\": \"ูุฃุชู\",\n",
    "    \"ููุชุงู\": \"ูุชู\",\n",
    "    \"ููุชุงุด\": \"ูุชู\",\n",
    "    \"ููุชุด\": \"ูุชู\",\n",
    "    \"ุชุฑุฏูููุง\": \"ุชุฑุฏูู\",\n",
    "    \"ูุชุงุน\": \"ุฎุงุต ุจ\",\n",
    "    \"ุดููู\": \"ูู\",\n",
    "    \"ูุญูุชููุง\": \"ูุฒุน\",\n",
    "    \"ูุญูุชู\": \"ูุฒุน\",\n",
    "    \"ูุญูุช\": \"ูุฒุน\",\n",
    "    \"ุณูููู\": \"ูุฑุถ\",\n",
    "    \"ุณููููู\": \"ูุฑุถ\",\n",
    "    \"ุบุฏูุฉ\": \"ุบุฏุง\",\n",
    "    \"ุชููู\": \"ุชุฌุฏ\",\n",
    "    \"ูููู\": \"ุงุฌุฏ\",\n",
    "    \"ูุฃูุชููููุง\": \"ุชูุนูู\",\n",
    "    \"ูุฃูุชููู\": \"ุชูุนูู\",\n",
    "    \"ูุงูุชููู\": \"ุชูุนูู\",\n",
    "    \"ูุนุงููู\": \"ูุนุงููู\",\n",
    "    \"ูุนุงูู\": \"ูุนุงููู\",\n",
    "    \"ููุช ุญุงู\": \"ุฑุฏูุก\",\n",
    "    \"ููููุชุด\": \"ูู ุงููู\",\n",
    "    \"ุงูู\": \"ุงูู\",\n",
    "    \"ุนูุงุจุงูู\": \"ุงุนูู\",\n",
    "    \"ููุชู\": \"ุงุตุจุญุชู\",\n",
    "    \"ูููุชู\": \"ุงุตุจุญุชู\",\n",
    "    \"ุชุฏู\": \"ุชุงุฎุฐูู\",\n",
    "    \"ุงูู\": \"ุฅูู\",\n",
    "    \"ุฎุงุณุชูู\": \"ุงุญุชุงุฌ\",\n",
    "    \"ุฎุณุชูู\": \"ุงุญุชุงุฌ\",\n",
    "    \"ูุดู\": \"ุชุนูู\",\n",
    "    \"ูุดุง\": \"ุชุนูู\",\n",
    "    \"ุดูุง\": \"ุดููู\",\n",
    "    \"ุดููุช\": \"ุดููู\",\n",
    "    \"ุฒุฑู\": \"ุณูุก\",\n",
    "    \"ุฒูุฑู\": \"ุณูุก\",\n",
    "    \"ุณุฑููู\": \"ุฎุฏูุฉ\",\n",
    "    \"ุณุฑููุณ\": \"ุฎุฏูุฉ\",\n",
    "    \"ุฌูุฒู ุงุจ\": \"djezzy app\",\n",
    "    \"nchlh\": \"incha allah\",\n",
    "    \"riglou\": \"regler\",\n",
    "    \"bah\": \"pour\",\n",
    "    \"nwaliw\": \"devenir\",\n",
    "    \"ูุฑุงุญุด\": \"ูู\",\n",
    "    \"ูููุด\": \"ููุณู\",\n",
    "    \"ุชุนููุน\": \"ุชุนููู\",\n",
    "    \"ุฒุงุงู\": \"ูุซูุฑุง\",\n",
    "    \"khayan\": \"voleur\",\n",
    "    \"djezzyy\": \"djezzy\",\n",
    "    \"ููุฑุฏูุชุด\": \"ูู ุชุฑุฏ\",\n",
    "    \"ูุงุด\": \"ูุงุฐุง\",\n",
    "    \"ููุจุนุฏ\": \"ุจุนุฏ ุฐูู\",\n",
    "    \"ุชูุชุญุด\": \"ูุง ุชูุชุญ\",\n",
    "    \"ูุฏูุฑ\": \"ุงูุนู\",\n",
    "    \"ุฑุงู\": \"ุงุตุจุญ\",\n",
    "    \"ูุงุฒู\": \"ูุฌุจ\",\n",
    "    \"pix\": \"pixx\",\n",
    "    \"Twanty\": \"Twenty\",\n",
    "    \"orod\": \"prod\",\n",
    "    \"imtiyaaz\": \"imtiyaz\",\n",
    "    \"tm\": \"ok\",\n",
    "    \"ูู\": \"ุชู\",\n",
    "    \"ุฌุฏุงู\": \"ุฌุฏุง\",\n",
    "    \"ุฒูุจ\": \"ุฒุจู\",\n",
    "    \"ูููุทุฑุง\": \"ุนูุฏ\",\n",
    "    \"ุดุฑู\": \"ุดุฑุงุก\",\n",
    "    \"ุชูุจ\": \"ุฑุงุฆุน\",\n",
    "    \"ุฌุฒู\": \"ุฌุฒููุง\",\n",
    "    \"ูุงุณุฑ\": \"ูุซูุฑุง\",\n",
    "    \"golde\": \"gold\",\n",
    "    \"mknch\": \"introuvable\",\n",
    "    \"rani\": \"je suis\",\n",
    "    \"ุดูุฑุงููู\": \"ุดูุฑุง ููู\",\n",
    "    \"viv\": \"vive\",\n",
    "    \"ุนุชู\": \"ุงุฑุณู\",\n",
    "    \"ุจุนุช\": \"ุงุฑุณู\",\n",
    "    \"ูุงุฌููุณ\": \"ููุฑ\",\n",
    "    \"rpnd\": \"repond\",\n",
    "    \"prv\": \"prive\",\n",
    "    \"svp\": \"s il vous plais\",\n",
    "    \"yennayer\": \"ุณูุฉ\",\n",
    "    \"amervuh\": \"ุณุนูุฏุฉ\",\n",
    "    \"assgas\": \"assegas\",\n",
    "    \"asugas\": \"assegas\",\n",
    "    \"asegas\": \"assegas\",\n",
    "    \"amegaz\": \"amegas\",\n",
    "    \"amgaz\": \"amegas\",\n",
    "    \"amegaz\": \"amegas\",\n",
    "    \"amgaz\": \"amegas\",\n",
    "    \"amegaz\": \"amegas\",\n",
    "    \"ุฎุฎ\": \"ุถุญู\",\n",
    "    \"ูู\": \"ุถุญู\",\n",
    "    \"ุณุจู\": \"ุณุจูุณูุงู\",\n",
    "    \"ุดุจูููุดููุฑูู\": \"ุดุจูุฉ ูุดููุฑูู\",\n",
    "    \"ูุนุทูููุตุญู\": \"ูุนุทููู ุตุญุฉ\",\n",
    "    \"ูุดูู\": \"ุงู ุดุงุก ุงููู\",\n",
    "    \"ุนูุฏูุด\": \"ูุง ููุฌุฏ\",\n",
    "    \"ุฎูุธู\": \"ุชุฎููุถ\",\n",
    "    \"ูููุญุฉ\": \"ุญุณู\",\n",
    "    \"ูููุญู\": \"ุญุณู\",\n",
    "    \"ููู\": \"ู ุงููู\",\n",
    "    \"ูููุงุช\": \"ููุงููุงุช\",\n",
    "    \"ูููุชุง\": \"ูุชู\",\n",
    "    \"ุชุฏููุง\": \"ุชุงุฎุฐูู\",\n",
    "    \"felawen\": \"tous\",\n",
    "    \"ya\": \"il y a\",\n",
    "    \"en\": \"ูู\",\n",
    "    \"panne\": \"ุนุทู\",\n",
    "    \"happy\": \"ุณุนูุฏุฉ\",\n",
    "    \"koum\": \"votre\",\n",
    "    \"ayi\": \"faible\",\n",
    "    \"new\": \"ุฌุฏูุฏุฉ\",\n",
    "    \"year\": \"ุณูุฉ\",\n",
    "    \"years\": \"ุณูุฉ\",\n",
    "    \"ุดูู\": \"ูุง ูู\",\n",
    "    \"ูุฏุง\": \"ูุฐุง\",\n",
    "    \"ุดุงููุฌ\": \"ุชุญุฏู\",\n",
    "    \"li\": \"qui\",\n",
    "    \"bghi\": \"aime\",\n",
    "    \"ndirlo\": \"faire\",\n",
    "    \"yji\": \"viens\",\n",
    "    \"lah\": \"pourquoi\",\n",
    "    \"raho\": \"que il\",\n",
    "    \"hbs\": \"arret\",\n",
    "    \"ุจุฑ\": \"ููุท\",\n",
    "    \"ุจุฑู\": \"ููุท\",\n",
    "    \"ุบู\": \"ุงูุง\",\n",
    "    \"ุบูุฑ\": \"ุงูุง\",\n",
    "    \"ุงูู\": \"ุงูู\",\n",
    "    \"ุญุณูู\": \"ุงุตูุงุญ\",\n",
    "    \"ุณููู\": \"ุงุตูุงุญ\",\n",
    "    \"ุฌููุฏ\": \"legend\",\n",
    "    \"ูุฌุงูุฏ\": \"legend\",\n",
    "    \"ููุฌูุฏ\": \"legend\",\n",
    "    \"ุนูุฌุงู\": \"ูู ุฃุฌู\",\n",
    "    \"ุชุซูุงู\": \"ุจุทุก\",\n",
    "    \"ููู\": \"ููุช\",\n",
    "    \"ุจุบู\": \"ุงุฑุงุฏ\",\n",
    "    \"ูุจุบู\": \"ูุฑูุฏ\",\n",
    "    \"ูุจุบู\": \"ูุฑูุฏ\",\n",
    "    \"ุชูุฑุฌ\": \"ูุดุงูุฏุฉ\",\n",
    "    \"ูุงุชุด\": \"ูุจุงุฑุงุฉ\",\n",
    "    \"ุฑุฌุง\": \"ุฑุฌุงุก\",\n",
    "    \"ูุชูุดููุด\": \"ูุง ุชุนูู\",\n",
    "    \"ูุชูุณูููุด\": \"ูุง ุชุนูู\",\n",
    "    \"ูุงูุต\": \"ุงูุงูู\",\n",
    "    \"ุจูุงูุต\": \"ุงูุงูู\",\n",
    "    \"ุจูุงุตุฉ\": \"ุงูุงูู\",\n",
    "    \"ูุณูุณู\": \"ุงุณุฃู\",\n",
    "    \"ุงุฐ\": \"ุงุฐุง\",\n",
    "    \"ููุชู\": \"ุจูุง ุญุฏูุฏ\",\n",
    "    \"ุงููููุชู\": \"ุจูุง ุญุฏูุฏ\",\n",
    "    \"ุฎุณูู\": \"ุงุฑูุฏ\",\n",
    "    \"ุจุงุทู\": \"ูุฌุงูุง\",\n",
    "    \"ูููุฏ\": \"gold\",\n",
    "    \"ุชุนูู\": \"ุณูุก\",\n",
    "    \"ูุณููู\": \"ูุญุงููุฉ\",\n",
    "    \"ููุนุจู\": \"ูุนุจ\",\n",
    "    \"ููููู\": \"ุฃููู\",\n",
    "    \"ุนุจ\": \"ูุนุจ\",\n",
    "    \"ูู\": \"ููู\",\n",
    "    \"ุงููููููููุงุฌููุนุงูููููุงุฑุจ\": \"ุงููู ูููููุง ุฌููุน ุงูููู ูุงุฑุจ\",\n",
    "    \"congratulations\": \"ูุจุฑูู\",\n",
    "    \"berkaw\": \"arret\",\n",
    "    \"ser\": \"vole\",\n",
    "    \"ุชุฑุฏูุด\": \"ูุง ุชุฑุฏูู\",\n",
    "    \"ูุถุฑุช\": \"ุชูููุช\",\n",
    "    \"ุจุงุด\": \"ููู\",\n",
    "    \"ุชุญูู\": \"ุญู\",\n",
    "    \"ุชุญูู\": \"ุญู\",\n",
    "    \"ูููุง\": \"ููุง\",\n",
    "    \"ุญุถ\": \"ุญุธ\",\n",
    "    \"wech\": \"Quoi\",\n",
    "    \"ndirou\": \"faire\",\n",
    "    \"bach\": \"pour\",\n",
    "    \"nrebhou\": \"gagner\",\n",
    "    \"elfe\": \"mille\",\n",
    "    \"mabrok\": \"felicitations\",\n",
    "    \"koules\": \"tous\",\n",
    "    \"moucharikones\": \"participants\",\n",
    "    \"el\": \"les\",\n",
    "    \"mabrouk\": \"ูุจุฑูู\",\n",
    "    \"ุงุทูููุงูู\": \"ุงุนุทููุง ูู\",\n",
    "    \"ุดุงุจ\": \"ุฌููู\",\n",
    "    \"ูุนุทูููุงูุตุญุฉ\": \"ูุนุทููู ุงูุตุญุฉ\",\n",
    "    \"illa\": \"lent\",\n",
    "    \"woww\": \"wow\",\n",
    "    \"ูุงุฑุจ\": \"ูุง ุฑุจ\",\n",
    "    \"ููุดู\": \"ูู ุดูุก\",\n",
    "    \"ูููุชู\": \"ุชูุงุตู\",\n",
    "    \"ูุงููููููุชูุด\": \"ูุง ุฃุชูุงุตู\",\n",
    "    \"ูููุฒ\": \"yooz\",\n",
    "    \"ููุฒ\": \"yooz\",\n",
    "    \"ูุด\": \"ูุง ูู\",\n",
    "    \"ูุดูู\": \"ุงู\",\n",
    "    \"ุฏููุง\": \"dima\",\n",
    "    \"ุฑุงู\": \"ุงูู\",\n",
    "    \"ูุนุฌุจุชููุด\": \"ุณูุก\",\n",
    "    \"ุชุญุจุณูู\": \"ุชููู\",\n",
    "    \"ุงูุชุงุน\": \"ู\",\n",
    "    \"ููุณ\": \"plus\",\n",
    "    \"ุดูุฑุงูุฑูุฏู\": \"ุดูุฑุง ุฃูุฑูุฏู\",\n",
    "    \"ุฏุฑ\": \"ูุนู\",\n",
    "    \"ุฑูู\": \"ุงูู\",\n",
    "    \"ูุงูู\": \"ููุฌุฏ\",\n",
    "    \"ูุจุงุบุด\": \"ูุง ูุฑูุฏ\",\n",
    "    \"ููุฏูู\": \"ูุนุทููู\",\n",
    "    \"ูุฎุฑุฌู\": \"ุฎุฑูุฌ\",\n",
    "    \"ุงูุชุฑ\": \"ุฃูุซุฑ\",\n",
    "    \"ูุงููุดูุด\": \"ูุง ูุนูู\",\n",
    "    \"ุณูุงูุน\": \"ุณุงุนุฉ\",\n",
    "    \"ูุญุจุชุด\": \"ูุง\",\n",
    "    \"ุฌุงู\": \"ูุณุชุญูู\",\n",
    "    \"ุฌุงูู\": \"ูุณุชุญูู\",\n",
    "    \"ุชูุดูู\": \"ุชุนูู\",\n",
    "    \"ุฑููู\": \"ุฎุงุต\",\n",
    "    \"ูุงุน\": \"ูู\",\n",
    "    \"ููุฑุจุญุด\": \"ูุง ุฃุฑุจุญ\",\n",
    "    \"ููุฑุจุญูุด\": \"ูุง ุฃุฑุจุญ\",\n",
    "    \"ููุงุฑุน\": \"ุตุจุฑ\",\n",
    "    \"ููุชุญุชููุงููุด\": \"ูุง ุชูุชุญ\",\n",
    "    \"ุงุจููููู\": \"ุงุดุชุฑุงู\",\n",
    "    \"ูุณุงุฌ\": \"ุฑุณุงูุฉ\",\n",
    "    \"ุฑุฌุนู\": \"ุฑุฏ\",\n",
    "    \"ุตุญูุชู\": \"ุดูุฑุง\",\n",
    "    \"ูุงุชูุฌุฏ\": \"ูุง ุชูุฌุฏ\",\n",
    "    \"ูููุงุด\": \"ูุง ุฃุฌุฏ\",\n",
    "    \"ูุง ูููุงุด\": \"ูุง ุฃุฌุฏ\",\n",
    "    \"ูุฑูุฏู\": \"ุฑุตูุฏ\",\n",
    "    \"ุฑูุจููุฏููููุง\": \"ุฑุฏ\",\n",
    "    \"ุฌุฏ\": \"ุฌุฏุง\",\n",
    "    \"ููุญูููู\": \"ูุฒุน\",\n",
    "    \"ูุญุฐูููู\": \"ูุฒุน\",\n",
    "    \"ูุงุณููุช\": \"ูู ุงูุชุฑุถ\",\n",
    "    \"ูุฏุงูุฑุง\": \"ูู ุฃูุนู\",\n",
    "    \"ุฑุงูู\": \"ุฅููุง\",\n",
    "    \"ููุฑ\": \"ููุชุงุฒ\",\n",
    "    \"ูุงูู\": \"ููุชุงุฒ\",\n",
    "    \"ูููุญ\": \"ุฌูุฏ\",\n",
    "    \"ุดุงุจุฉ\": \"ุฌููู\",\n",
    "    \"ูุงุตูุญุชููุด\": \"ูุง ุชุนูู\",\n",
    "    \"ุฅุณุชูุงู\": \"ูุฑุถ\",\n",
    "    \"ุฎุต\": \"ุงุฑูุฏ\",\n",
    "    \"ูุงุฐ\": \"ูุฐุง\",\n",
    "    \"ุดุญุงู\": \"ูู\",\n",
    "    \"ุชุงูุชูููู\": \"ุชูุนูู\",\n",
    "    \"ุญุชุงู\": \"ูู\",\n",
    "    \"ูููุงุด\": \"ููู\",\n",
    "    \"ุบูุทุฉ\": \"ุฎุทุง\",\n",
    "    \"ุฎุชุงุฑูุช\": \"ุฎูุงุฑ\",\n",
    "    \"ุฏูุงูู\": \"ุฎุงุต ุจู\",\n",
    "    \"ุญุงุจ\": \"ุงุฑูุฏ\",\n",
    "    \"ููู\": \"ุฃู\",\n",
    "    \"ุงุจุนุซ\": \"ุงุฑุณุงู\",\n",
    "    \"goold\": \"gold\",\n",
    "    \"ูุงุชุฌุงูุจูุด\": \"ุนุฏู ุฑุฏ\",\n",
    "    \"ููุฏู\": \"ูุฏูุฉ\",\n",
    "    \"ูุงุดูุฑุงูุฌุงู\": \"ุดูุฑ ููุงูู\",\n",
    "    \"ูุฎูุตุด\": \"ูุง ุฃุฏูุน\",\n",
    "    \"ุงุจููุณ\": \"plus\",\n",
    "    \"ุชุฃูุชูููุง\": \"ุชูุนูู\",\n",
    "    \"ููู\": \"hayla\",\n",
    "    \"ูุงุฐู\": \"ูุฐู\",\n",
    "    \"ูุดูู\": \"ูุง ูู\",\n",
    "    \"ุฌุฒุงูุฑ\": \"ุฌุฒุงุฆุฑ\",\n",
    "    \"ูุนู\": \"ูุนูู\",\n",
    "    \"ูุงู\": \"ูููุง\",\n",
    "    \"ูุงุด\": \"ุงู\",\n",
    "    \"ูููุจู\": \"ููุทูุน\",\n",
    "    \"ูู\": \"ููู\",\n",
    "    \"ูุงููุดููู\": \"ูุง ูุนูู\",\n",
    "    \"ูุฏูุฑููู\": \"ุงุนูู ููู\",\n",
    "    \"ุชุชูุณุฎุฑู\": \"ุงุณุชูุฒุงุก\",\n",
    "    \"ุฑูุจููุฏูู\": \"ุฑุฏ\",\n",
    "    \"plais\" : \"ูู ูุธููู\",\n",
    "    \"ููุงู\": \"ููู\",\n",
    "    \"ูุฏูููุฏู\": \"ุทูุจ\",\n",
    "    \"ุฏุฎูุชู\": \"ุงุฏุฎุงู\",\n",
    "    \"ุงูุนุงูููู\": \"ุนุงูููุฉ\",\n",
    "    \"ูุงุช\": \"ุจูู\",\n",
    "    \"ุจูุงุช\": \"ุจูู\",\n",
    "    \"nechlh\": \"incha allah\",\n",
    "    \"jdida\": \"ุฌุฏูุฏ\",\n",
    "    \"ููููุง\": \"ููู\",\n",
    "    \"ุงูุฏูุฑ\": \"ุงูุนู\",\n",
    "    \"ุฐูู\": \"ุฏุงุฆูุง\",\n",
    "    \"ููู\": \"ุฃูู\",\n",
    "    \"ุฑุงูู\": \"ูู\",\n",
    "    \"ูุงูุฏูุช\": \"ูุฏู\",\n",
    "    \"ุญุดู\": \"ุฎุฏุนุฉ\",\n",
    "    \"ุญุดูุฉ\": \"ุฎุฏุนุฉ\",\n",
    "    \"ุงูุดุงุกุงูููุชููููููุตูุจู\": \"ุงู ุดุงุก ุงููู ุชููู ูู ูุตูุจู\",\n",
    "    \"ูุชููุงููู\": \"ุงุชููู\",\n",
    "    \"ุฑุงุญูุด\": \"ูู ูุฐูุจ\",\n",
    "    \"ุจุงุฏู\": \"ุจุงุฐู\",\n",
    "    \"ุงูู\": \"ุงูุฐู\",\n",
    "    \"ุชุบูููู\": \"ุบูู\",\n",
    "    \"ูููุฑูู\": \"ุฑูู\",\n",
    "    \"ูุณุชุฑุฌุนู\": \"ุงุณุชุฑุฌุงุน\",\n",
    "    \"ุฑุงูููู\": \"ranini\",\n",
    "    \"ุนููุจุฉ\": \"ุนุงูุจุฉ\",\n",
    "    \"ููุจ\": \"ุนุงูุจุฉ\",\n",
    "    \"ุญุทู\": \"ูุถุน\",\n",
    "    \"ูููุง\": \"ููุง\",\n",
    "    \"ุณุชูุฑุงุฑ\": \"ูุณุชูุฑ\",\n",
    "    \"ูุงุจูููุงุณูู\": \"ุชุทุจูู\",\n",
    "    \"ูุจูููุงุณูู\": \"ุชุทุจูู\",\n",
    "    \"ูุชูุดูุด\": \"ูุง ุชุนูู\",\n",
    "    \"ุญุจุณุชููุง\": \"ุชููู\",\n",
    "    \"ุญูุงู\": \"ุชุญููู\",\n",
    "    \"ูุฒุงู\": \"ููุฒุงู\",\n",
    "    \"ุฌูู\": \"ุฌูุฉ\",\n",
    "    \"ููุงุชุฑุฏุฏู\": \"ููุง ุชุชุฑุฏุฏู\",\n",
    "    \"ุฎุฏูููุนุฑูุถุงุทุงูู\": \"ุฎุฏูุฉ ู ุนุฑูุถ ุทุงูู\",\n",
    "    \"ููุนุงุตูุฉ\": \"ูู ุนุงุตูุฉ\",\n",
    "    \"nztjwice\": \" \",\n",
    "    \"refvf\": \" \",\n",
    "    \"b\": \" \",\n",
    "    \"br\": \" \",\n",
    "    \"ุงุจุงุฑ\": \"ูุจุงุฑู\",\n",
    "    \"ูุญูุถูู\": \"ูุญูุธูู\",\n",
    "    \"ูููุณ\": \"plus\",\n",
    "    \"ุชุงู\": \"ูุชู\",\n",
    "    \"ุจู\": \" \",\n",
    "    \"sagmou\": \"regler\",\n",
    "    \"ุดููุด\": \"switch\",\n",
    "    \"ุจุบูุฉ\": \"ุงุฑูุฏ\",\n",
    "    \"dialkom\": \"vous\",\n",
    "    \"sahel\": \"facile\",\n",
    "    \"toop\": \"top\",\n",
    "    \"ูููุก\": \"ูุจุฑูู\",\n",
    "    \"puse\": \"sim\",\n",
    "    \"pui\": \"puis\",\n",
    "    \"nerbah\": \"gagne\",\n",
    "    \"ghir\": \"sauf\",\n",
    "    \"ุจูุงู\": \"ุฌูุฏุง\",\n",
    "    \"ูุงุชูุดูุด\": \"ูุง ุชุนูู\",\n",
    "    \"ูุญุงูุถู\": \"ุญูุงุธ\",\n",
    "    \"ุชุฎูุงุต\": \"ุงูุชูุงุก\",\n",
    "    \"ูุชุนุฑูุด\": \"ูุง ุชุนูู\",\n",
    "    \"ุฎุงุตุชุง\": \"ุฎุงุตุฉ\",\n",
    "    \"ููู\": \"ู ูู\",\n",
    "    \"ุธู\": \"ุฏุงุฆูุง\",\n",
    "    \"ูุฏุฑุชู\": \"ูู ุชูุนูู\",\n",
    "    \"ูููุจููุณ\": \"ููุจูููุณ\",\n",
    "    \"ุฑุง\": \"ุงูู\",\n",
    "    \"ุตุฑ\": \"ุญุฏุซ\",\n",
    "    \"rah\": \"il est\",\n",
    "    \"gae\": \"tous\",\n",
    "    \"dok\": \"maintenant\",\n",
    "    \"ูุงุจูููุงุณููู\": \"ุชุทุจูู\",\n",
    "    \"ููุด\": \"ูู\",\n",
    "    \"ูุดุงุกุงููู\": \"ูุง ุดุงุก ุงููู\",\n",
    "    \"ุญุจุณ\": \"ุชููู\",\n",
    "    \"ุฒูุฏ\": \"ุงูุถุง\",\n",
    "    \"ุชุณุฑูู\": \"ุณุฑู\",\n",
    "    \"ุชุงูุชููู\": \"ุชูุนูู\",\n",
    "    \"ุฒูุนุงูุงุก\": \"ุฒุนูุงุก\",\n",
    "    \"ul\": \" \",\n",
    "    \"ูุฏุจ\": \"ูุฐุจ\",\n",
    "    \"ูููุฑุงุณููู\": \"ุชุจุฏูู\",\n",
    "    \"ุดุญ\": \"ูู\",\n",
    "    \"ูููุงุด\": \"ูุง ููุฌุฏ\",\n",
    "    \"ูุฌุงูุจ\": \"ุงุฌูุจ\",\n",
    "    \"ุฑุงุญุช\": \"ุฐูุจ\",\n",
    "    \"ูุชุณูุงุด\": \"ุณูุก\",\n",
    "    \"ุชุนูู\": \"ุฎุงุต ุจูู\",\n",
    "    \"ุญูุงูุงููุฉ\": \"ููุชุงุฒ\",\n",
    "    \"ุตุฑูููู\": \"ุณุฑู\",\n",
    "    \"ุตุฑู\": \"ุณุฑู\",\n",
    "    \"ูููู\": \"ุงูู\",\n",
    "    \"ุญูุฏููู\": \"ุญูุฏ ููู\",\n",
    "    \"ุฑุญูู\": \"ุฑุญูุงู\",\n",
    "    \"ูุดุงู\": \"ุดุงุก ุงููู\",\n",
    "    \"ูุงุดุงุก\": \"ูุง ุดุงุก\",\n",
    "    \"ุชูุญููู\": \"ูุฒุน\",\n",
    "    \"ุฎูุณูุงู\": \"ุฎูุณุฉ ุฃูู\",\n",
    "    \"ุฎูุณูุงู\": \"ุฎูุณุฉ ุฃูู\",\n",
    "    \"ููุนูุชูุงุด\": \"ูุง ุชูุนูู\",\n",
    "    \"ุณุฑูุชููู\": \"ุณุฑู\",\n",
    "    \"ููุฑูุฏู\": \"ุฑุตูุฏ\",\n",
    "    \"ุงูุชุฑูุชูุฑุงูุง\": \"ุงูู ุงูุชุฑูุช\",\n",
    "    \"ุชุนููู\": \"ุณูุก\",\n",
    "    \"ุชุนูู\": \"ุณูุก\",\n",
    "    \"ุถู\": \"ุงูุงู\",\n",
    "    \"ุฌุฒู\": \"ุฌุฒุงู\",\n",
    "    \"ูุดุงุก\": \"ุงู ุดุงุก\",\n",
    "    \"ุฅูุดุงุกุงููู\": \"ุงู ุดุงุก ุงููู\",\n",
    "    \"ูุดุงููู\": \"ุงู ุดุงุก ุงููู\",\n",
    "    \"ุดุงุกุงููู\": \"ุดุงุก ุงููู\"\n",
    "}\n",
    "\n",
    "def replace_abbreviations(text):\n",
    "    words = text.split()\n",
    "    return ' '.join([abbreviations[word] if word in abbreviations else word for word in words])\n",
    "\n",
    "comments_df['Comments'] = comments_df['Comments'].apply(replace_abbreviations)\n",
    "posts_df['Contents'] = posts_df['Contents'].apply(replace_abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# Dictionnaire de regroupement phonรฉtique\n",
    "phonetic_groups = {\n",
    "    \"ุชุนุจุฆุฉ\": [\"ููููููุณูู\", \"ูููููุณู\", \"ูููููุณูู\", \"ููููุณ\", \"ุชููููุณู\", \"ููููุณูููุง\", \"ูููุจูุณู\", \"ููููุณูุช\", \"ูุณู\", \"ููููุณู\"],\n",
    "    \"connexion\": [\"conx\", \"cnx\", \"ncx\", \"conexion\", \"connection\"],\n",
    "    \"reseau\": [\"wrizo\", \"rizo\", \"riso\", \"rysou\", \"resou\", \"risou\"],\n",
    "    \"ุงุตูุญูุง\": [\"ุฑููููู\", \"ุฑูููู\", \"ุตูุญู\", \"ุฑููููู\", \"ุตูุญููุง\", \"ุนุฏูู\", \"ุฑูุบูููุง\", \"ุฑูููู\", \"ุชุฑูุบููููุง\", \"ููุชุตูุญููููุง\", \"ุชุฑูููููุง\", \"ูุฑููููู\"],\n",
    "    \"ุดุจูุฉ\": [\"ุฑูุฒู\", \"ุงุฑูุฒู\", \"ุงูุฑูุฒู\", \"ุงุงุฑูุฒู\", \"ุฎุท\", \"ุฎุทู\", \"ุฑุฒู\"],\n",
    "    \"ูุง ุจู\": [\"ูุงุดู\", \"ูุดุจูู\", \"ุดุจูู\"],\n",
    "    \"ูุง ููุฌุฏ\": [\"ูุงูุงุด\", \"ููุงูุด\", \"ููุงุด\", \"ููุงุงุด\", \"ูุงูู\", \"ูุนูุฏูุด\", \"ุงูู\"], \n",
    "    \"ุฃู\": [\"ูุด\", \"ูุงุด\"],\n",
    "    \"ุงูุชุฑูุช\": [\"ูููููุณููู\", \"ููููุณูู\", \"ููููุฒููู\", \"ูููููุณูู\", \"ููุฏููู\", \"ุงูุชุฑูุงุช\", \"ุงูุชุฑููุช\",\"ูุชุฑูุช\", \"ุฃูุชุฑูุงุช\", \"ุงููููุณูู\", \"ุงูุงูุซุฑูุงุช\", \"ุงูุงูุชุฑูุช\", \"ุฃูุชุฑูุช\",  \"ุงุชุฑูุงุช\", \"ุงููููููุณููู\", \"ูุช\", \"ููููููุณูู\", \"ูููุณูู\", \"ูููููุณู\", \"ุงูุชุฑู\"],\n",
    "    \"ุฌุงุฒู\": [\"ุฌุงูุฒ\", \"ุฌุงุฒ\", \"ุฏุฌูุฒู\", \"ุฏุฌุฒู\", \"ุฌูุฒู\", \"ุฌุงูุฒู\"],\n",
    "    \"ุงุณูุงุณ\": [\"ุงุณููุงุณ\", \"ุงุตูุงุณ\", \"ุงุณููุงุณ\", \"ุงุณูุงุณ\"],\n",
    "    \"ุงููุงุฒ\": [\"ุฃูููุงุฒ\", \"ุงููุงุฒ\"],\n",
    "    \"ุฑูุฒ\": [\"ููุฏ\", \"ุฑุฒู\"],\n",
    "    \"ุจุงุฑู\": [\"ุจุงุฑู\", \"ุจูุงุฑ\", \"ุจุงุฑุงู\", \"ูุจุงุฑู\"],\n",
    "    \"ุดุฑูุญุฉ\": [\"ูุงุจูุณ\", \"ูุจูุณ\", \"ุจูุณ\", \"ูุงุจูุณ\", \"ูุจููุณ\", \"ููุจูุณ\", \"ุจูุณ\", \"ุณุจูุณู\", \"ูุจููุณ\", \"pis\"],\n",
    "    \"ุงูุฑูุฏู\": [\"ุงุฑูุฏูู\", \"ูุฃูุฑูุฏ\", \"ูุงุคุฑูุฏูุง\", \"ุงูุฑูุฏูุง\", \"ูุงูุฑูุฏู\", \"ุงุงูุฑูุฏู\", \"ุงุฑูุฏู\"],\n",
    "    \"ุงู ุดุงุก\": [\"ุฅูุดุงุก\", \"ูุดุงููู\", \"ุงูุดุงุก\"],\n",
    "    \"ilimite\": [\"ilm\", \"ilmt\", \"ilimiti\", \"ilim\"],\n",
    "}\n",
    "\n",
    "# Crรฉation dโun mapping inverse (pour accรฉlรฉrer la recherche)\n",
    "phonetic_mapping = {}\n",
    "for standard, variations in phonetic_groups.items():\n",
    "    for variant in variations:\n",
    "        phonetic_mapping[variant] = standard\n",
    "\n",
    "# Fonction de remplacement des variantes phonรฉtiques\n",
    "def replace_phonetic_variants(text):\n",
    "    words = text.split()\n",
    "    return ' '.join([phonetic_mapping[word] if word in phonetic_mapping else word for word in words])\n",
    "\n",
    "comments_df['Comments'] = comments_df['Comments'].apply(replace_phonetic_variants)\n",
    "posts_df['Contents'] = posts_df['Contents'].apply(replace_phonetic_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ุณูุงู ุนูููู ูุฑุญูุฉ ูุฏูุง ูุดููุฉ ! ุชุนุจุฆุฉ 100 ุฏุฌ ู ุจุฏุฃุช ุชููุต ูููู ูููู ูู 100 ุฏุฌ ุฅูู 75ุฏุฌ ู ุจุนุฏูุง ุฅูู 50 ุฏุฌ ู ุจุนุฏูุง ุฅูู 25 ุฏุฌ ! ุงูู ุฐูุจุช ุฑุตูุฏ ุชุงุนู ุ! ูู ุฃุชููู ุจูุง ู ูู ุงุชุตู ุจูุง ู ููุณ ูู ุฎุงุตูุฉ ุฑูุชู ุงุฐู ุงูู ุฐูุจ ูุงููุ!ุ!ุ!ุ ู ุตุงุฑ ููุณ ุงูุดูุก ูุน ุฃุฎู! ูุงูุฐุง ูุงุจุฏ ูู ุงุณุชุฑุฌุงุนู'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df[\"Comments\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ุฑุงู ูู ุนุทู ู ุฎุตู ุฑุตูุฏ ุ ูุน ุฎุฏูุฉ tranquilo ุฎุงุต ุจ djezzy ูู ุณุงูู ุฌุงุฒู astuces ุณุงููุฉ'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df[\"Contents\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: llama-cpp-python in c:\\users\\kikoo\\appdata\\roaming\\python\\python312\\site-packages (0.3.8)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kikoo\\appdata\\roaming\\python\\python312\\site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from llama-cpp-python) (1.26.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\kikoo\\appdata\\roaming\\python\\python312\\site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from llama-cpp-python) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\kikoo\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installer la bibliothรจque pour exรฉcuter GGUF\n",
    "%pip install llama-cpp-python tqdm\n",
    "\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modรจle\n",
    "model_path = \"models/DeepSeek-R1-Distill-Qwen-7B-Q8_0.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 30 key-value pairs and 339 tensors from models/DeepSeek-R1-Distill-Qwen-7B-Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = DeepSeek R1 Distill Qwen 7B\n",
      "llama_model_loader: - kv   3:                           general.basename str              = DeepSeek-R1-Distill-Qwen\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 7B\n",
      "llama_model_loader: - kv   5:                          qwen2.block_count u32              = 28\n",
      "llama_model_loader: - kv   6:                       qwen2.context_length u32              = 131072\n",
      "llama_model_loader: - kv   7:                     qwen2.embedding_length u32              = 3584\n",
      "llama_model_loader: - kv   8:                  qwen2.feed_forward_length u32              = 18944\n",
      "llama_model_loader: - kv   9:                 qwen2.attention.head_count u32              = 28\n",
      "llama_model_loader: - kv  10:              qwen2.attention.head_count_kv u32              = 4\n",
      "llama_model_loader: - kv  11:                       qwen2.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  12:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = deepseek-r1-qwen\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,152064]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,152064]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,151387]  = [\"ฤ ฤ\", \"ฤฤ ฤฤ\", \"i n\", \"ฤ t\",...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 151646\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% if not add_generation_prompt is de...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  25:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  26:                      quantize.imatrix.file str              = /models_out/DeepSeek-R1-Distill-Qwen-...\n",
      "llama_model_loader: - kv  27:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  28:             quantize.imatrix.entries_count i32              = 196\n",
      "llama_model_loader: - kv  29:              quantize.imatrix.chunks_count i32              = 128\n",
      "llama_model_loader: - type  f32:  141 tensors\n",
      "llama_model_loader: - type q8_0:  198 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q8_0\n",
      "print_info: file size   = 7.54 GiB (8.50 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 151661 '<|fim_suffix|>' is not marked as EOG\n",
      "load: control token: 151647 '<|EOT|>' is not marked as EOG\n",
      "load: control token: 151654 '<|vision_pad|>' is not marked as EOG\n",
      "load: control token: 151659 '<|fim_prefix|>' is not marked as EOG\n",
      "load: control token: 151646 '<๏ฝbeginโofโsentence๏ฝ>' is not marked as EOG\n",
      "load: control token: 151643 '<๏ฝendโofโsentence๏ฝ>' is not marked as EOG\n",
      "load: control token: 151644 '<๏ฝUser๏ฝ>' is not marked as EOG\n",
      "load: control token: 151645 '<๏ฝAssistant๏ฝ>' is not marked as EOG\n",
      "load: control token: 151650 '<|quad_start|>' is not marked as EOG\n",
      "load: control token: 151651 '<|quad_end|>' is not marked as EOG\n",
      "load: control token: 151652 '<|vision_start|>' is not marked as EOG\n",
      "load: control token: 151653 '<|vision_end|>' is not marked as EOG\n",
      "load: control token: 151655 '<|image_pad|>' is not marked as EOG\n",
      "load: control token: 151656 '<|video_pad|>' is not marked as EOG\n",
      "load: control token: 151660 '<|fim_middle|>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 22\n",
      "load: token to piece cache size = 0.9310 MB\n",
      "print_info: arch             = qwen2\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3584\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 28\n",
      "print_info: n_head_kv        = 4\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 7\n",
      "print_info: n_embd_k_gqa     = 512\n",
      "print_info: n_embd_v_gqa     = 512\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-06\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 18944\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.62 B\n",
      "print_info: general.name     = DeepSeek R1 Distill Qwen 7B\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 152064\n",
      "print_info: n_merges         = 151387\n",
      "print_info: BOS token        = 151646 '<๏ฝbeginโofโsentence๏ฝ>'\n",
      "print_info: EOS token        = 151643 '<๏ฝendโofโsentence๏ฝ>'\n",
      "print_info: EOT token        = 151643 '<๏ฝendโofโsentence๏ฝ>'\n",
      "print_info: PAD token        = 151643 '<๏ฝendโofโsentence๏ฝ>'\n",
      "print_info: LF token         = 198 'ฤ'\n",
      "print_info: FIM PRE token    = 151659 '<|fim_prefix|>'\n",
      "print_info: FIM SUF token    = 151661 '<|fim_suffix|>'\n",
      "print_info: FIM MID token    = 151660 '<|fim_middle|>'\n",
      "print_info: FIM PAD token    = 151662 '<|fim_pad|>'\n",
      "print_info: FIM REP token    = 151663 '<|repo_name|>'\n",
      "print_info: FIM SEP token    = 151664 '<|file_sep|>'\n",
      "print_info: EOG token        = 151643 '<๏ฝendโofโsentence๏ฝ>'\n",
      "print_info: EOG token        = 151662 '<|fim_pad|>'\n",
      "print_info: EOG token        = 151663 '<|repo_name|>'\n",
      "print_info: EOG token        = 151664 '<|file_sep|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU\n",
      "load_tensors: layer   1 assigned to device CPU\n",
      "load_tensors: layer   2 assigned to device CPU\n",
      "load_tensors: layer   3 assigned to device CPU\n",
      "load_tensors: layer   4 assigned to device CPU\n",
      "load_tensors: layer   5 assigned to device CPU\n",
      "load_tensors: layer   6 assigned to device CPU\n",
      "load_tensors: layer   7 assigned to device CPU\n",
      "load_tensors: layer   8 assigned to device CPU\n",
      "load_tensors: layer   9 assigned to device CPU\n",
      "load_tensors: layer  10 assigned to device CPU\n",
      "load_tensors: layer  11 assigned to device CPU\n",
      "load_tensors: layer  12 assigned to device CPU\n",
      "load_tensors: layer  13 assigned to device CPU\n",
      "load_tensors: layer  14 assigned to device CPU\n",
      "load_tensors: layer  15 assigned to device CPU\n",
      "load_tensors: layer  16 assigned to device CPU\n",
      "load_tensors: layer  17 assigned to device CPU\n",
      "load_tensors: layer  18 assigned to device CPU\n",
      "load_tensors: layer  19 assigned to device CPU\n",
      "load_tensors: layer  20 assigned to device CPU\n",
      "load_tensors: layer  21 assigned to device CPU\n",
      "load_tensors: layer  22 assigned to device CPU\n",
      "load_tensors: layer  23 assigned to device CPU\n",
      "load_tensors: layer  24 assigned to device CPU\n",
      "load_tensors: layer  25 assigned to device CPU\n",
      "load_tensors: layer  26 assigned to device CPU\n",
      "load_tensors: layer  27 assigned to device CPU\n",
      "load_tensors: layer  28 assigned to device CPU\n",
      "load_tensors: tensor 'token_embd.weight' (q8_0) (and 338 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =  7717.68 MiB\n",
      "........................................................................................\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 2048\n",
      "llama_init_from_model: n_ctx_per_seq = 2048\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 10000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 2048, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init:        CPU KV buffer size =   112.00 MiB\n",
      "llama_init_from_model: KV self size  =  112.00 MiB, K (f16):   56.00 MiB, V (f16):   56.00 MiB\n",
      "llama_init_from_model:        CPU  output buffer size =     0.58 MiB\n",
      "llama_init_from_model:        CPU compute buffer size =   304.00 MiB\n",
      "llama_init_from_model: graph nodes  = 986\n",
      "llama_init_from_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.name': 'DeepSeek R1 Distill Qwen 7B', 'general.architecture': 'qwen2', 'general.type': 'model', 'general.basename': 'DeepSeek-R1-Distill-Qwen', 'qwen2.block_count': '28', 'general.size_label': '7B', 'qwen2.context_length': '131072', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'qwen2.embedding_length': '3584', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '151646', 'qwen2.feed_forward_length': '18944', 'qwen2.attention.head_count': '28', 'qwen2.attention.head_count_kv': '4', 'tokenizer.ggml.padding_token_id': '151643', 'qwen2.rope.freq_base': '10000.000000', 'qwen2.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'deepseek-r1-qwen', 'general.file_type': '7', 'tokenizer.ggml.eos_token_id': '151643', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.chat_template': \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<๏ฝUser๏ฝ>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<๏ฝAssistant๏ฝ><๏ฝtoolโcallsโbegin๏ฝ><๏ฝtoolโcallโbegin๏ฝ>' + tool['type'] + '<๏ฝtoolโsep๏ฝ>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<๏ฝtoolโcallโend๏ฝ>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\\\n' + '<๏ฝtoolโcallโbegin๏ฝ>' + tool['type'] + '<๏ฝtoolโsep๏ฝ>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<๏ฝtoolโcallโend๏ฝ>'}}{{'<๏ฝtoolโcallsโend๏ฝ><๏ฝendโofโsentence๏ฝ>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<๏ฝtoolโoutputsโend๏ฝ>' + message['content'] + '<๏ฝendโofโsentence๏ฝ>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<๏ฝAssistant๏ฝ>' + content + '<๏ฝendโofโsentence๏ฝ>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<๏ฝtoolโoutputsโbegin๏ฝ><๏ฝtoolโoutputโbegin๏ฝ>' + message['content'] + '<๏ฝtoolโoutputโend๏ฝ>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\\\n<๏ฝtoolโoutputโbegin๏ฝ>' + message['content'] + '<๏ฝtoolโoutputโend๏ฝ>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<๏ฝtoolโoutputsโend๏ฝ>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<๏ฝAssistant๏ฝ>'}}{% endif %}\", 'quantize.imatrix.chunks_count': '128', 'quantize.imatrix.file': '/models_out/DeepSeek-R1-Distill-Qwen-7B-GGUF/DeepSeek-R1-Distill-Qwen-7B.imatrix', 'quantize.imatrix.entries_count': '196'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<๏ฝUser๏ฝ>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<๏ฝAssistant๏ฝ><๏ฝtoolโcallsโbegin๏ฝ><๏ฝtoolโcallโbegin๏ฝ>' + tool['type'] + '<๏ฝtoolโsep๏ฝ>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<๏ฝtoolโcallโend๏ฝ>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<๏ฝtoolโcallโbegin๏ฝ>' + tool['type'] + '<๏ฝtoolโsep๏ฝ>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<๏ฝtoolโcallโend๏ฝ>'}}{{'<๏ฝtoolโcallsโend๏ฝ><๏ฝendโofโsentence๏ฝ>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<๏ฝtoolโoutputsโend๏ฝ>' + message['content'] + '<๏ฝendโofโsentence๏ฝ>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<๏ฝAssistant๏ฝ>' + content + '<๏ฝendโofโsentence๏ฝ>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<๏ฝtoolโoutputsโbegin๏ฝ><๏ฝtoolโoutputโbegin๏ฝ>' + message['content'] + '<๏ฝtoolโoutputโend๏ฝ>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\n<๏ฝtoolโoutputโbegin๏ฝ>' + message['content'] + '<๏ฝtoolโoutputโend๏ฝ>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<๏ฝtoolโoutputsโend๏ฝ>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<๏ฝAssistant๏ฝ>'}}{% endif %}\n",
      "Using chat eos_token: <๏ฝendโofโsentence๏ฝ>\n",
      "Using chat bos_token: <๏ฝbeginโofโsentence๏ฝ>\n"
     ]
    }
   ],
   "source": [
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_ctx=2048,\n",
    "    n_threads=4,\n",
    "    n_gpu_layers=1  # Mettez une valeur >0 si vous avez un GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dรฉfinir le prompt systรจme\n",
    "system_prompt = \"\"\"\n",
    "### Tรขche ###\n",
    "Analyse le sentiment du commentaire et classe-le exclusivement sous l'un de ces trois labels:\n",
    "- **\"Positif\"** : Pour les commentaires contenant des **รฉmotions positives**, des **รฉloges**, de la **satisfaction**, des **fรฉlicitations**, des **encouragements**, des **salutations**, des **remerciements** ...ect.  \n",
    "- **\"Negatif\"** : Pour les commentaires contenant des **รฉmotions nรฉgatives**, des **critiques**, des **plaintes**, des **dรฉceptions**, des **insultes**, des **frustrations**, des **menaces** ou des mots nรฉgatifs ...ect.  \n",
    "- **\"Neutre\"** : Pour les commentaires **factuels**, **informatifs**, **neutres en tonalitรฉ**, **des suggestions**, ou **des demandes d'information** ...ect.\n",
    "\n",
    "### Rรจgles Strictes ###\n",
    "1. Rรฉpondre UNIQUEMENT par un des trois mots: Positif, Negatif ou Neutre.\n",
    "2. Pas d'explications, pas de phrases complรจtes.\n",
    "3. Langues supportรฉes: Arabe, Darija Algรฉrienne, Franรงais, Anglais.\n",
    "4. Attention il faut bien rรฉflรฉchir.\n",
    "5. Si le commentaire contient des abrรฉviations, remplacez-les par leur forme complรจte avant d'analyser le sentiment.\n",
    "6. Si le commentaire contient des variantes phonรฉtiques, remplacez-les par leur forme standard avant d'analyser le sentiment.\n",
    "7. Avant finir, assurez-vous que le commentaire est bien nettoyรฉ et comprรฉhensible.\n",
    "8. Avant de rรฉpondre, assurez-vous que le commentaire est bien nettoyรฉ et comprรฉhensible.\n",
    "\n",
    "### **EXEMPLES**\n",
    "\n",
    "#### **Arabe et Darija Algรฉrienne**\n",
    "- `\"ุงูููุชุฌ ุฑุงุฆุน!\"` โ **Positif**  \n",
    "- `\"ุงูุฎุฏูุฉ ุณูุฆุฉ ุฌุฏุงู\"` โ **Negatif**  \n",
    "- `\"ุงูุชูุตูู ุงุณุชุบุฑู ููููู\"` โ **Neutre**  \n",
    "\n",
    "- `\"ุงูุฎุฏูุฉ ูููุญุฉ\"` โ **Positif**\n",
    "- `\"ูุงูุงุด ุฑูุฒู\"` โ **Negatif**  \n",
    "- `\"ุฌุงุชูู ุงููุงุชูุฑุฉ\"` โ **Neutre**  \n",
    "\n",
    "#### **Franรงais**\n",
    "- `\"Super produit !\"` โ **Positif**  \n",
    "- `\"Service horrible\"` โ **Negatif**  \n",
    "- `\"D'accord\"` โ **Neutre**  \n",
    "\n",
    "- `\"Merci pour votre aide !\"` โ **Positif**  \n",
    "- `\"Je suis extrรชmement dรฉรงu du service\"` โ **Negatif**  \n",
    "- `\"La livraison รฉtait de 3 jours\"` โ **Neutre**  \n",
    "\n",
    "#### **Anglais**\n",
    "- `\"Great product!\"` โ **Positif**  \n",
    "- `\"Terrible service\"` โ **Negatif**  \n",
    "- `\"Received in 2 days\"` โ **Neutre**  \n",
    "\n",
    "### **Tests et Validation**\n",
    "Tu peux tester plusieurs exemples pour vรฉrifier si le modรจle les prรฉdit correctement.  \n",
    "Ton objectif est dโoptimiser lโannotation automatique pour assurer une **prรฉcision maximale**. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(comment_text):\n",
    "    prompt = f\"{system_prompt}\\nComment: {comment_text}\\nSentiment:\"\n",
    "    \n",
    "    output = llm(\n",
    "        prompt,\n",
    "        max_tokens=10,\n",
    "        temperature=1,\n",
    "        stop=[\"\\n\"],\n",
    "        echo=False\n",
    "    )\n",
    "    \n",
    "    # Nettoyer la sortie pour ne garder que le label\n",
    "    sentiment = output['choices'][0]['text'].strip()\n",
    "    sentiment = sentiment.split()[0] if sentiment else \"Neutre\"\n",
    "    \n",
    "    # Forcer l'un des trois labels\n",
    "    if sentiment not in [\"Positif\", \"Negatif\", \"Neutre\"]:\n",
    "        sentiment = \"Neutre\"\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendre seulement les 30 premiers commentaires pour le test\n",
    "test_df = comments_df.head(30).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing comments:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Annotation des commentaires\n",
    "tqdm.pandas(desc=\"Analyzing comments\")\n",
    "test_df['Predicted_Sentiment'] = test_df['Comments'].progress_apply(\n",
    "    lambda x: analyze_sentiment(x) if pd.notna(x) else \"Neutre\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les rรฉsultats du test\n",
    "test_df.to_csv(\"Data/Test_Comments_Annotated.csv\", index=False)\n",
    "print(\"\\nTest terminรฉ. Rรฉsultats sauvegardรฉs dans Test_Comments_Annotated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Annotation des commentaires\n",
    "tqdm.pandas(desc=\"Analyzing comments\")\n",
    "comments_df['Predicted_Sentiment'] = comments_df['Comments'].progress_apply(\n",
    "    lambda x: analyze_sentiment(x) if pd.notna(x) else \"Neutre\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "โ Matrice de confusion enregistrรฉe dans : Results/confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "output_dir = \"Results/\"\n",
    "\n",
    "# รvaluation des Rรฉsultats\n",
    "y_true = comments_df[\"Sentiments\"]\n",
    "y_pred = comments_df[\"Sentiment_Predicted\"]\n",
    "\n",
    "# Calcul des mรฉtriques\n",
    "accuracy = accuracy_score(y_true, y_pred) * 100  # Pourcentage\n",
    "precision = precision_score(y_true, y_pred, average=None) * 100\n",
    "recall = recall_score(y_true, y_pred, average=None) * 100\n",
    "\n",
    "# Gรฉnรฉrer la matrice de confusion\n",
    "labels = [\"Negatif\", \"Neutre\", \"Positif\"]\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "# Tracer la matrice de confusion\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "# Titres et labels\n",
    "plt.title(\"Matrice de Confusion de Model DeepSeek-R1-Distill-Qwen-7B-Q8_0\", fontsize=12)\n",
    "plt.xlabel(\"Prรฉdit\", fontsize=15)\n",
    "plt.ylabel(\"Rรฉel\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "# Sauvegarde de la Matrice\n",
    "confusion_matrix_path = os.path.join(output_dir, \"confusion_matrix.png\")\n",
    "plt.savefig(confusion_matrix_path)\n",
    "print(f\"โ Matrice de confusion enregistrรฉe dans : {confusion_matrix_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "โ Accuracy du modรจle sur l'ensemble de test : 59.93 %\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.63      0.84      0.72       863\n",
      "      Neutre       0.43      0.17      0.25      1139\n",
      "     Positif       0.62      0.79      0.70      1467\n",
      "\n",
      "    accuracy                           0.60      3469\n",
      "   macro avg       0.56      0.60      0.55      3469\n",
      "weighted avg       0.56      0.60      0.55      3469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Affichage des rรฉsultats\n",
    "print(f\"\\nโ Accuracy du modรจle sur l'ensemble de test : {round(accuracy, 2)} %\\n\")\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "โ Annotation terminรฉe ! Rรฉsultats enregistrรฉs dans : Results/comments_annotated.csv\n",
      "โ Scores des mรฉtriques enregistrรฉs dans : Results/metrics_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Enregistrement des Rรฉsultats\n",
    "metrics_path = os.path.join(output_dir, \"metrics_results.txt\")\n",
    "annotated_csv_path = os.path.join(output_dir, \"comments_annotated.csv\")\n",
    "\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    f.write(f\"๐ รvaluation des Sentiments\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    f.write(f\"\\nโ Accuracy du modรจle sur l'ensemble de test : {round(accuracy, 2)} %\\n\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "# Sauvegarde du DataFrame annotรฉ\n",
    "comments_df.to_csv(annotated_csv_path, index=False)\n",
    "\n",
    "print(f\"\\nโ Annotation terminรฉe ! Rรฉsultats enregistrรฉs dans : {annotated_csv_path}\")\n",
    "print(f\"โ Scores des mรฉtriques enregistrรฉs dans : {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ๐ Load Mistral-7B-Instruct-v0.3 GGUF Model\n",
    "model_path = \"models/Mistral-7B-Instruct-v0.3.fp16.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 25 key-value pairs and 291 tensors from models/Mistral-7B-Instruct-v0.3.fp16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = models--mistralai--Mistral-7B-Instruc...\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 32768\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32768]   = [\"<unk>\", \"<s>\", \"</s>\", \"[INST]\", \"[...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32768]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32768]   = [2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type  f16:  226 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = F16\n",
      "print_info: file size   = 13.50 GiB (16.00 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:     48 '[control_46]' is not marked as EOG\n",
      "load: control token:    624 '[control_622]' is not marked as EOG\n",
      "load: control token:    216 '[control_214]' is not marked as EOG\n",
      "load: control token:     40 '[control_38]' is not marked as EOG\n",
      "load: control token:    322 '[control_320]' is not marked as EOG\n",
      "load: control token:      4 '[/INST]' is not marked as EOG\n",
      "load: control token:    366 '[control_364]' is not marked as EOG\n",
      "load: control token:     32 '[control_30]' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: control token:    425 '[control_423]' is not marked as EOG\n",
      "load: control token:     44 '[control_42]' is not marked as EOG\n",
      "load: control token:      7 '[/AVAILABLE_TOOLS]' is not marked as EOG\n",
      "load: control token:    206 '[control_204]' is not marked as EOG\n",
      "load: control token:     22 '[control_20]' is not marked as EOG\n",
      "load: control token:    241 '[control_239]' is not marked as EOG\n",
      "load: control token:    112 '[control_110]' is not marked as EOG\n",
      "load: control token:    398 '[control_396]' is not marked as EOG\n",
      "load: control token:      5 '[TOOL_CALLS]' is not marked as EOG\n",
      "load: control token:    655 '[control_653]' is not marked as EOG\n",
      "load: control token:    725 '[control_723]' is not marked as EOG\n",
      "load: control token:    340 '[control_338]' is not marked as EOG\n",
      "load: control token:    523 '[control_521]' is not marked as EOG\n",
      "load: control token:    242 '[control_240]' is not marked as EOG\n",
      "load: control token:      3 '[INST]' is not marked as EOG\n",
      "load: control token:    364 '[control_362]' is not marked as EOG\n",
      "load: control token:     38 '[control_36]' is not marked as EOG\n",
      "load: control token:    333 '[control_331]' is not marked as EOG\n",
      "load: control token:    530 '[control_528]' is not marked as EOG\n",
      "load: control token:    251 '[control_249]' is not marked as EOG\n",
      "load: control token:      6 '[AVAILABLE_TOOLS]' is not marked as EOG\n",
      "load: control token:     63 '[control_61]' is not marked as EOG\n",
      "load: control token:    346 '[control_344]' is not marked as EOG\n",
      "load: control token:     12 '[control_10]' is not marked as EOG\n",
      "load: control token:    409 '[control_407]' is not marked as EOG\n",
      "load: control token:      8 '[TOOL_RESULTS]' is not marked as EOG\n",
      "load: control token:    694 '[control_692]' is not marked as EOG\n",
      "load: control token:    153 '[control_151]' is not marked as EOG\n",
      "load: control token:    374 '[control_372]' is not marked as EOG\n",
      "load: control token:      9 '[/TOOL_RESULTS]' is not marked as EOG\n",
      "load: control token:     59 '[control_57]' is not marked as EOG\n",
      "load: control token:    191 '[control_189]' is not marked as EOG\n",
      "load: control token:    284 '[control_282]' is not marked as EOG\n",
      "load: control token:     10 '[control_8]' is not marked as EOG\n",
      "load: control token:     58 '[control_56]' is not marked as EOG\n",
      "load: control token:    190 '[control_188]' is not marked as EOG\n",
      "load: control token:    285 '[control_283]' is not marked as EOG\n",
      "load: control token:     11 '[control_9]' is not marked as EOG\n",
      "load: control token:     62 '[control_60]' is not marked as EOG\n",
      "load: control token:    347 '[control_345]' is not marked as EOG\n",
      "load: control token:     13 '[control_11]' is not marked as EOG\n",
      "load: control token:    348 '[control_346]' is not marked as EOG\n",
      "load: control token:     14 '[control_12]' is not marked as EOG\n",
      "load: control token:    349 '[control_347]' is not marked as EOG\n",
      "load: control token:     15 '[control_13]' is not marked as EOG\n",
      "load: control token:    698 '[control_696]' is not marked as EOG\n",
      "load: control token:    405 '[control_403]' is not marked as EOG\n",
      "load: control token:    157 '[control_155]' is not marked as EOG\n",
      "load: control token:     60 '[control_58]' is not marked as EOG\n",
      "load: control token:    342 '[control_340]' is not marked as EOG\n",
      "load: control token:     16 '[control_14]' is not marked as EOG\n",
      "load: control token:    699 '[control_697]' is not marked as EOG\n",
      "load: control token:    404 '[control_402]' is not marked as EOG\n",
      "load: control token:    156 '[control_154]' is not marked as EOG\n",
      "load: control token:     61 '[control_59]' is not marked as EOG\n",
      "load: control token:    343 '[control_341]' is not marked as EOG\n",
      "load: control token:     17 '[control_15]' is not marked as EOG\n",
      "load: control token:    344 '[control_342]' is not marked as EOG\n",
      "load: control token:     18 '[control_16]' is not marked as EOG\n",
      "load: control token:    345 '[control_343]' is not marked as EOG\n",
      "load: control token:     19 '[control_17]' is not marked as EOG\n",
      "load: control token:    161 '[control_159]' is not marked as EOG\n",
      "load: control token:     56 '[control_54]' is not marked as EOG\n",
      "load: control token:     20 '[control_18]' is not marked as EOG\n",
      "load: control token:     57 '[control_55]' is not marked as EOG\n",
      "load: control token:    160 '[control_158]' is not marked as EOG\n",
      "load: control token:     21 '[control_19]' is not marked as EOG\n",
      "load: control token:    207 '[control_205]' is not marked as EOG\n",
      "load: control token:     23 '[control_21]' is not marked as EOG\n",
      "load: control token:     24 '[control_22]' is not marked as EOG\n",
      "load: control token:    208 '[control_206]' is not marked as EOG\n",
      "load: control token:    209 '[control_207]' is not marked as EOG\n",
      "load: control token:     25 '[control_23]' is not marked as EOG\n",
      "load: control token:    380 '[control_378]' is not marked as EOG\n",
      "load: control token:     26 '[control_24]' is not marked as EOG\n",
      "load: control token:    202 '[control_200]' is not marked as EOG\n",
      "load: control token:    381 '[control_379]' is not marked as EOG\n",
      "load: control token:    203 '[control_201]' is not marked as EOG\n",
      "load: control token:     27 '[control_25]' is not marked as EOG\n",
      "load: control token:     28 '[control_26]' is not marked as EOG\n",
      "load: control token:    204 '[control_202]' is not marked as EOG\n",
      "load: control token:    205 '[control_203]' is not marked as EOG\n",
      "load: control token:     29 '[control_27]' is not marked as EOG\n",
      "load: control token:    376 '[control_374]' is not marked as EOG\n",
      "load: control token:     30 '[control_28]' is not marked as EOG\n",
      "load: control token:    377 '[control_375]' is not marked as EOG\n",
      "load: control token:     31 '[control_29]' is not marked as EOG\n",
      "load: control token:    367 '[control_365]' is not marked as EOG\n",
      "load: control token:     33 '[control_31]' is not marked as EOG\n",
      "load: control token:    368 '[control_366]' is not marked as EOG\n",
      "load: control token:     34 '[control_32]' is not marked as EOG\n",
      "load: control token:    369 '[control_367]' is not marked as EOG\n",
      "load: control token:     35 '[control_33]' is not marked as EOG\n",
      "load: control token:    362 '[control_360]' is not marked as EOG\n",
      "load: control token:    220 '[control_218]' is not marked as EOG\n",
      "load: control token:     36 '[control_34]' is not marked as EOG\n",
      "load: control token:    363 '[control_361]' is not marked as EOG\n",
      "load: control token:    221 '[control_219]' is not marked as EOG\n",
      "load: control token:     37 '[control_35]' is not marked as EOG\n",
      "load: control token:    365 '[control_363]' is not marked as EOG\n",
      "load: control token:     39 '[control_37]' is not marked as EOG\n",
      "load: control token:     41 '[control_39]' is not marked as EOG\n",
      "load: control token:    217 '[control_215]' is not marked as EOG\n",
      "load: control token:     42 '[control_40]' is not marked as EOG\n",
      "load: control token:     43 '[control_41]' is not marked as EOG\n",
      "load: control token:     45 '[control_43]' is not marked as EOG\n",
      "load: control token:    481 '[control_479]' is not marked as EOG\n",
      "load: control token:     46 '[control_44]' is not marked as EOG\n",
      "load: control token:    480 '[control_478]' is not marked as EOG\n",
      "load: control token:     47 '[control_45]' is not marked as EOG\n",
      "load: control token:     49 '[control_47]' is not marked as EOG\n",
      "load: control token:    477 '[control_475]' is not marked as EOG\n",
      "load: control token:     50 '[control_48]' is not marked as EOG\n",
      "load: control token:    476 '[control_474]' is not marked as EOG\n",
      "load: control token:     51 '[control_49]' is not marked as EOG\n",
      "load: control token:     52 '[control_50]' is not marked as EOG\n",
      "load: control token:     53 '[control_51]' is not marked as EOG\n",
      "load: control token:    411 '[control_409]' is not marked as EOG\n",
      "load: control token:     54 '[control_52]' is not marked as EOG\n",
      "load: control token:    410 '[control_408]' is not marked as EOG\n",
      "load: control token:     55 '[control_53]' is not marked as EOG\n",
      "load: control token:     64 '[control_62]' is not marked as EOG\n",
      "load: control token:     65 '[control_63]' is not marked as EOG\n",
      "load: control token:     66 '[control_64]' is not marked as EOG\n",
      "load: control token:     67 '[control_65]' is not marked as EOG\n",
      "load: control token:     68 '[control_66]' is not marked as EOG\n",
      "load: control token:     69 '[control_67]' is not marked as EOG\n",
      "load: control token:     70 '[control_68]' is not marked as EOG\n",
      "load: control token:     71 '[control_69]' is not marked as EOG\n",
      "load: control token:     72 '[control_70]' is not marked as EOG\n",
      "load: control token:     73 '[control_71]' is not marked as EOG\n",
      "load: control token:     74 '[control_72]' is not marked as EOG\n",
      "load: control token:     75 '[control_73]' is not marked as EOG\n",
      "load: control token:     76 '[control_74]' is not marked as EOG\n",
      "load: control token:     77 '[control_75]' is not marked as EOG\n",
      "load: control token:     78 '[control_76]' is not marked as EOG\n",
      "load: control token:     79 '[control_77]' is not marked as EOG\n",
      "load: control token:     80 '[control_78]' is not marked as EOG\n",
      "load: control token:     81 '[control_79]' is not marked as EOG\n",
      "load: control token:     82 '[control_80]' is not marked as EOG\n",
      "load: control token:     83 '[control_81]' is not marked as EOG\n",
      "load: control token:     84 '[control_82]' is not marked as EOG\n",
      "load: control token:     85 '[control_83]' is not marked as EOG\n",
      "load: control token:     86 '[control_84]' is not marked as EOG\n",
      "load: control token:     87 '[control_85]' is not marked as EOG\n",
      "load: control token:     88 '[control_86]' is not marked as EOG\n",
      "load: control token:     89 '[control_87]' is not marked as EOG\n",
      "load: control token:     90 '[control_88]' is not marked as EOG\n",
      "load: control token:     91 '[control_89]' is not marked as EOG\n",
      "load: control token:     92 '[control_90]' is not marked as EOG\n",
      "load: control token:     93 '[control_91]' is not marked as EOG\n",
      "load: control token:     94 '[control_92]' is not marked as EOG\n",
      "load: control token:     95 '[control_93]' is not marked as EOG\n",
      "load: control token:     96 '[control_94]' is not marked as EOG\n",
      "load: control token:     97 '[control_95]' is not marked as EOG\n",
      "load: control token:     98 '[control_96]' is not marked as EOG\n",
      "load: control token:     99 '[control_97]' is not marked as EOG\n",
      "load: control token:    100 '[control_98]' is not marked as EOG\n",
      "load: control token:    101 '[control_99]' is not marked as EOG\n",
      "load: control token:    454 '[control_452]' is not marked as EOG\n",
      "load: control token:    102 '[control_100]' is not marked as EOG\n",
      "load: control token:    455 '[control_453]' is not marked as EOG\n",
      "load: control token:    103 '[control_101]' is not marked as EOG\n",
      "load: control token:    452 '[control_450]' is not marked as EOG\n",
      "load: control token:    104 '[control_102]' is not marked as EOG\n",
      "load: control token:    390 '[control_388]' is not marked as EOG\n",
      "load: control token:    453 '[control_451]' is not marked as EOG\n",
      "load: control token:    105 '[control_103]' is not marked as EOG\n",
      "load: control token:    391 '[control_389]' is not marked as EOG\n",
      "load: control token:    458 '[control_456]' is not marked as EOG\n",
      "load: control token:    106 '[control_104]' is not marked as EOG\n",
      "load: control token:    459 '[control_457]' is not marked as EOG\n",
      "load: control token:    107 '[control_105]' is not marked as EOG\n",
      "load: control token:    456 '[control_454]' is not marked as EOG\n",
      "load: control token:    108 '[control_106]' is not marked as EOG\n",
      "load: control token:    457 '[control_455]' is not marked as EOG\n",
      "load: control token:    109 '[control_107]' is not marked as EOG\n",
      "load: control token:    110 '[control_108]' is not marked as EOG\n",
      "load: control token:    384 '[control_382]' is not marked as EOG\n",
      "load: control token:    111 '[control_109]' is not marked as EOG\n",
      "load: control token:    385 '[control_383]' is not marked as EOG\n",
      "load: control token:    240 '[control_238]' is not marked as EOG\n",
      "load: control token:    113 '[control_111]' is not marked as EOG\n",
      "load: control token:    399 '[control_397]' is not marked as EOG\n",
      "load: control token:    114 '[control_112]' is not marked as EOG\n",
      "load: control token:    396 '[control_394]' is not marked as EOG\n",
      "load: control token:    115 '[control_113]' is not marked as EOG\n",
      "load: control token:    397 '[control_395]' is not marked as EOG\n",
      "load: control token:    116 '[control_114]' is not marked as EOG\n",
      "load: control token:    394 '[control_392]' is not marked as EOG\n",
      "load: control token:    395 '[control_393]' is not marked as EOG\n",
      "load: control token:    117 '[control_115]' is not marked as EOG\n",
      "load: control token:    450 '[control_448]' is not marked as EOG\n",
      "load: control token:    657 '[control_655]' is not marked as EOG\n",
      "load: control token:    118 '[control_116]' is not marked as EOG\n",
      "load: control token:    392 '[control_390]' is not marked as EOG\n",
      "load: control token:    656 '[control_654]' is not marked as EOG\n",
      "load: control token:    451 '[control_449]' is not marked as EOG\n",
      "load: control token:    119 '[control_117]' is not marked as EOG\n",
      "load: control token:    393 '[control_391]' is not marked as EOG\n",
      "load: control token:    448 '[control_446]' is not marked as EOG\n",
      "load: control token:    120 '[control_118]' is not marked as EOG\n",
      "load: control token:    233 '[control_231]' is not marked as EOG\n",
      "load: control token:    449 '[control_447]' is not marked as EOG\n",
      "load: control token:    121 '[control_119]' is not marked as EOG\n",
      "load: control token:    232 '[control_230]' is not marked as EOG\n",
      "load: control token:    122 '[control_120]' is not marked as EOG\n",
      "load: control token:    123 '[control_121]' is not marked as EOG\n",
      "load: control token:    124 '[control_122]' is not marked as EOG\n",
      "load: control token:    125 '[control_123]' is not marked as EOG\n",
      "load: control token:    126 '[control_124]' is not marked as EOG\n",
      "load: control token:    127 '[control_125]' is not marked as EOG\n",
      "load: control token:    510 '[control_508]' is not marked as EOG\n",
      "load: control token:    231 '[control_229]' is not marked as EOG\n",
      "load: control token:    128 '[control_126]' is not marked as EOG\n",
      "load: control token:    129 '[control_127]' is not marked as EOG\n",
      "load: control token:    230 '[control_228]' is not marked as EOG\n",
      "load: control token:    511 '[control_509]' is not marked as EOG\n",
      "load: control token:    130 '[control_128]' is not marked as EOG\n",
      "load: control token:    229 '[control_227]' is not marked as EOG\n",
      "load: control token:    508 '[control_506]' is not marked as EOG\n",
      "load: control token:    131 '[control_129]' is not marked as EOG\n",
      "load: control token:    228 '[control_226]' is not marked as EOG\n",
      "load: control token:    509 '[control_507]' is not marked as EOG\n",
      "load: control token:    132 '[control_130]' is not marked as EOG\n",
      "load: control token:    261 '[control_259]' is not marked as EOG\n",
      "load: control token:    133 '[control_131]' is not marked as EOG\n",
      "load: control token:    260 '[control_258]' is not marked as EOG\n",
      "load: control token:    520 '[control_518]' is not marked as EOG\n",
      "load: control token:    134 '[control_132]' is not marked as EOG\n",
      "load: control token:    135 '[control_133]' is not marked as EOG\n",
      "load: control token:    521 '[control_519]' is not marked as EOG\n",
      "load: control token:    136 '[control_134]' is not marked as EOG\n",
      "load: control token:    137 '[control_135]' is not marked as EOG\n",
      "load: control token:    138 '[control_136]' is not marked as EOG\n",
      "load: control token:    139 '[control_137]' is not marked as EOG\n",
      "load: control token:    514 '[control_512]' is not marked as EOG\n",
      "load: control token:    140 '[control_138]' is not marked as EOG\n",
      "load: control token:    253 '[control_251]' is not marked as EOG\n",
      "load: control token:    515 '[control_513]' is not marked as EOG\n",
      "load: control token:    141 '[control_139]' is not marked as EOG\n",
      "load: control token:    252 '[control_250]' is not marked as EOG\n",
      "load: control token:    414 '[control_412]' is not marked as EOG\n",
      "load: control token:    142 '[control_140]' is not marked as EOG\n",
      "load: control token:    415 '[control_413]' is not marked as EOG\n",
      "load: control token:    143 '[control_141]' is not marked as EOG\n",
      "load: control token:    412 '[control_410]' is not marked as EOG\n",
      "load: control token:    144 '[control_142]' is not marked as EOG\n",
      "load: control token:    413 '[control_411]' is not marked as EOG\n",
      "load: control token:    145 '[control_143]' is not marked as EOG\n",
      "load: control token:    418 '[control_416]' is not marked as EOG\n",
      "load: control token:    146 '[control_144]' is not marked as EOG\n",
      "load: control token:    419 '[control_417]' is not marked as EOG\n",
      "load: control token:    147 '[control_145]' is not marked as EOG\n",
      "load: control token:    416 '[control_414]' is not marked as EOG\n",
      "load: control token:    148 '[control_146]' is not marked as EOG\n",
      "load: control token:    417 '[control_415]' is not marked as EOG\n",
      "load: control token:    149 '[control_147]' is not marked as EOG\n",
      "load: control token:    150 '[control_148]' is not marked as EOG\n",
      "load: control token:    151 '[control_149]' is not marked as EOG\n",
      "load: control token:    695 '[control_693]' is not marked as EOG\n",
      "load: control token:    408 '[control_406]' is not marked as EOG\n",
      "load: control token:    152 '[control_150]' is not marked as EOG\n",
      "load: control token:    406 '[control_404]' is not marked as EOG\n",
      "load: control token:    693 '[control_691]' is not marked as EOG\n",
      "load: control token:    154 '[control_152]' is not marked as EOG\n",
      "load: control token:    692 '[control_690]' is not marked as EOG\n",
      "load: control token:    407 '[control_405]' is not marked as EOG\n",
      "load: control token:    155 '[control_153]' is not marked as EOG\n",
      "load: control token:    697 '[control_695]' is not marked as EOG\n",
      "load: control token:    402 '[control_400]' is not marked as EOG\n",
      "load: control token:    158 '[control_156]' is not marked as EOG\n",
      "load: control token:    696 '[control_694]' is not marked as EOG\n",
      "load: control token:    403 '[control_401]' is not marked as EOG\n",
      "load: control token:    159 '[control_157]' is not marked as EOG\n",
      "load: control token:    162 '[control_160]' is not marked as EOG\n",
      "load: control token:    163 '[control_161]' is not marked as EOG\n",
      "load: control token:    164 '[control_162]' is not marked as EOG\n",
      "load: control token:    165 '[control_163]' is not marked as EOG\n",
      "load: control token:    166 '[control_164]' is not marked as EOG\n",
      "load: control token:    167 '[control_165]' is not marked as EOG\n",
      "load: control token:    761 '[control_759]' is not marked as EOG\n",
      "load: control token:    168 '[control_166]' is not marked as EOG\n",
      "load: control token:    760 '[control_758]' is not marked as EOG\n",
      "load: control token:    169 '[control_167]' is not marked as EOG\n",
      "load: control token:    759 '[control_757]' is not marked as EOG\n",
      "load: control token:    170 '[control_168]' is not marked as EOG\n",
      "load: control token:    758 '[control_756]' is not marked as EOG\n",
      "load: control token:    171 '[control_169]' is not marked as EOG\n",
      "load: control token:    464 '[control_462]' is not marked as EOG\n",
      "load: control token:    172 '[control_170]' is not marked as EOG\n",
      "load: control token:    465 '[control_463]' is not marked as EOG\n",
      "load: control token:    173 '[control_171]' is not marked as EOG\n",
      "load: control token:    462 '[control_460]' is not marked as EOG\n",
      "load: control token:    174 '[control_172]' is not marked as EOG\n",
      "load: control token:    463 '[control_461]' is not marked as EOG\n",
      "load: control token:    175 '[control_173]' is not marked as EOG\n",
      "load: control token:    468 '[control_466]' is not marked as EOG\n",
      "load: control token:    176 '[control_174]' is not marked as EOG\n",
      "load: control token:    469 '[control_467]' is not marked as EOG\n",
      "load: control token:    177 '[control_175]' is not marked as EOG\n",
      "load: control token:    466 '[control_464]' is not marked as EOG\n",
      "load: control token:    178 '[control_176]' is not marked as EOG\n",
      "load: control token:    467 '[control_465]' is not marked as EOG\n",
      "load: control token:    179 '[control_177]' is not marked as EOG\n",
      "load: control token:    180 '[control_178]' is not marked as EOG\n",
      "load: control token:    181 '[control_179]' is not marked as EOG\n",
      "load: control token:    182 '[control_180]' is not marked as EOG\n",
      "load: control token:    183 '[control_181]' is not marked as EOG\n",
      "load: control token:    184 '[control_182]' is not marked as EOG\n",
      "load: control token:    291 '[control_289]' is not marked as EOG\n",
      "load: control token:    185 '[control_183]' is not marked as EOG\n",
      "load: control token:    290 '[control_288]' is not marked as EOG\n",
      "load: control token:    186 '[control_184]' is not marked as EOG\n",
      "load: control token:    187 '[control_185]' is not marked as EOG\n",
      "load: control token:    188 '[control_186]' is not marked as EOG\n",
      "load: control token:    189 '[control_187]' is not marked as EOG\n",
      "load: control token:    192 '[control_190]' is not marked as EOG\n",
      "load: control token:    318 '[control_316]' is not marked as EOG\n",
      "load: control token:    193 '[control_191]' is not marked as EOG\n",
      "load: control token:    319 '[control_317]' is not marked as EOG\n",
      "load: control token:    194 '[control_192]' is not marked as EOG\n",
      "load: control token:    316 '[control_314]' is not marked as EOG\n",
      "load: control token:    195 '[control_193]' is not marked as EOG\n",
      "load: control token:    317 '[control_315]' is not marked as EOG\n",
      "load: control token:    196 '[control_194]' is not marked as EOG\n",
      "load: control token:    314 '[control_312]' is not marked as EOG\n",
      "load: control token:    315 '[control_313]' is not marked as EOG\n",
      "load: control token:    197 '[control_195]' is not marked as EOG\n",
      "load: control token:    198 '[control_196]' is not marked as EOG\n",
      "load: control token:    312 '[control_310]' is not marked as EOG\n",
      "load: control token:    551 '[control_549]' is not marked as EOG\n",
      "load: control token:    270 '[control_268]' is not marked as EOG\n",
      "load: control token:    199 '[control_197]' is not marked as EOG\n",
      "load: control token:    313 '[control_311]' is not marked as EOG\n",
      "load: control token:    550 '[control_548]' is not marked as EOG\n",
      "load: control token:    271 '[control_269]' is not marked as EOG\n",
      "load: control token:    268 '[control_266]' is not marked as EOG\n",
      "load: control token:    549 '[control_547]' is not marked as EOG\n",
      "load: control token:    200 '[control_198]' is not marked as EOG\n",
      "load: control token:    548 '[control_546]' is not marked as EOG\n",
      "load: control token:    269 '[control_267]' is not marked as EOG\n",
      "load: control token:    201 '[control_199]' is not marked as EOG\n",
      "load: control token:    372 '[control_370]' is not marked as EOG\n",
      "load: control token:    210 '[control_208]' is not marked as EOG\n",
      "load: control token:    373 '[control_371]' is not marked as EOG\n",
      "load: control token:    211 '[control_209]' is not marked as EOG\n",
      "load: control token:    370 '[control_368]' is not marked as EOG\n",
      "load: control token:    212 '[control_210]' is not marked as EOG\n",
      "load: control token:    371 '[control_369]' is not marked as EOG\n",
      "load: control token:    213 '[control_211]' is not marked as EOG\n",
      "load: control token:    214 '[control_212]' is not marked as EOG\n",
      "load: control token:    215 '[control_213]' is not marked as EOG\n",
      "load: control token:    218 '[control_216]' is not marked as EOG\n",
      "load: control token:    219 '[control_217]' is not marked as EOG\n",
      "load: control token:    222 '[control_220]' is not marked as EOG\n",
      "load: control token:    503 '[control_501]' is not marked as EOG\n",
      "load: control token:    502 '[control_500]' is not marked as EOG\n",
      "load: control token:    223 '[control_221]' is not marked as EOG\n",
      "load: control token:    224 '[control_222]' is not marked as EOG\n",
      "load: control token:    505 '[control_503]' is not marked as EOG\n",
      "load: control token:    504 '[control_502]' is not marked as EOG\n",
      "load: control token:    225 '[control_223]' is not marked as EOG\n",
      "load: control token:    226 '[control_224]' is not marked as EOG\n",
      "load: control token:    507 '[control_505]' is not marked as EOG\n",
      "load: control token:    227 '[control_225]' is not marked as EOG\n",
      "load: control token:    506 '[control_504]' is not marked as EOG\n",
      "load: control token:    660 '[control_658]' is not marked as EOG\n",
      "load: control token:    447 '[control_445]' is not marked as EOG\n",
      "load: control token:    234 '[control_232]' is not marked as EOG\n",
      "load: control token:    661 '[control_659]' is not marked as EOG\n",
      "load: control token:    446 '[control_444]' is not marked as EOG\n",
      "load: control token:    235 '[control_233]' is not marked as EOG\n",
      "load: control token:    445 '[control_443]' is not marked as EOG\n",
      "load: control token:    236 '[control_234]' is not marked as EOG\n",
      "load: control token:    444 '[control_442]' is not marked as EOG\n",
      "load: control token:    237 '[control_235]' is not marked as EOG\n",
      "load: control token:    443 '[control_441]' is not marked as EOG\n",
      "load: control token:    238 '[control_236]' is not marked as EOG\n",
      "load: control token:    401 '[control_399]' is not marked as EOG\n",
      "load: control token:    442 '[control_440]' is not marked as EOG\n",
      "load: control token:    239 '[control_237]' is not marked as EOG\n",
      "load: control token:    400 '[control_398]' is not marked as EOG\n",
      "load: control token:    341 '[control_339]' is not marked as EOG\n",
      "load: control token:    724 '[control_722]' is not marked as EOG\n",
      "load: control token:    522 '[control_520]' is not marked as EOG\n",
      "load: control token:    243 '[control_241]' is not marked as EOG\n",
      "load: control token:    525 '[control_523]' is not marked as EOG\n",
      "load: control token:    244 '[control_242]' is not marked as EOG\n",
      "load: control token:    245 '[control_243]' is not marked as EOG\n",
      "load: control token:    524 '[control_522]' is not marked as EOG\n",
      "load: control token:    246 '[control_244]' is not marked as EOG\n",
      "load: control token:    527 '[control_525]' is not marked as EOG\n",
      "load: control token:    526 '[control_524]' is not marked as EOG\n",
      "load: control token:    247 '[control_245]' is not marked as EOG\n",
      "load: control token:    529 '[control_527]' is not marked as EOG\n",
      "load: control token:    248 '[control_246]' is not marked as EOG\n",
      "load: control token:    249 '[control_247]' is not marked as EOG\n",
      "load: control token:    528 '[control_526]' is not marked as EOG\n",
      "load: control token:    332 '[control_330]' is not marked as EOG\n",
      "load: control token:    531 '[control_529]' is not marked as EOG\n",
      "load: control token:    250 '[control_248]' is not marked as EOG\n",
      "load: control token:    254 '[control_252]' is not marked as EOG\n",
      "load: control token:    513 '[control_511]' is not marked as EOG\n",
      "load: control token:    255 '[control_253]' is not marked as EOG\n",
      "load: control token:    512 '[control_510]' is not marked as EOG\n",
      "load: control token:    519 '[control_517]' is not marked as EOG\n",
      "load: control token:    256 '[control_254]' is not marked as EOG\n",
      "load: control token:    518 '[control_516]' is not marked as EOG\n",
      "load: control token:    257 '[control_255]' is not marked as EOG\n",
      "load: control token:    517 '[control_515]' is not marked as EOG\n",
      "load: control token:    258 '[control_256]' is not marked as EOG\n",
      "load: control token:    516 '[control_514]' is not marked as EOG\n",
      "load: control token:    259 '[control_257]' is not marked as EOG\n",
      "load: control token:    320 '[control_318]' is not marked as EOG\n",
      "load: control token:    543 '[control_541]' is not marked as EOG\n",
      "load: control token:    262 '[control_260]' is not marked as EOG\n",
      "load: control token:    321 '[control_319]' is not marked as EOG\n",
      "load: control token:    542 '[control_540]' is not marked as EOG\n",
      "load: control token:    263 '[control_261]' is not marked as EOG\n",
      "load: control token:    264 '[control_262]' is not marked as EOG\n",
      "load: control token:    545 '[control_543]' is not marked as EOG\n",
      "load: control token:    544 '[control_542]' is not marked as EOG\n",
      "load: control token:    265 '[control_263]' is not marked as EOG\n",
      "load: control token:    547 '[control_545]' is not marked as EOG\n",
      "load: control token:    266 '[control_264]' is not marked as EOG\n",
      "load: control token:    267 '[control_265]' is not marked as EOG\n",
      "load: control token:    546 '[control_544]' is not marked as EOG\n",
      "load: control token:    310 '[control_308]' is not marked as EOG\n",
      "load: control token:    733 '[control_731]' is not marked as EOG\n",
      "load: control token:    539 '[control_537]' is not marked as EOG\n",
      "load: control token:    272 '[control_270]' is not marked as EOG\n",
      "load: control token:    311 '[control_309]' is not marked as EOG\n",
      "load: control token:    732 '[control_730]' is not marked as EOG\n",
      "load: control token:    273 '[control_271]' is not marked as EOG\n",
      "load: control token:    538 '[control_536]' is not marked as EOG\n",
      "load: control token:    537 '[control_535]' is not marked as EOG\n",
      "load: control token:    274 '[control_272]' is not marked as EOG\n",
      "load: control token:    536 '[control_534]' is not marked as EOG\n",
      "load: control token:    275 '[control_273]' is not marked as EOG\n",
      "load: control token:    535 '[control_533]' is not marked as EOG\n",
      "load: control token:    276 '[control_274]' is not marked as EOG\n",
      "load: control token:    534 '[control_532]' is not marked as EOG\n",
      "load: control token:    277 '[control_275]' is not marked as EOG\n",
      "load: control token:    533 '[control_531]' is not marked as EOG\n",
      "load: control token:    278 '[control_276]' is not marked as EOG\n",
      "load: control token:    532 '[control_530]' is not marked as EOG\n",
      "load: control token:    279 '[control_277]' is not marked as EOG\n",
      "load: control token:    741 '[control_739]' is not marked as EOG\n",
      "load: control token:    302 '[control_300]' is not marked as EOG\n",
      "load: control token:    280 '[control_278]' is not marked as EOG\n",
      "load: control token:    303 '[control_301]' is not marked as EOG\n",
      "load: control token:    740 '[control_738]' is not marked as EOG\n",
      "load: control token:    281 '[control_279]' is not marked as EOG\n",
      "load: control token:    282 '[control_280]' is not marked as EOG\n",
      "load: control token:    283 '[control_281]' is not marked as EOG\n",
      "load: control token:    286 '[control_284]' is not marked as EOG\n",
      "load: control token:    287 '[control_285]' is not marked as EOG\n",
      "load: control token:    288 '[control_286]' is not marked as EOG\n",
      "load: control token:    289 '[control_287]' is not marked as EOG\n",
      "load: control token:    292 '[control_290]' is not marked as EOG\n",
      "load: control token:    293 '[control_291]' is not marked as EOG\n",
      "load: control token:    294 '[control_292]' is not marked as EOG\n",
      "load: control token:    295 '[control_293]' is not marked as EOG\n",
      "load: control token:    296 '[control_294]' is not marked as EOG\n",
      "load: control token:    297 '[control_295]' is not marked as EOG\n",
      "load: control token:    298 '[control_296]' is not marked as EOG\n",
      "load: control token:    299 '[control_297]' is not marked as EOG\n",
      "load: control token:    300 '[control_298]' is not marked as EOG\n",
      "load: control token:    301 '[control_299]' is not marked as EOG\n",
      "load: control token:    304 '[control_302]' is not marked as EOG\n",
      "load: control token:    305 '[control_303]' is not marked as EOG\n",
      "load: control token:    306 '[control_304]' is not marked as EOG\n",
      "load: control token:    307 '[control_305]' is not marked as EOG\n",
      "load: control token:    308 '[control_306]' is not marked as EOG\n",
      "load: control token:    309 '[control_307]' is not marked as EOG\n",
      "load: control token:    323 '[control_321]' is not marked as EOG\n",
      "load: control token:    324 '[control_322]' is not marked as EOG\n",
      "load: control token:    325 '[control_323]' is not marked as EOG\n",
      "load: control token:    326 '[control_324]' is not marked as EOG\n",
      "load: control token:    327 '[control_325]' is not marked as EOG\n",
      "load: control token:    328 '[control_326]' is not marked as EOG\n",
      "load: control token:    329 '[control_327]' is not marked as EOG\n",
      "load: control token:    330 '[control_328]' is not marked as EOG\n",
      "load: control token:    331 '[control_329]' is not marked as EOG\n",
      "load: control token:    334 '[control_332]' is not marked as EOG\n",
      "load: control token:    731 '[control_729]' is not marked as EOG\n",
      "load: control token:    730 '[control_728]' is not marked as EOG\n",
      "load: control token:    335 '[control_333]' is not marked as EOG\n",
      "load: control token:    336 '[control_334]' is not marked as EOG\n",
      "load: control token:    337 '[control_335]' is not marked as EOG\n",
      "load: control token:    338 '[control_336]' is not marked as EOG\n",
      "load: control token:    339 '[control_337]' is not marked as EOG\n",
      "load: control token:    350 '[control_348]' is not marked as EOG\n",
      "load: control token:    351 '[control_349]' is not marked as EOG\n",
      "load: control token:    352 '[control_350]' is not marked as EOG\n",
      "load: control token:    353 '[control_351]' is not marked as EOG\n",
      "load: control token:    354 '[control_352]' is not marked as EOG\n",
      "load: control token:    355 '[control_353]' is not marked as EOG\n",
      "load: control token:    356 '[control_354]' is not marked as EOG\n",
      "load: control token:    357 '[control_355]' is not marked as EOG\n",
      "load: control token:    358 '[control_356]' is not marked as EOG\n",
      "load: control token:    359 '[control_357]' is not marked as EOG\n",
      "load: control token:    360 '[control_358]' is not marked as EOG\n",
      "load: control token:    361 '[control_359]' is not marked as EOG\n",
      "load: control token:    375 '[control_373]' is not marked as EOG\n",
      "load: control token:    378 '[control_376]' is not marked as EOG\n",
      "load: control token:    379 '[control_377]' is not marked as EOG\n",
      "load: control token:    460 '[control_458]' is not marked as EOG\n",
      "load: control token:    382 '[control_380]' is not marked as EOG\n",
      "load: control token:    461 '[control_459]' is not marked as EOG\n",
      "load: control token:    383 '[control_381]' is not marked as EOG\n",
      "load: control token:    386 '[control_384]' is not marked as EOG\n",
      "load: control token:    387 '[control_385]' is not marked as EOG\n",
      "load: control token:    388 '[control_386]' is not marked as EOG\n",
      "load: control token:    389 '[control_387]' is not marked as EOG\n",
      "load: control token:    420 '[control_418]' is not marked as EOG\n",
      "load: control token:    421 '[control_419]' is not marked as EOG\n",
      "load: control token:    422 '[control_420]' is not marked as EOG\n",
      "load: control token:    423 '[control_421]' is not marked as EOG\n",
      "load: control token:    424 '[control_422]' is not marked as EOG\n",
      "load: control token:    426 '[control_424]' is not marked as EOG\n",
      "load: control token:    427 '[control_425]' is not marked as EOG\n",
      "load: control token:    428 '[control_426]' is not marked as EOG\n",
      "load: control token:    429 '[control_427]' is not marked as EOG\n",
      "load: control token:    430 '[control_428]' is not marked as EOG\n",
      "load: control token:    431 '[control_429]' is not marked as EOG\n",
      "load: control token:    432 '[control_430]' is not marked as EOG\n",
      "load: control token:    433 '[control_431]' is not marked as EOG\n",
      "load: control token:    434 '[control_432]' is not marked as EOG\n",
      "load: control token:    435 '[control_433]' is not marked as EOG\n",
      "load: control token:    436 '[control_434]' is not marked as EOG\n",
      "load: control token:    437 '[control_435]' is not marked as EOG\n",
      "load: control token:    438 '[control_436]' is not marked as EOG\n",
      "load: control token:    439 '[control_437]' is not marked as EOG\n",
      "load: control token:    440 '[control_438]' is not marked as EOG\n",
      "load: control token:    441 '[control_439]' is not marked as EOG\n",
      "load: control token:    470 '[control_468]' is not marked as EOG\n",
      "load: control token:    471 '[control_469]' is not marked as EOG\n",
      "load: control token:    472 '[control_470]' is not marked as EOG\n",
      "load: control token:    473 '[control_471]' is not marked as EOG\n",
      "load: control token:    474 '[control_472]' is not marked as EOG\n",
      "load: control token:    475 '[control_473]' is not marked as EOG\n",
      "load: control token:    478 '[control_476]' is not marked as EOG\n",
      "load: control token:    479 '[control_477]' is not marked as EOG\n",
      "load: control token:    617 '[control_615]' is not marked as EOG\n",
      "load: control token:    482 '[control_480]' is not marked as EOG\n",
      "load: control token:    616 '[control_614]' is not marked as EOG\n",
      "load: control token:    483 '[control_481]' is not marked as EOG\n",
      "load: control token:    619 '[control_617]' is not marked as EOG\n",
      "load: control token:    484 '[control_482]' is not marked as EOG\n",
      "load: control token:    618 '[control_616]' is not marked as EOG\n",
      "load: control token:    485 '[control_483]' is not marked as EOG\n",
      "load: control token:    613 '[control_611]' is not marked as EOG\n",
      "load: control token:    486 '[control_484]' is not marked as EOG\n",
      "load: control token:    612 '[control_610]' is not marked as EOG\n",
      "load: control token:    487 '[control_485]' is not marked as EOG\n",
      "load: control token:    615 '[control_613]' is not marked as EOG\n",
      "load: control token:    488 '[control_486]' is not marked as EOG\n",
      "load: control token:    489 '[control_487]' is not marked as EOG\n",
      "load: control token:    614 '[control_612]' is not marked as EOG\n",
      "load: control token:    490 '[control_488]' is not marked as EOG\n",
      "load: control token:    491 '[control_489]' is not marked as EOG\n",
      "load: control token:    665 '[control_663]' is not marked as EOG\n",
      "load: control token:    492 '[control_490]' is not marked as EOG\n",
      "load: control token:    664 '[control_662]' is not marked as EOG\n",
      "load: control token:    493 '[control_491]' is not marked as EOG\n",
      "load: control token:    663 '[control_661]' is not marked as EOG\n",
      "load: control token:    494 '[control_492]' is not marked as EOG\n",
      "load: control token:    662 '[control_660]' is not marked as EOG\n",
      "load: control token:    495 '[control_493]' is not marked as EOG\n",
      "load: control token:    669 '[control_667]' is not marked as EOG\n",
      "load: control token:    496 '[control_494]' is not marked as EOG\n",
      "load: control token:    668 '[control_666]' is not marked as EOG\n",
      "load: control token:    497 '[control_495]' is not marked as EOG\n",
      "load: control token:    667 '[control_665]' is not marked as EOG\n",
      "load: control token:    498 '[control_496]' is not marked as EOG\n",
      "load: control token:    666 '[control_664]' is not marked as EOG\n",
      "load: control token:    499 '[control_497]' is not marked as EOG\n",
      "load: control token:    500 '[control_498]' is not marked as EOG\n",
      "load: control token:    501 '[control_499]' is not marked as EOG\n",
      "load: control token:    540 '[control_538]' is not marked as EOG\n",
      "load: control token:    541 '[control_539]' is not marked as EOG\n",
      "load: control token:    552 '[control_550]' is not marked as EOG\n",
      "load: control token:    553 '[control_551]' is not marked as EOG\n",
      "load: control token:    554 '[control_552]' is not marked as EOG\n",
      "load: control token:    555 '[control_553]' is not marked as EOG\n",
      "load: control token:    556 '[control_554]' is not marked as EOG\n",
      "load: control token:    557 '[control_555]' is not marked as EOG\n",
      "load: control token:    558 '[control_556]' is not marked as EOG\n",
      "load: control token:    559 '[control_557]' is not marked as EOG\n",
      "load: control token:    560 '[control_558]' is not marked as EOG\n",
      "load: control token:    561 '[control_559]' is not marked as EOG\n",
      "load: control token:    562 '[control_560]' is not marked as EOG\n",
      "load: control token:    563 '[control_561]' is not marked as EOG\n",
      "load: control token:    564 '[control_562]' is not marked as EOG\n",
      "load: control token:    565 '[control_563]' is not marked as EOG\n",
      "load: control token:    566 '[control_564]' is not marked as EOG\n",
      "load: control token:    567 '[control_565]' is not marked as EOG\n",
      "load: control token:    568 '[control_566]' is not marked as EOG\n",
      "load: control token:    569 '[control_567]' is not marked as EOG\n",
      "load: control token:    570 '[control_568]' is not marked as EOG\n",
      "load: control token:    571 '[control_569]' is not marked as EOG\n",
      "load: control token:    572 '[control_570]' is not marked as EOG\n",
      "load: control token:    573 '[control_571]' is not marked as EOG\n",
      "load: control token:    574 '[control_572]' is not marked as EOG\n",
      "load: control token:    575 '[control_573]' is not marked as EOG\n",
      "load: control token:    576 '[control_574]' is not marked as EOG\n",
      "load: control token:    577 '[control_575]' is not marked as EOG\n",
      "load: control token:    578 '[control_576]' is not marked as EOG\n",
      "load: control token:    579 '[control_577]' is not marked as EOG\n",
      "load: control token:    580 '[control_578]' is not marked as EOG\n",
      "load: control token:    581 '[control_579]' is not marked as EOG\n",
      "load: control token:    582 '[control_580]' is not marked as EOG\n",
      "load: control token:    583 '[control_581]' is not marked as EOG\n",
      "load: control token:    584 '[control_582]' is not marked as EOG\n",
      "load: control token:    585 '[control_583]' is not marked as EOG\n",
      "load: control token:    586 '[control_584]' is not marked as EOG\n",
      "load: control token:    587 '[control_585]' is not marked as EOG\n",
      "load: control token:    588 '[control_586]' is not marked as EOG\n",
      "load: control token:    589 '[control_587]' is not marked as EOG\n",
      "load: control token:    590 '[control_588]' is not marked as EOG\n",
      "load: control token:    591 '[control_589]' is not marked as EOG\n",
      "load: control token:    592 '[control_590]' is not marked as EOG\n",
      "load: control token:    593 '[control_591]' is not marked as EOG\n",
      "load: control token:    594 '[control_592]' is not marked as EOG\n",
      "load: control token:    595 '[control_593]' is not marked as EOG\n",
      "load: control token:    596 '[control_594]' is not marked as EOG\n",
      "load: control token:    690 '[control_688]' is not marked as EOG\n",
      "load: control token:    597 '[control_595]' is not marked as EOG\n",
      "load: control token:    691 '[control_689]' is not marked as EOG\n",
      "load: control token:    598 '[control_596]' is not marked as EOG\n",
      "load: control token:    599 '[control_597]' is not marked as EOG\n",
      "load: control token:    600 '[control_598]' is not marked as EOG\n",
      "load: control token:    686 '[control_684]' is not marked as EOG\n",
      "load: control token:    601 '[control_599]' is not marked as EOG\n",
      "load: control token:    687 '[control_685]' is not marked as EOG\n",
      "load: control token:    711 '[control_709]' is not marked as EOG\n",
      "load: control token:    602 '[control_600]' is not marked as EOG\n",
      "load: control token:    710 '[control_708]' is not marked as EOG\n",
      "load: control token:    603 '[control_601]' is not marked as EOG\n",
      "load: control token:    604 '[control_602]' is not marked as EOG\n",
      "load: control token:    605 '[control_603]' is not marked as EOG\n",
      "load: control token:    606 '[control_604]' is not marked as EOG\n",
      "load: control token:    607 '[control_605]' is not marked as EOG\n",
      "load: control token:    608 '[control_606]' is not marked as EOG\n",
      "load: control token:    609 '[control_607]' is not marked as EOG\n",
      "load: control token:    703 '[control_701]' is not marked as EOG\n",
      "load: control token:    610 '[control_608]' is not marked as EOG\n",
      "load: control token:    702 '[control_700]' is not marked as EOG\n",
      "load: control token:    611 '[control_609]' is not marked as EOG\n",
      "load: control token:    620 '[control_618]' is not marked as EOG\n",
      "load: control token:    621 '[control_619]' is not marked as EOG\n",
      "load: control token:    622 '[control_620]' is not marked as EOG\n",
      "load: control token:    770 '[control_768]' is not marked as EOG\n",
      "load: control token:    623 '[control_621]' is not marked as EOG\n",
      "load: control token:    625 '[control_623]' is not marked as EOG\n",
      "load: control token:    626 '[control_624]' is not marked as EOG\n",
      "load: control token:    627 '[control_625]' is not marked as EOG\n",
      "load: control token:    628 '[control_626]' is not marked as EOG\n",
      "load: control token:    629 '[control_627]' is not marked as EOG\n",
      "load: control token:    763 '[control_761]' is not marked as EOG\n",
      "load: control token:    630 '[control_628]' is not marked as EOG\n",
      "load: control token:    762 '[control_760]' is not marked as EOG\n",
      "load: control token:    631 '[control_629]' is not marked as EOG\n",
      "load: control token:    632 '[control_630]' is not marked as EOG\n",
      "load: control token:    633 '[control_631]' is not marked as EOG\n",
      "load: control token:    634 '[control_632]' is not marked as EOG\n",
      "load: control token:    635 '[control_633]' is not marked as EOG\n",
      "load: control token:    636 '[control_634]' is not marked as EOG\n",
      "load: control token:    637 '[control_635]' is not marked as EOG\n",
      "load: control token:    638 '[control_636]' is not marked as EOG\n",
      "load: control token:    721 '[control_719]' is not marked as EOG\n",
      "load: control token:    639 '[control_637]' is not marked as EOG\n",
      "load: control token:    720 '[control_718]' is not marked as EOG\n",
      "load: control token:    719 '[control_717]' is not marked as EOG\n",
      "load: control token:    640 '[control_638]' is not marked as EOG\n",
      "load: control token:    718 '[control_716]' is not marked as EOG\n",
      "load: control token:    641 '[control_639]' is not marked as EOG\n",
      "load: control token:    642 '[control_640]' is not marked as EOG\n",
      "load: control token:    643 '[control_641]' is not marked as EOG\n",
      "load: control token:    644 '[control_642]' is not marked as EOG\n",
      "load: control token:    645 '[control_643]' is not marked as EOG\n",
      "load: control token:    646 '[control_644]' is not marked as EOG\n",
      "load: control token:    647 '[control_645]' is not marked as EOG\n",
      "load: control token:    648 '[control_646]' is not marked as EOG\n",
      "load: control token:    649 '[control_647]' is not marked as EOG\n",
      "load: control token:    650 '[control_648]' is not marked as EOG\n",
      "load: control token:    651 '[control_649]' is not marked as EOG\n",
      "load: control token:    652 '[control_650]' is not marked as EOG\n",
      "load: control token:    653 '[control_651]' is not marked as EOG\n",
      "load: control token:    654 '[control_652]' is not marked as EOG\n",
      "load: control token:    658 '[control_656]' is not marked as EOG\n",
      "load: control token:    659 '[control_657]' is not marked as EOG\n",
      "load: control token:    670 '[control_668]' is not marked as EOG\n",
      "load: control token:    671 '[control_669]' is not marked as EOG\n",
      "load: control token:    672 '[control_670]' is not marked as EOG\n",
      "load: control token:    673 '[control_671]' is not marked as EOG\n",
      "load: control token:    674 '[control_672]' is not marked as EOG\n",
      "load: control token:    675 '[control_673]' is not marked as EOG\n",
      "load: control token:    676 '[control_674]' is not marked as EOG\n",
      "load: control token:    677 '[control_675]' is not marked as EOG\n",
      "load: control token:    678 '[control_676]' is not marked as EOG\n",
      "load: control token:    679 '[control_677]' is not marked as EOG\n",
      "load: control token:    680 '[control_678]' is not marked as EOG\n",
      "load: control token:    681 '[control_679]' is not marked as EOG\n",
      "load: control token:    682 '[control_680]' is not marked as EOG\n",
      "load: control token:    683 '[control_681]' is not marked as EOG\n",
      "load: control token:    684 '[control_682]' is not marked as EOG\n",
      "load: control token:    685 '[control_683]' is not marked as EOG\n",
      "load: control token:    688 '[control_686]' is not marked as EOG\n",
      "load: control token:    689 '[control_687]' is not marked as EOG\n",
      "load: control token:    700 '[control_698]' is not marked as EOG\n",
      "load: control token:    701 '[control_699]' is not marked as EOG\n",
      "load: control token:    704 '[control_702]' is not marked as EOG\n",
      "load: control token:    705 '[control_703]' is not marked as EOG\n",
      "load: control token:    706 '[control_704]' is not marked as EOG\n",
      "load: control token:    707 '[control_705]' is not marked as EOG\n",
      "load: control token:    708 '[control_706]' is not marked as EOG\n",
      "load: control token:    709 '[control_707]' is not marked as EOG\n",
      "load: control token:    712 '[control_710]' is not marked as EOG\n",
      "load: control token:    713 '[control_711]' is not marked as EOG\n",
      "load: control token:    714 '[control_712]' is not marked as EOG\n",
      "load: control token:    715 '[control_713]' is not marked as EOG\n",
      "load: control token:    716 '[control_714]' is not marked as EOG\n",
      "load: control token:    717 '[control_715]' is not marked as EOG\n",
      "load: control token:    722 '[control_720]' is not marked as EOG\n",
      "load: control token:    723 '[control_721]' is not marked as EOG\n",
      "load: control token:    726 '[control_724]' is not marked as EOG\n",
      "load: control token:    727 '[control_725]' is not marked as EOG\n",
      "load: control token:    728 '[control_726]' is not marked as EOG\n",
      "load: control token:    729 '[control_727]' is not marked as EOG\n",
      "load: control token:    734 '[control_732]' is not marked as EOG\n",
      "load: control token:    735 '[control_733]' is not marked as EOG\n",
      "load: control token:    736 '[control_734]' is not marked as EOG\n",
      "load: control token:    737 '[control_735]' is not marked as EOG\n",
      "load: control token:    738 '[control_736]' is not marked as EOG\n",
      "load: control token:    739 '[control_737]' is not marked as EOG\n",
      "load: control token:    742 '[control_740]' is not marked as EOG\n",
      "load: control token:    743 '[control_741]' is not marked as EOG\n",
      "load: control token:    744 '[control_742]' is not marked as EOG\n",
      "load: control token:    745 '[control_743]' is not marked as EOG\n",
      "load: control token:    746 '[control_744]' is not marked as EOG\n",
      "load: control token:    747 '[control_745]' is not marked as EOG\n",
      "load: control token:    748 '[control_746]' is not marked as EOG\n",
      "load: control token:    749 '[control_747]' is not marked as EOG\n",
      "load: control token:    750 '[control_748]' is not marked as EOG\n",
      "load: control token:    751 '[control_749]' is not marked as EOG\n",
      "load: control token:    752 '[control_750]' is not marked as EOG\n",
      "load: control token:    753 '[control_751]' is not marked as EOG\n",
      "load: control token:    754 '[control_752]' is not marked as EOG\n",
      "load: control token:    755 '[control_753]' is not marked as EOG\n",
      "load: control token:    756 '[control_754]' is not marked as EOG\n",
      "load: control token:    757 '[control_755]' is not marked as EOG\n",
      "load: control token:    764 '[control_762]' is not marked as EOG\n",
      "load: control token:    765 '[control_763]' is not marked as EOG\n",
      "load: control token:    766 '[control_764]' is not marked as EOG\n",
      "load: control token:    767 '[control_765]' is not marked as EOG\n",
      "load: control token:    768 '[control_766]' is not marked as EOG\n",
      "load: control token:    769 '[control_767]' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 771\n",
      "load: token to piece cache size = 0.1731 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.25 B\n",
      "print_info: general.name     = models--mistralai--Mistral-7B-Instruct-v0.3\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32768\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: LF token         = 781 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU\n",
      "load_tensors: layer   1 assigned to device CPU\n",
      "load_tensors: layer   2 assigned to device CPU\n",
      "load_tensors: layer   3 assigned to device CPU\n",
      "load_tensors: layer   4 assigned to device CPU\n",
      "load_tensors: layer   5 assigned to device CPU\n",
      "load_tensors: layer   6 assigned to device CPU\n",
      "load_tensors: layer   7 assigned to device CPU\n",
      "load_tensors: layer   8 assigned to device CPU\n",
      "load_tensors: layer   9 assigned to device CPU\n",
      "load_tensors: layer  10 assigned to device CPU\n",
      "load_tensors: layer  11 assigned to device CPU\n",
      "load_tensors: layer  12 assigned to device CPU\n",
      "load_tensors: layer  13 assigned to device CPU\n",
      "load_tensors: layer  14 assigned to device CPU\n",
      "load_tensors: layer  15 assigned to device CPU\n",
      "load_tensors: layer  16 assigned to device CPU\n",
      "load_tensors: layer  17 assigned to device CPU\n",
      "load_tensors: layer  18 assigned to device CPU\n",
      "load_tensors: layer  19 assigned to device CPU\n",
      "load_tensors: layer  20 assigned to device CPU\n",
      "load_tensors: layer  21 assigned to device CPU\n",
      "load_tensors: layer  22 assigned to device CPU\n",
      "load_tensors: layer  23 assigned to device CPU\n",
      "load_tensors: layer  24 assigned to device CPU\n",
      "load_tensors: layer  25 assigned to device CPU\n",
      "load_tensors: layer  26 assigned to device CPU\n",
      "load_tensors: layer  27 assigned to device CPU\n",
      "load_tensors: layer  28 assigned to device CPU\n",
      "load_tensors: layer  29 assigned to device CPU\n",
      "load_tensors: layer  30 assigned to device CPU\n",
      "load_tensors: layer  31 assigned to device CPU\n",
      "load_tensors: layer  32 assigned to device CPU\n",
      "load_tensors: tensor 'token_embd.weight' (f16) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size = 13825.02 MiB\n",
      "...................................................................................................\n",
      "llama_init_from_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 4096\n",
      "llama_init_from_model: n_ctx_per_seq = 4096\n",
      "llama_init_from_model: n_batch       = 64\n",
      "llama_init_from_model: n_ubatch      = 32\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 1000000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 4096, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
      "llama_init_from_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_init_from_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_init_from_model:        CPU compute buffer size =    19.00 MiB\n",
      "llama_init_from_model: graph nodes  = 1030\n",
      "llama_init_from_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.name': 'models--mistralai--Mistral-7B-Instruct-v0.3', 'general.architecture': 'llama', 'llama.block_count': '32', 'llama.context_length': '32768', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '1', 'llama.attention.head_count_kv': '8', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '1000000.000000', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.vocab_size': '32768', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.model': 'llama', 'tokenizer.ggml.pre': 'default', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\"}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from llama_cpp import Llama\n",
    "from tqdm import tqdm\n",
    "\n",
    "llm = Llama(model_path=model_path, n_gpu_layers=50, n_ctx=4096, n_batch=32)  # Adjust GPU layers if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE_SENTIMENT = (\n",
    "    \"You are a sentiment classification assistant. Your task is to analyze the sentiment of a comment \"\n",
    "    \"and classify it into one of three categories: 'Positif', 'Negatif', or 'Neutre'.\\n\\n\"\n",
    "    \"### Sentiment Classification Rules:\\n\"\n",
    "    \"- **Positif**: If the comment expresses satisfaction, praise, or something good.\\n\"\n",
    "    \"- **Negatif**: If the comment expresses dissatisfaction, criticism, or a complaint or a something not good.\\n\"\n",
    "    \"- **Neutre**: If the comment is vague, neutral, or lacks strong sentiment.\\n\\n\"\n",
    "    \"### Instructions:\\n\"\n",
    "    \"1. Read the comment carefully.\\n\"\n",
    "    \"2. Return only one of the three labels: **Positif, Negatif, or Neutre**.\\n\"\n",
    "    \"3. Do NOT provide explanations.\\n\\n\"\n",
    "    \"### Supported Languages:\\n\"\n",
    "    \"- Arabic (including Algerian Darija)\\n\"\n",
    "    \"- French\\n\"\n",
    "    \"- English\\n\\n\"\n",
    "    \"### Example:\\n\"\n",
    "    \"- **Comment:** 'ุฃูุชุฑูุช ูููุญุฉ'\\n\"\n",
    "    \"- **Output:** 'Positif'\\n\"\n",
    "    \"- **Comment:** 'ุงูุฎุฏูุฉ ุณูุฆุฉ ุฌุฏุง ูุจุทูุฆุฉ'\\n\"\n",
    "    \"- **Output:** 'Negatif'\\n\"\n",
    "    \"- **Comment:** 'ูู ููุฌุฏ ุนุฑุถ ุฌุฏูุฏุ'\\n\"\n",
    "    \"- **Output:** 'Neutre'\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ๐ Function to Predict Sentiment\n",
    "def classify_sentiment(comment):\n",
    "    if not isinstance(comment, str) or comment.strip() == \"\":\n",
    "        return \"Neutre\"  # Default for empty comments\n",
    "    \n",
    "    prompt = f\"{SYSTEM_MESSAGE_SENTIMENT}\\n\\nComment: {comment}\\nSentiment:\"\n",
    "    \n",
    "    response = llm(prompt, max_tokens=5, stop=[\"\\n\"])\n",
    "    sentiment = response[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    # Ensure output is one of the three classes\n",
    "    if sentiment not in [\"Positif\", \"Negatif\", \"Neutre\"]:\n",
    "        return \"Neutre\"\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3487 [00:00<?, ?it/s]Llama.generate: 307 prefix-match hit, remaining 254 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   73947.73 ms /   273 tokens (  270.87 ms per token,     3.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2844.20 ms /     3 runs   (  948.07 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   61926.00 ms /   276 tokens\n",
      "  0%|          | 2/3487 [01:01<29:58:39, 30.97s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5077.10 ms /    22 tokens (  230.78 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2941.92 ms /     3 runs   (  980.64 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    8021.36 ms /    25 tokens\n",
      "  0%|          | 3/3487 [01:09<20:43:09, 21.41s/it]Llama.generate: 315 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2908.73 ms /    13 tokens (  223.75 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.18 ms /     3 runs   (  900.06 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5611.49 ms /    16 tokens\n",
      "  0%|          | 4/3487 [01:15<15:00:48, 15.52s/it]Llama.generate: 315 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2459.49 ms /    12 tokens (  204.96 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.34 ms /     3 runs   (  886.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5121.48 ms /    15 tokens\n",
      "  0%|          | 5/3487 [01:20<11:30:57, 11.91s/it]Llama.generate: 315 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13106.45 ms /    65 tokens (  201.64 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.59 ms /     3 runs   (  888.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15774.78 ms /    68 tokens\n",
      "  0%|          | 6/3487 [01:36<12:45:25, 13.19s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3809.21 ms /    19 tokens (  200.48 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.68 ms /     3 runs   (  903.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6523.97 ms /    22 tokens\n",
      "  0%|          | 7/3487 [01:43<10:40:58, 11.05s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5004.26 ms /    25 tokens (  200.17 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2868.68 ms /     3 runs   (  956.23 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    7875.59 ms /    28 tokens\n",
      "  0%|          | 8/3487 [01:50<9:43:01, 10.05s/it] Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3008.11 ms /    13 tokens (  231.39 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4229.67 ms /     3 runs   ( 1409.89 ms per token,     0.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    7241.90 ms /    16 tokens\n",
      "  0%|          | 9/3487 [01:58<8:52:26,  9.19s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2785.49 ms /    11 tokens (  253.23 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2874.16 ms /     3 runs   (  958.05 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    5662.55 ms /    14 tokens\n",
      "  0%|          | 10/3487 [02:03<7:49:45,  8.11s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9898.33 ms /    52 tokens (  190.35 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.64 ms /     3 runs   (  875.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12526.70 ms /    55 tokens\n",
      "  0%|          | 11/3487 [02:16<9:07:51,  9.46s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4527.93 ms /    24 tokens (  188.66 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.04 ms /     3 runs   (  887.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7191.89 ms /    27 tokens\n",
      "  0%|          | 12/3487 [02:23<8:28:02,  8.77s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15945.34 ms /    69 tokens (  231.09 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3939.70 ms /     3 runs   ( 1313.23 ms per token,     0.76 tokens per second)\n",
      "llama_perf_context_print:       total time =   19888.81 ms /    72 tokens\n",
      "  0%|          | 13/3487 [02:43<11:42:44, 12.14s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3351.47 ms /    17 tokens (  197.15 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.38 ms /     3 runs   (  892.13 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6031.68 ms /    20 tokens\n",
      "  0%|          | 14/3487 [02:49<9:56:06, 10.30s/it] Llama.generate: 307 prefix-match hit, remaining 208 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   39268.58 ms /   208 tokens (  188.79 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.43 ms /     3 runs   (  900.48 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   41972.50 ms /   211 tokens\n",
      "  0%|          | 15/3487 [03:31<19:08:04, 19.84s/it]Llama.generate: 307 prefix-match hit, remaining 161 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   30710.57 ms /   161 tokens (  190.75 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2766.87 ms /     3 runs   (  922.29 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   33480.01 ms /   164 tokens\n",
      "  0%|          | 16/3487 [04:04<23:05:13, 23.95s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10636.24 ms /    50 tokens (  212.72 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2730.22 ms /     3 runs   (  910.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   13369.36 ms /    53 tokens\n",
      "  0%|          | 17/3487 [04:18<20:01:13, 20.77s/it]Llama.generate: 309 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4353.88 ms /    22 tokens (  197.90 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.14 ms /     3 runs   (  891.05 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7029.66 ms /    25 tokens\n",
      "  1%|          | 18/3487 [04:25<16:02:23, 16.65s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7900.61 ms /    41 tokens (  192.70 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.00 ms /     3 runs   (  888.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10569.08 ms /    44 tokens\n",
      "  1%|          | 19/3487 [04:35<14:16:47, 14.82s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9227.92 ms /    49 tokens (  188.32 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.86 ms /     3 runs   (  873.29 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11850.97 ms /    52 tokens\n",
      "  1%|          | 20/3487 [04:47<13:25:07, 13.93s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6930.03 ms /    34 tokens (  203.82 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.15 ms /     3 runs   (  872.05 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9548.53 ms /    37 tokens\n",
      "  1%|          | 21/3487 [04:57<12:09:00, 12.62s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4357.40 ms /    23 tokens (  189.45 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.15 ms /     3 runs   (  873.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6980.87 ms /    26 tokens\n",
      "  1%|          | 22/3487 [05:04<10:31:14, 10.93s/it]Llama.generate: 308 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6086.55 ms /    32 tokens (  190.20 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.00 ms /     3 runs   (  870.33 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8700.50 ms /    35 tokens\n",
      "  1%|          | 23/3487 [05:13<9:52:33, 10.26s/it] Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3389.55 ms /    18 tokens (  188.31 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.97 ms /     3 runs   (  881.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6038.35 ms /    21 tokens\n",
      "  1%|          | 24/3487 [05:19<8:39:21,  9.00s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9175.74 ms /    48 tokens (  191.16 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.70 ms /     3 runs   (  879.57 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11816.82 ms /    51 tokens\n",
      "  1%|          | 25/3487 [05:30<9:28:09,  9.85s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2082.99 ms /    10 tokens (  208.30 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.97 ms /     3 runs   (  872.66 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4703.49 ms /    13 tokens\n",
      "  1%|          | 26/3487 [05:35<7:59:09,  8.31s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5680.47 ms /    27 tokens (  210.39 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.66 ms /     3 runs   (  887.89 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8347.59 ms /    30 tokens\n",
      "  1%|          | 27/3487 [05:44<7:59:50,  8.32s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3487.77 ms /    18 tokens (  193.77 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2905.53 ms /     3 runs   (  968.51 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6396.62 ms /    21 tokens\n",
      "  1%|          | 28/3487 [05:50<7:26:36,  7.75s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4400.52 ms /    20 tokens (  220.03 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.10 ms /     3 runs   (  910.37 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7134.45 ms /    23 tokens\n",
      "  1%|          | 29/3487 [05:57<7:16:07,  7.57s/it]Llama.generate: 306 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15392.98 ms /    80 tokens (  192.41 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.19 ms /     3 runs   (  874.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18018.58 ms /    83 tokens\n",
      "  1%|          | 30/3487 [06:15<10:16:48, 10.71s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5551.04 ms /    29 tokens (  191.42 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.51 ms /     3 runs   (  890.50 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8225.15 ms /    32 tokens\n",
      "  1%|          | 31/3487 [06:23<9:33:53,  9.96s/it] Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1768.44 ms /     8 tokens (  221.06 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.16 ms /     3 runs   (  881.05 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4413.93 ms /    11 tokens\n",
      "  1%|          | 32/3487 [06:28<7:58:00,  8.30s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4087.29 ms /    21 tokens (  194.63 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.30 ms /     3 runs   (  873.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6709.64 ms /    24 tokens\n",
      "  1%|          | 33/3487 [06:34<7:30:33,  7.83s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4019.75 ms /    20 tokens (  200.99 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2768.06 ms /     3 runs   (  922.69 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6790.35 ms /    23 tokens\n",
      "  1%|          | 34/3487 [06:41<7:12:40,  7.52s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7134.22 ms /    34 tokens (  209.83 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.38 ms /     3 runs   (  879.79 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9776.52 ms /    37 tokens\n",
      "  1%|          | 35/3487 [06:51<7:51:41,  8.20s/it]Llama.generate: 307 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15562.10 ms /    80 tokens (  194.53 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.57 ms /     3 runs   (  874.52 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18188.46 ms /    83 tokens\n",
      "  1%|          | 36/3487 [07:09<10:44:06, 11.20s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4043.43 ms /    21 tokens (  192.54 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.27 ms /     3 runs   (  875.09 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6671.52 ms /    24 tokens\n",
      "  1%|          | 37/3487 [07:16<9:26:01,  9.84s/it] Llama.generate: 306 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21004.87 ms /   102 tokens (  205.93 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3181.33 ms /     3 runs   ( 1060.44 ms per token,     0.94 tokens per second)\n",
      "llama_perf_context_print:       total time =   24189.69 ms /   105 tokens\n",
      "  1%|          | 38/3487 [07:40<13:33:24, 14.15s/it]Llama.generate: 307 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16262.21 ms /    78 tokens (  208.49 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2785.95 ms /     3 runs   (  928.65 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   19050.51 ms /    81 tokens\n",
      "  1%|          | 39/3487 [07:59<14:57:48, 15.62s/it]Llama.generate: 307 prefix-match hit, remaining 181 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   35943.44 ms /   181 tokens (  198.58 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.15 ms /     3 runs   (  898.72 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   38642.44 ms /   184 tokens\n",
      "  1%|          | 40/3487 [08:38<21:34:26, 22.53s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6096.49 ms /    31 tokens (  196.66 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2776.26 ms /     3 runs   (  925.42 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8875.36 ms /    34 tokens\n",
      "  1%|          | 41/3487 [08:47<17:38:55, 18.44s/it]Llama.generate: 306 prefix-match hit, remaining 134 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26070.55 ms /   134 tokens (  194.56 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3081.97 ms /     3 runs   ( 1027.32 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =   29154.94 ms /   137 tokens\n",
      "  1%|          | 42/3487 [09:16<20:43:20, 21.65s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10110.52 ms /    51 tokens (  198.25 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.60 ms /     3 runs   (  873.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12734.87 ms /    54 tokens\n",
      "  1%|          | 43/3487 [09:29<18:09:32, 18.98s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3317.38 ms /    16 tokens (  207.34 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.76 ms /     3 runs   (  873.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5942.14 ms /    19 tokens\n",
      "  1%|โ         | 44/3487 [09:35<14:24:54, 15.07s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1836.75 ms /     7 tokens (  262.39 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.05 ms /     3 runs   (  875.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4465.30 ms /    10 tokens\n",
      "  1%|โ         | 45/3487 [09:39<11:22:47, 11.90s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7532.14 ms /    38 tokens (  198.21 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.82 ms /     3 runs   (  877.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10166.98 ms /    41 tokens\n",
      "  1%|โ         | 46/3487 [09:49<10:52:53, 11.38s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6835.38 ms /    31 tokens (  220.50 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.27 ms /     3 runs   (  891.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9511.10 ms /    34 tokens\n",
      "  1%|โ         | 47/3487 [09:59<10:20:40, 10.83s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6106.22 ms /    31 tokens (  196.97 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.42 ms /     3 runs   (  873.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8729.24 ms /    34 tokens\n",
      "  1%|โ         | 48/3487 [10:08<9:44:34, 10.20s/it] Llama.generate: 308 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4945.91 ms /    25 tokens (  197.84 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.82 ms /     3 runs   (  879.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7588.73 ms /    28 tokens\n",
      "  1%|โ         | 49/3487 [10:15<8:59:40,  9.42s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7416.86 ms /    37 tokens (  200.46 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.68 ms /     3 runs   (  874.89 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10044.11 ms /    40 tokens\n",
      "  1%|โ         | 50/3487 [10:25<9:10:24,  9.61s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3421.39 ms /    17 tokens (  201.26 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.97 ms /     3 runs   (  879.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6062.36 ms /    20 tokens\n",
      "  1%|โ         | 51/3487 [10:31<8:09:29,  8.55s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2438.52 ms /    10 tokens (  243.85 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.72 ms /     3 runs   (  884.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5095.75 ms /    13 tokens\n",
      "  1%|โ         | 52/3487 [10:36<7:10:14,  7.52s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12035.78 ms /    62 tokens (  194.13 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.36 ms /     3 runs   (  891.45 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14712.36 ms /    65 tokens\n",
      "  2%|โ         | 53/3487 [10:51<9:13:52,  9.68s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5419.02 ms /    27 tokens (  200.70 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.53 ms /     3 runs   (  884.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8076.52 ms /    30 tokens\n",
      "  2%|โ         | 54/3487 [10:59<8:46:22,  9.20s/it]Llama.generate: 306 prefix-match hit, remaining 170 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   32811.79 ms /   170 tokens (  193.01 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.52 ms /     3 runs   (  874.84 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   35439.52 ms /   173 tokens\n",
      "  2%|โ         | 55/3487 [11:35<16:16:38, 17.07s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9873.07 ms /    51 tokens (  193.59 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.62 ms /     3 runs   (  879.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12514.83 ms /    54 tokens\n",
      "  2%|โ         | 56/3487 [11:47<14:58:19, 15.71s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7806.10 ms /    39 tokens (  200.16 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.11 ms /     3 runs   (  877.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10442.45 ms /    42 tokens\n",
      "  2%|โ         | 57/3487 [11:58<13:27:54, 14.13s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10761.30 ms /    56 tokens (  192.17 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2605.66 ms /     3 runs   (  868.55 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   13369.74 ms /    59 tokens\n",
      "  2%|โ         | 58/3487 [12:11<13:14:45, 13.91s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9267.69 ms /    47 tokens (  197.18 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2832.12 ms /     3 runs   (  944.04 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   12102.21 ms /    50 tokens\n",
      "  2%|โ         | 59/3487 [12:23<12:43:45, 13.37s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5186.11 ms /    25 tokens (  207.44 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.31 ms /     3 runs   (  915.77 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7936.53 ms /    28 tokens\n",
      "  2%|โ         | 60/3487 [12:31<11:10:40, 11.74s/it]Llama.generate: 307 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17017.64 ms /    84 tokens (  202.59 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.51 ms /     3 runs   (  883.17 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19670.60 ms /    87 tokens\n",
      "  2%|โ         | 61/3487 [12:51<13:26:25, 14.12s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1797.92 ms /     8 tokens (  224.74 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.41 ms /     3 runs   (  877.80 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4433.60 ms /    11 tokens\n",
      "  2%|โ         | 62/3487 [12:55<10:40:24, 11.22s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7076.26 ms /    33 tokens (  214.43 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.34 ms /     3 runs   (  879.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9717.50 ms /    36 tokens\n",
      "  2%|โ         | 63/3487 [13:05<10:14:43, 10.77s/it]Llama.generate: 306 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12185.11 ms /    63 tokens (  193.41 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.97 ms /     3 runs   (  881.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14832.83 ms /    66 tokens\n",
      "  2%|โ         | 64/3487 [13:20<11:24:10, 11.99s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7947.53 ms /    40 tokens (  198.69 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.18 ms /     3 runs   (  875.06 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10575.50 ms /    43 tokens\n",
      "  2%|โ         | 65/3487 [13:30<10:59:52, 11.57s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8279.51 ms /    41 tokens (  201.94 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.05 ms /     3 runs   (  878.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10918.98 ms /    44 tokens\n",
      "  2%|โ         | 66/3487 [13:41<10:48:43, 11.38s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7473.10 ms /    37 tokens (  201.98 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.78 ms /     3 runs   (  880.93 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10118.97 ms /    40 tokens\n",
      "  2%|โ         | 67/3487 [13:51<10:27:08, 11.00s/it]Llama.generate: 306 prefix-match hit, remaining 136 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27219.48 ms /   136 tokens (  200.14 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2814.46 ms /     3 runs   (  938.15 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   30036.64 ms /   139 tokens\n",
      "  2%|โ         | 68/3487 [14:21<15:52:30, 16.72s/it]Llama.generate: 306 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13440.88 ms /    65 tokens (  206.78 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.47 ms /     3 runs   (  883.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16095.18 ms /    68 tokens\n",
      "  2%|โ         | 69/3487 [14:38<15:41:46, 16.53s/it]Llama.generate: 306 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11265.79 ms /    58 tokens (  194.24 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.30 ms /     3 runs   (  883.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13919.50 ms /    61 tokens\n",
      "  2%|โ         | 70/3487 [14:51<14:57:01, 15.75s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7219.91 ms /    33 tokens (  218.79 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.40 ms /     3 runs   (  882.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9870.35 ms /    36 tokens\n",
      "  2%|โ         | 71/3487 [15:01<13:16:27, 13.99s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2930.58 ms /    14 tokens (  209.33 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.95 ms /     3 runs   (  880.98 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5576.18 ms /    17 tokens\n",
      "  2%|โ         | 72/3487 [15:07<10:52:42, 11.47s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3574.36 ms /    18 tokens (  198.58 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.70 ms /     3 runs   (  890.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6250.16 ms /    21 tokens\n",
      "  2%|โ         | 73/3487 [15:13<9:23:38,  9.91s/it] Llama.generate: 307 prefix-match hit, remaining 122 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24862.20 ms /   122 tokens (  203.79 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.30 ms /     3 runs   (  879.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27504.45 ms /   125 tokens\n",
      "  2%|โ         | 74/3487 [15:41<14:23:57, 15.19s/it]Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11052.60 ms /    57 tokens (  193.91 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.25 ms /     3 runs   (  887.08 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13716.67 ms /    60 tokens\n",
      "  2%|โ         | 75/3487 [15:54<13:58:43, 14.75s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4532.95 ms /    24 tokens (  188.87 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.25 ms /     3 runs   (  885.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7192.15 ms /    27 tokens\n",
      "  2%|โ         | 76/3487 [16:02<11:49:45, 12.48s/it]Llama.generate: 308 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4537.94 ms /    23 tokens (  197.30 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2813.35 ms /     3 runs   (  937.78 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7353.89 ms /    26 tokens\n",
      "  2%|โ         | 77/3487 [16:09<10:22:13, 10.95s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1403.45 ms /     6 tokens (  233.91 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.16 ms /     3 runs   (  885.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4062.50 ms /     9 tokens\n",
      "  2%|โ         | 78/3487 [16:13<8:24:48,  8.88s/it] Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3798.65 ms /    19 tokens (  199.93 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.35 ms /     3 runs   (  889.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6468.45 ms /    22 tokens\n",
      "  2%|โ         | 79/3487 [16:20<7:43:37,  8.16s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11820.05 ms /    62 tokens (  190.65 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.54 ms /     3 runs   (  873.18 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14441.73 ms /    65 tokens\n",
      "  2%|โ         | 80/3487 [16:34<9:30:37, 10.05s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12910.68 ms /    67 tokens (  192.70 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.71 ms /     3 runs   (  873.90 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15534.91 ms /    70 tokens\n",
      "  2%|โ         | 81/3487 [16:50<11:04:01, 11.70s/it]Llama.generate: 307 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25233.42 ms /   133 tokens (  189.72 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.75 ms /     3 runs   (  878.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27872.07 ms /   136 tokens\n",
      "  2%|โ         | 82/3487 [17:17<15:39:18, 16.55s/it]Llama.generate: 307 prefix-match hit, remaining 132 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25651.77 ms /   132 tokens (  194.33 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3293.86 ms /     3 runs   ( 1097.95 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =   28948.54 ms /   135 tokens\n",
      "  2%|โ         | 83/3487 [17:46<19:10:13, 20.27s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14596.79 ms /    67 tokens (  217.86 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2826.12 ms /     3 runs   (  942.04 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   17425.91 ms /    70 tokens\n",
      "  2%|โ         | 84/3487 [18:04<18:21:34, 19.42s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3166.52 ms /    13 tokens (  243.58 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2823.36 ms /     3 runs   (  941.12 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5993.08 ms /    16 tokens\n",
      "  2%|โ         | 85/3487 [18:10<14:33:00, 15.40s/it]Llama.generate: 312 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1448.06 ms /     5 tokens (  289.61 ms per token,     3.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2718.11 ms /     3 runs   (  906.04 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4169.29 ms /     8 tokens\n",
      "  2%|โ         | 86/3487 [18:14<11:21:59, 12.03s/it]Llama.generate: 312 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1149.40 ms /     4 tokens (  287.35 ms per token,     3.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2783.29 ms /     3 runs   (  927.76 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    3935.16 ms /     7 tokens\n",
      "  2%|โ         | 87/3487 [18:18<9:04:21,  9.61s/it] Llama.generate: 310 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2327.65 ms /    10 tokens (  232.76 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.94 ms /     3 runs   (  913.31 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5069.95 ms /    13 tokens\n",
      "  3%|โ         | 88/3487 [18:23<7:47:14,  8.25s/it]Llama.generate: 310 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1407.30 ms /     6 tokens (  234.55 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.20 ms /     3 runs   (  883.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4060.07 ms /     9 tokens\n",
      "  3%|โ         | 89/3487 [18:27<6:36:07,  6.99s/it]Llama.generate: 312 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1921.31 ms /     9 tokens (  213.48 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.15 ms /     3 runs   (  878.72 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4559.95 ms /    12 tokens\n",
      "  3%|โ         | 90/3487 [18:32<5:54:45,  6.27s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11997.95 ms /    62 tokens (  193.52 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.44 ms /     3 runs   (  883.81 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14651.43 ms /    65 tokens\n",
      "  3%|โ         | 91/3487 [18:46<8:17:09,  8.78s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4897.92 ms /    25 tokens (  195.92 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.42 ms /     3 runs   (  878.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7537.52 ms /    28 tokens\n",
      "  3%|โ         | 92/3487 [18:54<7:55:58,  8.41s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2451.04 ms /    11 tokens (  222.82 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.59 ms /     3 runs   (  900.53 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5155.89 ms /    14 tokens\n",
      "  3%|โ         | 93/3487 [18:59<7:00:43,  7.44s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3278.33 ms /    16 tokens (  204.90 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.52 ms /     3 runs   (  880.17 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5921.25 ms /    19 tokens\n",
      "  3%|โ         | 94/3487 [19:05<6:35:01,  6.99s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2204.07 ms /    10 tokens (  220.41 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.30 ms /     3 runs   (  884.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4859.41 ms /    13 tokens\n",
      "  3%|โ         | 95/3487 [19:10<5:59:01,  6.35s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3548.81 ms /    18 tokens (  197.16 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.82 ms /     3 runs   (  876.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6181.55 ms /    21 tokens\n",
      "  3%|โ         | 96/3487 [19:16<5:56:12,  6.30s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2836.97 ms /    14 tokens (  202.64 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3193.90 ms /     3 runs   ( 1064.63 ms per token,     0.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    6033.45 ms /    17 tokens\n",
      "  3%|โ         | 97/3487 [19:22<5:51:41,  6.22s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2978.58 ms /    14 tokens (  212.76 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.33 ms /     3 runs   (  887.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5643.96 ms /    17 tokens\n",
      "  3%|โ         | 98/3487 [19:28<5:41:53,  6.05s/it]Llama.generate: 307 prefix-match hit, remaining 125 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23717.44 ms /   125 tokens (  189.74 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.25 ms /     3 runs   (  878.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   26354.44 ms /   128 tokens\n",
      "  3%|โ         | 99/3487 [19:54<11:25:50, 12.15s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5522.44 ms /    29 tokens (  190.43 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.85 ms /     3 runs   (  880.95 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8167.84 ms /    32 tokens\n",
      "  3%|โ         | 100/3487 [20:02<10:18:25, 10.96s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7077.99 ms /    33 tokens (  214.48 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.20 ms /     3 runs   (  875.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9707.93 ms /    36 tokens\n",
      "  3%|โ         | 101/3487 [20:12<9:57:15, 10.58s/it] Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4555.86 ms /    24 tokens (  189.83 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.07 ms /     3 runs   (  887.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7222.03 ms /    27 tokens\n",
      "  3%|โ         | 102/3487 [20:19<9:00:19,  9.58s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5164.65 ms /    27 tokens (  191.28 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.62 ms /     3 runs   (  876.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7798.04 ms /    30 tokens\n",
      "  3%|โ         | 103/3487 [20:27<8:30:11,  9.05s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6054.86 ms /    32 tokens (  189.21 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.01 ms /     3 runs   (  889.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8726.27 ms /    35 tokens\n",
      "  3%|โ         | 104/3487 [20:36<8:24:48,  8.95s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3876.23 ms /    19 tokens (  204.01 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.53 ms /     3 runs   (  876.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6507.59 ms /    22 tokens\n",
      "  3%|โ         | 105/3487 [20:42<7:43:26,  8.22s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3876.19 ms /    20 tokens (  193.81 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.85 ms /     3 runs   (  874.28 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6502.02 ms /    23 tokens\n",
      "  3%|โ         | 106/3487 [20:49<7:14:21,  7.71s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3905.16 ms /    19 tokens (  205.53 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.95 ms /     3 runs   (  880.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6549.32 ms /    22 tokens\n",
      "  3%|โ         | 107/3487 [20:55<6:54:45,  7.36s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2685.22 ms /    13 tokens (  206.56 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.90 ms /     3 runs   (  889.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5357.74 ms /    16 tokens\n",
      "  3%|โ         | 108/3487 [21:01<6:20:54,  6.76s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8849.21 ms /    46 tokens (  192.37 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.34 ms /     3 runs   (  887.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11513.39 ms /    49 tokens\n",
      "  3%|โ         | 109/3487 [21:12<7:41:08,  8.19s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13131.88 ms /    66 tokens (  198.97 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.00 ms /     3 runs   (  907.33 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   15856.70 ms /    69 tokens\n",
      "  3%|โ         | 110/3487 [21:28<9:50:37, 10.49s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2845.90 ms /    13 tokens (  218.92 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.09 ms /     3 runs   (  894.03 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5530.51 ms /    16 tokens\n",
      "  3%|โ         | 111/3487 [21:34<8:26:47,  9.01s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1623.88 ms /     7 tokens (  231.98 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.79 ms /     3 runs   (  886.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4287.58 ms /    10 tokens\n",
      "  3%|โ         | 112/3487 [21:38<7:07:08,  7.59s/it]Llama.generate: 306 prefix-match hit, remaining 146 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27364.50 ms /   146 tokens (  187.43 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.41 ms /     3 runs   (  888.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   30032.47 ms /   149 tokens\n",
      "  3%|โ         | 113/3487 [22:08<13:25:42, 14.33s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2408.93 ms /    12 tokens (  200.74 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.78 ms /     3 runs   (  878.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5046.23 ms /    15 tokens\n",
      "  3%|โ         | 114/3487 [22:13<10:49:03, 11.55s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4026.88 ms /    21 tokens (  191.76 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.57 ms /     3 runs   (  892.52 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6707.57 ms /    24 tokens\n",
      "  3%|โ         | 115/3487 [22:20<9:27:26, 10.10s/it] Llama.generate: 306 prefix-match hit, remaining 229 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   43628.67 ms /   229 tokens (  190.52 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.12 ms /     3 runs   (  890.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   46302.19 ms /   232 tokens\n",
      "  3%|โ         | 116/3487 [23:06<19:37:41, 20.96s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6025.07 ms /    32 tokens (  188.28 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.53 ms /     3 runs   (  879.51 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8666.90 ms /    35 tokens\n",
      "  3%|โ         | 117/3487 [23:15<16:10:18, 17.28s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7046.61 ms /    35 tokens (  201.33 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.66 ms /     3 runs   (  879.89 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9689.00 ms /    38 tokens\n",
      "  3%|โ         | 118/3487 [23:24<14:02:21, 15.00s/it]Llama.generate: 307 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19481.15 ms /    98 tokens (  198.79 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2770.26 ms /     3 runs   (  923.42 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   22255.21 ms /   101 tokens\n",
      "  3%|โ         | 119/3487 [23:47<16:04:24, 17.18s/it]Llama.generate: 307 prefix-match hit, remaining 88 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28304.07 ms /    88 tokens (  321.64 ms per token,     3.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12804.07 ms /     3 runs   ( 4268.02 ms per token,     0.23 tokens per second)\n",
      "llama_perf_context_print:       total time =   41138.56 ms /    91 tokens\n",
      "  3%|โ         | 120/3487 [24:28<22:48:28, 24.39s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4218.40 ms /    13 tokens (  324.49 ms per token,     3.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4448.98 ms /     3 runs   ( 1482.99 ms per token,     0.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    8678.05 ms /    16 tokens\n",
      "  3%|โ         | 121/3487 [24:37<18:24:26, 19.69s/it]Llama.generate: 306 prefix-match hit, remaining 88 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19329.04 ms /    88 tokens (  219.65 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2865.94 ms /     3 runs   (  955.31 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   22198.56 ms /    91 tokens\n",
      "  3%|โ         | 122/3487 [24:59<19:06:34, 20.44s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7983.42 ms /    33 tokens (  241.92 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.47 ms /     3 runs   (  881.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10632.02 ms /    36 tokens\n",
      "  4%|โ         | 123/3487 [25:09<16:21:20, 17.50s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5804.03 ms /    30 tokens (  193.47 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.64 ms /     3 runs   (  900.22 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8507.62 ms /    33 tokens\n",
      "  4%|โ         | 124/3487 [25:18<13:49:58, 14.81s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7473.67 ms /    37 tokens (  201.99 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2791.13 ms /     3 runs   (  930.38 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   10267.60 ms /    40 tokens\n",
      "  4%|โ         | 125/3487 [25:28<12:33:33, 13.45s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3636.85 ms /    16 tokens (  227.30 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3381.99 ms /     3 runs   ( 1127.33 ms per token,     0.89 tokens per second)\n",
      "llama_perf_context_print:       total time =    7022.38 ms /    19 tokens\n",
      "  4%|โ         | 126/3487 [25:35<10:45:31, 11.52s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1774.72 ms /     6 tokens (  295.79 ms per token,     3.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2807.33 ms /     3 runs   (  935.78 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4585.11 ms /     9 tokens\n",
      "  4%|โ         | 127/3487 [25:40<8:49:00,  9.45s/it] Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4611.23 ms /    22 tokens (  209.60 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.64 ms /     3 runs   (  881.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7259.30 ms /    25 tokens\n",
      "  4%|โ         | 128/3487 [25:47<8:12:16,  8.79s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5516.42 ms /    28 tokens (  197.01 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.12 ms /     3 runs   (  888.37 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8183.65 ms /    31 tokens\n",
      "  4%|โ         | 129/3487 [25:55<8:02:03,  8.61s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13580.24 ms /    70 tokens (  194.00 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.68 ms /     3 runs   (  897.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   16276.82 ms /    73 tokens\n",
      "  4%|โ         | 130/3487 [26:12<10:10:44, 10.92s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7483.00 ms /    33 tokens (  226.76 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.72 ms /     3 runs   (  875.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10114.22 ms /    36 tokens\n",
      "  4%|โ         | 131/3487 [26:22<9:57:20, 10.68s/it] Llama.generate: 313 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1907.32 ms /     8 tokens (  238.41 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.30 ms /     3 runs   (  880.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4551.12 ms /    11 tokens\n",
      "  4%|โ         | 132/3487 [26:26<8:14:31,  8.84s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7670.45 ms /    37 tokens (  207.31 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.65 ms /     3 runs   (  874.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10297.70 ms /    40 tokens\n",
      "  4%|โ         | 133/3487 [26:37<8:38:54,  9.28s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4134.35 ms /    20 tokens (  206.72 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.78 ms /     3 runs   (  880.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6777.69 ms /    23 tokens\n",
      "  4%|โ         | 134/3487 [26:43<7:56:51,  8.53s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1282.45 ms /     5 tokens (  256.49 ms per token,     3.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.78 ms /     3 runs   (  875.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    3911.05 ms /     8 tokens\n",
      "  4%|โ         | 135/3487 [26:47<6:39:27,  7.15s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3166.18 ms /    15 tokens (  211.08 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.32 ms /     3 runs   (  872.77 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5787.32 ms /    18 tokens\n",
      "  4%|โ         | 136/3487 [26:53<6:16:41,  6.74s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5900.37 ms /    30 tokens (  196.68 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.89 ms /     3 runs   (  880.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8544.00 ms /    33 tokens\n",
      "  4%|โ         | 137/3487 [27:02<6:46:52,  7.29s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7699.69 ms /    38 tokens (  202.62 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.88 ms /     3 runs   (  876.63 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10332.61 ms /    41 tokens\n",
      "  4%|โ         | 138/3487 [27:12<7:37:53,  8.20s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4007.29 ms /    20 tokens (  200.36 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.09 ms /     3 runs   (  878.36 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6644.98 ms /    23 tokens\n",
      "  4%|โ         | 139/3487 [27:19<7:11:49,  7.74s/it]Llama.generate: 307 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10953.11 ms /    55 tokens (  199.15 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.94 ms /     3 runs   (  903.98 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   13667.78 ms /    58 tokens\n",
      "  4%|โ         | 140/3487 [27:32<8:51:03,  9.52s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3075.49 ms /    15 tokens (  205.03 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2925.53 ms /     3 runs   (  975.18 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6003.75 ms /    18 tokens\n",
      "  4%|โ         | 141/3487 [27:38<7:52:11,  8.47s/it]Llama.generate: 313 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1771.89 ms /     8 tokens (  221.49 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.89 ms /     3 runs   (  875.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4402.65 ms /    11 tokens\n",
      "  4%|โ         | 142/3487 [27:43<6:44:13,  7.25s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2531.22 ms /    12 tokens (  210.93 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.66 ms /     3 runs   (  875.89 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5162.02 ms /    15 tokens\n",
      "  4%|โ         | 143/3487 [27:48<6:09:19,  6.63s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3018.81 ms /    14 tokens (  215.63 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.44 ms /     3 runs   (  877.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5654.49 ms /    17 tokens\n",
      "  4%|โ         | 144/3487 [27:54<5:53:05,  6.34s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4349.13 ms /    21 tokens (  207.10 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.39 ms /     3 runs   (  878.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6987.34 ms /    24 tokens\n",
      "  4%|โ         | 145/3487 [28:01<6:04:00,  6.54s/it]Llama.generate: 307 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11679.34 ms /    60 tokens (  194.66 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.97 ms /     3 runs   (  872.32 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14298.85 ms /    63 tokens\n",
      "  4%|โ         | 146/3487 [28:15<8:13:43,  8.87s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7763.19 ms /    39 tokens (  199.06 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.42 ms /     3 runs   (  875.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10391.50 ms /    42 tokens\n",
      "  4%|โ         | 147/3487 [28:25<8:39:11,  9.33s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9083.12 ms /    46 tokens (  197.46 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2737.61 ms /     3 runs   (  912.54 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   11823.31 ms /    49 tokens\n",
      "  4%|โ         | 148/3487 [28:37<9:20:51, 10.08s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13673.40 ms /    69 tokens (  198.17 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.33 ms /     3 runs   (  875.44 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16302.36 ms /    72 tokens\n",
      "  4%|โ         | 149/3487 [28:53<11:04:43, 11.95s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12330.15 ms /    62 tokens (  198.87 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2732.20 ms /     3 runs   (  910.73 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   15064.84 ms /    65 tokens\n",
      "  4%|โ         | 150/3487 [29:09<11:56:39, 12.89s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12284.68 ms /    63 tokens (  194.99 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2771.35 ms /     3 runs   (  923.78 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   15058.37 ms /    66 tokens\n",
      "  4%|โ         | 151/3487 [29:24<12:32:51, 13.54s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6250.98 ms /    29 tokens (  215.55 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.12 ms /     3 runs   (  893.71 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8934.77 ms /    32 tokens\n",
      "  4%|โ         | 152/3487 [29:33<11:16:00, 12.16s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10231.44 ms /    52 tokens (  196.76 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.17 ms /     3 runs   (  875.72 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12861.80 ms /    55 tokens\n",
      "  4%|โ         | 153/3487 [29:45<11:27:38, 12.37s/it]Llama.generate: 306 prefix-match hit, remaining 121 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23328.63 ms /   121 tokens (  192.80 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.59 ms /     3 runs   (  874.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   25953.83 ms /   124 tokens\n",
      "  4%|โ         | 154/3487 [30:11<15:13:51, 16.45s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7300.47 ms /    31 tokens (  235.50 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3237.90 ms /     3 runs   ( 1079.30 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =   10542.70 ms /    34 tokens\n",
      "  4%|โ         | 155/3487 [30:22<13:35:18, 14.68s/it]Llama.generate: 306 prefix-match hit, remaining 220 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   44626.20 ms /   220 tokens (  202.85 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.65 ms /     3 runs   (  882.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   47277.89 ms /   223 tokens\n",
      "  4%|โ         | 156/3487 [31:09<22:38:08, 24.46s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13237.37 ms /    70 tokens (  189.11 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.28 ms /     3 runs   (  874.09 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15862.33 ms /    73 tokens\n",
      "  5%|โ         | 157/3487 [31:25<20:14:38, 21.89s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9535.00 ms /    49 tokens (  194.59 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.57 ms /     3 runs   (  884.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12192.52 ms /    52 tokens\n",
      "  5%|โ         | 158/3487 [31:37<17:33:04, 18.98s/it]Llama.generate: 307 prefix-match hit, remaining 193 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   36347.25 ms /   193 tokens (  188.33 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.98 ms /     3 runs   (  874.66 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   38973.60 ms /   196 tokens\n",
      "  5%|โ         | 159/3487 [32:16<23:05:35, 24.98s/it]Llama.generate: 307 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16028.91 ms /    78 tokens (  205.50 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3205.52 ms /     3 runs   ( 1068.51 ms per token,     0.94 tokens per second)\n",
      "llama_perf_context_print:       total time =   19237.80 ms /    81 tokens\n",
      "  5%|โ         | 160/3487 [32:36<21:29:48, 23.26s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4330.81 ms /    20 tokens (  216.54 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.39 ms /     3 runs   (  882.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6979.61 ms /    23 tokens\n",
      "  5%|โ         | 161/3487 [32:42<16:58:47, 18.38s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2727.85 ms /    13 tokens (  209.83 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.42 ms /     3 runs   (  878.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5364.76 ms /    16 tokens\n",
      "  5%|โ         | 162/3487 [32:48<13:22:14, 14.48s/it]Llama.generate: 307 prefix-match hit, remaining 132 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24970.34 ms /   132 tokens (  189.17 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.89 ms /     3 runs   (  874.63 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27596.41 ms /   135 tokens\n",
      "  5%|โ         | 163/3487 [33:15<17:00:12, 18.42s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7656.22 ms /    39 tokens (  196.31 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3252.11 ms /     3 runs   ( 1084.04 ms per token,     0.92 tokens per second)\n",
      "llama_perf_context_print:       total time =   10910.98 ms /    42 tokens\n",
      "  5%|โ         | 164/3487 [33:26<14:55:23, 16.17s/it]Llama.generate: 306 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17568.81 ms /    87 tokens (  201.94 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3280.58 ms /     3 runs   ( 1093.53 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =   20851.82 ms /    90 tokens\n",
      "  5%|โ         | 165/3487 [33:47<16:13:13, 17.58s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6898.62 ms /     7 tokens (  985.52 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6078.46 ms /     3 runs   ( 2026.15 ms per token,     0.49 tokens per second)\n",
      "llama_perf_context_print:       total time =   12982.22 ms /    10 tokens\n",
      "  5%|โ         | 166/3487 [34:02<15:25:11, 16.72s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10786.49 ms /    38 tokens (  283.85 ms per token,     3.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3230.34 ms /     3 runs   ( 1076.78 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =   14020.56 ms /    41 tokens\n",
      "  5%|โ         | 167/3487 [34:16<14:40:34, 15.91s/it]Llama.generate: 307 prefix-match hit, remaining 104 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   36040.72 ms /   104 tokens (  346.55 ms per token,     2.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3818.79 ms /     3 runs   ( 1272.93 ms per token,     0.79 tokens per second)\n",
      "llama_perf_context_print:       total time =   39864.57 ms /   107 tokens\n",
      "  5%|โ         | 168/3487 [34:56<21:18:03, 23.10s/it]Llama.generate: 307 prefix-match hit, remaining 81 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17712.53 ms /    81 tokens (  218.67 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3399.30 ms /     3 runs   ( 1133.10 ms per token,     0.88 tokens per second)\n",
      "llama_perf_context_print:       total time =   21115.63 ms /    84 tokens\n",
      "  5%|โ         | 169/3487 [35:17<20:44:59, 22.51s/it]Llama.generate: 307 prefix-match hit, remaining 156 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   45801.50 ms /   156 tokens (  293.60 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2806.82 ms /     3 runs   (  935.61 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   48612.39 ms /   159 tokens\n",
      "  5%|โ         | 170/3487 [36:06<27:57:41, 30.35s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8070.40 ms /    40 tokens (  201.76 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.57 ms /     3 runs   (  873.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10694.85 ms /    43 tokens\n",
      "  5%|โ         | 171/3487 [36:16<22:31:32, 24.45s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8794.91 ms /    47 tokens (  187.13 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.57 ms /     3 runs   (  880.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11437.71 ms /    50 tokens\n",
      "  5%|โ         | 172/3487 [36:28<18:55:32, 20.55s/it]Llama.generate: 307 prefix-match hit, remaining 92 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17098.03 ms /    92 tokens (  185.85 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.46 ms /     3 runs   (  879.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19738.95 ms /    95 tokens\n",
      "  5%|โ         | 173/3487 [36:48<18:41:54, 20.31s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5529.32 ms /    28 tokens (  197.48 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.37 ms /     3 runs   (  877.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8163.92 ms /    31 tokens\n",
      "  5%|โ         | 174/3487 [36:56<15:20:28, 16.67s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4816.90 ms /    25 tokens (  192.68 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.02 ms /     3 runs   (  875.01 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7444.76 ms /    28 tokens\n",
      "  5%|โ         | 175/3487 [37:03<12:47:35, 13.91s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7630.38 ms /    40 tokens (  190.76 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.99 ms /     3 runs   (  888.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10297.14 ms /    43 tokens\n",
      "  5%|โ         | 176/3487 [37:13<11:47:45, 12.83s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2341.22 ms /    11 tokens (  212.84 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.83 ms /     3 runs   (  882.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4992.79 ms /    14 tokens\n",
      "  5%|โ         | 177/3487 [37:19<9:41:19, 10.54s/it] Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5358.81 ms /    28 tokens (  191.39 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.55 ms /     3 runs   (  878.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7997.11 ms /    31 tokens\n",
      "  5%|โ         | 178/3487 [37:27<8:59:20,  9.78s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4457.84 ms /    22 tokens (  202.63 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.95 ms /     3 runs   (  894.32 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7144.10 ms /    25 tokens\n",
      "  5%|โ         | 179/3487 [37:34<8:15:43,  8.99s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7298.70 ms /    35 tokens (  208.53 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.12 ms /     3 runs   (  873.04 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9920.93 ms /    38 tokens\n",
      "  5%|โ         | 180/3487 [37:44<8:31:05,  9.27s/it]Llama.generate: 306 prefix-match hit, remaining 88 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16495.83 ms /    88 tokens (  187.45 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.47 ms /     3 runs   (  900.16 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   19199.18 ms /    91 tokens\n",
      "  5%|โ         | 181/3487 [38:03<11:15:08, 12.25s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2196.96 ms /    11 tokens (  199.72 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.24 ms /     3 runs   (  872.41 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4818.32 ms /    14 tokens\n",
      "  5%|โ         | 182/3487 [38:08<9:12:12, 10.03s/it] Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5474.69 ms /    29 tokens (  188.78 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.40 ms /     3 runs   (  879.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8114.24 ms /    32 tokens\n",
      "  5%|โ         | 183/3487 [38:16<8:40:36,  9.45s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8155.24 ms /    42 tokens (  194.17 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.96 ms /     3 runs   (  875.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10784.57 ms /    45 tokens\n",
      "  5%|โ         | 184/3487 [38:27<9:02:33,  9.86s/it]Llama.generate: 306 prefix-match hit, remaining 114 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21430.36 ms /   114 tokens (  187.99 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.91 ms /     3 runs   (  873.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   24055.40 ms /   117 tokens\n",
      "  5%|โ         | 185/3487 [38:51<12:56:58, 14.12s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16102.77 ms /    86 tokens (  187.24 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.11 ms /     3 runs   (  873.04 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   18724.65 ms /    89 tokens\n",
      "  5%|โ         | 186/3487 [39:10<14:12:53, 15.50s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12713.82 ms /    67 tokens (  189.76 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.92 ms /     3 runs   (  880.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15357.58 ms /    70 tokens\n",
      "  5%|โ         | 187/3487 [39:25<14:10:24, 15.46s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13206.38 ms /    67 tokens (  197.11 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2801.51 ms /     3 runs   (  933.84 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   16010.43 ms /    70 tokens\n",
      "  5%|โ         | 188/3487 [39:41<14:19:22, 15.63s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8167.41 ms /    40 tokens (  204.19 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.46 ms /     3 runs   (  878.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10805.71 ms /    43 tokens\n",
      "  5%|โ         | 189/3487 [39:52<12:59:43, 14.19s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5124.29 ms /    27 tokens (  189.79 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2718.68 ms /     3 runs   (  906.23 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7846.91 ms /    30 tokens\n",
      "  5%|โ         | 190/3487 [40:00<11:15:07, 12.29s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4407.67 ms /    22 tokens (  200.35 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.10 ms /     3 runs   (  870.70 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7022.59 ms /    25 tokens\n",
      "  5%|โ         | 191/3487 [40:07<9:48:20, 10.71s/it] Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9404.75 ms /    50 tokens (  188.09 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.18 ms /     3 runs   (  874.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12031.63 ms /    53 tokens\n",
      "  6%|โ         | 192/3487 [40:19<10:10:04, 11.11s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4131.79 ms /    21 tokens (  196.75 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.54 ms /     3 runs   (  880.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6774.98 ms /    24 tokens\n",
      "  6%|โ         | 193/3487 [40:25<8:58:40,  9.81s/it] Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5545.84 ms /    29 tokens (  191.24 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2752.61 ms /     3 runs   (  917.54 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8300.25 ms /    32 tokens\n",
      "  6%|โ         | 194/3487 [40:34<8:33:44,  9.36s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3791.16 ms /    18 tokens (  210.62 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.93 ms /     3 runs   (  894.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6478.40 ms /    21 tokens\n",
      "  6%|โ         | 195/3487 [40:40<7:46:17,  8.50s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4535.04 ms /    24 tokens (  188.96 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.49 ms /     3 runs   (  880.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7179.86 ms /    27 tokens\n",
      "  6%|โ         | 196/3487 [40:47<7:24:36,  8.11s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8830.04 ms /    47 tokens (  187.87 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.51 ms /     3 runs   (  882.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11479.80 ms /    50 tokens\n",
      "  6%|โ         | 197/3487 [40:59<8:20:05,  9.12s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1922.45 ms /     9 tokens (  213.61 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.17 ms /     3 runs   (  881.06 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4568.56 ms /    12 tokens\n",
      "  6%|โ         | 198/3487 [41:03<7:05:15,  7.76s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8270.74 ms /    42 tokens (  196.92 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.79 ms /     3 runs   (  870.93 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10885.75 ms /    45 tokens\n",
      "  6%|โ         | 199/3487 [41:14<7:56:41,  8.70s/it]Llama.generate: 306 prefix-match hit, remaining 238 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   44017.07 ms /   238 tokens (  184.95 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.78 ms /     3 runs   (  898.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   46716.50 ms /   241 tokens\n",
      "  6%|โ         | 200/3487 [42:01<18:21:35, 20.11s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11406.44 ms /    62 tokens (  183.97 ms per token,     5.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.06 ms /     3 runs   (  877.69 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14042.42 ms /    65 tokens\n",
      "  6%|โ         | 201/3487 [42:15<16:41:44, 18.29s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10976.51 ms /    59 tokens (  186.04 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.58 ms /     3 runs   (  899.19 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   13676.24 ms /    62 tokens\n",
      "  6%|โ         | 202/3487 [42:29<15:25:47, 16.91s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6857.52 ms /    33 tokens (  207.80 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.96 ms /     3 runs   (  872.32 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9477.78 ms /    36 tokens\n",
      "  6%|โ         | 203/3487 [42:38<13:23:36, 14.68s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4145.86 ms /    19 tokens (  218.20 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2604.45 ms /     3 runs   (  868.15 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6753.04 ms /    22 tokens\n",
      "  6%|โ         | 204/3487 [42:45<11:13:22, 12.31s/it]Llama.generate: 306 prefix-match hit, remaining 110 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20443.02 ms /   110 tokens (  185.85 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.60 ms /     3 runs   (  873.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   23066.77 ms /   113 tokens\n",
      "  6%|โ         | 205/3487 [43:08<14:09:52, 15.54s/it]Llama.generate: 306 prefix-match hit, remaining 129 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24231.89 ms /   129 tokens (  187.84 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.23 ms /     3 runs   (  878.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   26868.88 ms /   132 tokens\n",
      "  6%|โ         | 206/3487 [43:35<17:15:37, 18.94s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7384.70 ms /    38 tokens (  194.33 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.86 ms /     3 runs   (  870.95 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9999.51 ms /    41 tokens\n",
      "  6%|โ         | 207/3487 [43:45<14:48:51, 16.26s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7513.94 ms /    38 tokens (  197.74 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.48 ms /     3 runs   (  872.16 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10132.91 ms /    41 tokens\n",
      "  6%|โ         | 208/3487 [43:55<13:08:16, 14.42s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9887.38 ms /    53 tokens (  186.55 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2817.98 ms /     3 runs   (  939.33 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   12708.69 ms /    56 tokens\n",
      "  6%|โ         | 209/3487 [44:08<12:40:05, 13.91s/it]Llama.generate: 307 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16115.72 ms /    86 tokens (  187.39 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.48 ms /     3 runs   (  882.49 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18766.19 ms /    89 tokens\n",
      "  6%|โ         | 210/3487 [44:27<13:59:30, 15.37s/it]Llama.generate: 307 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11606.35 ms /    61 tokens (  190.27 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2776.37 ms /     3 runs   (  925.46 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   14385.41 ms /    64 tokens\n",
      "  6%|โ         | 211/3487 [44:41<13:43:17, 15.08s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2275.17 ms /    11 tokens (  206.83 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.95 ms /     3 runs   (  890.32 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4948.97 ms /    14 tokens\n",
      "  6%|โ         | 212/3487 [44:46<10:57:19, 12.04s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8806.32 ms /    46 tokens (  191.44 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2605.75 ms /     3 runs   (  868.58 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11414.68 ms /    49 tokens\n",
      "  6%|โ         | 213/3487 [44:57<10:46:58, 11.86s/it]Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10792.84 ms /    57 tokens (  189.35 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.58 ms /     3 runs   (  873.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13417.00 ms /    60 tokens\n",
      "  6%|โ         | 214/3487 [45:11<11:12:26, 12.33s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7326.37 ms /    38 tokens (  192.80 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.93 ms /     3 runs   (  872.98 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9948.03 ms /    41 tokens\n",
      "  6%|โ         | 215/3487 [45:21<10:33:26, 11.62s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9429.96 ms /    37 tokens (  254.86 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4424.51 ms /     3 runs   ( 1474.84 ms per token,     0.68 tokens per second)\n",
      "llama_perf_context_print:       total time =   13857.28 ms /    40 tokens\n",
      "  6%|โ         | 216/3487 [45:35<11:10:03, 12.29s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10788.34 ms /    39 tokens (  276.62 ms per token,     3.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.55 ms /     3 runs   (  879.52 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13430.21 ms /    42 tokens\n",
      "  6%|โ         | 217/3487 [45:48<11:28:39, 12.64s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5622.11 ms /    28 tokens (  200.79 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2785.65 ms /     3 runs   (  928.55 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8411.12 ms /    31 tokens\n",
      "  6%|โ         | 218/3487 [45:57<10:19:34, 11.37s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6804.65 ms /    32 tokens (  212.65 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.66 ms /     3 runs   (  880.89 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9449.77 ms /    35 tokens\n",
      "  6%|โ         | 219/3487 [46:06<9:48:07, 10.80s/it] Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7681.37 ms /    40 tokens (  192.03 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.60 ms /     3 runs   (  874.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10306.60 ms /    43 tokens\n",
      "  6%|โ         | 220/3487 [46:16<9:40:05, 10.65s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3589.07 ms /    18 tokens (  199.39 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.58 ms /     3 runs   (  873.19 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6211.34 ms /    21 tokens\n",
      "  6%|โ         | 221/3487 [46:23<8:27:29,  9.32s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7283.19 ms /    37 tokens (  196.84 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.31 ms /     3 runs   (  882.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9934.22 ms /    40 tokens\n",
      "  6%|โ         | 222/3487 [46:33<8:37:25,  9.51s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6062.06 ms /    32 tokens (  189.44 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.95 ms /     3 runs   (  882.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8712.67 ms /    35 tokens\n",
      "  6%|โ         | 223/3487 [46:41<8:24:23,  9.27s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1829.85 ms /     8 tokens (  228.73 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2605.68 ms /     3 runs   (  868.56 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4437.71 ms /    11 tokens\n",
      "  6%|โ         | 224/3487 [46:46<7:05:29,  7.82s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12895.89 ms /    66 tokens (  195.39 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.50 ms /     3 runs   (  877.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15531.45 ms /    69 tokens\n",
      "  6%|โ         | 225/3487 [47:01<9:11:13, 10.14s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13712.85 ms /    72 tokens (  190.46 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.32 ms /     3 runs   (  871.11 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   16328.85 ms /    75 tokens\n",
      "  6%|โ         | 226/3487 [47:18<10:52:07, 12.00s/it]Llama.generate: 306 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14894.29 ms /    76 tokens (  195.98 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2862.60 ms /     3 runs   (  954.20 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   17790.51 ms /    79 tokens\n",
      "  7%|โ         | 227/3487 [47:35<12:26:31, 13.74s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10332.81 ms /    52 tokens (  198.71 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.64 ms /     3 runs   (  880.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12976.01 ms /    55 tokens\n",
      "  7%|โ         | 228/3487 [47:48<12:13:58, 13.51s/it]Llama.generate: 314 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5059.67 ms /    27 tokens (  187.40 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.87 ms /     3 runs   (  873.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7683.98 ms /    30 tokens\n",
      "  7%|โ         | 229/3487 [47:56<10:38:55, 11.77s/it]Llama.generate: 308 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2927.19 ms /    14 tokens (  209.09 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.33 ms /     3 runs   (  873.11 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5549.51 ms /    17 tokens\n",
      "  7%|โ         | 230/3487 [48:02<8:57:35,  9.90s/it] Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13883.79 ms /    72 tokens (  192.83 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.57 ms /     3 runs   (  871.52 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   16500.83 ms /    75 tokens\n",
      "  7%|โ         | 231/3487 [48:18<10:45:00, 11.89s/it]Llama.generate: 306 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14729.96 ms /    78 tokens (  188.85 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.89 ms /     3 runs   (  870.96 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   17344.96 ms /    81 tokens\n",
      "  7%|โ         | 232/3487 [48:35<12:13:47, 13.53s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10147.25 ms /    54 tokens (  187.91 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.85 ms /     3 runs   (  881.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12794.73 ms /    57 tokens\n",
      "  7%|โ         | 233/3487 [48:48<12:01:46, 13.31s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4501.86 ms /    24 tokens (  187.58 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.75 ms /     3 runs   (  870.58 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7116.05 ms /    27 tokens\n",
      "  7%|โ         | 234/3487 [48:55<10:20:57, 11.45s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8897.21 ms /    45 tokens (  197.72 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.48 ms /     3 runs   (  870.83 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11511.91 ms /    48 tokens\n",
      "  7%|โ         | 235/3487 [49:07<10:21:50, 11.47s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7272.18 ms /    38 tokens (  191.37 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.54 ms /     3 runs   (  880.51 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9916.58 ms /    41 tokens\n",
      "  7%|โ         | 236/3487 [49:17<9:56:30, 11.01s/it] Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4037.21 ms /    21 tokens (  192.25 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.57 ms /     3 runs   (  880.52 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6681.18 ms /    24 tokens\n",
      "  7%|โ         | 237/3487 [49:24<8:46:08,  9.71s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13715.88 ms /    72 tokens (  190.50 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.13 ms /     3 runs   (  884.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16372.32 ms /    75 tokens\n",
      "  7%|โ         | 238/3487 [49:40<10:34:18, 11.71s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5535.87 ms /    29 tokens (  190.89 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.23 ms /     3 runs   (  881.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8182.47 ms /    32 tokens\n",
      "  7%|โ         | 239/3487 [49:48<9:36:55, 10.66s/it] Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5211.78 ms /    27 tokens (  193.03 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.84 ms /     3 runs   (  884.28 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7867.19 ms /    30 tokens\n",
      "  7%|โ         | 240/3487 [49:56<8:51:35,  9.82s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8066.45 ms /    41 tokens (  196.74 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.91 ms /     3 runs   (  874.64 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10693.01 ms /    44 tokens\n",
      "  7%|โ         | 241/3487 [50:07<9:05:43, 10.09s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7236.24 ms /    36 tokens (  201.01 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.30 ms /     3 runs   (  878.10 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9872.96 ms /    39 tokens\n",
      "  7%|โ         | 242/3487 [50:17<9:02:11, 10.03s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3891.88 ms /    20 tokens (  194.59 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.76 ms /     3 runs   (  880.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6534.64 ms /    23 tokens\n",
      "  7%|โ         | 243/3487 [50:23<8:05:32,  8.98s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5710.37 ms /    29 tokens (  196.91 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.13 ms /     3 runs   (  878.04 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8347.08 ms /    32 tokens\n",
      "  7%|โ         | 244/3487 [50:31<7:55:15,  8.79s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9210.17 ms /    48 tokens (  191.88 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2751.22 ms /     3 runs   (  917.07 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   11964.35 ms /    51 tokens\n",
      "  7%|โ         | 245/3487 [50:43<8:46:39,  9.75s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3549.23 ms /    17 tokens (  208.78 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2770.23 ms /     3 runs   (  923.41 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6322.04 ms /    20 tokens\n",
      "  7%|โ         | 246/3487 [50:50<7:51:10,  8.72s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6100.01 ms /    31 tokens (  196.77 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.60 ms /     3 runs   (  881.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8746.71 ms /    34 tokens\n",
      "  7%|โ         | 247/3487 [50:59<7:51:33,  8.73s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4883.60 ms /    23 tokens (  212.33 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.95 ms /     3 runs   (  898.98 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7583.34 ms /    26 tokens\n",
      "  7%|โ         | 248/3487 [51:06<7:33:27,  8.40s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8439.04 ms /    44 tokens (  191.80 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.91 ms /     3 runs   (  875.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11069.95 ms /    47 tokens\n",
      "  7%|โ         | 249/3487 [51:17<8:16:40,  9.20s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5501.67 ms /    29 tokens (  189.71 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.74 ms /     3 runs   (  880.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8145.35 ms /    32 tokens\n",
      "  7%|โ         | 250/3487 [51:25<7:59:31,  8.89s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2866.16 ms /    13 tokens (  220.47 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.32 ms /     3 runs   (  878.44 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5504.00 ms /    16 tokens\n",
      "  7%|โ         | 251/3487 [51:31<7:04:44,  7.88s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1878.59 ms /     8 tokens (  234.82 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.58 ms /     3 runs   (  878.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4515.74 ms /    11 tokens\n",
      "  7%|โ         | 252/3487 [51:35<6:10:22,  6.87s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7311.18 ms /    37 tokens (  197.60 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.87 ms /     3 runs   (  882.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9961.67 ms /    40 tokens\n",
      "  7%|โ         | 253/3487 [51:45<7:00:26,  7.80s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1716.19 ms /     7 tokens (  245.17 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.23 ms /     3 runs   (  882.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4367.17 ms /    10 tokens\n",
      "  7%|โ         | 254/3487 [51:50<6:04:54,  6.77s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1764.11 ms /     8 tokens (  220.51 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.26 ms /     3 runs   (  881.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4412.09 ms /    11 tokens\n",
      "  7%|โ         | 255/3487 [51:54<5:26:45,  6.07s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2006.92 ms /     8 tokens (  250.87 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.19 ms /     3 runs   (  888.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4673.76 ms /    11 tokens\n",
      "  7%|โ         | 256/3487 [51:59<5:04:18,  5.65s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1374.64 ms /     6 tokens (  229.11 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.57 ms /     3 runs   (  878.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4012.00 ms /     9 tokens\n",
      "  7%|โ         | 257/3487 [52:03<4:37:50,  5.16s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2950.66 ms /    14 tokens (  210.76 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.47 ms /     3 runs   (  876.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5583.71 ms /    17 tokens\n",
      "  7%|โ         | 258/3487 [52:08<4:44:43,  5.29s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9538.30 ms /    50 tokens (  190.77 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.45 ms /     3 runs   (  885.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12197.29 ms /    53 tokens\n",
      "  7%|โ         | 259/3487 [52:21<6:36:15,  7.37s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8075.53 ms /    41 tokens (  196.96 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.25 ms /     3 runs   (  879.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10715.35 ms /    44 tokens\n",
      "  7%|โ         | 260/3487 [52:31<7:30:18,  8.37s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4972.29 ms /    25 tokens (  198.89 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.59 ms /     3 runs   (  881.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7620.55 ms /    28 tokens\n",
      "  7%|โ         | 261/3487 [52:39<7:18:10,  8.15s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12255.57 ms /    63 tokens (  194.53 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.17 ms /     3 runs   (  880.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14899.45 ms /    66 tokens\n",
      "  8%|โ         | 262/3487 [52:54<9:07:00, 10.18s/it]Llama.generate: 307 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20331.80 ms /   107 tokens (  190.02 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.54 ms /     3 runs   (  880.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   22975.37 ms /   110 tokens\n",
      "  8%|โ         | 263/3487 [53:17<12:33:16, 14.02s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3879.48 ms /    20 tokens (  193.97 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.20 ms /     3 runs   (  882.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6528.90 ms /    23 tokens\n",
      "  8%|โ         | 264/3487 [53:23<10:32:29, 11.77s/it]Llama.generate: 307 prefix-match hit, remaining 193 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   37242.97 ms /   193 tokens (  192.97 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.72 ms /     3 runs   (  885.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   39900.76 ms /   196 tokens\n",
      "  8%|โ         | 265/3487 [54:03<18:05:32, 20.21s/it]Llama.generate: 312 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15483.72 ms /    82 tokens (  188.83 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2755.28 ms /     3 runs   (  918.43 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   18272.80 ms /    85 tokens\n",
      "  8%|โ         | 266/3487 [54:22<17:34:03, 19.63s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13635.49 ms /    70 tokens (  194.79 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.27 ms /     3 runs   (  877.42 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16269.72 ms /    73 tokens\n",
      "  8%|โ         | 267/3487 [54:38<16:39:41, 18.63s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1977.99 ms /     9 tokens (  219.78 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.44 ms /     3 runs   (  886.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4640.13 ms /    12 tokens\n",
      "  8%|โ         | 268/3487 [54:43<12:54:22, 14.43s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13697.60 ms /    70 tokens (  195.68 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.61 ms /     3 runs   (  883.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16350.77 ms /    73 tokens\n",
      "  8%|โ         | 269/3487 [54:59<13:25:06, 15.01s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2585.68 ms /    12 tokens (  215.47 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.39 ms /     3 runs   (  885.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5244.39 ms /    15 tokens\n",
      "  8%|โ         | 270/3487 [55:04<10:47:53, 12.08s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5559.91 ms /    28 tokens (  198.57 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.90 ms /     3 runs   (  884.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8215.99 ms /    31 tokens\n",
      "  8%|โ         | 271/3487 [55:12<9:45:37, 10.93s/it] Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7927.24 ms /    41 tokens (  193.35 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.28 ms /     3 runs   (  881.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10574.68 ms /    44 tokens\n",
      "  8%|โ         | 272/3487 [55:23<9:39:55, 10.82s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2386.89 ms /    11 tokens (  216.99 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.93 ms /     3 runs   (  873.31 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5009.16 ms /    14 tokens\n",
      "  8%|โ         | 273/3487 [55:28<8:06:25,  9.08s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9541.92 ms /    48 tokens (  198.79 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.70 ms /     3 runs   (  887.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12207.13 ms /    51 tokens\n",
      "  8%|โ         | 274/3487 [55:40<8:56:38, 10.02s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7050.12 ms /    35 tokens (  201.43 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.71 ms /     3 runs   (  876.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9681.21 ms /    38 tokens\n",
      "  8%|โ         | 275/3487 [55:50<8:51:09,  9.92s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3601.03 ms /    18 tokens (  200.06 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.25 ms /     3 runs   (  878.42 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6239.42 ms /    21 tokens\n",
      "  8%|โ         | 276/3487 [55:56<7:52:00,  8.82s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14754.93 ms /    74 tokens (  199.39 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.20 ms /     3 runs   (  875.07 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17382.74 ms /    77 tokens\n",
      "  8%|โ         | 277/3487 [56:14<10:09:24, 11.39s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3586.34 ms /    18 tokens (  199.24 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.22 ms /     3 runs   (  876.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6218.73 ms /    21 tokens\n",
      "  8%|โ         | 278/3487 [56:20<8:46:52,  9.85s/it] Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7078.78 ms /    35 tokens (  202.25 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.61 ms /     3 runs   (  880.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9723.45 ms /    38 tokens\n",
      "  8%|โ         | 279/3487 [56:30<8:44:46,  9.82s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4264.36 ms /    21 tokens (  203.06 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.50 ms /     3 runs   (  880.50 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6908.24 ms /    24 tokens\n",
      "  8%|โ         | 280/3487 [56:36<7:58:08,  8.95s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8367.14 ms /    43 tokens (  194.58 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.55 ms /     3 runs   (  877.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11001.24 ms /    46 tokens\n",
      "  8%|โ         | 281/3487 [56:47<8:31:04,  9.56s/it]Llama.generate: 307 prefix-match hit, remaining 127 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24027.55 ms /   127 tokens (  189.19 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.87 ms /     3 runs   (  882.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   26677.87 ms /   130 tokens\n",
      "  8%|โ         | 282/3487 [57:14<13:05:16, 14.70s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9994.30 ms /    52 tokens (  192.20 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.68 ms /     3 runs   (  909.89 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   12727.32 ms /    55 tokens\n",
      "  8%|โ         | 283/3487 [57:27<12:34:02, 14.12s/it]Llama.generate: 306 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13905.96 ms /    71 tokens (  195.86 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.89 ms /     3 runs   (  887.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16571.85 ms /    74 tokens\n",
      "  8%|โ         | 284/3487 [57:43<13:13:13, 14.86s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8073.70 ms /    39 tokens (  207.02 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.67 ms /     3 runs   (  886.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10734.94 ms /    42 tokens\n",
      "  8%|โ         | 285/3487 [57:54<12:07:06, 13.62s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4453.69 ms /    22 tokens (  202.44 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.74 ms /     3 runs   (  883.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7105.46 ms /    25 tokens\n",
      "  8%|โ         | 286/3487 [58:01<10:23:09, 11.68s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5441.85 ms /    28 tokens (  194.35 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.74 ms /     3 runs   (  874.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8068.63 ms /    31 tokens\n",
      "  8%|โ         | 287/3487 [58:09<9:25:15, 10.60s/it] Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2028.17 ms /     8 tokens (  253.52 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.08 ms /     3 runs   (  876.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4658.07 ms /    11 tokens\n",
      "  8%|โ         | 288/3487 [58:14<7:50:12,  8.82s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3827.37 ms /    19 tokens (  201.44 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.13 ms /     3 runs   (  882.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6476.95 ms /    22 tokens\n",
      "  8%|โ         | 289/3487 [58:21<7:12:44,  8.12s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9202.63 ms /    47 tokens (  195.80 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.86 ms /     3 runs   (  885.29 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11861.16 ms /    50 tokens\n",
      "  8%|โ         | 290/3487 [58:32<8:12:32,  9.24s/it]Llama.generate: 307 prefix-match hit, remaining 193 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   37110.15 ms /   193 tokens (  192.28 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2880.08 ms /     3 runs   (  960.03 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   39992.72 ms /   196 tokens\n",
      "  8%|โ         | 291/3487 [59:13<16:24:27, 18.48s/it]Llama.generate: 307 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14927.71 ms /    79 tokens (  188.96 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.79 ms /     3 runs   (  881.26 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17574.09 ms /    82 tokens\n",
      "  8%|โ         | 292/3487 [59:30<16:09:48, 18.21s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5374.05 ms /    28 tokens (  191.93 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.61 ms /     3 runs   (  881.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8020.76 ms /    31 tokens\n",
      "  8%|โ         | 293/3487 [59:38<13:26:53, 15.16s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13359.28 ms /    69 tokens (  193.61 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.88 ms /     3 runs   (  882.96 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16010.73 ms /    72 tokens\n",
      "  8%|โ         | 294/3487 [59:54<13:40:23, 15.42s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7158.30 ms /    34 tokens (  210.54 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.84 ms /     3 runs   (  874.95 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9785.26 ms /    37 tokens\n",
      "  8%|โ         | 295/3487 [1:00:04<12:10:53, 13.74s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3336.95 ms /    16 tokens (  208.56 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.14 ms /     3 runs   (  876.05 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5967.47 ms /    19 tokens\n",
      "  8%|โ         | 296/3487 [1:00:10<10:06:47, 11.41s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2888.14 ms /    14 tokens (  206.30 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.65 ms /     3 runs   (  887.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5553.78 ms /    17 tokens\n",
      "  9%|โ         | 297/3487 [1:00:16<8:33:22,  9.66s/it] Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2073.77 ms /     9 tokens (  230.42 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.44 ms /     3 runs   (  878.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4711.06 ms /    12 tokens\n",
      "  9%|โ         | 298/3487 [1:00:20<7:14:30,  8.18s/it]Llama.generate: 307 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16481.80 ms /    87 tokens (  189.45 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2602.15 ms /     3 runs   (  867.38 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   19086.37 ms /    90 tokens\n",
      "  9%|โ         | 299/3487 [1:00:39<10:08:25, 11.45s/it]Llama.generate: 306 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11549.78 ms /    61 tokens (  189.34 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2606.58 ms /     3 runs   (  868.86 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14159.08 ms /    64 tokens\n",
      "  9%|โ         | 300/3487 [1:00:53<10:51:29, 12.27s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3789.64 ms /    19 tokens (  199.45 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.60 ms /     3 runs   (  879.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6429.66 ms /    22 tokens\n",
      "  9%|โ         | 301/3487 [1:01:00<9:18:26, 10.52s/it] Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5499.85 ms /    27 tokens (  203.70 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.95 ms /     3 runs   (  885.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8158.18 ms /    30 tokens\n",
      "  9%|โ         | 302/3487 [1:01:08<8:40:51,  9.81s/it]Llama.generate: 307 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24991.26 ms /   133 tokens (  187.90 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2606.74 ms /     3 runs   (  868.91 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   27600.27 ms /   136 tokens\n",
      "  9%|โ         | 303/3487 [1:01:36<13:24:31, 15.16s/it]Llama.generate: 307 prefix-match hit, remaining 194 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   36274.08 ms /   194 tokens (  186.98 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.24 ms /     3 runs   (  872.75 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   38894.96 ms /   197 tokens\n",
      "  9%|โ         | 304/3487 [1:02:15<19:42:05, 22.28s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7890.25 ms /    40 tokens (  197.26 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.99 ms /     3 runs   (  870.66 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10504.81 ms /    43 tokens\n",
      "  9%|โ         | 305/3487 [1:02:25<16:34:29, 18.75s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8562.05 ms /    45 tokens (  190.27 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.85 ms /     3 runs   (  876.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11193.90 ms /    48 tokens\n",
      "  9%|โ         | 306/3487 [1:02:36<14:34:03, 16.49s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11205.64 ms /    59 tokens (  189.93 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2880.39 ms /     3 runs   (  960.13 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   14088.48 ms /    62 tokens\n",
      "  9%|โ         | 307/3487 [1:02:50<13:55:46, 15.77s/it]Llama.generate: 306 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14488.48 ms /    77 tokens (  188.16 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2610.63 ms /     3 runs   (  870.21 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   17133.55 ms /    80 tokens\n",
      "  9%|โ         | 308/3487 [1:03:08<14:17:21, 16.18s/it]Llama.generate: 307 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15048.72 ms /    80 tokens (  188.11 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.92 ms /     3 runs   (  876.64 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17720.26 ms /    83 tokens\n",
      "  9%|โ         | 309/3487 [1:03:25<14:41:40, 16.65s/it]Llama.generate: 307 prefix-match hit, remaining 99 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18917.45 ms /    99 tokens (  191.09 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2606.43 ms /     3 runs   (  868.81 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   21527.51 ms /   102 tokens\n",
      "  9%|โ         | 310/3487 [1:03:47<15:59:04, 18.11s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1747.26 ms /     7 tokens (  249.61 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.16 ms /     3 runs   (  871.39 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4363.53 ms /    10 tokens\n",
      "  9%|โ         | 311/3487 [1:03:51<12:20:35, 13.99s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7171.41 ms /    36 tokens (  199.21 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.79 ms /     3 runs   (  878.93 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9810.90 ms /    39 tokens\n",
      "  9%|โ         | 312/3487 [1:04:01<11:14:06, 12.74s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7018.32 ms /    33 tokens (  212.68 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.61 ms /     3 runs   (  875.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9646.19 ms /    36 tokens\n",
      "  9%|โ         | 313/3487 [1:04:11<10:24:58, 11.81s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2805.38 ms /    13 tokens (  215.80 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.39 ms /     3 runs   (  874.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5432.19 ms /    16 tokens\n",
      "  9%|โ         | 314/3487 [1:04:16<8:44:07,  9.91s/it] Llama.generate: 306 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19054.24 ms /   100 tokens (  190.54 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.74 ms /     3 runs   (  874.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21679.39 ms /   103 tokens\n",
      "  9%|โ         | 315/3487 [1:04:38<11:50:43, 13.44s/it]Llama.generate: 307 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13864.37 ms /    73 tokens (  189.92 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2610.30 ms /     3 runs   (  870.10 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   16477.52 ms /    76 tokens\n",
      "  9%|โ         | 316/3487 [1:04:54<12:38:44, 14.36s/it]Llama.generate: 307 prefix-match hit, remaining 134 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25321.90 ms /   134 tokens (  188.97 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.18 ms /     3 runs   (  876.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27954.47 ms /   137 tokens\n",
      "  9%|โ         | 317/3487 [1:05:22<16:14:08, 18.44s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9206.96 ms /    49 tokens (  187.90 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2610.33 ms /     3 runs   (  870.11 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11820.10 ms /    52 tokens\n",
      "  9%|โ         | 318/3487 [1:05:34<14:29:06, 16.46s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9292.85 ms /    49 tokens (  189.65 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.41 ms /     3 runs   (  871.14 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11908.75 ms /    52 tokens\n",
      "  9%|โ         | 319/3487 [1:05:46<13:16:57, 15.09s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5324.11 ms /    28 tokens (  190.15 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.00 ms /     3 runs   (  873.00 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7946.04 ms /    31 tokens\n",
      "  9%|โ         | 320/3487 [1:05:54<11:23:37, 12.95s/it]Llama.generate: 307 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17851.95 ms /    93 tokens (  191.96 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.86 ms /     3 runs   (  873.29 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   20474.45 ms /    96 tokens\n",
      "  9%|โ         | 321/3487 [1:06:14<13:22:36, 15.21s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10904.65 ms /    59 tokens (  184.82 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.86 ms /     3 runs   (  871.29 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   13521.48 ms /    62 tokens\n",
      "  9%|โ         | 322/3487 [1:06:28<12:55:45, 14.71s/it]Llama.generate: 306 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16266.99 ms /    87 tokens (  186.98 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.36 ms /     3 runs   (  871.79 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   18884.71 ms /    90 tokens\n",
      "  9%|โ         | 323/3487 [1:06:47<14:01:41, 15.96s/it]Llama.generate: 307 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13598.67 ms /    71 tokens (  191.53 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.58 ms /     3 runs   (  873.53 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16222.05 ms /    74 tokens\n",
      "  9%|โ         | 324/3487 [1:07:03<14:05:39, 16.04s/it]Llama.generate: 309 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7886.53 ms /    41 tokens (  192.35 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2608.59 ms /     3 runs   (  869.53 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10497.02 ms /    44 tokens\n",
      "  9%|โ         | 325/3487 [1:07:14<12:37:52, 14.38s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8139.48 ms /    42 tokens (  193.80 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2601.26 ms /     3 runs   (  867.09 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10743.69 ms /    45 tokens\n",
      "  9%|โ         | 326/3487 [1:07:24<11:40:16, 13.29s/it]Llama.generate: 306 prefix-match hit, remaining 106 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20128.37 ms /   106 tokens (  189.89 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.68 ms /     3 runs   (  878.23 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   22765.77 ms /   109 tokens\n",
      "  9%|โ         | 327/3487 [1:07:47<14:09:51, 16.14s/it]Llama.generate: 306 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10549.35 ms /    55 tokens (  191.81 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.44 ms /     3 runs   (  876.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13182.54 ms /    58 tokens\n",
      "  9%|โ         | 328/3487 [1:08:00<13:23:03, 15.25s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7251.63 ms /    37 tokens (  195.99 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2609.70 ms /     3 runs   (  869.90 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9864.20 ms /    40 tokens\n",
      "  9%|โ         | 329/3487 [1:08:10<11:57:51, 13.64s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3715.72 ms /    19 tokens (  195.56 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.46 ms /     3 runs   (  871.15 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6331.26 ms /    22 tokens\n",
      "  9%|โ         | 330/3487 [1:08:17<10:02:53, 11.46s/it]Llama.generate: 307 prefix-match hit, remaining 147 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27608.57 ms /   147 tokens (  187.81 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.39 ms /     3 runs   (  872.13 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   30227.61 ms /   150 tokens\n",
      "  9%|โ         | 331/3487 [1:08:47<14:59:00, 17.09s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5558.13 ms /    30 tokens (  185.27 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.34 ms /     3 runs   (  870.45 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8172.12 ms /    33 tokens\n",
      " 10%|โ         | 332/3487 [1:08:55<12:38:11, 14.42s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1533.60 ms /     6 tokens (  255.60 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.10 ms /     3 runs   (  882.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4181.86 ms /     9 tokens\n",
      " 10%|โ         | 333/3487 [1:08:59<9:56:37, 11.35s/it] Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11000.77 ms /    59 tokens (  186.45 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2765.74 ms /     3 runs   (  921.91 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   13769.18 ms /    62 tokens\n",
      " 10%|โ         | 334/3487 [1:09:13<10:34:42, 12.08s/it]Llama.generate: 307 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15043.97 ms /    80 tokens (  188.05 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.16 ms /     3 runs   (  876.05 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17674.52 ms /    83 tokens\n",
      " 10%|โ         | 335/3487 [1:09:31<12:02:49, 13.76s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6966.65 ms /    34 tokens (  204.90 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.35 ms /     3 runs   (  871.45 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9583.73 ms /    37 tokens\n",
      " 10%|โ         | 336/3487 [1:09:40<10:56:57, 12.51s/it]Llama.generate: 306 prefix-match hit, remaining 81 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15819.07 ms /    81 tokens (  195.30 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.39 ms /     3 runs   (  908.13 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   18546.35 ms /    84 tokens\n",
      " 10%|โ         | 337/3487 [1:09:59<12:31:58, 14.32s/it]Llama.generate: 307 prefix-match hit, remaining 99 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19511.66 ms /    99 tokens (  197.09 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.66 ms /     3 runs   (  899.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   22214.10 ms /   102 tokens\n",
      " 10%|โ         | 338/3487 [1:10:21<14:36:07, 16.69s/it]Llama.generate: 307 prefix-match hit, remaining 188 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   37490.14 ms /   188 tokens (  199.42 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.97 ms /     3 runs   (  880.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   40133.53 ms /   191 tokens\n",
      " 10%|โ         | 339/3487 [1:11:01<20:44:56, 23.73s/it]Llama.generate: 307 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11185.95 ms /    55 tokens (  203.38 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.94 ms /     3 runs   (  879.98 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13828.17 ms /    58 tokens\n",
      " 10%|โ         | 340/3487 [1:11:15<18:08:52, 20.76s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4097.17 ms /    20 tokens (  204.86 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.72 ms /     3 runs   (  879.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6737.64 ms /    23 tokens\n",
      " 10%|โ         | 341/3487 [1:11:22<14:28:07, 16.56s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7430.09 ms /    35 tokens (  212.29 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.76 ms /     3 runs   (  874.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10057.42 ms /    38 tokens\n",
      " 10%|โ         | 342/3487 [1:11:32<12:45:45, 14.61s/it]Llama.generate: 307 prefix-match hit, remaining 81 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16398.70 ms /    81 tokens (  202.45 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.73 ms /     3 runs   (  877.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19034.07 ms /    84 tokens\n",
      " 10%|โ         | 343/3487 [1:11:51<13:55:13, 15.94s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5131.58 ms /    25 tokens (  205.26 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.13 ms /     3 runs   (  874.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7757.32 ms /    28 tokens\n",
      " 10%|โ         | 344/3487 [1:11:59<11:46:29, 13.49s/it]Llama.generate: 307 prefix-match hit, remaining 96 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19057.17 ms /    96 tokens (  198.51 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.41 ms /     3 runs   (  873.80 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21681.12 ms /    99 tokens\n",
      " 10%|โ         | 345/3487 [1:12:20<13:55:09, 15.95s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4706.48 ms /    23 tokens (  204.63 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2852.14 ms /     3 runs   (  950.71 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    7560.94 ms /    26 tokens\n",
      " 10%|โ         | 346/3487 [1:12:28<11:43:47, 13.44s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7367.57 ms /    35 tokens (  210.50 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.69 ms /     3 runs   (  873.90 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9991.59 ms /    38 tokens\n",
      " 10%|โ         | 347/3487 [1:12:38<10:49:29, 12.41s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4821.90 ms /    24 tokens (  200.91 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.44 ms /     3 runs   (  872.81 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7442.82 ms /    27 tokens\n",
      " 10%|โ         | 348/3487 [1:12:45<9:31:26, 10.92s/it] Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2823.60 ms /    13 tokens (  217.20 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.35 ms /     3 runs   (  903.78 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5537.27 ms /    16 tokens\n",
      " 10%|โ         | 349/3487 [1:12:51<8:06:52,  9.31s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2212.65 ms /     7 tokens (  316.09 ms per token,     3.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.08 ms /     3 runs   (  879.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4852.45 ms /    10 tokens\n",
      " 10%|โ         | 350/3487 [1:12:56<6:56:57,  7.97s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9945.58 ms /    50 tokens (  198.91 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.95 ms /     3 runs   (  878.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12583.81 ms /    53 tokens\n",
      " 10%|โ         | 351/3487 [1:13:08<8:09:12,  9.36s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12339.63 ms /    64 tokens (  192.81 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.89 ms /     3 runs   (  888.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15009.34 ms /    67 tokens\n",
      " 10%|โ         | 352/3487 [1:13:23<9:37:44, 11.06s/it]Llama.generate: 306 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20030.25 ms /   102 tokens (  196.38 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.37 ms /     3 runs   (  877.79 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   22698.48 ms /   105 tokens\n",
      " 10%|โ         | 353/3487 [1:13:46<12:40:05, 14.55s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6190.89 ms /    31 tokens (  199.71 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.43 ms /     3 runs   (  885.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8850.34 ms /    34 tokens\n",
      " 10%|โ         | 354/3487 [1:13:55<11:10:40, 12.84s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1830.52 ms /     8 tokens (  228.81 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.19 ms /     3 runs   (  902.06 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4538.85 ms /    11 tokens\n",
      " 10%|โ         | 355/3487 [1:14:00<9:00:32, 10.36s/it] Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2545.83 ms /    11 tokens (  231.44 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.16 ms /     3 runs   (  878.05 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5182.86 ms /    14 tokens\n",
      " 10%|โ         | 356/3487 [1:14:05<7:39:34,  8.81s/it]Llama.generate: 306 prefix-match hit, remaining 123 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24362.26 ms /   123 tokens (  198.07 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.16 ms /     3 runs   (  879.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27003.18 ms /   126 tokens\n",
      " 10%|โ         | 357/3487 [1:14:32<12:24:19, 14.27s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4277.45 ms /    21 tokens (  203.69 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.27 ms /     3 runs   (  889.42 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6948.17 ms /    24 tokens\n",
      " 10%|โ         | 358/3487 [1:14:39<10:29:40, 12.07s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1962.36 ms /     8 tokens (  245.29 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.64 ms /     3 runs   (  879.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4605.18 ms /    11 tokens\n",
      " 10%|โ         | 359/3487 [1:14:43<8:32:45,  9.84s/it] Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11669.15 ms /    59 tokens (  197.78 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.58 ms /     3 runs   (  882.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14320.85 ms /    62 tokens\n",
      " 10%|โ         | 360/3487 [1:14:58<9:43:23, 11.19s/it]Llama.generate: 307 prefix-match hit, remaining 181 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   35089.50 ms /   181 tokens (  193.86 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.31 ms /     3 runs   (  881.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   37738.33 ms /   184 tokens\n",
      " 10%|โ         | 361/3487 [1:15:35<16:38:13, 19.16s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7496.08 ms /    36 tokens (  208.22 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.15 ms /     3 runs   (  882.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10146.62 ms /    39 tokens\n",
      " 10%|โ         | 362/3487 [1:15:46<14:17:13, 16.46s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3440.09 ms /    16 tokens (  215.01 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.47 ms /     3 runs   (  891.49 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6116.82 ms /    19 tokens\n",
      " 10%|โ         | 363/3487 [1:15:52<11:35:32, 13.36s/it]Llama.generate: 307 prefix-match hit, remaining 188 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   36757.10 ms /   188 tokens (  195.52 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.86 ms /     3 runs   (  885.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   39418.07 ms /   191 tokens\n",
      " 10%|โ         | 364/3487 [1:16:31<18:22:23, 21.18s/it]Llama.generate: 307 prefix-match hit, remaining 134 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25942.63 ms /   134 tokens (  193.60 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.39 ms /     3 runs   (  879.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   28582.43 ms /   137 tokens\n",
      " 10%|โ         | 365/3487 [1:17:00<20:17:43, 23.40s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12034.86 ms /    62 tokens (  194.11 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.49 ms /     3 runs   (  881.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14680.87 ms /    65 tokens\n",
      " 10%|โ         | 366/3487 [1:17:14<18:01:21, 20.79s/it]Llama.generate: 307 prefix-match hit, remaining 161 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   31964.61 ms /   161 tokens (  198.54 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3253.57 ms /     3 runs   ( 1084.52 ms per token,     0.92 tokens per second)\n",
      "llama_perf_context_print:       total time =   35221.05 ms /   164 tokens\n",
      " 11%|โ         | 367/3487 [1:17:50<21:46:17, 25.12s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10499.31 ms /    46 tokens (  228.25 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2792.01 ms /     3 runs   (  930.67 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   13293.97 ms /    49 tokens\n",
      " 11%|โ         | 368/3487 [1:18:03<18:41:35, 21.58s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9474.12 ms /    42 tokens (  225.57 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2770.31 ms /     3 runs   (  923.44 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   12247.39 ms /    45 tokens\n",
      " 11%|โ         | 369/3487 [1:18:15<16:15:56, 18.78s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4113.79 ms /    20 tokens (  205.69 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.89 ms /     3 runs   (  877.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6750.64 ms /    23 tokens\n",
      " 11%|โ         | 370/3487 [1:18:22<13:08:17, 15.17s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8047.65 ms /    39 tokens (  206.35 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.87 ms /     3 runs   (  876.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10680.74 ms /    42 tokens\n",
      " 11%|โ         | 371/3487 [1:18:33<11:58:08, 13.83s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5351.37 ms /    27 tokens (  198.20 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.77 ms /     3 runs   (  890.92 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8027.11 ms /    30 tokens\n",
      " 11%|โ         | 372/3487 [1:18:41<10:27:40, 12.09s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2820.76 ms /    13 tokens (  216.98 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.60 ms /     3 runs   (  884.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5477.69 ms /    16 tokens\n",
      " 11%|โ         | 373/3487 [1:18:46<8:44:39, 10.11s/it] Llama.generate: 307 prefix-match hit, remaining 187 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   36057.02 ms /   187 tokens (  192.82 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.89 ms /     3 runs   (  884.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   38713.92 ms /   190 tokens\n",
      " 11%|โ         | 374/3487 [1:19:25<16:09:53, 18.69s/it]Llama.generate: 307 prefix-match hit, remaining 229 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   44272.86 ms /   229 tokens (  193.33 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.59 ms /     3 runs   (  876.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   46906.55 ms /   232 tokens\n",
      " 11%|โ         | 375/3487 [1:20:12<23:28:43, 27.16s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6413.57 ms /    32 tokens (  200.42 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.08 ms /     3 runs   (  889.03 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9083.73 ms /    35 tokens\n",
      " 11%|โ         | 376/3487 [1:20:21<18:47:14, 21.74s/it]Llama.generate: 307 prefix-match hit, remaining 145 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27681.10 ms /   145 tokens (  190.90 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.35 ms /     3 runs   (  883.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   30334.79 ms /   148 tokens\n",
      " 11%|โ         | 377/3487 [1:20:51<21:00:38, 24.32s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4150.01 ms /    20 tokens (  207.50 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.88 ms /     3 runs   (  878.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6788.28 ms /    23 tokens\n",
      " 11%|โ         | 378/3487 [1:20:58<16:27:49, 19.06s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8141.61 ms /    40 tokens (  203.54 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.81 ms /     3 runs   (  874.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10769.08 ms /    43 tokens\n",
      " 11%|โ         | 379/3487 [1:21:09<14:18:44, 16.58s/it]Llama.generate: 306 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21341.52 ms /   108 tokens (  197.61 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.06 ms /     3 runs   (  882.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   24008.57 ms /   111 tokens\n",
      " 11%|โ         | 380/3487 [1:21:33<16:14:03, 18.81s/it]Llama.generate: 307 prefix-match hit, remaining 185 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   35384.18 ms /   185 tokens (  191.27 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.61 ms /     3 runs   (  878.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   38021.63 ms /   188 tokens\n",
      " 11%|โ         | 381/3487 [1:22:11<21:12:14, 24.58s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5054.15 ms /    25 tokens (  202.17 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.98 ms /     3 runs   (  880.66 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7699.23 ms /    28 tokens\n",
      " 11%|โ         | 382/3487 [1:22:19<16:49:57, 19.52s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14485.27 ms /    74 tokens (  195.75 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.77 ms /     3 runs   (  875.59 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17114.99 ms /    77 tokens\n",
      " 11%|โ         | 383/3487 [1:22:36<16:12:30, 18.80s/it]Llama.generate: 306 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14231.84 ms /    73 tokens (  194.96 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.82 ms /     3 runs   (  875.61 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16861.13 ms /    76 tokens\n",
      " 11%|โ         | 384/3487 [1:22:53<15:42:15, 18.22s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5146.73 ms /    26 tokens (  197.95 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2870.20 ms /     3 runs   (  956.73 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    8019.98 ms /    29 tokens\n",
      " 11%|โ         | 385/3487 [1:23:01<13:03:53, 15.16s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7124.19 ms /    33 tokens (  215.88 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.72 ms /     3 runs   (  879.57 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9766.01 ms /    36 tokens\n",
      " 11%|โ         | 386/3487 [1:23:10<11:40:07, 13.55s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8841.14 ms /    34 tokens (  260.03 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2775.52 ms /     3 runs   (  925.17 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   11619.19 ms /    37 tokens\n",
      " 11%|โ         | 387/3487 [1:23:22<11:10:12, 12.97s/it]Llama.generate: 306 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20329.97 ms /   105 tokens (  193.62 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.32 ms /     3 runs   (  889.77 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   23002.11 ms /   108 tokens\n",
      " 11%|โ         | 388/3487 [1:23:45<13:45:34, 15.98s/it]Llama.generate: 307 prefix-match hit, remaining 91 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17307.41 ms /    91 tokens (  190.19 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.37 ms /     3 runs   (  879.12 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19978.48 ms /    94 tokens\n",
      " 11%|โ         | 389/3487 [1:24:05<14:47:20, 17.19s/it]Llama.generate: 307 prefix-match hit, remaining 101 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20247.48 ms /   101 tokens (  200.47 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2786.59 ms /     3 runs   (  928.86 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   23037.25 ms /   104 tokens\n",
      " 11%|โ         | 390/3487 [1:24:28<16:17:50, 18.94s/it]Llama.generate: 307 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14018.95 ms /    66 tokens (  212.41 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2793.52 ms /     3 runs   (  931.17 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   16847.34 ms /    69 tokens\n",
      " 11%|โ         | 391/3487 [1:24:45<15:45:12, 18.32s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9408.84 ms /    46 tokens (  204.54 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2787.95 ms /     3 runs   (  929.32 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   12199.55 ms /    49 tokens\n",
      " 11%|โ         | 392/3487 [1:24:57<14:10:23, 16.49s/it]Llama.generate: 307 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20522.93 ms /   102 tokens (  201.21 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.23 ms /     3 runs   (  882.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23173.93 ms /   105 tokens\n",
      " 11%|โโ        | 393/3487 [1:25:20<15:54:11, 18.50s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5239.68 ms /    26 tokens (  201.53 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.43 ms /     3 runs   (  873.14 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7861.75 ms /    29 tokens\n",
      " 11%|โโ        | 394/3487 [1:25:28<13:09:26, 15.31s/it]Llama.generate: 307 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14742.89 ms /    77 tokens (  191.47 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.30 ms /     3 runs   (  876.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17376.71 ms /    80 tokens\n",
      " 11%|โโ        | 395/3487 [1:25:46<13:41:42, 15.95s/it]Llama.generate: 306 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20683.71 ms /   108 tokens (  191.52 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.26 ms /     3 runs   (  878.75 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   23323.11 ms /   111 tokens\n",
      " 11%|โโ        | 396/3487 [1:26:09<15:35:38, 18.16s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12036.67 ms /    62 tokens (  194.14 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.14 ms /     3 runs   (  874.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14662.02 ms /    65 tokens\n",
      " 11%|โโ        | 397/3487 [1:26:24<14:41:54, 17.12s/it]Llama.generate: 306 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13935.85 ms /    73 tokens (  190.90 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.10 ms /     3 runs   (  874.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16560.26 ms /    76 tokens\n",
      " 11%|โโ        | 398/3487 [1:26:40<14:33:03, 16.96s/it]Llama.generate: 306 prefix-match hit, remaining 145 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27510.33 ms /   145 tokens (  189.73 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.48 ms /     3 runs   (  871.49 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   30127.11 ms /   148 tokens\n",
      " 11%|โโ        | 399/3487 [1:27:10<17:56:13, 20.91s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11581.00 ms /    60 tokens (  193.02 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.57 ms /     3 runs   (  870.52 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14195.23 ms /    63 tokens\n",
      " 11%|โโ        | 400/3487 [1:27:25<16:12:20, 18.90s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3033.30 ms /    14 tokens (  216.66 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.03 ms /     3 runs   (  900.34 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5736.65 ms /    17 tokens\n",
      " 11%|โโ        | 401/3487 [1:27:30<12:49:05, 14.95s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6289.90 ms /    32 tokens (  196.56 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.20 ms /     3 runs   (  882.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8938.93 ms /    35 tokens\n",
      " 12%|โโ        | 402/3487 [1:27:39<11:16:11, 13.15s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9187.78 ms /    47 tokens (  195.48 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.51 ms /     3 runs   (  881.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11834.67 ms /    50 tokens\n",
      " 12%|โโ        | 403/3487 [1:27:51<10:55:48, 12.76s/it]Llama.generate: 308 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13794.25 ms /    68 tokens (  202.86 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.34 ms /     3 runs   (  871.11 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   16410.43 ms /    71 tokens\n",
      " 12%|โโ        | 404/3487 [1:28:07<11:51:59, 13.86s/it]Llama.generate: 308 prefix-match hit, remaining 189 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   35525.20 ms /   189 tokens (  187.96 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.54 ms /     3 runs   (  873.51 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   38148.52 ms /   192 tokens\n",
      " 12%|โโ        | 405/3487 [1:28:46<18:06:13, 21.15s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13087.52 ms /    67 tokens (  195.34 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.79 ms /     3 runs   (  878.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15724.83 ms /    70 tokens\n",
      " 12%|โโ        | 406/3487 [1:29:01<16:42:29, 19.52s/it]Llama.generate: 307 prefix-match hit, remaining 140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26724.80 ms /   140 tokens (  190.89 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.83 ms /     3 runs   (  871.61 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   29342.39 ms /   143 tokens\n",
      " 12%|โโ        | 407/3487 [1:29:31<19:13:31, 22.47s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11042.43 ms /    57 tokens (  193.73 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.30 ms /     3 runs   (  874.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13668.17 ms /    60 tokens\n",
      " 12%|โโ        | 408/3487 [1:29:44<16:57:43, 19.83s/it]Llama.generate: 308 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10781.34 ms /    56 tokens (  192.52 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2758.31 ms /     3 runs   (  919.44 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   13542.66 ms /    59 tokens\n",
      " 12%|โโ        | 409/3487 [1:29:58<15:21:05, 17.95s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8335.16 ms /    42 tokens (  198.46 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.71 ms /     3 runs   (  910.57 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   11069.77 ms /    45 tokens\n",
      " 12%|โโ        | 410/3487 [1:30:09<13:35:00, 15.89s/it]Llama.generate: 306 prefix-match hit, remaining 85 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20430.49 ms /    85 tokens (  240.36 ms per token,     4.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2908.52 ms /     3 runs   (  969.51 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   23342.20 ms /    88 tokens\n",
      " 12%|โโ        | 411/3487 [1:30:32<15:29:27, 18.13s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9377.99 ms /    46 tokens (  203.87 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.18 ms /     3 runs   (  891.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12054.56 ms /    49 tokens\n",
      " 12%|โโ        | 412/3487 [1:30:44<13:55:53, 16.31s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3066.98 ms /    15 tokens (  204.47 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.96 ms /     3 runs   (  901.65 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5774.60 ms /    18 tokens\n",
      " 12%|โโ        | 413/3487 [1:30:50<11:13:48, 13.15s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7241.00 ms /    34 tokens (  212.97 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.52 ms /     3 runs   (  889.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9911.94 ms /    37 tokens\n",
      " 12%|โโ        | 414/3487 [1:31:00<10:23:57, 12.18s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5920.76 ms /    30 tokens (  197.36 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.76 ms /     3 runs   (  881.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8566.98 ms /    33 tokens\n",
      " 12%|โโ        | 415/3487 [1:31:09<9:28:20, 11.10s/it] Llama.generate: 313 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7646.76 ms /    35 tokens (  218.48 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.60 ms /     3 runs   (  900.53 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10351.07 ms /    38 tokens\n",
      " 12%|โโ        | 416/3487 [1:31:19<9:16:48, 10.88s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9577.97 ms /    48 tokens (  199.54 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.91 ms /     3 runs   (  889.64 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12249.84 ms /    51 tokens\n",
      " 12%|โโ        | 417/3487 [1:31:31<9:37:47, 11.29s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7584.29 ms /    38 tokens (  199.59 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.30 ms /     3 runs   (  884.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10239.84 ms /    41 tokens\n",
      " 12%|โโ        | 418/3487 [1:31:42<9:21:34, 10.98s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10529.56 ms /    53 tokens (  198.67 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.53 ms /     3 runs   (  881.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13176.03 ms /    56 tokens\n",
      " 12%|โโ        | 419/3487 [1:31:55<9:55:11, 11.64s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4148.99 ms /    20 tokens (  207.45 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.27 ms /     3 runs   (  889.42 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6819.81 ms /    23 tokens\n",
      " 12%|โโ        | 420/3487 [1:32:02<8:41:12, 10.20s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5404.58 ms /    27 tokens (  200.17 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.10 ms /     3 runs   (  882.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8054.60 ms /    30 tokens\n",
      " 12%|โโ        | 421/3487 [1:32:10<8:08:19,  9.56s/it]Llama.generate: 308 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5405.67 ms /    27 tokens (  200.21 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.75 ms /     3 runs   (  891.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8083.45 ms /    30 tokens\n",
      " 12%|โโ        | 422/3487 [1:32:18<7:45:45,  9.12s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5729.72 ms /    28 tokens (  204.63 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.84 ms /     3 runs   (  881.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8377.01 ms /    31 tokens\n",
      " 12%|โโ        | 423/3487 [1:32:26<7:34:21,  8.90s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7237.17 ms /    35 tokens (  206.78 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.65 ms /     3 runs   (  879.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9877.23 ms /    38 tokens\n",
      " 12%|โโ        | 424/3487 [1:32:36<7:49:19,  9.19s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10311.50 ms /    53 tokens (  194.56 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.34 ms /     3 runs   (  892.11 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12990.31 ms /    56 tokens\n",
      " 12%|โโ        | 425/3487 [1:32:49<8:47:25, 10.33s/it]Llama.generate: 306 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20079.38 ms /   100 tokens (  200.79 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.30 ms /     3 runs   (  890.43 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   22753.51 ms /   103 tokens\n",
      " 12%|โโ        | 426/3487 [1:33:12<11:57:54, 14.07s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7414.17 ms /    36 tokens (  205.95 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.47 ms /     3 runs   (  886.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10077.24 ms /    39 tokens\n",
      " 12%|โโ        | 427/3487 [1:33:22<10:56:40, 12.88s/it]Llama.generate: 308 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9195.97 ms /    46 tokens (  199.91 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.31 ms /     3 runs   (  882.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11845.02 ms /    49 tokens\n",
      " 12%|โโ        | 428/3487 [1:33:34<10:40:49, 12.57s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3089.22 ms /    14 tokens (  220.66 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.96 ms /     3 runs   (  883.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5744.27 ms /    17 tokens\n",
      " 12%|โโ        | 429/3487 [1:33:40<8:56:21, 10.52s/it] Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3487.72 ms /    16 tokens (  217.98 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.43 ms /     3 runs   (  896.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6179.38 ms /    19 tokens\n",
      " 12%|โโ        | 430/3487 [1:33:46<7:49:57,  9.22s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10088.18 ms /    51 tokens (  197.81 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2714.87 ms /     3 runs   (  904.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   12805.64 ms /    54 tokens\n",
      " 12%|โโ        | 431/3487 [1:33:59<8:44:39, 10.30s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8205.36 ms /    40 tokens (  205.13 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.02 ms /     3 runs   (  884.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10862.40 ms /    43 tokens\n",
      " 12%|โโ        | 432/3487 [1:34:09<8:53:14, 10.47s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2375.55 ms /    11 tokens (  215.96 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.45 ms /     3 runs   (  884.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5030.28 ms /    14 tokens\n",
      " 12%|โโ        | 433/3487 [1:34:14<7:30:04,  8.84s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4657.49 ms /    23 tokens (  202.50 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.98 ms /     3 runs   (  889.66 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7329.14 ms /    26 tokens\n",
      " 12%|โโ        | 434/3487 [1:34:22<7:06:59,  8.39s/it]Llama.generate: 307 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17627.66 ms /    90 tokens (  195.86 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.69 ms /     3 runs   (  896.90 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   20321.91 ms /    93 tokens\n",
      " 12%|โโ        | 435/3487 [1:34:42<10:09:03, 11.97s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2173.37 ms /     9 tokens (  241.49 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.90 ms /     3 runs   (  890.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4849.10 ms /    12 tokens\n",
      " 13%|โโ        | 436/3487 [1:34:47<8:20:18,  9.84s/it] Llama.generate: 306 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10392.64 ms /    53 tokens (  196.09 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.33 ms /     3 runs   (  891.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13069.63 ms /    56 tokens\n",
      " 13%|โโ        | 437/3487 [1:35:00<9:09:31, 10.81s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8175.54 ms /    41 tokens (  199.40 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.18 ms /     3 runs   (  887.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10838.76 ms /    44 tokens\n",
      " 13%|โโ        | 438/3487 [1:35:11<9:09:54, 10.82s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1727.53 ms /     7 tokens (  246.79 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.39 ms /     3 runs   (  887.80 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4393.52 ms /    10 tokens\n",
      " 13%|โโ        | 439/3487 [1:35:15<7:31:54,  8.90s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3982.12 ms /    18 tokens (  221.23 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.35 ms /     3 runs   (  894.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6669.17 ms /    21 tokens\n",
      " 13%|โโ        | 440/3487 [1:35:22<6:57:57,  8.23s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2782.22 ms /    13 tokens (  214.02 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.44 ms /     3 runs   (  876.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5413.20 ms /    16 tokens\n",
      " 13%|โโ        | 441/3487 [1:35:27<6:15:03,  7.39s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8357.89 ms /    42 tokens (  199.00 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.40 ms /     3 runs   (  879.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10998.54 ms /    45 tokens\n",
      " 13%|โโ        | 442/3487 [1:35:38<7:10:02,  8.47s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5328.56 ms /    27 tokens (  197.35 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.80 ms /     3 runs   (  887.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7993.07 ms /    30 tokens\n",
      " 13%|โโ        | 443/3487 [1:35:46<7:02:44,  8.33s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5884.12 ms /    29 tokens (  202.90 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.01 ms /     3 runs   (  874.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8511.23 ms /    32 tokens\n",
      " 13%|โโ        | 444/3487 [1:35:55<7:05:55,  8.40s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4545.04 ms /    23 tokens (  197.61 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.30 ms /     3 runs   (  873.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7168.00 ms /    26 tokens\n",
      " 13%|โโ        | 445/3487 [1:36:02<6:47:09,  8.03s/it]Llama.generate: 306 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10769.11 ms /    55 tokens (  195.80 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.12 ms /     3 runs   (  870.37 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   13382.51 ms /    58 tokens\n",
      " 13%|โโ        | 446/3487 [1:36:16<8:08:30,  9.64s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4912.46 ms /    23 tokens (  213.59 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.79 ms /     3 runs   (  875.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7540.33 ms /    26 tokens\n",
      " 13%|โโ        | 447/3487 [1:36:23<7:36:34,  9.01s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3703.92 ms /    18 tokens (  205.77 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.26 ms /     3 runs   (  874.42 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6329.60 ms /    21 tokens\n",
      " 13%|โโ        | 448/3487 [1:36:29<6:55:47,  8.21s/it]Llama.generate: 316 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2879.39 ms /    14 tokens (  205.67 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.38 ms /     3 runs   (  876.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5510.36 ms /    17 tokens\n",
      " 13%|โโ        | 449/3487 [1:36:35<6:14:48,  7.40s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8087.09 ms /    40 tokens (  202.18 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.48 ms /     3 runs   (  873.16 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10709.81 ms /    43 tokens\n",
      " 13%|โโ        | 450/3487 [1:36:46<7:05:01,  8.40s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5090.43 ms /    26 tokens (  195.79 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.38 ms /     3 runs   (  874.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7716.34 ms /    29 tokens\n",
      " 13%|โโ        | 451/3487 [1:36:53<6:54:58,  8.20s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4211.52 ms /    21 tokens (  200.55 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.05 ms /     3 runs   (  878.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6849.79 ms /    24 tokens\n",
      " 13%|โโ        | 452/3487 [1:37:00<6:34:26,  7.80s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2093.45 ms /     9 tokens (  232.61 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.33 ms /     3 runs   (  876.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4726.21 ms /    12 tokens\n",
      " 13%|โโ        | 453/3487 [1:37:05<5:48:18,  6.89s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1960.02 ms /     8 tokens (  245.00 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.07 ms /     3 runs   (  872.02 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4579.01 ms /    11 tokens\n",
      " 13%|โโ        | 454/3487 [1:37:10<5:13:19,  6.20s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5007.57 ms /    25 tokens (  200.30 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.82 ms /     3 runs   (  877.61 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7642.58 ms /    28 tokens\n",
      " 13%|โโ        | 455/3487 [1:37:17<5:35:15,  6.63s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2825.93 ms /    13 tokens (  217.38 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.64 ms /     3 runs   (  871.21 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5441.34 ms /    16 tokens\n",
      " 13%|โโ        | 456/3487 [1:37:23<5:17:10,  6.28s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2385.59 ms /    10 tokens (  238.56 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.73 ms /     3 runs   (  881.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5033.83 ms /    13 tokens\n",
      " 13%|โโ        | 457/3487 [1:37:28<4:58:19,  5.91s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1946.65 ms /     9 tokens (  216.29 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.82 ms /     3 runs   (  877.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4583.23 ms /    12 tokens\n",
      " 13%|โโ        | 458/3487 [1:37:32<4:38:16,  5.51s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2770.95 ms /    13 tokens (  213.15 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.53 ms /     3 runs   (  874.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5396.11 ms /    16 tokens\n",
      " 13%|โโ        | 459/3487 [1:37:38<4:36:33,  5.48s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3168.60 ms /    14 tokens (  226.33 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.07 ms /     3 runs   (  878.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5805.62 ms /    17 tokens\n",
      " 13%|โโ        | 460/3487 [1:37:44<4:42:04,  5.59s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2387.09 ms /    10 tokens (  238.71 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.72 ms /     3 runs   (  878.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5026.65 ms /    13 tokens\n",
      " 13%|โโ        | 461/3487 [1:37:49<4:34:02,  5.43s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2089.12 ms /     9 tokens (  232.12 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.95 ms /     3 runs   (  872.32 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4708.30 ms /    12 tokens\n",
      " 13%|โโ        | 462/3487 [1:37:53<4:23:05,  5.22s/it]Llama.generate: 312 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2541.74 ms /     9 tokens (  282.42 ms per token,     3.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.43 ms /     3 runs   (  875.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5170.99 ms /    12 tokens\n",
      " 13%|โโ        | 463/3487 [1:37:59<4:22:54,  5.22s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1569.81 ms /     6 tokens (  261.64 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2912.79 ms /     3 runs   (  970.93 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    4486.14 ms /     9 tokens\n",
      " 13%|โโ        | 464/3487 [1:38:03<4:11:57,  5.00s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3080.76 ms /    15 tokens (  205.38 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.94 ms /     3 runs   (  877.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5716.04 ms /    18 tokens\n",
      " 13%|โโ        | 465/3487 [1:38:09<4:23:17,  5.23s/it]Llama.generate: 312 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1239.75 ms /     4 tokens (  309.94 ms per token,     3.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.62 ms /     3 runs   (  884.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    3895.58 ms /     7 tokens\n",
      " 13%|โโ        | 466/3487 [1:38:13<4:03:13,  4.83s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8318.57 ms /    41 tokens (  202.89 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.37 ms /     3 runs   (  871.79 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10937.24 ms /    44 tokens\n",
      " 13%|โโ        | 467/3487 [1:38:24<5:35:29,  6.67s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1919.44 ms /     8 tokens (  239.93 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.87 ms /     3 runs   (  874.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4544.13 ms /    11 tokens\n",
      " 13%|โโ        | 468/3487 [1:38:28<5:03:58,  6.04s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7684.77 ms /    38 tokens (  202.23 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.70 ms /     3 runs   (  871.90 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10303.09 ms /    41 tokens\n",
      " 13%|โโ        | 469/3487 [1:38:39<6:08:19,  7.32s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13509.49 ms /    65 tokens (  207.84 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.17 ms /     3 runs   (  874.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16134.92 ms /    68 tokens\n",
      " 13%|โโ        | 470/3487 [1:38:55<8:21:16,  9.97s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9460.23 ms /    48 tokens (  197.09 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.56 ms /     3 runs   (  871.19 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12076.74 ms /    51 tokens\n",
      " 14%|โโ        | 471/3487 [1:39:07<8:53:00, 10.60s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5891.25 ms /    30 tokens (  196.38 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.86 ms /     3 runs   (  872.62 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8512.40 ms /    33 tokens\n",
      " 14%|โโ        | 472/3487 [1:39:15<8:21:26,  9.98s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5424.14 ms /    27 tokens (  200.89 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.62 ms /     3 runs   (  873.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8048.65 ms /    30 tokens\n",
      " 14%|โโ        | 473/3487 [1:39:23<7:52:19,  9.40s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5059.75 ms /    25 tokens (  202.39 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.60 ms /     3 runs   (  878.53 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7698.33 ms /    28 tokens\n",
      " 14%|โโ        | 474/3487 [1:39:31<7:27:06,  8.90s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4792.69 ms /    24 tokens (  199.70 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.39 ms /     3 runs   (  875.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7420.81 ms /    27 tokens\n",
      " 14%|โโ        | 475/3487 [1:39:39<7:04:46,  8.46s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4811.45 ms /    23 tokens (  209.19 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.19 ms /     3 runs   (  879.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7452.14 ms /    26 tokens\n",
      " 14%|โโ        | 476/3487 [1:39:46<6:49:34,  8.16s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1948.52 ms /     8 tokens (  243.56 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.29 ms /     3 runs   (  878.10 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4585.86 ms /    11 tokens\n",
      " 14%|โโ        | 477/3487 [1:39:51<5:55:46,  7.09s/it]Llama.generate: 306 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11820.94 ms /    61 tokens (  193.79 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.22 ms /     3 runs   (  878.41 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14458.85 ms /    64 tokens\n",
      " 14%|โโ        | 478/3487 [1:40:05<7:46:38,  9.30s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3773.23 ms /    17 tokens (  221.95 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.63 ms /     3 runs   (  876.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6403.77 ms /    20 tokens\n",
      " 14%|โโ        | 479/3487 [1:40:12<7:02:58,  8.44s/it]Llama.generate: 306 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16388.34 ms /    84 tokens (  195.10 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.45 ms /     3 runs   (  875.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19017.12 ms /    87 tokens\n",
      " 14%|โโ        | 480/3487 [1:40:31<9:42:01, 11.61s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8999.86 ms /    45 tokens (  200.00 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.81 ms /     3 runs   (  872.94 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11621.03 ms /    48 tokens\n",
      " 14%|โโ        | 481/3487 [1:40:42<9:42:05, 11.62s/it]Llama.generate: 307 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11315.86 ms /    58 tokens (  195.10 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.46 ms /     3 runs   (  876.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13947.32 ms /    61 tokens\n",
      " 14%|โโ        | 482/3487 [1:40:56<10:17:02, 12.32s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9224.18 ms /    47 tokens (  196.26 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.88 ms /     3 runs   (  871.96 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11843.06 ms /    50 tokens\n",
      " 14%|โโ        | 483/3487 [1:41:08<10:10:14, 12.19s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4646.68 ms /    23 tokens (  202.03 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.79 ms /     3 runs   (  872.60 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7267.15 ms /    26 tokens\n",
      " 14%|โโ        | 484/3487 [1:41:15<8:56:16, 10.71s/it] Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8028.63 ms /    38 tokens (  211.28 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.10 ms /     3 runs   (  874.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10655.68 ms /    41 tokens\n",
      " 14%|โโ        | 485/3487 [1:41:26<8:55:51, 10.71s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9797.66 ms /    50 tokens (  195.95 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2608.96 ms /     3 runs   (  869.65 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12409.21 ms /    53 tokens\n",
      " 14%|โโ        | 486/3487 [1:41:38<9:21:17, 11.22s/it]Llama.generate: 307 prefix-match hit, remaining 117 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   22269.51 ms /   117 tokens (  190.34 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.04 ms /     3 runs   (  879.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   24911.95 ms /   120 tokens\n",
      " 14%|โโ        | 487/3487 [1:42:03<12:46:35, 15.33s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4612.84 ms /    22 tokens (  209.67 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.12 ms /     3 runs   (  871.04 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7228.11 ms /    25 tokens\n",
      " 14%|โโ        | 488/3487 [1:42:11<10:44:55, 12.90s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14288.82 ms /    74 tokens (  193.09 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2748.41 ms /     3 runs   (  916.14 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   17039.79 ms /    77 tokens\n",
      " 14%|โโ        | 489/3487 [1:42:28<11:46:49, 14.15s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3144.12 ms /    15 tokens (  209.61 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.06 ms /     3 runs   (  884.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5801.07 ms /    18 tokens\n",
      " 14%|โโ        | 490/3487 [1:42:33<9:41:38, 11.64s/it] Llama.generate: 308 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9190.13 ms /    47 tokens (  195.53 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.57 ms /     3 runs   (  872.19 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11809.22 ms /    50 tokens\n",
      " 14%|โโ        | 491/3487 [1:42:45<9:44:01, 11.70s/it]Llama.generate: 308 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4110.36 ms /    20 tokens (  205.52 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.82 ms /     3 runs   (  884.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6765.81 ms /    23 tokens\n",
      " 14%|โโ        | 492/3487 [1:42:52<8:30:06, 10.22s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5734.77 ms /    29 tokens (  197.75 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.56 ms /     3 runs   (  874.52 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8361.04 ms /    32 tokens\n",
      " 14%|โโ        | 493/3487 [1:43:00<8:02:15,  9.66s/it]Llama.generate: 307 prefix-match hit, remaining 132 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25745.85 ms /   132 tokens (  195.04 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.09 ms /     3 runs   (  872.03 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   28364.63 ms /   135 tokens\n",
      " 14%|โโ        | 494/3487 [1:43:29<12:42:05, 15.28s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7938.36 ms /    40 tokens (  198.46 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.13 ms /     3 runs   (  872.38 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10557.97 ms /    43 tokens\n",
      " 14%|โโ        | 495/3487 [1:43:39<11:31:21, 13.86s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8295.72 ms /    42 tokens (  197.52 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.97 ms /     3 runs   (  876.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10927.14 ms /    45 tokens\n",
      " 14%|โโ        | 496/3487 [1:43:50<10:47:18, 12.99s/it]Llama.generate: 308 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19563.89 ms /    98 tokens (  199.63 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.28 ms /     3 runs   (  872.76 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   22184.55 ms /   101 tokens\n",
      " 14%|โโ        | 497/3487 [1:44:12<13:04:46, 15.75s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8407.34 ms /    42 tokens (  200.17 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.83 ms /     3 runs   (  874.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11034.85 ms /    45 tokens\n",
      " 14%|โโ        | 498/3487 [1:44:23<11:54:13, 14.34s/it]Llama.generate: 307 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13488.64 ms /    68 tokens (  198.36 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.58 ms /     3 runs   (  872.86 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   16143.04 ms /    71 tokens\n",
      " 14%|โโ        | 499/3487 [1:44:40<12:21:08, 14.88s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4090.32 ms /    19 tokens (  215.28 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.25 ms /     3 runs   (  875.42 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6718.93 ms /    22 tokens\n",
      " 14%|โโ        | 500/3487 [1:44:46<10:19:03, 12.44s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3443.77 ms /    17 tokens (  202.57 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.62 ms /     3 runs   (  871.87 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6062.87 ms /    20 tokens\n",
      " 14%|โโ        | 501/3487 [1:44:52<8:43:50, 10.53s/it] Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9604.61 ms /    49 tokens (  196.01 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.53 ms /     3 runs   (  875.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12232.93 ms /    52 tokens\n",
      " 14%|โโ        | 502/3487 [1:45:05<9:09:44, 11.05s/it]Llama.generate: 306 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19600.91 ms /   100 tokens (  196.01 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.96 ms /     3 runs   (  874.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   22228.78 ms /   103 tokens\n",
      " 14%|โโ        | 503/3487 [1:45:27<11:56:55, 14.42s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9764.55 ms /    49 tokens (  199.28 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.71 ms /     3 runs   (  899.90 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   12466.84 ms /    52 tokens\n",
      " 14%|โโ        | 504/3487 [1:45:39<11:27:45, 13.83s/it]Llama.generate: 306 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19573.60 ms /   100 tokens (  195.74 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.78 ms /     3 runs   (  873.26 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   22196.19 ms /   103 tokens\n",
      " 14%|โโ        | 505/3487 [1:46:02<13:32:22, 16.35s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4790.96 ms /    24 tokens (  199.62 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.90 ms /     3 runs   (  880.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7434.26 ms /    27 tokens\n",
      " 15%|โโ        | 506/3487 [1:46:09<11:19:24, 13.67s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4642.79 ms /    23 tokens (  201.86 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.19 ms /     3 runs   (  873.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7265.36 ms /    26 tokens\n",
      " 15%|โโ        | 507/3487 [1:46:16<9:43:46, 11.75s/it] Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9796.99 ms /    48 tokens (  204.10 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3218.90 ms /     3 runs   ( 1072.97 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =   13019.25 ms /    51 tokens\n",
      " 15%|โโ        | 508/3487 [1:46:29<10:02:35, 12.14s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9915.82 ms /    33 tokens (  300.48 ms per token,     3.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2844.14 ms /     3 runs   (  948.05 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   12763.26 ms /    36 tokens\n",
      " 15%|โโ        | 509/3487 [1:46:42<10:11:49, 12.33s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3061.79 ms /    14 tokens (  218.70 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.90 ms /     3 runs   (  889.30 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5732.10 ms /    17 tokens\n",
      " 15%|โโ        | 510/3487 [1:46:48<8:33:34, 10.35s/it] Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13669.38 ms /    65 tokens (  210.30 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.06 ms /     3 runs   (  893.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16350.69 ms /    68 tokens\n",
      " 15%|โโ        | 511/3487 [1:47:04<10:02:50, 12.15s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9131.15 ms /    46 tokens (  198.50 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.39 ms /     3 runs   (  895.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11820.55 ms /    49 tokens\n",
      " 15%|โโ        | 512/3487 [1:47:16<9:57:50, 12.06s/it] Llama.generate: 306 prefix-match hit, remaining 136 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26427.47 ms /   136 tokens (  194.32 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.38 ms /     3 runs   (  884.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   29084.92 ms /   139 tokens\n",
      " 15%|โโ        | 513/3487 [1:47:45<14:11:25, 17.18s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10270.37 ms /    51 tokens (  201.38 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.05 ms /     3 runs   (  888.68 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12939.00 ms /    54 tokens\n",
      " 15%|โโ        | 514/3487 [1:47:58<13:08:15, 15.91s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7623.42 ms /    35 tokens (  217.81 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.79 ms /     3 runs   (  888.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10291.89 ms /    38 tokens\n",
      " 15%|โโ        | 515/3487 [1:48:08<11:44:37, 14.23s/it]Llama.generate: 307 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11719.64 ms /    60 tokens (  195.33 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.43 ms /     3 runs   (  889.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14392.51 ms /    63 tokens\n",
      " 15%|โโ        | 516/3487 [1:48:23<11:47:00, 14.28s/it]Llama.generate: 306 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17443.62 ms /    90 tokens (  193.82 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2814.39 ms /     3 runs   (  938.13 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   20260.91 ms /    93 tokens\n",
      " 15%|โโ        | 517/3487 [1:48:43<13:15:43, 16.08s/it]Llama.generate: 306 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14499.58 ms /    73 tokens (  198.62 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2744.56 ms /     3 runs   (  914.85 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   17247.00 ms /    76 tokens\n",
      " 15%|โโ        | 518/3487 [1:49:00<13:32:59, 16.43s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7249.03 ms /    35 tokens (  207.12 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.49 ms /     3 runs   (  893.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9933.88 ms /    38 tokens\n",
      " 15%|โโ        | 519/3487 [1:49:10<11:56:26, 14.48s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10011.19 ms /    50 tokens (  200.22 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.00 ms /     3 runs   (  891.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12687.94 ms /    53 tokens\n",
      " 15%|โโ        | 520/3487 [1:49:23<11:29:40, 13.95s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4603.70 ms /    22 tokens (  209.26 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.99 ms /     3 runs   (  894.33 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7290.03 ms /    25 tokens\n",
      " 15%|โโ        | 521/3487 [1:49:30<9:50:51, 11.95s/it] Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9607.47 ms /    47 tokens (  204.41 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.47 ms /     3 runs   (  895.82 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12297.23 ms /    50 tokens\n",
      " 15%|โโ        | 522/3487 [1:49:43<9:55:53, 12.06s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10373.61 ms /    52 tokens (  199.49 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.55 ms /     3 runs   (  900.18 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   13077.14 ms /    55 tokens\n",
      " 15%|โโ        | 523/3487 [1:49:56<10:10:54, 12.37s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9268.29 ms /    46 tokens (  201.48 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.53 ms /     3 runs   (  889.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11939.14 ms /    49 tokens\n",
      " 15%|โโ        | 524/3487 [1:50:08<10:04:59, 12.25s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7324.07 ms /    35 tokens (  209.26 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.18 ms /     3 runs   (  892.73 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10004.70 ms /    38 tokens\n",
      " 15%|โโ        | 525/3487 [1:50:18<9:31:38, 11.58s/it] Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4661.55 ms /    22 tokens (  211.89 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.88 ms /     3 runs   (  899.63 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7363.36 ms /    25 tokens\n",
      " 15%|โโ        | 526/3487 [1:50:25<8:29:09, 10.32s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4179.96 ms /    20 tokens (  209.00 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.64 ms /     3 runs   (  896.88 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6873.93 ms /    23 tokens\n",
      " 15%|โโ        | 527/3487 [1:50:32<7:38:09,  9.29s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7481.55 ms /    36 tokens (  207.82 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.43 ms /     3 runs   (  902.81 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10192.85 ms /    39 tokens\n",
      " 15%|โโ        | 528/3487 [1:50:42<7:51:30,  9.56s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5312.97 ms /    25 tokens (  212.52 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.21 ms /     3 runs   (  892.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7992.77 ms /    28 tokens\n",
      " 15%|โโ        | 529/3487 [1:50:50<7:28:15,  9.09s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4078.74 ms /    19 tokens (  214.67 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2815.58 ms /     3 runs   (  938.53 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6897.18 ms /    22 tokens\n",
      " 15%|โโ        | 530/3487 [1:50:57<6:55:46,  8.44s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4736.11 ms /    22 tokens (  215.28 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2730.95 ms /     3 runs   (  910.32 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7469.70 ms /    25 tokens\n",
      " 15%|โโ        | 531/3487 [1:51:05<6:41:29,  8.15s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3918.81 ms /    18 tokens (  217.71 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.96 ms /     3 runs   (  893.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6603.15 ms /    21 tokens\n",
      " 15%|โโ        | 532/3487 [1:51:11<6:18:38,  7.69s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3684.27 ms /    17 tokens (  216.72 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.78 ms /     3 runs   (  897.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6380.73 ms /    20 tokens\n",
      " 15%|โโ        | 533/3487 [1:51:18<5:59:46,  7.31s/it]Llama.generate: 307 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11383.82 ms /    56 tokens (  203.28 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2736.20 ms /     3 runs   (  912.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   14122.25 ms /    59 tokens\n",
      " 15%|โโ        | 534/3487 [1:51:32<7:40:22,  9.35s/it]Llama.generate: 307 prefix-match hit, remaining 144 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   29015.77 ms /   144 tokens (  201.50 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.75 ms /     3 runs   (  879.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   31656.84 ms /   147 tokens\n",
      " 15%|โโ        | 535/3487 [1:52:03<13:09:33, 16.05s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12046.35 ms /    63 tokens (  191.21 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.98 ms /     3 runs   (  907.66 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   14771.58 ms /    66 tokens\n",
      " 15%|โโ        | 536/3487 [1:52:18<12:50:36, 15.67s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11159.39 ms /    57 tokens (  195.78 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.31 ms /     3 runs   (  882.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13808.76 ms /    60 tokens\n",
      " 15%|โโ        | 537/3487 [1:52:32<12:23:02, 15.11s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8462.74 ms /    43 tokens (  196.81 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.04 ms /     3 runs   (  876.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11095.00 ms /    46 tokens\n",
      " 15%|โโ        | 538/3487 [1:52:43<11:23:41, 13.91s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3564.14 ms /    17 tokens (  209.66 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.64 ms /     3 runs   (  877.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6200.49 ms /    20 tokens\n",
      " 15%|โโ        | 539/3487 [1:52:49<9:29:54, 11.60s/it] Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5100.58 ms /    25 tokens (  204.02 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.08 ms /     3 runs   (  878.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7737.25 ms /    28 tokens\n",
      " 15%|โโ        | 540/3487 [1:52:57<8:32:55, 10.44s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8319.66 ms /    42 tokens (  198.09 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2888.33 ms /     3 runs   (  962.78 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   11210.34 ms /    45 tokens\n",
      " 16%|โโ        | 541/3487 [1:53:08<8:44:11, 10.68s/it]Llama.generate: 307 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14981.23 ms /    78 tokens (  192.07 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.41 ms /     3 runs   (  874.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17607.16 ms /    81 tokens\n",
      " 16%|โโ        | 542/3487 [1:53:26<10:26:11, 12.76s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7239.23 ms /    36 tokens (  201.09 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.54 ms /     3 runs   (  883.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9892.37 ms /    39 tokens\n",
      " 16%|โโ        | 543/3487 [1:53:36<9:43:55, 11.90s/it] Llama.generate: 306 prefix-match hit, remaining 146 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27792.45 ms /   146 tokens (  190.36 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.09 ms /     3 runs   (  879.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   30434.25 ms /   149 tokens\n",
      " 16%|โโ        | 544/3487 [1:54:06<14:16:34, 17.46s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9349.54 ms /    48 tokens (  194.78 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.81 ms /     3 runs   (  877.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11986.10 ms /    51 tokens\n",
      " 16%|โโ        | 545/3487 [1:54:18<12:55:48, 15.82s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5821.83 ms /    30 tokens (  194.06 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.92 ms /     3 runs   (  879.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8464.89 ms /    33 tokens\n",
      " 16%|โโ        | 546/3487 [1:54:27<11:07:28, 13.62s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7591.03 ms /    38 tokens (  199.76 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.59 ms /     3 runs   (  891.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10266.78 ms /    41 tokens\n",
      " 16%|โโ        | 547/3487 [1:54:37<10:18:07, 12.61s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13241.00 ms /    67 tokens (  197.63 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.85 ms /     3 runs   (  886.28 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15933.86 ms /    70 tokens\n",
      " 16%|โโ        | 548/3487 [1:54:53<11:06:51, 13.61s/it]Llama.generate: 306 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17827.56 ms /    94 tokens (  189.65 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.85 ms /     3 runs   (  881.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20474.88 ms /    97 tokens\n",
      " 16%|โโ        | 549/3487 [1:55:13<12:47:32, 15.67s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3457.97 ms /    17 tokens (  203.41 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.62 ms /     3 runs   (  879.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6099.84 ms /    20 tokens\n",
      " 16%|โโ        | 550/3487 [1:55:20<10:26:46, 12.80s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4650.46 ms /    23 tokens (  202.19 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.93 ms /     3 runs   (  883.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7305.13 ms /    26 tokens\n",
      " 16%|โโ        | 551/3487 [1:55:27<9:06:00, 11.16s/it] Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11221.05 ms /    59 tokens (  190.19 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2849.41 ms /     3 runs   (  949.80 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   14073.19 ms /    62 tokens\n",
      " 16%|โโ        | 552/3487 [1:55:41<9:48:44, 12.04s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6281.47 ms /    28 tokens (  224.34 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3106.90 ms /     3 runs   ( 1035.63 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    9391.75 ms /    31 tokens\n",
      " 16%|โโ        | 553/3487 [1:55:50<9:09:56, 11.25s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8351.73 ms /    40 tokens (  208.79 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2780.00 ms /     3 runs   (  926.67 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   11135.01 ms /    43 tokens\n",
      " 16%|โโ        | 554/3487 [1:56:01<9:08:16, 11.22s/it]Llama.generate: 306 prefix-match hit, remaining 303 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   58481.56 ms /   303 tokens (  193.01 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.92 ms /     3 runs   (  886.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   61143.25 ms /   306 tokens\n",
      " 16%|โโ        | 555/3487 [1:57:03<21:20:11, 26.20s/it]Llama.generate: 306 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17895.54 ms /    94 tokens (  190.38 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2843.08 ms /     3 runs   (  947.69 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   20740.93 ms /    97 tokens\n",
      " 16%|โโ        | 556/3487 [1:57:23<19:59:55, 24.56s/it]Llama.generate: 307 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11658.05 ms /    58 tokens (  201.00 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2851.38 ms /     3 runs   (  950.46 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   14512.83 ms /    61 tokens\n",
      " 16%|โโ        | 557/3487 [1:57:38<17:32:26, 21.55s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5230.38 ms /    25 tokens (  209.22 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.26 ms /     3 runs   (  890.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7903.87 ms /    28 tokens\n",
      " 16%|โโ        | 558/3487 [1:57:46<14:12:23, 17.46s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13787.30 ms /    69 tokens (  199.82 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2785.35 ms /     3 runs   (  928.45 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   16574.85 ms /    72 tokens\n",
      " 16%|โโ        | 559/3487 [1:58:02<13:59:15, 17.20s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4390.70 ms /    20 tokens (  219.53 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2973.38 ms /     3 runs   (  991.13 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    7366.71 ms /    23 tokens\n",
      " 16%|โโ        | 560/3487 [1:58:10<11:35:13, 14.25s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6168.15 ms /    28 tokens (  220.29 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2798.34 ms /     3 runs   (  932.78 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    8969.31 ms /    31 tokens\n",
      " 16%|โโ        | 561/3487 [1:58:19<10:17:51, 12.67s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5674.02 ms /    23 tokens (  246.70 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3691.85 ms /     3 runs   ( 1230.62 ms per token,     0.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    9369.34 ms /    26 tokens\n",
      " 16%|โโ        | 562/3487 [1:58:28<9:29:33, 11.68s/it] Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11532.08 ms /    41 tokens (  281.27 ms per token,     3.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3102.87 ms /     3 runs   ( 1034.29 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =   14638.43 ms /    44 tokens\n",
      " 16%|โโ        | 563/3487 [1:58:43<10:12:44, 12.57s/it]Llama.generate: 307 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12454.00 ms /    58 tokens (  214.72 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2938.68 ms /     3 runs   (  979.56 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =   15395.43 ms /    61 tokens\n",
      " 16%|โโ        | 564/3487 [1:58:58<10:53:56, 13.42s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7262.55 ms /    32 tokens (  226.95 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2923.45 ms /     3 runs   (  974.48 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   10189.03 ms /    35 tokens\n",
      " 16%|โโ        | 565/3487 [1:59:08<10:06:35, 12.46s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8131.07 ms /    33 tokens (  246.40 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2797.80 ms /     3 runs   (  932.60 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   10931.87 ms /    36 tokens\n",
      " 16%|โโ        | 566/3487 [1:59:19<9:44:16, 12.00s/it] Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5910.95 ms /    28 tokens (  211.11 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.73 ms /     3 runs   (  896.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8602.72 ms /    31 tokens\n",
      " 16%|โโ        | 567/3487 [1:59:28<8:54:33, 10.98s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7583.38 ms /    32 tokens (  236.98 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2916.16 ms /     3 runs   (  972.05 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   10501.59 ms /    35 tokens\n",
      " 16%|โโ        | 568/3487 [1:59:38<8:47:45, 10.85s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8438.00 ms /    42 tokens (  200.90 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.25 ms /     3 runs   (  879.75 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11079.88 ms /    45 tokens\n",
      " 16%|โโ        | 569/3487 [1:59:50<8:51:05, 10.92s/it]Llama.generate: 307 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14851.09 ms /    76 tokens (  195.41 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.80 ms /     3 runs   (  898.27 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   17548.57 ms /    79 tokens\n",
      " 16%|โโ        | 570/3487 [2:00:07<10:28:09, 12.92s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6286.97 ms /    32 tokens (  196.47 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.53 ms /     3 runs   (  890.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8961.74 ms /    35 tokens\n",
      " 16%|โโ        | 571/3487 [2:00:16<9:30:19, 11.74s/it] Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2797.17 ms /    13 tokens (  215.17 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.55 ms /     3 runs   (  882.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5446.46 ms /    16 tokens\n",
      " 16%|โโ        | 572/3487 [2:00:22<7:58:35,  9.85s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4166.36 ms /    21 tokens (  198.40 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.64 ms /     3 runs   (  878.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6804.43 ms /    24 tokens\n",
      " 16%|โโ        | 573/3487 [2:00:28<7:14:09,  8.94s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2062.71 ms /     9 tokens (  229.19 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.71 ms /     3 runs   (  880.90 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4708.45 ms /    12 tokens\n",
      " 16%|โโ        | 574/3487 [2:00:33<6:12:31,  7.67s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4928.18 ms /    25 tokens (  197.13 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2837.39 ms /     3 runs   (  945.80 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7768.39 ms /    28 tokens\n",
      " 16%|โโ        | 575/3487 [2:00:41<6:13:55,  7.70s/it]Llama.generate: 306 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15042.09 ms /    79 tokens (  190.41 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.63 ms /     3 runs   (  871.54 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   17658.57 ms /    82 tokens\n",
      " 17%|โโ        | 576/3487 [2:00:59<8:38:47, 10.69s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4156.02 ms /    20 tokens (  207.80 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.63 ms /     3 runs   (  881.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6803.08 ms /    23 tokens\n",
      " 17%|โโ        | 577/3487 [2:01:05<7:42:08,  9.53s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9814.37 ms /    51 tokens (  192.44 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.44 ms /     3 runs   (  878.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12452.47 ms /    54 tokens\n",
      " 17%|โโ        | 578/3487 [2:01:18<8:24:39, 10.41s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4171.46 ms /    21 tokens (  198.64 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2885.92 ms /     3 runs   (  961.97 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    7061.02 ms /    24 tokens\n",
      " 17%|โโ        | 579/3487 [2:01:25<7:35:56,  9.41s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3661.49 ms /    18 tokens (  203.42 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.87 ms /     3 runs   (  873.29 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6283.93 ms /    21 tokens\n",
      " 17%|โโ        | 580/3487 [2:01:31<6:50:30,  8.47s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8990.46 ms /    47 tokens (  191.29 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.59 ms /     3 runs   (  881.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11639.57 ms /    50 tokens\n",
      " 17%|โโ        | 581/3487 [2:01:43<7:36:28,  9.42s/it]Llama.generate: 306 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11575.07 ms /    61 tokens (  189.76 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.20 ms /     3 runs   (  871.07 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14190.80 ms /    64 tokens\n",
      " 17%|โโ        | 582/3487 [2:01:57<8:45:39, 10.86s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4202.85 ms /    21 tokens (  200.14 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.79 ms /     3 runs   (  873.26 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6825.05 ms /    24 tokens\n",
      " 17%|โโ        | 583/3487 [2:02:04<7:47:04,  9.65s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9474.96 ms /    49 tokens (  193.37 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2607.77 ms /     3 runs   (  869.26 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12084.72 ms /    52 tokens\n",
      " 17%|โโ        | 584/3487 [2:02:16<8:22:20, 10.38s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7845.67 ms /    40 tokens (  196.14 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.56 ms /     3 runs   (  873.19 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10468.38 ms /    43 tokens\n",
      " 17%|โโ        | 585/3487 [2:02:26<8:23:32, 10.41s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2340.44 ms /    11 tokens (  212.77 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.29 ms /     3 runs   (  872.43 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4960.19 ms /    14 tokens\n",
      " 17%|โโ        | 586/3487 [2:02:31<7:04:24,  8.78s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7936.56 ms /    40 tokens (  198.41 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.77 ms /     3 runs   (  872.26 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10556.34 ms /    43 tokens\n",
      " 17%|โโ        | 587/3487 [2:02:42<7:30:09,  9.31s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3495.66 ms /    17 tokens (  205.63 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.00 ms /     3 runs   (  880.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6140.60 ms /    20 tokens\n",
      " 17%|โโ        | 588/3487 [2:02:48<6:44:09,  8.36s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5702.30 ms /    28 tokens (  203.65 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.64 ms /     3 runs   (  887.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8366.73 ms /    31 tokens\n",
      " 17%|โโ        | 589/3487 [2:02:56<6:44:10,  8.37s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9001.64 ms /    47 tokens (  191.52 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.63 ms /     3 runs   (  878.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11639.25 ms /    50 tokens\n",
      " 17%|โโ        | 590/3487 [2:03:08<7:31:58,  9.36s/it]Llama.generate: 306 prefix-match hit, remaining 388 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   72813.98 ms /   388 tokens (  187.66 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.87 ms /     3 runs   (  879.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   75455.54 ms /   391 tokens\n",
      " 17%|โโ        | 591/3487 [2:04:24<23:29:01, 29.19s/it]Llama.generate: 306 prefix-match hit, remaining 197 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   37301.09 ms /   197 tokens (  189.35 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.35 ms /     3 runs   (  878.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   39939.56 ms /   200 tokens\n",
      " 17%|โโ        | 592/3487 [2:05:04<26:04:14, 32.42s/it]Llama.generate: 309 prefix-match hit, remaining 137 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25600.48 ms /   137 tokens (  186.86 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.30 ms /     3 runs   (  874.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   28227.05 ms /   140 tokens\n",
      " 17%|โโ        | 593/3487 [2:05:32<25:03:10, 31.16s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3971.67 ms /    19 tokens (  209.04 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.04 ms /     3 runs   (  870.35 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6586.21 ms /    22 tokens\n",
      " 17%|โโ        | 594/3487 [2:05:38<19:07:14, 23.79s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5243.28 ms /    27 tokens (  194.20 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.04 ms /     3 runs   (  871.68 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7860.45 ms /    30 tokens\n",
      " 17%|โโ        | 595/3487 [2:05:46<15:16:34, 19.02s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11953.22 ms /    63 tokens (  189.73 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.66 ms /     3 runs   (  877.89 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14590.08 ms /    66 tokens\n",
      " 17%|โโ        | 596/3487 [2:06:01<14:12:24, 17.69s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9674.16 ms /    50 tokens (  193.48 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.46 ms /     3 runs   (  871.15 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12291.01 ms /    53 tokens\n",
      " 17%|โโ        | 597/3487 [2:06:13<12:54:13, 16.07s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7057.01 ms /    35 tokens (  201.63 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2607.33 ms /     3 runs   (  869.11 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9667.48 ms /    38 tokens\n",
      " 17%|โโ        | 598/3487 [2:06:23<11:21:33, 14.16s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7404.67 ms /    34 tokens (  217.78 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.07 ms /     3 runs   (  883.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10056.64 ms /    37 tokens\n",
      " 17%|โโ        | 599/3487 [2:06:33<10:22:15, 12.93s/it]Llama.generate: 306 prefix-match hit, remaining 143 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26905.87 ms /   143 tokens (  188.15 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.42 ms /     3 runs   (  871.47 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   29522.68 ms /   146 tokens\n",
      " 17%|โโ        | 600/3487 [2:07:02<14:21:44, 17.91s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6306.11 ms /    32 tokens (  197.07 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.14 ms /     3 runs   (  875.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8934.45 ms /    35 tokens\n",
      " 17%|โโ        | 601/3487 [2:07:11<12:12:03, 15.22s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7368.55 ms /    38 tokens (  193.91 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.10 ms /     3 runs   (  871.03 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9983.82 ms /    41 tokens\n",
      " 17%|โโ        | 602/3487 [2:07:21<10:56:26, 13.65s/it]Llama.generate: 308 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10343.86 ms /    54 tokens (  191.55 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2607.10 ms /     3 runs   (  869.03 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12953.66 ms /    57 tokens\n",
      " 17%|โโ        | 603/3487 [2:07:34<10:46:15, 13.45s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5626.78 ms /    28 tokens (  200.96 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2610.49 ms /     3 runs   (  870.16 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8240.04 ms /    31 tokens\n",
      " 17%|โโ        | 604/3487 [2:07:43<9:31:07, 11.89s/it] Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4188.35 ms /    21 tokens (  199.45 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.38 ms /     3 runs   (  874.79 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6815.31 ms /    24 tokens\n",
      " 17%|โโ        | 605/3487 [2:07:49<8:17:57, 10.37s/it]Llama.generate: 308 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5173.66 ms /    26 tokens (  198.99 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.01 ms /     3 runs   (  879.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7815.71 ms /    29 tokens\n",
      " 17%|โโ        | 606/3487 [2:07:57<7:41:09,  9.60s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12145.75 ms /    64 tokens (  189.78 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2609.85 ms /     3 runs   (  869.95 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14757.89 ms /    67 tokens\n",
      " 17%|โโ        | 607/3487 [2:08:12<8:55:19, 11.15s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7414.28 ms /    35 tokens (  211.84 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.16 ms /     3 runs   (  873.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10037.42 ms /    38 tokens\n",
      " 17%|โโ        | 608/3487 [2:08:22<8:39:12, 10.82s/it]Llama.generate: 308 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7131.74 ms /    35 tokens (  203.76 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.03 ms /     3 runs   (  870.68 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9746.53 ms /    38 tokens\n",
      " 17%|โโ        | 609/3487 [2:08:32<8:23:41, 10.50s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8321.88 ms /    42 tokens (  198.14 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.28 ms /     3 runs   (  883.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10975.97 ms /    45 tokens\n",
      " 17%|โโ        | 610/3487 [2:08:43<8:30:28, 10.65s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6050.34 ms /    31 tokens (  195.17 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.25 ms /     3 runs   (  874.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8675.42 ms /    34 tokens\n",
      " 18%|โโ        | 611/3487 [2:08:51<8:02:06, 10.06s/it]Llama.generate: 307 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13056.12 ms /    66 tokens (  197.82 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.13 ms /     3 runs   (  872.38 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   15675.73 ms /    69 tokens\n",
      " 18%|โโ        | 612/3487 [2:09:07<9:22:48, 11.75s/it]Llama.generate: 307 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20284.16 ms /   103 tokens (  196.93 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.26 ms /     3 runs   (  872.75 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   22905.26 ms /   106 tokens\n",
      " 18%|โโ        | 613/3487 [2:09:30<12:03:06, 15.10s/it]Llama.generate: 306 prefix-match hit, remaining 387 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   73591.69 ms /   387 tokens (  190.16 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.23 ms /     3 runs   (  880.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   76234.48 ms /   390 tokens\n",
      " 18%|โโ        | 614/3487 [2:10:46<26:41:15, 33.44s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10053.58 ms /    51 tokens (  197.13 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.43 ms /     3 runs   (  875.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12682.49 ms /    54 tokens\n",
      " 18%|โโ        | 615/3487 [2:10:59<21:42:42, 27.22s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3881.06 ms /    19 tokens (  204.27 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.17 ms /     3 runs   (  875.06 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6508.95 ms /    22 tokens\n",
      " 18%|โโ        | 616/3487 [2:11:06<16:45:07, 21.01s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7154.10 ms /    35 tokens (  204.40 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.04 ms /     3 runs   (  872.01 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9772.63 ms /    38 tokens\n",
      " 18%|โโ        | 617/3487 [2:11:15<14:03:42, 17.64s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3653.31 ms /    17 tokens (  214.90 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.65 ms /     3 runs   (  880.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6297.65 ms /    20 tokens\n",
      " 18%|โโ        | 618/3487 [2:11:22<11:20:50, 14.24s/it]Llama.generate: 307 prefix-match hit, remaining 91 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17550.26 ms /    91 tokens (  192.86 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.05 ms /     3 runs   (  871.35 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   20198.43 ms /    94 tokens\n",
      " 18%|โโ        | 619/3487 [2:11:42<12:46:10, 16.03s/it]Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8521.79 ms /    44 tokens (  193.68 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.50 ms /     3 runs   (  879.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11163.36 ms /    47 tokens\n",
      " 18%|โโ        | 620/3487 [2:11:53<11:36:43, 14.58s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10108.39 ms /    53 tokens (  190.72 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.42 ms /     3 runs   (  872.81 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12729.20 ms /    56 tokens\n",
      " 18%|โโ        | 621/3487 [2:12:06<11:10:04, 14.03s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7515.28 ms /    38 tokens (  197.77 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.27 ms /     3 runs   (  873.09 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10137.46 ms /    41 tokens\n",
      " 18%|โโ        | 622/3487 [2:12:16<10:14:12, 12.86s/it]Llama.generate: 308 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14037.29 ms /    73 tokens (  192.29 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.82 ms /     3 runs   (  887.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16701.55 ms /    76 tokens\n",
      " 18%|โโ        | 623/3487 [2:12:33<11:10:00, 14.04s/it]Llama.generate: 306 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10451.60 ms /    53 tokens (  197.20 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.63 ms /     3 runs   (  887.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13115.80 ms /    56 tokens\n",
      " 18%|โโ        | 624/3487 [2:12:46<10:56:46, 13.76s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4732.19 ms /    24 tokens (  197.17 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.19 ms /     3 runs   (  888.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7400.73 ms /    27 tokens\n",
      " 18%|โโ        | 625/3487 [2:12:53<9:26:03, 11.87s/it] Llama.generate: 307 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19519.84 ms /   102 tokens (  191.37 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2890.83 ms /     3 runs   (  963.61 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   22413.59 ms /   105 tokens\n",
      " 18%|โโ        | 626/3487 [2:13:16<11:56:51, 15.03s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4776.89 ms /    24 tokens (  199.04 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.01 ms /     3 runs   (  880.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7422.11 ms /    27 tokens\n",
      " 18%|โโ        | 627/3487 [2:13:23<10:07:54, 12.75s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10276.75 ms /    52 tokens (  197.63 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.99 ms /     3 runs   (  879.00 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12916.27 ms /    55 tokens\n",
      " 18%|โโ        | 628/3487 [2:13:36<10:10:06, 12.80s/it]Llama.generate: 307 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13145.94 ms /    66 tokens (  199.18 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.93 ms /     3 runs   (  882.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15797.58 ms /    69 tokens\n",
      " 18%|โโ        | 629/3487 [2:13:52<10:52:45, 13.70s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7509.90 ms /    35 tokens (  214.57 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.07 ms /     3 runs   (  880.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10153.33 ms /    38 tokens\n",
      " 18%|โโ        | 630/3487 [2:14:02<10:01:55, 12.64s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6330.99 ms /    32 tokens (  197.84 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.45 ms /     3 runs   (  887.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8996.39 ms /    35 tokens\n",
      " 18%|โโ        | 631/3487 [2:14:11<9:09:47, 11.55s/it] Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5905.03 ms /    29 tokens (  203.62 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.10 ms /     3 runs   (  881.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8551.19 ms /    32 tokens\n",
      " 18%|โโ        | 632/3487 [2:14:20<8:26:54, 10.65s/it]Llama.generate: 308 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4777.35 ms /    24 tokens (  199.06 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.34 ms /     3 runs   (  882.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7428.64 ms /    27 tokens\n",
      " 18%|โโ        | 633/3487 [2:14:27<7:40:51,  9.69s/it]Llama.generate: 307 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11366.60 ms /    58 tokens (  195.98 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.77 ms /     3 runs   (  890.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14041.11 ms /    61 tokens\n",
      " 18%|โโ        | 634/3487 [2:14:41<8:42:53, 11.00s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9794.85 ms /    50 tokens (  195.90 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.14 ms /     3 runs   (  883.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12446.91 ms /    53 tokens\n",
      " 18%|โโ        | 635/3487 [2:14:53<9:03:29, 11.43s/it]Llama.generate: 306 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19514.42 ms /   100 tokens (  195.14 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3440.74 ms /     3 runs   ( 1146.91 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =   22958.60 ms /   103 tokens\n",
      " 18%|โโ        | 636/3487 [2:15:16<11:47:43, 14.89s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7558.29 ms /    24 tokens (  314.93 ms per token,     3.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3295.53 ms /     3 runs   ( 1098.51 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =   10856.95 ms /    27 tokens\n",
      " 18%|โโ        | 637/3487 [2:15:27<10:50:07, 13.69s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8433.33 ms /    33 tokens (  255.56 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.44 ms /     3 runs   (  892.48 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11114.03 ms /    36 tokens\n",
      " 18%|โโ        | 638/3487 [2:15:38<10:13:24, 12.92s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6710.16 ms /    32 tokens (  209.69 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2881.81 ms /     3 runs   (  960.60 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    9594.77 ms /    35 tokens\n",
      " 18%|โโ        | 639/3487 [2:15:48<9:26:29, 11.93s/it] Llama.generate: 307 prefix-match hit, remaining 206 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   39876.26 ms /   206 tokens (  193.57 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3006.19 ms /     3 runs   ( 1002.06 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =   42884.86 ms /   209 tokens\n",
      " 18%|โโ        | 640/3487 [2:16:31<16:47:00, 21.22s/it]Llama.generate: 308 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4440.89 ms /    20 tokens (  222.04 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2758.68 ms /     3 runs   (  919.56 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7202.28 ms /    23 tokens\n",
      " 18%|โโ        | 641/3487 [2:16:38<13:27:15, 17.02s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3761.52 ms /    18 tokens (  208.97 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.46 ms /     3 runs   (  904.49 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6477.90 ms /    21 tokens\n",
      " 18%|โโ        | 642/3487 [2:16:45<10:57:09, 13.86s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3544.27 ms /    16 tokens (  221.52 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.10 ms /     3 runs   (  892.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6223.48 ms /    19 tokens\n",
      " 18%|โโ        | 643/3487 [2:16:51<9:08:26, 11.57s/it] Llama.generate: 306 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20737.90 ms /   108 tokens (  192.02 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.41 ms /     3 runs   (  898.47 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   23435.79 ms /   111 tokens\n",
      " 18%|โโ        | 644/3487 [2:17:14<11:57:02, 15.13s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8434.37 ms /    42 tokens (  200.82 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.23 ms /     3 runs   (  897.74 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11130.09 ms /    45 tokens\n",
      " 18%|โโ        | 645/3487 [2:17:26<11:00:02, 13.93s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5961.60 ms /    29 tokens (  205.57 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3251.55 ms /     3 runs   ( 1083.85 ms per token,     0.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    9216.18 ms /    32 tokens\n",
      " 19%|โโ        | 646/3487 [2:17:35<9:52:54, 12.52s/it] Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5684.04 ms /    24 tokens (  236.84 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2940.28 ms /     3 runs   (  980.09 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    8627.56 ms /    27 tokens\n",
      " 19%|โโ        | 647/3487 [2:17:43<8:57:33, 11.36s/it]Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12709.28 ms /    57 tokens (  222.97 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2839.14 ms /     3 runs   (  946.38 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   15550.32 ms /    60 tokens\n",
      " 19%|โโ        | 648/3487 [2:17:59<9:57:02, 12.62s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11635.88 ms /    51 tokens (  228.15 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2803.59 ms /     3 runs   (  934.53 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   14442.53 ms /    54 tokens\n",
      " 19%|โโ        | 649/3487 [2:18:13<10:22:50, 13.17s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5067.03 ms /    22 tokens (  230.32 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.26 ms /     3 runs   (  905.75 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7787.41 ms /    25 tokens\n",
      " 19%|โโ        | 650/3487 [2:18:21<9:06:27, 11.56s/it] Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4488.76 ms /    20 tokens (  224.44 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.64 ms /     3 runs   (  903.88 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7203.40 ms /    23 tokens\n",
      " 19%|โโ        | 651/3487 [2:18:28<8:04:38, 10.25s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14469.30 ms /    72 tokens (  200.96 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.10 ms /     3 runs   (  894.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   17155.59 ms /    75 tokens\n",
      " 19%|โโ        | 652/3487 [2:18:46<9:42:25, 12.33s/it]Llama.generate: 308 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3978.18 ms /    19 tokens (  209.38 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2745.48 ms /     3 runs   (  915.16 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6727.01 ms /    22 tokens\n",
      " 19%|โโ        | 653/3487 [2:18:52<8:22:59, 10.65s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7892.00 ms /    38 tokens (  207.68 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.17 ms /     3 runs   (  896.39 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10584.05 ms /    41 tokens\n",
      " 19%|โโ        | 654/3487 [2:19:03<8:22:00, 10.63s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7587.13 ms /    38 tokens (  199.66 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.10 ms /     3 runs   (  897.70 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10282.49 ms /    41 tokens\n",
      " 19%|โโ        | 655/3487 [2:19:13<8:17:02, 10.53s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7346.74 ms /    34 tokens (  216.08 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.10 ms /     3 runs   (  891.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10023.86 ms /    37 tokens\n",
      " 19%|โโ        | 656/3487 [2:19:23<8:09:48, 10.38s/it]Llama.generate: 312 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4548.50 ms /    22 tokens (  206.75 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.24 ms /     3 runs   (  892.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7228.50 ms /    25 tokens\n",
      " 19%|โโ        | 657/3487 [2:19:30<7:25:08,  9.44s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7399.55 ms /    35 tokens (  211.42 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.90 ms /     3 runs   (  898.30 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10096.63 ms /    38 tokens\n",
      " 19%|โโ        | 658/3487 [2:19:41<7:34:24,  9.64s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3683.04 ms /    18 tokens (  204.61 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.54 ms /     3 runs   (  891.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6361.76 ms /    21 tokens\n",
      " 19%|โโ        | 659/3487 [2:19:47<6:48:03,  8.66s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1619.50 ms /     5 tokens (  323.90 ms per token,     3.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.05 ms /     3 runs   (  898.02 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4316.03 ms /     8 tokens\n",
      " 19%|โโ        | 660/3487 [2:19:51<5:47:05,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4138.19 ms /    20 tokens (  206.91 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.89 ms /     3 runs   (  896.30 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6829.98 ms /    23 tokens\n",
      " 19%|โโ        | 661/3487 [2:19:58<5:39:29,  7.21s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4490.11 ms /    21 tokens (  213.81 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.03 ms /     3 runs   (  894.34 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7175.44 ms /    24 tokens\n",
      " 19%|โโ        | 662/3487 [2:20:05<5:39:01,  7.20s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7522.33 ms /    37 tokens (  203.31 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.67 ms /     3 runs   (  915.89 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10272.57 ms /    40 tokens\n",
      " 19%|โโ        | 663/3487 [2:20:16<6:22:24,  8.12s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6055.62 ms /    30 tokens (  201.85 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.31 ms /     3 runs   (  886.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8716.63 ms /    33 tokens\n",
      " 19%|โโ        | 664/3487 [2:20:24<6:30:43,  8.30s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7820.45 ms /    39 tokens (  200.52 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.79 ms /     3 runs   (  877.93 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10456.77 ms /    42 tokens\n",
      " 19%|โโ        | 665/3487 [2:20:35<7:01:03,  8.95s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1672.31 ms /     6 tokens (  278.72 ms per token,     3.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.16 ms /     3 runs   (  879.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4313.14 ms /     9 tokens\n",
      " 19%|โโ        | 666/3487 [2:20:39<5:56:01,  7.57s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7359.54 ms /    36 tokens (  204.43 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.88 ms /     3 runs   (  878.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9997.21 ms /    39 tokens\n",
      " 19%|โโ        | 667/3487 [2:20:49<6:30:12,  8.30s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5194.53 ms /    25 tokens (  207.78 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.96 ms /     3 runs   (  881.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7842.07 ms /    28 tokens\n",
      " 19%|โโ        | 668/3487 [2:20:57<6:23:42,  8.17s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5230.04 ms /    27 tokens (  193.71 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.85 ms /     3 runs   (  892.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7910.49 ms /    30 tokens\n",
      " 19%|โโ        | 669/3487 [2:21:05<6:20:03,  8.09s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6417.29 ms /    32 tokens (  200.54 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.72 ms /     3 runs   (  887.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9082.70 ms /    35 tokens\n",
      " 19%|โโ        | 670/3487 [2:21:14<6:33:58,  8.39s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4060.72 ms /    20 tokens (  203.04 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.81 ms /     3 runs   (  887.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6726.64 ms /    23 tokens\n",
      " 19%|โโ        | 671/3487 [2:21:21<6:10:32,  7.89s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5419.12 ms /    27 tokens (  200.71 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.96 ms /     3 runs   (  875.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8048.31 ms /    30 tokens\n",
      " 19%|โโ        | 672/3487 [2:21:29<6:12:41,  7.94s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7439.33 ms /    35 tokens (  212.55 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.92 ms /     3 runs   (  908.64 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   10167.47 ms /    38 tokens\n",
      " 19%|โโ        | 673/3487 [2:21:39<6:43:57,  8.61s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7253.15 ms /    34 tokens (  213.33 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.02 ms /     3 runs   (  877.01 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9886.27 ms /    37 tokens\n",
      " 19%|โโ        | 674/3487 [2:21:49<7:01:51,  9.00s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2422.99 ms /    10 tokens (  242.30 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.22 ms /     3 runs   (  891.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5100.13 ms /    13 tokens\n",
      " 19%|โโ        | 675/3487 [2:21:54<6:07:00,  7.83s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7496.81 ms /    37 tokens (  202.62 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.62 ms /     3 runs   (  877.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10133.16 ms /    40 tokens\n",
      " 19%|โโ        | 676/3487 [2:22:04<6:39:21,  8.52s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4867.34 ms /    24 tokens (  202.81 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.80 ms /     3 runs   (  879.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7508.07 ms /    27 tokens\n",
      " 19%|โโ        | 677/3487 [2:22:12<6:25:04,  8.22s/it]Llama.generate: 307 prefix-match hit, remaining 113 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21454.00 ms /   113 tokens (  189.86 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.64 ms /     3 runs   (  879.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   24127.52 ms /   116 tokens\n",
      " 19%|โโ        | 678/3487 [2:22:36<10:08:27, 13.00s/it]Llama.generate: 307 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19245.06 ms /    98 tokens (  196.38 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.30 ms /     3 runs   (  878.10 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21882.22 ms /   101 tokens\n",
      " 19%|โโ        | 679/3487 [2:22:58<12:13:05, 15.66s/it]Llama.generate: 306 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20372.71 ms /   107 tokens (  190.40 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2887.90 ms /     3 runs   (  962.63 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   23263.81 ms /   110 tokens\n",
      " 20%|โโ        | 680/3487 [2:23:21<13:59:37, 17.95s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4084.39 ms /    20 tokens (  204.22 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.61 ms /     3 runs   (  882.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6735.89 ms /    23 tokens\n",
      " 20%|โโ        | 681/3487 [2:23:28<11:22:08, 14.59s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2984.16 ms /    13 tokens (  229.55 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.53 ms /     3 runs   (  878.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5620.92 ms /    16 tokens\n",
      " 20%|โโ        | 682/3487 [2:23:33<9:16:15, 11.90s/it] Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4483.89 ms /    22 tokens (  203.81 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.72 ms /     3 runs   (  879.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7125.79 ms /    25 tokens\n",
      " 20%|โโ        | 683/3487 [2:23:40<8:09:15, 10.47s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4895.41 ms /    24 tokens (  203.98 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2830.00 ms /     3 runs   (  943.33 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7727.95 ms /    27 tokens\n",
      " 20%|โโ        | 684/3487 [2:23:48<7:30:46,  9.65s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6390.20 ms /    31 tokens (  206.14 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.19 ms /     3 runs   (  892.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9069.36 ms /    34 tokens\n",
      " 20%|โโ        | 685/3487 [2:23:57<7:22:37,  9.48s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6342.43 ms /    31 tokens (  204.59 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.43 ms /     3 runs   (  890.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9017.40 ms /    34 tokens\n",
      " 20%|โโ        | 686/3487 [2:24:06<7:16:09,  9.34s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13503.70 ms /    70 tokens (  192.91 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2772.83 ms /     3 runs   (  924.28 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   16279.29 ms /    73 tokens\n",
      " 20%|โโ        | 687/3487 [2:24:23<8:57:50, 11.53s/it]Llama.generate: 306 prefix-match hit, remaining 153 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   29701.85 ms /   153 tokens (  194.13 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.11 ms /     3 runs   (  880.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   32345.83 ms /   156 tokens\n",
      " 20%|โโ        | 688/3487 [2:24:55<13:49:34, 17.78s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1894.73 ms /     8 tokens (  236.84 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.33 ms /     3 runs   (  884.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4551.82 ms /    11 tokens\n",
      " 20%|โโ        | 689/3487 [2:25:00<10:44:18, 13.82s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9491.58 ms /    47 tokens (  201.95 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.55 ms /     3 runs   (  886.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12153.88 ms /    50 tokens\n",
      " 20%|โโ        | 690/3487 [2:25:12<10:21:23, 13.33s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4267.38 ms /    21 tokens (  203.21 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.41 ms /     3 runs   (  881.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6913.05 ms /    24 tokens\n",
      " 20%|โโ        | 691/3487 [2:25:19<8:51:35, 11.41s/it] Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2498.13 ms /    10 tokens (  249.81 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2609.75 ms /     3 runs   (  869.92 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5110.99 ms /    13 tokens\n",
      " 20%|โโ        | 692/3487 [2:25:24<7:23:59,  9.53s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1854.35 ms /     8 tokens (  231.79 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.12 ms /     3 runs   (  875.04 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4481.85 ms /    11 tokens\n",
      " 20%|โโ        | 693/3487 [2:25:29<6:13:24,  8.02s/it]Llama.generate: 306 prefix-match hit, remaining 125 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23683.94 ms /   125 tokens (  189.47 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.58 ms /     3 runs   (  886.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   26347.35 ms /   128 tokens\n",
      " 20%|โโ        | 694/3487 [2:25:55<10:29:19, 13.52s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5780.79 ms /    29 tokens (  199.34 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.32 ms /     3 runs   (  880.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8425.12 ms /    32 tokens\n",
      " 20%|โโ        | 695/3487 [2:26:03<9:18:05, 11.99s/it] Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1567.90 ms /     5 tokens (  313.58 ms per token,     3.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.40 ms /     3 runs   (  878.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4205.85 ms /     8 tokens\n",
      " 20%|โโ        | 696/3487 [2:26:08<7:29:19,  9.66s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5478.74 ms /    28 tokens (  195.67 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.86 ms /     3 runs   (  876.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8111.01 ms /    31 tokens\n",
      " 20%|โโ        | 697/3487 [2:26:16<7:07:39,  9.20s/it]Llama.generate: 306 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19993.21 ms /   105 tokens (  190.41 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2867.37 ms /     3 runs   (  955.79 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   22863.28 ms /   108 tokens\n",
      " 20%|โโ        | 698/3487 [2:26:39<10:18:12, 13.30s/it]Llama.generate: 306 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10425.05 ms /    53 tokens (  196.70 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.81 ms /     3 runs   (  873.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13049.10 ms /    56 tokens\n",
      " 20%|โโ        | 699/3487 [2:26:52<10:14:36, 13.23s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5449.23 ms /    27 tokens (  201.82 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.86 ms /     3 runs   (  880.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8123.09 ms /    30 tokens\n",
      " 20%|โโ        | 700/3487 [2:27:00<9:03:22, 11.70s/it] Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6100.70 ms /    31 tokens (  196.80 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.76 ms /     3 runs   (  874.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8725.62 ms /    34 tokens\n",
      " 20%|โโ        | 701/3487 [2:27:09<8:22:20, 10.82s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4198.45 ms /    20 tokens (  209.92 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.87 ms /     3 runs   (  875.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6828.00 ms /    23 tokens\n",
      " 20%|โโ        | 702/3487 [2:27:15<7:26:41,  9.62s/it]Llama.generate: 308 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4990.03 ms /    25 tokens (  199.60 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.65 ms /     3 runs   (  872.88 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7611.25 ms /    28 tokens\n",
      " 20%|โโ        | 703/3487 [2:27:23<6:58:37,  9.02s/it]Llama.generate: 308 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13777.75 ms /    70 tokens (  196.83 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.57 ms /     3 runs   (  880.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16422.47 ms /    73 tokens\n",
      " 20%|โโ        | 704/3487 [2:27:39<8:41:33, 11.24s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13179.31 ms /    65 tokens (  202.76 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.41 ms /     3 runs   (  890.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15884.11 ms /    68 tokens\n",
      " 20%|โโ        | 705/3487 [2:27:55<9:46:00, 12.64s/it]Llama.generate: 307 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11889.53 ms /    60 tokens (  198.16 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.96 ms /     3 runs   (  875.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14520.47 ms /    63 tokens\n",
      " 20%|โโ        | 706/3487 [2:28:10<10:12:05, 13.21s/it]Llama.generate: 307 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11453.33 ms /    60 tokens (  190.89 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.73 ms /     3 runs   (  874.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14079.05 ms /    63 tokens\n",
      " 20%|โโ        | 707/3487 [2:28:24<10:24:08, 13.47s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6625.99 ms /    32 tokens (  207.06 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.85 ms /     3 runs   (  883.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9279.04 ms /    35 tokens\n",
      " 20%|โโ        | 708/3487 [2:28:33<9:25:47, 12.22s/it] Llama.generate: 308 prefix-match hit, remaining 150 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   29089.81 ms /   150 tokens (  193.93 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.84 ms /     3 runs   (  892.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   31769.31 ms /   153 tokens\n",
      " 20%|โโ        | 709/3487 [2:29:05<13:57:17, 18.08s/it]Llama.generate: 307 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11825.40 ms /    60 tokens (  197.09 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.95 ms /     3 runs   (  889.65 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14497.00 ms /    63 tokens\n",
      " 20%|โโ        | 710/3487 [2:29:19<13:07:19, 17.01s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7549.54 ms /    38 tokens (  198.67 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.74 ms /     3 runs   (  892.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10230.69 ms /    41 tokens\n",
      " 20%|โโ        | 711/3487 [2:29:30<11:33:02, 14.98s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7437.31 ms /    36 tokens (  206.59 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.87 ms /     3 runs   (  872.62 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10057.21 ms /    39 tokens\n",
      " 20%|โโ        | 712/3487 [2:29:40<10:24:36, 13.50s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5749.97 ms /    29 tokens (  198.27 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.97 ms /     3 runs   (  880.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8393.34 ms /    32 tokens\n",
      " 20%|โโ        | 713/3487 [2:29:48<9:13:35, 11.97s/it] Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4412.74 ms /    21 tokens (  210.13 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.53 ms /     3 runs   (  875.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7040.35 ms /    24 tokens\n",
      " 20%|โโ        | 714/3487 [2:29:55<8:05:05, 10.50s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5289.01 ms /    27 tokens (  195.89 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.89 ms /     3 runs   (  872.63 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7909.78 ms /    30 tokens\n",
      " 21%|โโ        | 715/3487 [2:30:03<7:29:10,  9.72s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5795.26 ms /    29 tokens (  199.84 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.07 ms /     3 runs   (  881.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8442.39 ms /    32 tokens\n",
      " 21%|โโ        | 716/3487 [2:30:12<7:11:24,  9.34s/it]Llama.generate: 307 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20337.01 ms /   105 tokens (  193.69 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.55 ms /     3 runs   (  873.18 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   22959.82 ms /   108 tokens\n",
      " 21%|โโ        | 717/3487 [2:30:35<10:19:58, 13.43s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5528.64 ms /    27 tokens (  204.76 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.55 ms /     3 runs   (  884.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8185.36 ms /    30 tokens\n",
      " 21%|โโ        | 718/3487 [2:30:43<9:07:16, 11.86s/it] Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4754.92 ms /    24 tokens (  198.12 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2822.60 ms /     3 runs   (  940.87 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7580.01 ms /    27 tokens\n",
      " 21%|โโ        | 719/3487 [2:30:50<8:07:59, 10.58s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5982.54 ms /    29 tokens (  206.29 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.98 ms /     3 runs   (  877.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8619.16 ms /    32 tokens\n",
      " 21%|โโ        | 720/3487 [2:30:59<7:40:50,  9.99s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2477.95 ms /     9 tokens (  275.33 ms per token,     3.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.64 ms /     3 runs   (  877.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5113.30 ms /    12 tokens\n",
      " 21%|โโ        | 721/3487 [2:31:04<6:33:16,  8.53s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6260.99 ms /    31 tokens (  201.97 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.08 ms /     3 runs   (  871.69 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8878.74 ms /    34 tokens\n",
      " 21%|โโ        | 722/3487 [2:31:13<6:38:03,  8.64s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3137.11 ms /    15 tokens (  209.14 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.95 ms /     3 runs   (  871.65 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5754.76 ms /    18 tokens\n",
      " 21%|โโ        | 723/3487 [2:31:19<5:58:10,  7.78s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4826.18 ms /    23 tokens (  209.83 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.89 ms /     3 runs   (  871.63 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7443.25 ms /    26 tokens\n",
      " 21%|โโ        | 724/3487 [2:31:26<5:53:34,  7.68s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3000.27 ms /    14 tokens (  214.30 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.26 ms /     3 runs   (  874.42 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5625.69 ms /    17 tokens\n",
      " 21%|โโ        | 725/3487 [2:31:32<5:25:12,  7.06s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3800.99 ms /    18 tokens (  211.17 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.98 ms /     3 runs   (  883.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6453.75 ms /    21 tokens\n",
      " 21%|โโ        | 726/3487 [2:31:38<5:16:47,  6.88s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8603.78 ms /    41 tokens (  209.85 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.69 ms /     3 runs   (  873.23 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11226.13 ms /    44 tokens\n",
      " 21%|โโ        | 727/3487 [2:31:50<6:16:40,  8.19s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7224.32 ms /    34 tokens (  212.48 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.16 ms /     3 runs   (  888.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9893.63 ms /    37 tokens\n",
      " 21%|โโ        | 728/3487 [2:31:59<6:40:12,  8.70s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8449.82 ms /    42 tokens (  201.19 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.55 ms /     3 runs   (  872.85 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11070.59 ms /    45 tokens\n",
      " 21%|โโ        | 729/3487 [2:32:11<7:12:49,  9.42s/it]Llama.generate: 308 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11878.27 ms /    62 tokens (  191.58 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.95 ms /     3 runs   (  877.98 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14513.98 ms /    65 tokens\n",
      " 21%|โโ        | 730/3487 [2:32:25<8:23:04, 10.95s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3833.89 ms /    18 tokens (  212.99 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.28 ms /     3 runs   (  872.43 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6453.51 ms /    21 tokens\n",
      " 21%|โโ        | 731/3487 [2:32:32<7:21:04,  9.60s/it]Llama.generate: 306 prefix-match hit, remaining 153 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28917.44 ms /   153 tokens (  189.00 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.17 ms /     3 runs   (  879.06 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   31556.72 ms /   156 tokens\n",
      " 21%|โโ        | 732/3487 [2:33:03<12:23:25, 16.19s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1695.35 ms /     6 tokens (  282.56 ms per token,     3.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.40 ms /     3 runs   (  880.80 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4340.27 ms /     9 tokens\n",
      " 21%|โโ        | 733/3487 [2:33:07<9:40:06, 12.64s/it] Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4639.77 ms /    23 tokens (  201.73 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.04 ms /     3 runs   (  877.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7275.66 ms /    26 tokens\n",
      " 21%|โโ        | 734/3487 [2:33:15<8:26:13, 11.03s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2705.17 ms /    12 tokens (  225.43 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.50 ms /     3 runs   (  877.17 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5339.21 ms /    15 tokens\n",
      " 21%|โโ        | 735/3487 [2:33:20<7:07:48,  9.33s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3639.05 ms /    18 tokens (  202.17 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.61 ms /     3 runs   (  877.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6274.90 ms /    21 tokens\n",
      " 21%|โโ        | 736/3487 [2:33:26<6:25:46,  8.41s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4075.26 ms /    19 tokens (  214.49 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2904.16 ms /     3 runs   (  968.05 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6982.02 ms /    22 tokens\n",
      " 21%|โโ        | 737/3487 [2:33:33<6:06:03,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5858.92 ms /    30 tokens (  195.30 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.37 ms /     3 runs   (  870.79 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8473.81 ms /    33 tokens\n",
      " 21%|โโ        | 738/3487 [2:33:42<6:12:43,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4787.36 ms /    23 tokens (  208.15 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.06 ms /     3 runs   (  874.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7412.27 ms /    26 tokens\n",
      " 21%|โโ        | 739/3487 [2:33:49<6:02:46,  7.92s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5580.22 ms /    28 tokens (  199.29 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.53 ms /     3 runs   (  895.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8270.42 ms /    31 tokens\n",
      " 21%|โโ        | 740/3487 [2:33:58<6:07:33,  8.03s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2755.68 ms /    12 tokens (  229.64 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.38 ms /     3 runs   (  870.79 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5370.67 ms /    15 tokens\n",
      " 21%|โโโ       | 741/3487 [2:34:03<5:31:02,  7.23s/it]Llama.generate: 311 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4218.72 ms /    21 tokens (  200.89 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.80 ms /     3 runs   (  874.93 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6845.57 ms /    24 tokens\n",
      " 21%|โโโ       | 742/3487 [2:34:10<5:25:42,  7.12s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9563.90 ms /    48 tokens (  199.25 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.31 ms /     3 runs   (  871.10 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12180.12 ms /    51 tokens\n",
      " 21%|โโโ       | 743/3487 [2:34:22<6:35:08,  8.64s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9085.68 ms /    46 tokens (  197.51 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.27 ms /     3 runs   (  878.76 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11724.14 ms /    49 tokens\n",
      " 21%|โโโ       | 744/3487 [2:34:34<7:17:24,  9.57s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2539.02 ms /    10 tokens (  253.90 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.06 ms /     3 runs   (  886.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5201.71 ms /    13 tokens\n",
      " 21%|โโโ       | 745/3487 [2:34:39<6:17:30,  8.26s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2935.62 ms /    14 tokens (  209.69 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.03 ms /     3 runs   (  883.01 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5587.71 ms /    17 tokens\n",
      " 21%|โโโ       | 746/3487 [2:34:44<5:40:52,  7.46s/it]Llama.generate: 307 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13341.85 ms /    66 tokens (  202.15 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.02 ms /     3 runs   (  875.34 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15970.86 ms /    69 tokens\n",
      " 21%|โโโ       | 747/3487 [2:35:00<7:37:24, 10.02s/it]Llama.generate: 308 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2574.57 ms /    12 tokens (  214.55 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.46 ms /     3 runs   (  890.49 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5248.51 ms /    15 tokens\n",
      " 21%|โโโ       | 748/3487 [2:35:06<6:32:03,  8.59s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4898.44 ms /    24 tokens (  204.10 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.96 ms /     3 runs   (  871.32 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7515.27 ms /    27 tokens\n",
      " 21%|โโโ       | 749/3487 [2:35:13<6:17:20,  8.27s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3021.55 ms /    14 tokens (  215.82 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.63 ms /     3 runs   (  873.21 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5643.87 ms /    17 tokens\n",
      " 22%|โโโ       | 750/3487 [2:35:19<5:41:51,  7.49s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2091.55 ms /     6 tokens (  348.59 ms per token,     2.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.41 ms /     3 runs   (  880.80 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4737.87 ms /     9 tokens\n",
      " 22%|โโโ       | 751/3487 [2:35:24<5:04:34,  6.68s/it]Llama.generate: 306 prefix-match hit, remaining 619 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =  117823.99 ms /   619 tokens (  190.35 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.16 ms /     3 runs   (  882.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =  120475.27 ms /   622 tokens\n",
      " 22%|โโโ       | 752/3487 [2:37:24<31:00:45, 40.82s/it]Llama.generate: 306 prefix-match hit, remaining 148 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27864.13 ms /   148 tokens (  188.27 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.62 ms /     3 runs   (  875.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   30493.41 ms /   151 tokens\n",
      " 22%|โโโ       | 753/3487 [2:37:55<28:39:01, 37.73s/it]Llama.generate: 307 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11073.52 ms /    56 tokens (  197.74 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.42 ms /     3 runs   (  880.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13717.94 ms /    59 tokens\n",
      " 22%|โโโ       | 754/3487 [2:38:08<23:10:27, 30.53s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5246.50 ms /    27 tokens (  194.31 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.88 ms /     3 runs   (  872.96 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7867.88 ms /    30 tokens\n",
      " 22%|โโโ       | 755/3487 [2:38:16<18:00:32, 23.73s/it]Llama.generate: 308 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4869.29 ms /    24 tokens (  202.89 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.01 ms /     3 runs   (  874.00 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7494.42 ms /    27 tokens\n",
      " 22%|โโโ       | 756/3487 [2:38:24<14:18:33, 18.86s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4056.25 ms /    20 tokens (  202.81 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.71 ms /     3 runs   (  882.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6705.54 ms /    23 tokens\n",
      " 22%|โโโ       | 757/3487 [2:38:30<11:32:24, 15.22s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6278.31 ms /    30 tokens (  209.28 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.74 ms /     3 runs   (  878.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8916.80 ms /    33 tokens\n",
      " 22%|โโโ       | 758/3487 [2:38:39<10:06:44, 13.34s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3454.63 ms /    16 tokens (  215.91 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.45 ms /     3 runs   (  879.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6095.99 ms /    19 tokens\n",
      " 22%|โโโ       | 759/3487 [2:38:46<8:27:50, 11.17s/it] Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5215.33 ms /    25 tokens (  208.61 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.09 ms /     3 runs   (  871.70 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7832.85 ms /    28 tokens\n",
      " 22%|โโโ       | 760/3487 [2:38:53<7:42:15, 10.17s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3144.74 ms /    15 tokens (  209.65 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.87 ms /     3 runs   (  891.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5821.34 ms /    18 tokens\n",
      " 22%|โโโ       | 761/3487 [2:38:59<6:42:54,  8.87s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4147.99 ms /    19 tokens (  218.32 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.64 ms /     3 runs   (  873.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6772.59 ms /    22 tokens\n",
      " 22%|โโโ       | 762/3487 [2:39:06<6:14:19,  8.24s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4101.31 ms /    20 tokens (  205.07 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.80 ms /     3 runs   (  877.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6734.95 ms /    23 tokens\n",
      " 22%|โโโ       | 763/3487 [2:39:13<5:54:13,  7.80s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4132.85 ms /    19 tokens (  217.52 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.18 ms /     3 runs   (  887.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6798.96 ms /    22 tokens\n",
      " 22%|โโโ       | 764/3487 [2:39:20<5:40:32,  7.50s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2054.48 ms /     9 tokens (  228.28 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.29 ms /     3 runs   (  880.10 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4697.48 ms /    12 tokens\n",
      " 22%|โโโ       | 765/3487 [2:39:24<5:02:47,  6.67s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4071.97 ms /    19 tokens (  214.31 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.88 ms /     3 runs   (  880.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6715.21 ms /    22 tokens\n",
      " 22%|โโโ       | 766/3487 [2:39:31<5:03:20,  6.69s/it]Llama.generate: 306 prefix-match hit, remaining 172 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   32497.59 ms /   172 tokens (  188.94 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.09 ms /     3 runs   (  882.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   35146.33 ms /   175 tokens\n",
      " 22%|โโโ       | 767/3487 [2:40:06<11:30:23, 15.23s/it]Llama.generate: 307 prefix-match hit, remaining 99 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19369.53 ms /    99 tokens (  195.65 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.08 ms /     3 runs   (  871.03 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   21985.11 ms /   102 tokens\n",
      " 22%|โโโ       | 768/3487 [2:40:28<13:02:05, 17.26s/it]Llama.generate: 307 prefix-match hit, remaining 121 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   22863.85 ms /   121 tokens (  188.96 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.73 ms /     3 runs   (  872.91 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   25484.52 ms /   124 tokens\n",
      " 22%|โโโ       | 769/3487 [2:40:54<14:53:41, 19.73s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7223.88 ms /    33 tokens (  218.91 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.60 ms /     3 runs   (  872.20 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9842.84 ms /    36 tokens\n",
      " 22%|โโโ       | 770/3487 [2:41:04<12:39:36, 16.77s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4779.36 ms /    24 tokens (  199.14 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.55 ms /     3 runs   (  882.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7428.02 ms /    27 tokens\n",
      " 22%|โโโ       | 771/3487 [2:41:11<10:32:30, 13.97s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3780.22 ms /    18 tokens (  210.01 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.15 ms /     3 runs   (  872.72 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6401.43 ms /    21 tokens\n",
      " 22%|โโโ       | 772/3487 [2:41:17<8:49:35, 11.70s/it] Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6074.29 ms /    31 tokens (  195.94 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.72 ms /     3 runs   (  879.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8714.81 ms /    34 tokens\n",
      " 22%|โโโ       | 773/3487 [2:41:26<8:09:24, 10.82s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4002.23 ms /    19 tokens (  210.64 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.32 ms /     3 runs   (  882.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6650.99 ms /    22 tokens\n",
      " 22%|โโโ       | 774/3487 [2:41:33<7:12:48,  9.57s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6300.00 ms /    32 tokens (  196.87 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.71 ms /     3 runs   (  874.57 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8925.88 ms /    35 tokens\n",
      " 22%|โโโ       | 775/3487 [2:41:42<7:03:59,  9.38s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8084.76 ms /    39 tokens (  207.30 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.62 ms /     3 runs   (  882.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10734.09 ms /    42 tokens\n",
      " 22%|โโโ       | 776/3487 [2:41:53<7:22:17,  9.79s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2508.69 ms /    11 tokens (  228.06 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.45 ms /     3 runs   (  875.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5136.86 ms /    14 tokens\n",
      " 22%|โโโ       | 777/3487 [2:41:58<6:19:13,  8.40s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2568.46 ms /    10 tokens (  256.85 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.40 ms /     3 runs   (  878.80 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5207.78 ms /    13 tokens\n",
      " 22%|โโโ       | 778/3487 [2:42:03<5:36:00,  7.44s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10176.28 ms /    50 tokens (  203.53 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.03 ms /     3 runs   (  874.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12802.80 ms /    53 tokens\n",
      " 22%|โโโ       | 779/3487 [2:42:16<6:48:34,  9.05s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2965.86 ms /    13 tokens (  228.14 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.43 ms /     3 runs   (  880.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5608.96 ms /    16 tokens\n",
      " 22%|โโโ       | 780/3487 [2:42:21<6:01:56,  8.02s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2072.64 ms /     9 tokens (  230.29 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.58 ms /     3 runs   (  885.19 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4730.74 ms /    12 tokens\n",
      " 22%|โโโ       | 781/3487 [2:42:26<5:17:24,  7.04s/it]Llama.generate: 308 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1731.53 ms /     6 tokens (  288.59 ms per token,     3.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2754.78 ms /     3 runs   (  918.26 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4488.44 ms /     9 tokens\n",
      " 22%|โโโ       | 782/3487 [2:42:31<4:42:55,  6.28s/it]Llama.generate: 307 prefix-match hit, remaining 166 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   33955.94 ms /   166 tokens (  204.55 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.39 ms /     3 runs   (  902.13 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   36665.25 ms /   169 tokens\n",
      " 22%|โโโ       | 783/3487 [2:43:07<11:34:13, 15.40s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5517.83 ms /    27 tokens (  204.36 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.77 ms /     3 runs   (  886.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8179.54 ms /    30 tokens\n",
      " 22%|โโโ       | 784/3487 [2:43:15<9:56:27, 13.24s/it] Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11564.92 ms /    60 tokens (  192.75 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.19 ms /     3 runs   (  890.73 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14239.88 ms /    63 tokens\n",
      " 23%|โโโ       | 785/3487 [2:43:30<10:09:51, 13.54s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7802.22 ms /    36 tokens (  216.73 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.28 ms /     3 runs   (  873.09 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10424.45 ms /    39 tokens\n",
      " 23%|โโโ       | 786/3487 [2:43:40<9:27:38, 12.61s/it] Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3962.10 ms /    19 tokens (  208.53 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.96 ms /     3 runs   (  882.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6611.14 ms /    22 tokens\n",
      " 23%|โโโ       | 787/3487 [2:43:47<8:06:33, 10.81s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2944.77 ms /    13 tokens (  226.52 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.52 ms /     3 runs   (  882.17 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5593.67 ms /    16 tokens\n",
      " 23%|โโโ       | 788/3487 [2:43:52<6:56:03,  9.25s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3680.52 ms /    18 tokens (  204.47 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.13 ms /     3 runs   (  887.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6344.18 ms /    21 tokens\n",
      " 23%|โโโ       | 789/3487 [2:43:59<6:16:51,  8.38s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4380.58 ms /    20 tokens (  219.03 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.90 ms /     3 runs   (  880.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7025.90 ms /    23 tokens\n",
      " 23%|โโโ       | 790/3487 [2:44:06<5:58:58,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4876.56 ms /    24 tokens (  203.19 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.41 ms /     3 runs   (  879.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7516.79 ms /    27 tokens\n",
      " 23%|โโโ       | 791/3487 [2:44:13<5:52:37,  7.85s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7295.15 ms /    33 tokens (  221.07 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.13 ms /     3 runs   (  871.04 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9910.45 ms /    36 tokens\n",
      " 23%|โโโ       | 792/3487 [2:44:23<6:20:23,  8.47s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2518.72 ms /    11 tokens (  228.97 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.05 ms /     3 runs   (  876.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5149.19 ms /    14 tokens\n",
      " 23%|โโโ       | 793/3487 [2:44:28<5:35:38,  7.48s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2498.65 ms /    10 tokens (  249.86 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.58 ms /     3 runs   (  883.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5151.60 ms /    13 tokens\n",
      " 23%|โโโ       | 794/3487 [2:44:34<5:04:47,  6.79s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1558.79 ms /     5 tokens (  311.76 ms per token,     3.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.28 ms /     3 runs   (  887.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4222.87 ms /     8 tokens\n",
      " 23%|โโโ       | 795/3487 [2:44:38<4:30:13,  6.02s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2555.76 ms /    10 tokens (  255.58 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.32 ms /     3 runs   (  883.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5207.69 ms /    13 tokens\n",
      " 23%|โโโ       | 796/3487 [2:44:43<4:19:15,  5.78s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11320.83 ms /    59 tokens (  191.88 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.33 ms /     3 runs   (  883.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13973.38 ms /    62 tokens\n",
      " 23%|โโโ       | 797/3487 [2:44:57<6:09:28,  8.24s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8230.30 ms /    41 tokens (  200.74 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.89 ms /     3 runs   (  871.63 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10847.82 ms /    44 tokens\n",
      " 23%|โโโ       | 798/3487 [2:45:08<6:44:55,  9.04s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5282.53 ms /    27 tokens (  195.65 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.19 ms /     3 runs   (  878.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7921.26 ms /    30 tokens\n",
      " 23%|โโโ       | 799/3487 [2:45:16<6:29:53,  8.70s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7725.74 ms /    38 tokens (  203.31 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.81 ms /     3 runs   (  875.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10353.19 ms /    41 tokens\n",
      " 23%|โโโ       | 800/3487 [2:45:26<6:52:02,  9.20s/it]Llama.generate: 311 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4464.92 ms /    22 tokens (  202.95 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.65 ms /     3 runs   (  876.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7095.85 ms /    25 tokens\n",
      " 23%|โโโ       | 801/3487 [2:45:33<6:23:42,  8.57s/it]Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8685.51 ms /    44 tokens (  197.40 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.16 ms /     3 runs   (  877.72 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11321.59 ms /    47 tokens\n",
      " 23%|โโโ       | 802/3487 [2:45:45<7:00:35,  9.40s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5307.98 ms /    27 tokens (  196.59 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.68 ms /     3 runs   (  872.56 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7928.12 ms /    30 tokens\n",
      " 23%|โโโ       | 803/3487 [2:45:53<6:40:47,  8.96s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5852.68 ms /    29 tokens (  201.82 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.03 ms /     3 runs   (  896.01 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8543.86 ms /    32 tokens\n",
      " 23%|โโโ       | 804/3487 [2:46:01<6:35:11,  8.84s/it]Llama.generate: 307 prefix-match hit, remaining 209 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   39353.76 ms /   209 tokens (  188.30 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.22 ms /     3 runs   (  878.07 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   41990.98 ms /   212 tokens\n",
      " 23%|โโโ       | 805/3487 [2:46:43<13:59:45, 18.79s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9114.85 ms /    42 tokens (  217.02 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2876.61 ms /     3 runs   (  958.87 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   11993.98 ms /    45 tokens\n",
      " 23%|โโโ       | 806/3487 [2:46:55<12:28:28, 16.75s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8099.43 ms /    37 tokens (  218.90 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.40 ms /     3 runs   (  872.80 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10720.24 ms /    40 tokens\n",
      " 23%|โโโ       | 807/3487 [2:47:06<11:07:31, 14.94s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6333.29 ms /    32 tokens (  197.92 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.36 ms /     3 runs   (  886.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8994.88 ms /    35 tokens\n",
      " 23%|โโโ       | 808/3487 [2:47:15<9:47:42, 13.16s/it] Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5821.33 ms /    29 tokens (  200.74 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.24 ms /     3 runs   (  901.75 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8528.92 ms /    32 tokens\n",
      " 23%|โโโ       | 809/3487 [2:47:23<8:45:34, 11.78s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2282.15 ms /     7 tokens (  326.02 ms per token,     3.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.09 ms /     3 runs   (  897.03 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4975.65 ms /    10 tokens\n",
      " 23%|โโโ       | 810/3487 [2:47:28<7:14:30,  9.74s/it]Llama.generate: 313 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3711.65 ms /     4 runs   (  927.91 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    3713.89 ms /     5 tokens\n",
      " 23%|โโโ       | 811/3487 [2:47:32<5:53:50,  7.93s/it]Llama.generate: 313 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3720.00 ms /     4 runs   (  930.00 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    3726.46 ms /     5 tokens\n",
      " 23%|โโโ       | 812/3487 [2:47:36<4:57:30,  6.67s/it]Llama.generate: 313 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3777.39 ms /     4 runs   (  944.35 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    3780.16 ms /     5 tokens\n",
      " 23%|โโโ       | 813/3487 [2:47:40<4:18:47,  5.81s/it]Llama.generate: 313 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3686.26 ms /     4 runs   (  921.57 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    3688.44 ms /     5 tokens\n",
      " 23%|โโโ       | 814/3487 [2:47:43<3:50:30,  5.17s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2765.66 ms /    12 tokens (  230.47 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.23 ms /     3 runs   (  890.08 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5438.73 ms /    15 tokens\n",
      " 23%|โโโ       | 815/3487 [2:47:49<3:54:03,  5.26s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4891.18 ms /    24 tokens (  203.80 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.74 ms /     3 runs   (  889.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7562.63 ms /    27 tokens\n",
      " 23%|โโโ       | 816/3487 [2:47:56<4:24:54,  5.95s/it]Llama.generate: 306 prefix-match hit, remaining 169 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   32130.34 ms /   169 tokens (  190.12 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.80 ms /     3 runs   (  877.93 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   34766.74 ms /   172 tokens\n",
      " 23%|โโโ       | 817/3487 [2:48:31<10:49:40, 14.60s/it]Llama.generate: 307 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16615.02 ms /    83 tokens (  200.18 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2726.42 ms /     3 runs   (  908.81 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   19343.73 ms /    86 tokens\n",
      " 23%|โโโ       | 818/3487 [2:48:50<11:52:51, 16.03s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1583.38 ms /     6 tokens (  263.90 ms per token,     3.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.35 ms /     3 runs   (  886.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4245.55 ms /     9 tokens\n",
      " 23%|โโโ       | 819/3487 [2:48:55<9:15:33, 12.49s/it] Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10101.46 ms /    48 tokens (  210.45 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2903.70 ms /     3 runs   (  967.90 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   13008.04 ms /    51 tokens\n",
      " 24%|โโโ       | 820/3487 [2:49:08<9:22:19, 12.65s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4875.86 ms /    22 tokens (  221.63 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2841.87 ms /     3 runs   (  947.29 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7720.68 ms /    25 tokens\n",
      " 24%|โโโ       | 821/3487 [2:49:15<8:16:31, 11.17s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5295.80 ms /    25 tokens (  211.83 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.72 ms /     3 runs   (  900.57 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8000.50 ms /    28 tokens\n",
      " 24%|โโโ       | 822/3487 [2:49:23<7:34:09, 10.22s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3983.83 ms /    19 tokens (  209.68 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2861.20 ms /     3 runs   (  953.73 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    6847.86 ms /    22 tokens\n",
      " 24%|โโโ       | 823/3487 [2:49:30<6:49:32,  9.22s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4922.55 ms /    23 tokens (  214.02 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.93 ms /     3 runs   (  883.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7574.93 ms /    26 tokens\n",
      " 24%|โโโ       | 824/3487 [2:49:38<6:27:33,  8.73s/it]Llama.generate: 306 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12155.96 ms /    63 tokens (  192.95 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.00 ms /     3 runs   (  884.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14810.70 ms /    66 tokens\n",
      " 24%|โโโ       | 825/3487 [2:49:53<7:48:25, 10.56s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8066.66 ms /    39 tokens (  206.84 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2730.89 ms /     3 runs   (  910.30 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   10800.02 ms /    42 tokens\n",
      " 24%|โโโ       | 826/3487 [2:50:04<7:51:36, 10.63s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5416.63 ms /    25 tokens (  216.67 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2815.26 ms /     3 runs   (  938.42 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    8234.54 ms /    28 tokens\n",
      " 24%|โโโ       | 827/3487 [2:50:12<7:19:38,  9.92s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6060.12 ms /    30 tokens (  202.00 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.51 ms /     3 runs   (  885.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8719.08 ms /    33 tokens\n",
      " 24%|โโโ       | 828/3487 [2:50:21<7:03:39,  9.56s/it]Llama.generate: 306 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10163.09 ms /    53 tokens (  191.76 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.39 ms /     3 runs   (  883.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12814.48 ms /    56 tokens\n",
      " 24%|โโโ       | 829/3487 [2:50:33<7:46:52, 10.54s/it]Llama.generate: 306 prefix-match hit, remaining 124 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23728.83 ms /   124 tokens (  191.36 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2771.51 ms /     3 runs   (  923.84 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   26503.62 ms /   127 tokens\n",
      " 24%|โโโ       | 830/3487 [2:51:00<11:18:54, 15.33s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2529.68 ms /    11 tokens (  229.97 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3100.55 ms /     3 runs   ( 1033.52 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    5633.24 ms /    14 tokens\n",
      " 24%|โโโ       | 831/3487 [2:51:05<9:10:00, 12.42s/it] Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3232.31 ms /    13 tokens (  248.64 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2759.57 ms /     3 runs   (  919.86 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5995.19 ms /    16 tokens\n",
      " 24%|โโโ       | 832/3487 [2:51:11<7:44:33, 10.50s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8976.90 ms /    44 tokens (  204.02 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.11 ms /     3 runs   (  915.70 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   11726.88 ms /    47 tokens\n",
      " 24%|โโโ       | 833/3487 [2:51:23<8:00:48, 10.87s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1720.62 ms /     6 tokens (  286.77 ms per token,     3.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.44 ms /     3 runs   (  889.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4390.19 ms /     9 tokens\n",
      " 24%|โโโ       | 834/3487 [2:51:28<6:34:46,  8.93s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3324.54 ms /    13 tokens (  255.73 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.35 ms /     3 runs   (  894.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6009.63 ms /    16 tokens\n",
      " 24%|โโโ       | 835/3487 [2:51:34<5:56:02,  8.06s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2699.57 ms /    11 tokens (  245.42 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.54 ms /     3 runs   (  887.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5365.29 ms /    14 tokens\n",
      " 24%|โโโ       | 836/3487 [2:51:39<5:20:21,  7.25s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2140.02 ms /     9 tokens (  237.78 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.45 ms /     3 runs   (  895.82 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4830.49 ms /    12 tokens\n",
      " 24%|โโโ       | 837/3487 [2:51:44<4:48:42,  6.54s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3127.89 ms /    12 tokens (  260.66 ms per token,     3.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.03 ms /     3 runs   (  906.68 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5850.16 ms /    15 tokens\n",
      " 24%|โโโ       | 838/3487 [2:51:50<4:39:38,  6.33s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3017.47 ms /    14 tokens (  215.53 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2765.19 ms /     3 runs   (  921.73 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5785.96 ms /    17 tokens\n",
      " 24%|โโโ       | 839/3487 [2:51:56<4:32:25,  6.17s/it]Llama.generate: 307 prefix-match hit, remaining 99 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19717.15 ms /    99 tokens (  199.16 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2923.80 ms /     3 runs   (  974.60 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   22644.11 ms /   102 tokens\n",
      " 24%|โโโ       | 840/3487 [2:52:18<8:10:26, 11.12s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3094.07 ms /    14 tokens (  221.00 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.41 ms /     3 runs   (  885.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5753.06 ms /    17 tokens\n",
      " 24%|โโโ       | 841/3487 [2:52:24<6:59:24,  9.51s/it]Llama.generate: 317 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3051.57 ms /    13 tokens (  234.74 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.16 ms /     3 runs   (  883.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5705.13 ms /    16 tokens\n",
      " 24%|โโโ       | 842/3487 [2:52:30<6:09:00,  8.37s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2673.03 ms /    12 tokens (  222.75 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.77 ms /     3 runs   (  889.26 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5343.57 ms /    15 tokens\n",
      " 24%|โโโ       | 843/3487 [2:52:35<5:28:56,  7.46s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2371.69 ms /    10 tokens (  237.17 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.03 ms /     3 runs   (  879.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5013.38 ms /    13 tokens\n",
      " 24%|โโโ       | 844/3487 [2:52:40<4:56:32,  6.73s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2018.35 ms /     8 tokens (  252.29 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.97 ms /     3 runs   (  886.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4680.19 ms /    11 tokens\n",
      " 24%|โโโ       | 845/3487 [2:52:45<4:29:25,  6.12s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2936.25 ms /    13 tokens (  225.87 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.48 ms /     3 runs   (  883.49 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5589.18 ms /    16 tokens\n",
      " 24%|โโโ       | 846/3487 [2:52:50<4:22:25,  5.96s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5853.44 ms /    29 tokens (  201.84 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.79 ms /     3 runs   (  882.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8504.96 ms /    32 tokens\n",
      " 24%|โโโ       | 847/3487 [2:52:59<4:56:00,  6.73s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10219.31 ms /    52 tokens (  196.53 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.15 ms /     3 runs   (  876.72 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12852.13 ms /    55 tokens\n",
      " 24%|โโโ       | 848/3487 [2:53:12<6:16:49,  8.57s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7683.89 ms /    38 tokens (  202.21 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.01 ms /     3 runs   (  885.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10343.34 ms /    41 tokens\n",
      " 24%|โโโ       | 849/3487 [2:53:22<6:40:13,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5028.67 ms /    25 tokens (  201.15 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.59 ms /     3 runs   (  886.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7690.51 ms /    28 tokens\n",
      " 24%|โโโ       | 850/3487 [2:53:30<6:21:34,  8.68s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4915.98 ms /    24 tokens (  204.83 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.16 ms /     3 runs   (  885.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7575.64 ms /    27 tokens\n",
      " 24%|โโโ       | 851/3487 [2:53:37<6:06:56,  8.35s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5441.46 ms /    26 tokens (  209.29 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.20 ms /     3 runs   (  890.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8115.43 ms /    29 tokens\n",
      " 24%|โโโ       | 852/3487 [2:53:45<6:03:45,  8.28s/it]Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11036.80 ms /    57 tokens (  193.63 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.71 ms /     3 runs   (  902.90 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   13748.68 ms /    60 tokens\n",
      " 24%|โโโ       | 853/3487 [2:53:59<7:15:41,  9.92s/it]Llama.generate: 306 prefix-match hit, remaining 140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26613.98 ms /   140 tokens (  190.10 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.20 ms /     3 runs   (  877.07 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   29248.47 ms /   143 tokens\n",
      " 24%|โโโ       | 854/3487 [2:54:28<11:30:03, 15.72s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11817.02 ms /    60 tokens (  196.95 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.56 ms /     3 runs   (  886.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14479.08 ms /    63 tokens\n",
      " 25%|โโโ       | 855/3487 [2:54:43<11:13:29, 15.35s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9300.10 ms /    47 tokens (  197.87 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.66 ms /     3 runs   (  879.89 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11942.53 ms /    50 tokens\n",
      " 25%|โโโ       | 856/3487 [2:54:55<10:28:29, 14.33s/it]Llama.generate: 307 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20398.55 ms /   107 tokens (  190.64 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.37 ms /     3 runs   (  881.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23046.79 ms /   110 tokens\n",
      " 25%|โโโ       | 857/3487 [2:55:18<12:22:56, 16.95s/it]Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11135.64 ms /    57 tokens (  195.36 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.60 ms /     3 runs   (  873.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13759.63 ms /    60 tokens\n",
      " 25%|โโโ       | 858/3487 [2:55:32<11:40:50, 15.99s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5139.26 ms /    26 tokens (  197.66 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.82 ms /     3 runs   (  888.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7808.54 ms /    29 tokens\n",
      " 25%|โโโ       | 859/3487 [2:55:40<9:53:06, 13.54s/it] Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4851.16 ms /    24 tokens (  202.13 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.59 ms /     3 runs   (  877.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7484.97 ms /    27 tokens\n",
      " 25%|โโโ       | 860/3487 [2:55:47<8:33:26, 11.73s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7932.02 ms /    38 tokens (  208.74 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.27 ms /     3 runs   (  878.09 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10569.02 ms /    41 tokens\n",
      " 25%|โโโ       | 861/3487 [2:55:58<8:18:11, 11.38s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2770.07 ms /    12 tokens (  230.84 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.49 ms /     3 runs   (  888.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5439.24 ms /    15 tokens\n",
      " 25%|โโโ       | 862/3487 [2:56:03<7:00:06,  9.60s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2374.68 ms /    10 tokens (  237.47 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.33 ms /     3 runs   (  884.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5029.53 ms /    13 tokens\n",
      " 25%|โโโ       | 863/3487 [2:56:08<6:00:03,  8.23s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9319.51 ms /    46 tokens (  202.60 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.99 ms /     3 runs   (  884.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11973.93 ms /    49 tokens\n",
      " 25%|โโโ       | 864/3487 [2:56:20<6:49:03,  9.36s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2077.21 ms /     9 tokens (  230.80 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.21 ms /     3 runs   (  887.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4743.57 ms /    12 tokens\n",
      " 25%|โโโ       | 865/3487 [2:56:25<5:48:56,  7.98s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2129.99 ms /     8 tokens (  266.25 ms per token,     3.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.01 ms /     3 runs   (  886.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4790.03 ms /    11 tokens\n",
      " 25%|โโโ       | 866/3487 [2:56:30<5:07:02,  7.03s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2070.92 ms /     9 tokens (  230.10 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.31 ms /     3 runs   (  886.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4732.09 ms /    12 tokens\n",
      " 25%|โโโ       | 867/3487 [2:56:34<4:36:58,  6.34s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9673.34 ms /    48 tokens (  201.53 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.62 ms /     3 runs   (  887.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12337.95 ms /    51 tokens\n",
      " 25%|โโโ       | 868/3487 [2:56:47<5:55:29,  8.14s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5666.33 ms /    27 tokens (  209.86 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.26 ms /     3 runs   (  888.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8333.57 ms /    30 tokens\n",
      " 25%|โโโ       | 869/3487 [2:56:55<5:57:57,  8.20s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2743.40 ms /    12 tokens (  228.62 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.42 ms /     3 runs   (  894.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5430.20 ms /    15 tokens\n",
      " 25%|โโโ       | 870/3487 [2:57:01<5:21:36,  7.37s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3580.92 ms /    17 tokens (  210.64 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.76 ms /     3 runs   (  881.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6228.31 ms /    20 tokens\n",
      " 25%|โโโ       | 871/3487 [2:57:07<5:06:37,  7.03s/it]Llama.generate: 308 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3067.08 ms /    13 tokens (  235.93 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.87 ms /     3 runs   (  882.96 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5718.25 ms /    16 tokens\n",
      " 25%|โโโ       | 872/3487 [2:57:13<4:49:25,  6.64s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2624.29 ms /    12 tokens (  218.69 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.92 ms /     3 runs   (  883.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5277.63 ms /    15 tokens\n",
      " 25%|โโโ       | 873/3487 [2:57:18<4:31:37,  6.23s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3316.87 ms /    15 tokens (  221.12 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.54 ms /     3 runs   (  883.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5971.37 ms /    18 tokens\n",
      " 25%|โโโ       | 874/3487 [2:57:24<4:28:11,  6.16s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7857.23 ms /    38 tokens (  206.77 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.82 ms /     3 runs   (  907.94 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   10583.48 ms /    41 tokens\n",
      " 25%|โโโ       | 875/3487 [2:57:34<5:25:59,  7.49s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3349.84 ms /    15 tokens (  223.32 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.45 ms /     3 runs   (  887.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6015.72 ms /    18 tokens\n",
      " 25%|โโโ       | 876/3487 [2:57:40<5:06:45,  7.05s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2448.27 ms /    10 tokens (  244.83 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.24 ms /     3 runs   (  890.08 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5120.91 ms /    13 tokens\n",
      " 25%|โโโ       | 877/3487 [2:57:46<4:41:34,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4332.52 ms /    20 tokens (  216.63 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.17 ms /     3 runs   (  894.39 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7018.16 ms /    23 tokens\n",
      " 25%|โโโ       | 878/3487 [2:57:53<4:48:41,  6.64s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8545.98 ms /    43 tokens (  198.74 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.70 ms /     3 runs   (  899.57 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11246.97 ms /    46 tokens\n",
      " 25%|โโโ       | 879/3487 [2:58:04<5:48:45,  8.02s/it]Llama.generate: 306 prefix-match hit, remaining 101 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19684.48 ms /   101 tokens (  194.90 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.65 ms /     3 runs   (  877.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   22321.13 ms /   104 tokens\n",
      " 25%|โโโ       | 880/3487 [2:58:26<8:55:06, 12.32s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9151.17 ms /    46 tokens (  198.94 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.76 ms /     3 runs   (  881.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11797.77 ms /    49 tokens\n",
      " 25%|โโโ       | 881/3487 [2:58:38<8:48:15, 12.16s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2820.70 ms /    12 tokens (  235.06 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.90 ms /     3 runs   (  884.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5478.07 ms /    15 tokens\n",
      " 25%|โโโ       | 882/3487 [2:58:43<7:21:06, 10.16s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5233.10 ms /    26 tokens (  201.27 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.85 ms /     3 runs   (  887.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7899.69 ms /    29 tokens\n",
      " 25%|โโโ       | 883/3487 [2:58:51<6:51:36,  9.48s/it]Llama.generate: 307 prefix-match hit, remaining 104 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20502.36 ms /   104 tokens (  197.14 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.82 ms /     3 runs   (  881.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23149.06 ms /   107 tokens\n",
      " 25%|โโโ       | 884/3487 [2:59:14<9:49:26, 13.59s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5307.30 ms /    27 tokens (  196.57 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.98 ms /     3 runs   (  881.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7954.98 ms /    30 tokens\n",
      " 25%|โโโ       | 885/3487 [2:59:22<8:36:03, 11.90s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3143.09 ms /    14 tokens (  224.51 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.91 ms /     3 runs   (  876.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5774.98 ms /    17 tokens\n",
      " 25%|โโโ       | 886/3487 [2:59:28<7:16:18, 10.06s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4827.61 ms /    24 tokens (  201.15 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.87 ms /     3 runs   (  878.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7467.31 ms /    27 tokens\n",
      " 25%|โโโ       | 887/3487 [2:59:36<6:42:28,  9.29s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4127.74 ms /    17 tokens (  242.81 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.89 ms /     3 runs   (  875.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6756.51 ms /    20 tokens\n",
      " 25%|โโโ       | 888/3487 [2:59:42<6:09:31,  8.53s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5241.68 ms /    26 tokens (  201.60 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.04 ms /     3 runs   (  874.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7867.49 ms /    29 tokens\n",
      " 25%|โโโ       | 889/3487 [2:59:50<6:00:52,  8.33s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3203.75 ms /    14 tokens (  228.84 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.98 ms /     3 runs   (  879.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5846.67 ms /    17 tokens\n",
      " 26%|โโโ       | 890/3487 [2:59:56<5:28:32,  7.59s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5832.01 ms /    29 tokens (  201.10 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.43 ms /     3 runs   (  877.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8468.66 ms /    32 tokens\n",
      " 26%|โโโ       | 891/3487 [3:00:05<5:39:55,  7.86s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7315.53 ms /    33 tokens (  221.68 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.92 ms /     3 runs   (  883.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9968.79 ms /    36 tokens\n",
      " 26%|โโโ       | 892/3487 [3:00:15<6:07:18,  8.49s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13696.08 ms /    66 tokens (  207.52 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.54 ms /     3 runs   (  877.51 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16331.07 ms /    69 tokens\n",
      " 26%|โโโ       | 893/3487 [3:00:31<7:48:56, 10.85s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1988.18 ms /     7 tokens (  284.03 ms per token,     3.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.93 ms /     3 runs   (  884.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4645.36 ms /    10 tokens\n",
      " 26%|โโโ       | 894/3487 [3:00:36<6:28:27,  8.99s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2902.63 ms /    13 tokens (  223.28 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.57 ms /     3 runs   (  882.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5552.96 ms /    16 tokens\n",
      " 26%|โโโ       | 895/3487 [3:00:41<5:43:53,  7.96s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5233.06 ms /    25 tokens (  209.32 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.96 ms /     3 runs   (  873.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7856.98 ms /    28 tokens\n",
      " 26%|โโโ       | 896/3487 [3:00:49<5:42:31,  7.93s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6329.46 ms /    31 tokens (  204.18 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.84 ms /     3 runs   (  873.95 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8953.73 ms /    34 tokens\n",
      " 26%|โโโ       | 897/3487 [3:00:58<5:55:43,  8.24s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1973.39 ms /     8 tokens (  246.67 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.48 ms /     3 runs   (  874.16 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4598.25 ms /    11 tokens\n",
      " 26%|โโโ       | 898/3487 [3:01:03<5:08:32,  7.15s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8262.65 ms /    41 tokens (  201.53 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.24 ms /     3 runs   (  870.41 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10876.21 ms /    44 tokens\n",
      " 26%|โโโ       | 899/3487 [3:01:14<5:56:44,  8.27s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4258.40 ms /    21 tokens (  202.78 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.06 ms /     3 runs   (  876.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6888.55 ms /    24 tokens\n",
      " 26%|โโโ       | 900/3487 [3:01:20<5:38:50,  7.86s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4195.14 ms /    20 tokens (  209.76 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.41 ms /     3 runs   (  878.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6833.14 ms /    23 tokens\n",
      " 26%|โโโ       | 901/3487 [3:01:27<5:25:34,  7.55s/it]Llama.generate: 307 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16144.26 ms /    83 tokens (  194.51 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.54 ms /     3 runs   (  875.51 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18773.55 ms /    86 tokens\n",
      " 26%|โโโ       | 902/3487 [3:01:46<7:50:57, 10.93s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9647.87 ms /    48 tokens (  201.00 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2853.59 ms /     3 runs   (  951.20 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   12504.05 ms /    51 tokens\n",
      " 26%|โโโ       | 903/3487 [3:01:59<8:11:36, 11.41s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1863.29 ms /     7 tokens (  266.18 ms per token,     3.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.03 ms /     3 runs   (  915.68 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4612.98 ms /    10 tokens\n",
      " 26%|โโโ       | 904/3487 [3:02:03<6:43:43,  9.38s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2302.83 ms /     8 tokens (  287.85 ms per token,     3.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.58 ms /     3 runs   (  889.19 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5003.57 ms /    11 tokens\n",
      " 26%|โโโ       | 905/3487 [3:02:08<5:47:37,  8.08s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2134.87 ms /     8 tokens (  266.86 ms per token,     3.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.40 ms /     3 runs   (  881.80 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4783.09 ms /    11 tokens\n",
      " 26%|โโโ       | 906/3487 [3:02:13<5:05:07,  7.09s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5401.90 ms /    27 tokens (  200.07 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.13 ms /     3 runs   (  875.04 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8030.60 ms /    30 tokens\n",
      " 26%|โโโ       | 907/3487 [3:02:21<5:17:13,  7.38s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1747.69 ms /     6 tokens (  291.28 ms per token,     3.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.48 ms /     3 runs   (  877.16 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4381.48 ms /     9 tokens\n",
      " 26%|โโโ       | 908/3487 [3:02:26<4:38:35,  6.48s/it]Llama.generate: 307 prefix-match hit, remaining 91 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17388.56 ms /    91 tokens (  191.08 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.00 ms /     3 runs   (  870.67 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   20003.12 ms /    94 tokens\n",
      " 26%|โโโ       | 909/3487 [3:02:46<7:32:53, 10.54s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9099.44 ms /    45 tokens (  202.21 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.12 ms /     3 runs   (  873.37 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11722.12 ms /    48 tokens\n",
      " 26%|โโโ       | 910/3487 [3:02:57<7:48:02, 10.90s/it]Llama.generate: 307 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14907.10 ms /    78 tokens (  191.12 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.24 ms /     3 runs   (  872.41 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   17527.01 ms /    81 tokens\n",
      " 26%|โโโ       | 911/3487 [3:03:15<9:13:21, 12.89s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4256.71 ms /    20 tokens (  212.84 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.76 ms /     3 runs   (  879.59 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6897.79 ms /    23 tokens\n",
      " 26%|โโโ       | 912/3487 [3:03:22<7:56:05, 11.09s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2630.04 ms /    12 tokens (  219.17 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.74 ms /     3 runs   (  878.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5268.41 ms /    15 tokens\n",
      " 26%|โโโ       | 913/3487 [3:03:27<6:41:01,  9.35s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8082.90 ms /    38 tokens (  212.71 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.75 ms /     3 runs   (  870.58 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10697.12 ms /    41 tokens\n",
      " 26%|โโโ       | 914/3487 [3:03:38<6:58:18,  9.75s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7626.12 ms /    38 tokens (  200.69 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.83 ms /     3 runs   (  877.61 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10261.50 ms /    41 tokens\n",
      " 26%|โโโ       | 915/3487 [3:03:48<7:04:45,  9.91s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4088.81 ms /    19 tokens (  215.20 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.02 ms /     3 runs   (  878.34 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6726.48 ms /    22 tokens\n",
      " 26%|โโโ       | 916/3487 [3:03:55<6:23:49,  8.96s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4883.73 ms /    24 tokens (  203.49 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2854.29 ms /     3 runs   (  951.43 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    7740.60 ms /    27 tokens\n",
      " 26%|โโโ       | 917/3487 [3:04:02<6:08:10,  8.60s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7979.62 ms /    39 tokens (  204.61 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.46 ms /     3 runs   (  876.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10611.33 ms /    42 tokens\n",
      " 26%|โโโ       | 918/3487 [3:04:13<6:34:02,  9.20s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10180.31 ms /    52 tokens (  195.78 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.52 ms /     3 runs   (  872.51 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12800.35 ms /    55 tokens\n",
      " 26%|โโโ       | 919/3487 [3:04:26<7:20:11, 10.28s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7219.87 ms /    33 tokens (  218.78 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.69 ms /     3 runs   (  889.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9890.94 ms /    36 tokens\n",
      " 26%|โโโ       | 920/3487 [3:04:36<7:15:03, 10.17s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2273.98 ms /     9 tokens (  252.66 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.89 ms /     3 runs   (  871.63 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4891.66 ms /    12 tokens\n",
      " 26%|โโโ       | 921/3487 [3:04:41<6:07:18,  8.59s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4840.06 ms /    24 tokens (  201.67 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.03 ms /     3 runs   (  875.34 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7469.11 ms /    27 tokens\n",
      " 26%|โโโ       | 922/3487 [3:04:48<5:52:55,  8.26s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4922.77 ms /    24 tokens (  205.12 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.14 ms /     3 runs   (  873.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7545.96 ms /    27 tokens\n",
      " 26%|โโโ       | 923/3487 [3:04:56<5:43:47,  8.05s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3680.90 ms /    17 tokens (  216.52 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.12 ms /     3 runs   (  883.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6335.75 ms /    20 tokens\n",
      " 26%|โโโ       | 924/3487 [3:05:02<5:21:51,  7.53s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4797.17 ms /    24 tokens (  199.88 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.61 ms /     3 runs   (  874.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7422.25 ms /    27 tokens\n",
      " 27%|โโโ       | 925/3487 [3:05:09<5:20:24,  7.50s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3037.84 ms /    13 tokens (  233.68 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.46 ms /     3 runs   (  874.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5662.85 ms /    16 tokens\n",
      " 27%|โโโ       | 926/3487 [3:05:15<4:56:49,  6.95s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1809.52 ms /     7 tokens (  258.50 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.09 ms /     3 runs   (  875.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4438.81 ms /    10 tokens\n",
      " 27%|โโโ       | 927/3487 [3:05:20<4:24:36,  6.20s/it]Llama.generate: 307 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20709.82 ms /   108 tokens (  191.76 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.59 ms /     3 runs   (  882.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23361.09 ms /   111 tokens\n",
      " 27%|โโโ       | 928/3487 [3:05:43<8:04:09, 11.35s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1966.54 ms /     7 tokens (  280.93 ms per token,     3.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.97 ms /     3 runs   (  879.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4609.71 ms /    10 tokens\n",
      " 27%|โโโ       | 929/3487 [3:05:48<6:37:49,  9.33s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1955.83 ms /     8 tokens (  244.48 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.42 ms /     3 runs   (  878.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4592.47 ms /    11 tokens\n",
      " 27%|โโโ       | 930/3487 [3:05:52<5:37:11,  7.91s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5733.82 ms /    28 tokens (  204.78 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.40 ms /     3 runs   (  875.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8363.07 ms /    31 tokens\n",
      " 27%|โโโ       | 931/3487 [3:06:01<5:42:55,  8.05s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3092.22 ms /    13 tokens (  237.86 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.74 ms /     3 runs   (  873.25 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5714.64 ms /    16 tokens\n",
      " 27%|โโโ       | 932/3487 [3:06:06<5:13:04,  7.35s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5829.01 ms /    30 tokens (  194.30 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.81 ms /     3 runs   (  876.60 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8461.37 ms /    33 tokens\n",
      " 27%|โโโ       | 933/3487 [3:06:15<5:27:12,  7.69s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6320.01 ms /    31 tokens (  203.87 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.01 ms /     3 runs   (  873.34 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8942.88 ms /    34 tokens\n",
      " 27%|โโโ       | 934/3487 [3:06:24<5:43:13,  8.07s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4081.34 ms /    20 tokens (  204.07 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.45 ms /     3 runs   (  878.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6720.15 ms /    23 tokens\n",
      " 27%|โโโ       | 935/3487 [3:06:30<5:26:02,  7.67s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7638.93 ms /    37 tokens (  206.46 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.35 ms /     3 runs   (  884.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10294.85 ms /    40 tokens\n",
      " 27%|โโโ       | 936/3487 [3:06:41<5:59:31,  8.46s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13180.16 ms /    67 tokens (  196.72 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.88 ms /     3 runs   (  875.63 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15810.17 ms /    70 tokens\n",
      " 27%|โโโ       | 937/3487 [3:06:57<7:33:15, 10.66s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3074.44 ms /    13 tokens (  236.50 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.95 ms /     3 runs   (  875.98 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5705.14 ms /    16 tokens\n",
      " 27%|โโโ       | 938/3487 [3:07:02<6:29:59,  9.18s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2288.10 ms /     8 tokens (  286.01 ms per token,     3.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2870.06 ms /     3 runs   (  956.69 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    5160.59 ms /    11 tokens\n",
      " 27%|โโโ       | 939/3487 [3:07:07<5:38:43,  7.98s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5871.27 ms /    29 tokens (  202.46 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.16 ms /     3 runs   (  874.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8497.12 ms /    32 tokens\n",
      " 27%|โโโ       | 940/3487 [3:07:16<5:45:18,  8.13s/it]Llama.generate: 308 prefix-match hit, remaining 99 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19244.37 ms /    99 tokens (  194.39 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2604.95 ms /     3 runs   (  868.32 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   21851.39 ms /   102 tokens\n",
      " 27%|โโโ       | 941/3487 [3:07:38<8:39:53, 12.25s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6220.33 ms /    31 tokens (  200.66 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.16 ms /     3 runs   (  885.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8879.23 ms /    34 tokens\n",
      " 27%|โโโ       | 942/3487 [3:07:47<7:56:52, 11.24s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6500.24 ms /    32 tokens (  203.13 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.39 ms /     3 runs   (  881.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9146.57 ms /    35 tokens\n",
      " 27%|โโโ       | 943/3487 [3:07:56<7:30:10, 10.62s/it]Llama.generate: 307 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14701.15 ms /    76 tokens (  193.44 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2818.49 ms /     3 runs   (  939.50 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   17553.66 ms /    79 tokens\n",
      " 27%|โโโ       | 944/3487 [3:08:13<8:58:17, 12.70s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2285.94 ms /     8 tokens (  285.74 ms per token,     3.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3037.03 ms /     3 runs   ( 1012.34 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    5325.75 ms /    11 tokens\n",
      " 27%|โโโ       | 945/3487 [3:08:19<7:24:28, 10.49s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2103.71 ms /     8 tokens (  262.96 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.07 ms /     3 runs   (  910.36 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4837.94 ms /    11 tokens\n",
      " 27%|โโโ       | 946/3487 [3:08:24<6:12:36,  8.80s/it]Llama.generate: 306 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18102.06 ms /    90 tokens (  201.13 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.84 ms /     3 runs   (  886.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20765.49 ms /    93 tokens\n",
      " 27%|โโโ       | 947/3487 [3:08:44<8:44:33, 12.39s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16666.41 ms /    86 tokens (  193.80 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2794.31 ms /     3 runs   (  931.44 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   19465.12 ms /    89 tokens\n",
      " 27%|โโโ       | 948/3487 [3:09:04<10:14:21, 14.52s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9744.15 ms /    49 tokens (  198.86 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.62 ms /     3 runs   (  874.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12370.64 ms /    52 tokens\n",
      " 27%|โโโ       | 949/3487 [3:09:16<9:46:57, 13.88s/it] Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16575.47 ms /    86 tokens (  192.74 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.12 ms /     3 runs   (  872.37 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   19195.56 ms /    89 tokens\n",
      " 27%|โโโ       | 950/3487 [3:09:35<10:54:17, 15.47s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2504.14 ms /    11 tokens (  227.65 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.42 ms /     3 runs   (  885.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5162.88 ms /    14 tokens\n",
      " 27%|โโโ       | 951/3487 [3:09:41<8:43:22, 12.38s/it] Llama.generate: 306 prefix-match hit, remaining 199 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   38906.02 ms /   199 tokens (  195.51 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.24 ms /     3 runs   (  905.75 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   41625.54 ms /   202 tokens\n",
      " 27%|โโโ       | 952/3487 [3:10:22<14:53:58, 21.16s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11559.97 ms /    59 tokens (  195.93 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.21 ms /     3 runs   (  882.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14210.18 ms /    62 tokens\n",
      " 27%|โโโ       | 953/3487 [3:10:36<13:25:40, 19.08s/it]Llama.generate: 311 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3811.95 ms /    18 tokens (  211.77 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.17 ms /     3 runs   (  898.39 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6509.89 ms /    21 tokens\n",
      " 27%|โโโ       | 954/3487 [3:10:43<10:46:18, 15.31s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4493.66 ms /    21 tokens (  213.98 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.12 ms /     3 runs   (  881.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7141.69 ms /    24 tokens\n",
      " 27%|โโโ       | 955/3487 [3:10:50<9:02:46, 12.86s/it] Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2082.96 ms /     9 tokens (  231.44 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.30 ms /     3 runs   (  885.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4742.98 ms /    12 tokens\n",
      " 27%|โโโ       | 956/3487 [3:10:55<7:20:17, 10.44s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6392.01 ms /    31 tokens (  206.19 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.20 ms /     3 runs   (  895.73 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9082.17 ms /    34 tokens\n",
      " 27%|โโโ       | 957/3487 [3:11:04<7:03:04, 10.03s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10232.24 ms /    48 tokens (  213.17 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2888.29 ms /     3 runs   (  962.76 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   13123.56 ms /    51 tokens\n",
      " 27%|โโโ       | 958/3487 [3:11:17<7:42:05, 10.96s/it]Llama.generate: 306 prefix-match hit, remaining 97 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20384.64 ms /    97 tokens (  210.15 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.87 ms /     3 runs   (  875.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   23015.83 ms /   100 tokens\n",
      " 28%|โโโ       | 959/3487 [3:11:40<10:14:22, 14.58s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13653.58 ms /    69 tokens (  197.88 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.41 ms /     3 runs   (  881.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16299.56 ms /    72 tokens\n",
      " 28%|โโโ       | 960/3487 [3:11:56<10:35:56, 15.10s/it]Llama.generate: 306 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15016.29 ms /    76 tokens (  197.58 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.56 ms /     3 runs   (  895.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   17707.14 ms /    79 tokens\n",
      " 28%|โโโ       | 961/3487 [3:12:14<11:08:43, 15.88s/it]Llama.generate: 306 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14691.34 ms /    75 tokens (  195.88 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.84 ms /     3 runs   (  897.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   17386.60 ms /    78 tokens\n",
      " 28%|โโโ       | 962/3487 [3:12:32<11:27:31, 16.34s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4909.61 ms /    21 tokens (  233.79 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.07 ms /     3 runs   (  889.69 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7581.80 ms /    24 tokens\n",
      " 28%|โโโ       | 963/3487 [3:12:39<9:36:52, 13.71s/it] Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10729.33 ms /    24 tokens (  447.06 ms per token,     2.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3611.84 ms /     3 runs   ( 1203.94 ms per token,     0.83 tokens per second)\n",
      "llama_perf_context_print:       total time =   14345.36 ms /    27 tokens\n",
      " 28%|โโโ       | 964/3487 [3:12:54<9:44:44, 13.91s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8638.99 ms /    24 tokens (  359.96 ms per token,     2.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3081.55 ms /     3 runs   ( 1027.18 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =   11723.82 ms /    27 tokens\n",
      " 28%|โโโ       | 965/3487 [3:13:05<9:17:08, 13.25s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3480.40 ms /    15 tokens (  232.03 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3089.09 ms /     3 runs   ( 1029.70 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    6572.40 ms /    18 tokens\n",
      " 28%|โโโ       | 966/3487 [3:13:12<7:52:51, 11.25s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3434.32 ms /    14 tokens (  245.31 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.22 ms /     3 runs   (  886.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6097.65 ms /    17 tokens\n",
      " 28%|โโโ       | 967/3487 [3:13:18<6:47:52,  9.71s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7327.26 ms /    33 tokens (  222.04 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.65 ms /     3 runs   (  885.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9986.27 ms /    36 tokens\n",
      " 28%|โโโ       | 968/3487 [3:13:28<6:51:16,  9.80s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4814.05 ms /    22 tokens (  218.82 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.66 ms /     3 runs   (  892.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7495.21 ms /    25 tokens\n",
      " 28%|โโโ       | 969/3487 [3:13:35<6:22:17,  9.11s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11959.97 ms /    62 tokens (  192.90 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.90 ms /     3 runs   (  886.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14622.02 ms /    65 tokens\n",
      " 28%|โโโ       | 970/3487 [3:13:50<7:31:37, 10.77s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8098.78 ms /    39 tokens (  207.66 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.82 ms /     3 runs   (  884.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10756.37 ms /    42 tokens\n",
      " 28%|โโโ       | 971/3487 [3:14:01<7:31:24, 10.76s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7945.11 ms /    38 tokens (  209.08 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.40 ms /     3 runs   (  882.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10593.98 ms /    41 tokens\n",
      " 28%|โโโ       | 972/3487 [3:14:11<7:29:10, 10.72s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9579.47 ms /    45 tokens (  212.88 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.05 ms /     3 runs   (  883.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12231.23 ms /    48 tokens\n",
      " 28%|โโโ       | 973/3487 [3:14:24<7:48:11, 11.17s/it]Llama.generate: 307 prefix-match hit, remaining 112 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   22791.74 ms /   112 tokens (  203.50 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2767.68 ms /     3 runs   (  922.56 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   25563.69 ms /   115 tokens\n",
      " 28%|โโโ       | 974/3487 [3:14:49<10:48:55, 15.49s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2651.76 ms /    11 tokens (  241.07 ms per token,     4.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.47 ms /     3 runs   (  906.82 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5374.46 ms /    14 tokens\n",
      " 28%|โโโ       | 975/3487 [3:14:55<8:41:42, 12.46s/it] Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7533.68 ms /    37 tokens (  203.61 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.11 ms /     3 runs   (  879.37 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10174.29 ms /    40 tokens\n",
      " 28%|โโโ       | 976/3487 [3:15:05<8:12:53, 11.78s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4301.07 ms /    20 tokens (  215.05 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3057.84 ms /     3 runs   ( 1019.28 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    7364.63 ms /    23 tokens\n",
      " 28%|โโโ       | 977/3487 [3:15:12<7:17:30, 10.46s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7664.07 ms /    31 tokens (  247.23 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2924.98 ms /     3 runs   (  974.99 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   10592.27 ms /    34 tokens\n",
      " 28%|โโโ       | 978/3487 [3:15:23<7:19:09, 10.50s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5655.75 ms /    23 tokens (  245.90 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2851.15 ms /     3 runs   (  950.38 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    8510.41 ms /    26 tokens\n",
      " 28%|โโโ       | 979/3487 [3:15:31<6:54:08,  9.91s/it]Llama.generate: 306 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20593.92 ms /   102 tokens (  201.90 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.21 ms /     3 runs   (  903.74 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   23308.41 ms /   105 tokens\n",
      " 28%|โโโ       | 980/3487 [3:15:55<9:42:04, 13.93s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8731.46 ms /    42 tokens (  207.89 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.47 ms /     3 runs   (  889.49 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11402.73 ms /    45 tokens\n",
      " 28%|โโโ       | 981/3487 [3:16:06<9:10:16, 13.17s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11243.45 ms /    57 tokens (  197.25 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.33 ms /     3 runs   (  889.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13914.33 ms /    60 tokens\n",
      " 28%|โโโ       | 982/3487 [3:16:20<9:19:24, 13.40s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10123.38 ms /    47 tokens (  215.39 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2804.14 ms /     3 runs   (  934.71 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12929.76 ms /    50 tokens\n",
      " 28%|โโโ       | 983/3487 [3:16:33<9:13:25, 13.26s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10682.25 ms /    54 tokens (  197.82 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.14 ms /     3 runs   (  882.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13331.35 ms /    57 tokens\n",
      " 28%|โโโ       | 984/3487 [3:16:46<9:14:11, 13.28s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9210.89 ms /    41 tokens (  224.66 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2758.33 ms /     3 runs   (  919.44 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   11971.89 ms /    44 tokens\n",
      " 28%|โโโ       | 985/3487 [3:16:58<8:57:40, 12.89s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2121.95 ms /     8 tokens (  265.24 ms per token,     3.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2743.70 ms /     3 runs   (  914.57 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4868.58 ms /    11 tokens\n",
      " 28%|โโโ       | 986/3487 [3:17:03<7:17:13, 10.49s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4903.07 ms /    23 tokens (  213.18 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.13 ms /     3 runs   (  909.71 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7634.54 ms /    26 tokens\n",
      " 28%|โโโ       | 987/3487 [3:17:11<6:41:29,  9.64s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2655.25 ms /    11 tokens (  241.39 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.95 ms /     3 runs   (  900.32 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5359.11 ms /    14 tokens\n",
      " 28%|โโโ       | 988/3487 [3:17:16<5:48:01,  8.36s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8068.60 ms /    33 tokens (  244.50 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2746.24 ms /     3 runs   (  915.41 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10816.99 ms /    36 tokens\n",
      " 28%|โโโ       | 989/3487 [3:17:27<6:18:43,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4442.84 ms /    21 tokens (  211.56 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2782.63 ms /     3 runs   (  927.54 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7227.90 ms /    24 tokens\n",
      " 28%|โโโ       | 990/3487 [3:17:34<5:55:20,  8.54s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2849.81 ms /    11 tokens (  259.07 ms per token,     3.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.03 ms /     3 runs   (  888.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5518.05 ms /    14 tokens\n",
      " 28%|โโโ       | 991/3487 [3:17:40<5:17:35,  7.63s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8150.51 ms /    40 tokens (  203.76 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2849.22 ms /     3 runs   (  949.74 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   11002.38 ms /    43 tokens\n",
      " 28%|โโโ       | 992/3487 [3:17:51<5:59:35,  8.65s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3408.53 ms /    15 tokens (  227.24 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.84 ms /     3 runs   (  904.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6124.71 ms /    18 tokens\n",
      " 28%|โโโ       | 993/3487 [3:17:57<5:28:07,  7.89s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4925.84 ms /    23 tokens (  214.17 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.63 ms /     3 runs   (  888.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7595.80 ms /    26 tokens\n",
      " 29%|โโโ       | 994/3487 [3:18:04<5:24:23,  7.81s/it]Llama.generate: 306 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19902.51 ms /   102 tokens (  195.12 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.97 ms /     3 runs   (  884.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   22560.14 ms /   105 tokens\n",
      " 29%|โโโ       | 995/3487 [3:18:27<8:28:11, 12.24s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3816.25 ms /    17 tokens (  224.49 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.87 ms /     3 runs   (  898.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6515.56 ms /    20 tokens\n",
      " 29%|โโโ       | 996/3487 [3:18:34<7:16:49, 10.52s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5273.16 ms /    26 tokens (  202.81 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.54 ms /     3 runs   (  893.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7956.07 ms /    29 tokens\n",
      " 29%|โโโ       | 997/3487 [3:18:42<6:44:49,  9.75s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3679.58 ms /    16 tokens (  229.97 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.64 ms /     3 runs   (  892.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6358.96 ms /    19 tokens\n",
      " 29%|โโโ       | 998/3487 [3:18:48<6:02:30,  8.74s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4311.89 ms /    21 tokens (  205.33 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.32 ms /     3 runs   (  884.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6967.28 ms /    24 tokens\n",
      " 29%|โโโ       | 999/3487 [3:18:55<5:40:26,  8.21s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2678.91 ms /    11 tokens (  243.54 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.91 ms /     3 runs   (  909.97 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5411.56 ms /    14 tokens\n",
      " 29%|โโโ       | 1000/3487 [3:19:00<5:05:36,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9039.72 ms /    45 tokens (  200.88 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.43 ms /     3 runs   (  884.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11694.78 ms /    48 tokens\n",
      " 29%|โโโ       | 1001/3487 [3:19:12<5:59:17,  8.67s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6063.76 ms /    30 tokens (  202.13 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.01 ms /     3 runs   (  895.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8753.40 ms /    33 tokens\n",
      " 29%|โโโ       | 1002/3487 [3:19:21<6:00:16,  8.70s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4568.38 ms /    22 tokens (  207.65 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2905.89 ms /     3 runs   (  968.63 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    7476.95 ms /    25 tokens\n",
      " 29%|โโโ       | 1003/3487 [3:19:28<5:45:03,  8.33s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3823.85 ms /    18 tokens (  212.44 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.97 ms /     3 runs   (  900.66 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6528.12 ms /    21 tokens\n",
      " 29%|โโโ       | 1004/3487 [3:19:35<5:22:35,  7.80s/it]Llama.generate: 307 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12145.85 ms /    61 tokens (  199.11 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.12 ms /     3 runs   (  886.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14808.54 ms /    64 tokens\n",
      " 29%|โโโ       | 1005/3487 [3:19:50<6:49:34,  9.90s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11870.94 ms /    60 tokens (  197.85 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.64 ms /     3 runs   (  911.88 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   14609.26 ms /    63 tokens\n",
      " 29%|โโโ       | 1006/3487 [3:20:04<7:47:55, 11.32s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3283.09 ms /    13 tokens (  252.55 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2752.98 ms /     3 runs   (  917.66 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6038.52 ms /    16 tokens\n",
      " 29%|โโโ       | 1007/3487 [3:20:10<6:42:26,  9.74s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2519.06 ms /    10 tokens (  251.91 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2859.83 ms /     3 runs   (  953.28 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    5381.09 ms /    13 tokens\n",
      " 29%|โโโ       | 1008/3487 [3:20:16<5:48:25,  8.43s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4511.07 ms /    18 tokens (  250.61 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2785.31 ms /     3 runs   (  928.44 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7298.48 ms /    21 tokens\n",
      " 29%|โโโ       | 1009/3487 [3:20:23<5:34:17,  8.09s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3951.44 ms /    17 tokens (  232.44 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2761.28 ms /     3 runs   (  920.43 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6715.87 ms /    20 tokens\n",
      " 29%|โโโ       | 1010/3487 [3:20:30<5:17:13,  7.68s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8429.03 ms /    40 tokens (  210.73 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2754.98 ms /     3 runs   (  918.33 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   11186.27 ms /    43 tokens\n",
      " 29%|โโโ       | 1011/3487 [3:20:41<6:00:38,  8.74s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9953.67 ms /    46 tokens (  216.38 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3054.04 ms /     3 runs   ( 1018.01 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =   13010.86 ms /    49 tokens\n",
      " 29%|โโโ       | 1012/3487 [3:20:54<6:53:33, 10.03s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4066.67 ms /    14 tokens (  290.48 ms per token,     3.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2856.25 ms /     3 runs   (  952.08 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    6925.57 ms /    17 tokens\n",
      " 29%|โโโ       | 1013/3487 [3:21:01<6:15:12,  9.10s/it]Llama.generate: 320 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3858.35 ms /     4 runs   (  964.59 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    3861.18 ms /     5 tokens\n",
      " 29%|โโโ       | 1014/3487 [3:21:05<5:10:23,  7.53s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2497.37 ms /    10 tokens (  249.74 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.92 ms /     3 runs   (  903.64 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5210.64 ms /    13 tokens\n",
      " 29%|โโโ       | 1015/3487 [3:21:10<4:41:42,  6.84s/it]Llama.generate: 308 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7364.74 ms /    31 tokens (  237.57 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.61 ms /     3 runs   (  899.54 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10066.67 ms /    34 tokens\n",
      " 29%|โโโ       | 1016/3487 [3:21:20<5:21:35,  7.81s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8018.14 ms /    39 tokens (  205.59 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.32 ms /     3 runs   (  885.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10677.85 ms /    42 tokens\n",
      " 29%|โโโ       | 1017/3487 [3:21:31<5:57:00,  8.67s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3075.94 ms /    14 tokens (  219.71 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2741.22 ms /     3 runs   (  913.74 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5819.70 ms /    17 tokens\n",
      " 29%|โโโ       | 1018/3487 [3:21:37<5:21:44,  7.82s/it]Llama.generate: 320 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3833.74 ms /     4 runs   (  958.44 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    3836.23 ms /     5 tokens\n",
      " 29%|โโโ       | 1019/3487 [3:21:40<4:32:34,  6.63s/it]Llama.generate: 307 prefix-match hit, remaining 96 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20064.41 ms /    96 tokens (  209.00 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3862.16 ms /     3 runs   ( 1287.39 ms per token,     0.78 tokens per second)\n",
      "llama_perf_context_print:       total time =   23929.66 ms /    99 tokens\n",
      " 29%|โโโ       | 1020/3487 [3:22:04<8:06:00, 11.82s/it]Llama.generate: 311 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15386.52 ms /    66 tokens (  233.13 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.25 ms /     3 runs   (  897.42 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   18081.56 ms /    69 tokens\n",
      " 29%|โโโ       | 1021/3487 [3:22:22<9:23:08, 13.70s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12476.42 ms /    62 tokens (  201.23 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.19 ms /     3 runs   (  893.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15158.25 ms /    65 tokens\n",
      " 29%|โโโ       | 1022/3487 [3:22:38<9:40:58, 14.14s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13883.90 ms /    69 tokens (  201.22 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.98 ms /     3 runs   (  906.66 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   16606.53 ms /    72 tokens\n",
      " 29%|โโโ       | 1023/3487 [3:22:54<10:11:36, 14.89s/it]Llama.generate: 315 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1633.49 ms /     4 tokens (  408.37 ms per token,     2.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2796.03 ms /     3 runs   (  932.01 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4431.98 ms /     7 tokens\n",
      " 29%|โโโ       | 1024/3487 [3:22:59<8:02:38, 11.76s/it] Llama.generate: 311 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5467.11 ms /    27 tokens (  202.49 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.36 ms /     3 runs   (  879.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8107.50 ms /    30 tokens\n",
      " 29%|โโโ       | 1025/3487 [3:23:07<7:17:36, 10.66s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2657.32 ms /    11 tokens (  241.57 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.21 ms /     3 runs   (  895.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5347.36 ms /    14 tokens\n",
      " 29%|โโโ       | 1026/3487 [3:23:12<6:12:05,  9.07s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9259.99 ms /    47 tokens (  197.02 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.47 ms /     3 runs   (  894.16 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11944.83 ms /    50 tokens\n",
      " 29%|โโโ       | 1027/3487 [3:23:24<6:47:22,  9.94s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2750.21 ms /    12 tokens (  229.18 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.53 ms /     3 runs   (  888.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5418.52 ms /    15 tokens\n",
      " 29%|โโโ       | 1028/3487 [3:23:30<5:51:46,  8.58s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8177.73 ms /    41 tokens (  199.46 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.81 ms /     3 runs   (  882.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10827.87 ms /    44 tokens\n",
      " 30%|โโโ       | 1029/3487 [3:23:40<6:19:18,  9.26s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2830.23 ms /    12 tokens (  235.85 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.05 ms /     3 runs   (  900.35 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5533.55 ms /    15 tokens\n",
      " 30%|โโโ       | 1030/3487 [3:23:46<5:33:30,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2063.97 ms /     8 tokens (  258.00 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.87 ms /     3 runs   (  899.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4766.25 ms /    11 tokens\n",
      " 30%|โโโ       | 1031/3487 [3:23:51<4:51:58,  7.13s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3635.04 ms /    13 tokens (  279.62 ms per token,     3.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2750.77 ms /     3 runs   (  916.92 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6388.98 ms /    16 tokens\n",
      " 30%|โโโ       | 1032/3487 [3:23:57<4:43:13,  6.92s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6758.21 ms /    32 tokens (  211.19 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2784.58 ms /     3 runs   (  928.19 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    9545.31 ms /    35 tokens\n",
      " 30%|โโโ       | 1033/3487 [3:24:07<5:15:24,  7.71s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2037.06 ms /     8 tokens (  254.63 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.12 ms /     3 runs   (  893.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4719.27 ms /    11 tokens\n",
      " 30%|โโโ       | 1034/3487 [3:24:11<4:38:40,  6.82s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9614.16 ms /    47 tokens (  204.56 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.21 ms /     3 runs   (  882.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12264.03 ms /    50 tokens\n",
      " 30%|โโโ       | 1035/3487 [3:24:24<5:45:49,  8.46s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6641.64 ms /    32 tokens (  207.55 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3023.50 ms /     3 runs   ( 1007.83 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    9667.60 ms /    35 tokens\n",
      " 30%|โโโ       | 1036/3487 [3:24:33<6:00:33,  8.83s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3088.72 ms /    13 tokens (  237.59 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.63 ms /     3 runs   (  881.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5737.04 ms /    16 tokens\n",
      " 30%|โโโ       | 1037/3487 [3:24:39<5:22:40,  7.90s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2169.44 ms /     8 tokens (  271.18 ms per token,     3.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.09 ms /     3 runs   (  885.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4827.38 ms /    11 tokens\n",
      " 30%|โโโ       | 1038/3487 [3:24:44<4:45:01,  6.98s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2917.78 ms /    13 tokens (  224.44 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.27 ms /     3 runs   (  878.42 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5555.40 ms /    16 tokens\n",
      " 30%|โโโ       | 1039/3487 [3:24:50<4:27:33,  6.56s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4689.20 ms /    22 tokens (  213.15 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.58 ms /     3 runs   (  883.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7343.57 ms /    25 tokens\n",
      " 30%|โโโ       | 1040/3487 [3:24:57<4:37:10,  6.80s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3176.00 ms /    13 tokens (  244.31 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.76 ms /     3 runs   (  896.92 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5869.72 ms /    16 tokens\n",
      " 30%|โโโ       | 1041/3487 [3:25:03<4:25:50,  6.52s/it]Llama.generate: 308 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4146.08 ms /    20 tokens (  207.30 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.45 ms /     3 runs   (  874.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6772.46 ms /    23 tokens\n",
      " 30%|โโโ       | 1042/3487 [3:25:10<4:28:54,  6.60s/it]Llama.generate: 307 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20096.44 ms /   105 tokens (  191.39 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.55 ms /     3 runs   (  874.52 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   22753.73 ms /   108 tokens\n",
      " 30%|โโโ       | 1043/3487 [3:25:32<7:46:17, 11.45s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2430.12 ms /    10 tokens (  243.01 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.88 ms /     3 runs   (  887.29 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5093.79 ms /    13 tokens\n",
      " 30%|โโโ       | 1044/3487 [3:25:37<6:28:35,  9.54s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2055.07 ms /     7 tokens (  293.58 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.93 ms /     3 runs   (  882.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4705.03 ms /    10 tokens\n",
      " 30%|โโโ       | 1045/3487 [3:25:42<5:29:49,  8.10s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13465.98 ms /    69 tokens (  195.16 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.30 ms /     3 runs   (  882.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16115.03 ms /    72 tokens\n",
      " 30%|โโโ       | 1046/3487 [3:25:58<7:07:34, 10.51s/it]Llama.generate: 308 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4247.72 ms /    19 tokens (  223.56 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.27 ms /     3 runs   (  891.76 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6925.05 ms /    22 tokens\n",
      " 30%|โโโ       | 1047/3487 [3:26:05<6:23:45,  9.44s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3787.64 ms /    18 tokens (  210.42 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.08 ms /     3 runs   (  874.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6412.49 ms /    21 tokens\n",
      " 30%|โโโ       | 1048/3487 [3:26:12<5:46:48,  8.53s/it]Llama.generate: 309 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4407.66 ms /    21 tokens (  209.89 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.62 ms /     3 runs   (  875.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7036.52 ms /    24 tokens\n",
      " 30%|โโโ       | 1049/3487 [3:26:19<5:28:33,  8.09s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4703.69 ms /    23 tokens (  204.51 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.15 ms /     3 runs   (  891.72 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7381.15 ms /    26 tokens\n",
      " 30%|โโโ       | 1050/3487 [3:26:26<5:19:55,  7.88s/it]Llama.generate: 314 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3374.83 ms /    15 tokens (  224.99 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.38 ms /     3 runs   (  889.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6046.14 ms /    18 tokens\n",
      " 30%|โโโ       | 1051/3487 [3:26:32<4:57:36,  7.33s/it]Llama.generate: 314 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3201.28 ms /    15 tokens (  213.42 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.01 ms /     3 runs   (  876.34 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5832.44 ms /    18 tokens\n",
      " 30%|โโโ       | 1052/3487 [3:26:38<4:39:19,  6.88s/it]Llama.generate: 306 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11207.76 ms /    55 tokens (  203.78 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.43 ms /     3 runs   (  874.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13832.50 ms /    58 tokens\n",
      " 30%|โโโ       | 1053/3487 [3:26:52<6:04:15,  8.98s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7787.29 ms /    37 tokens (  210.47 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.28 ms /     3 runs   (  886.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10448.15 ms /    40 tokens\n",
      " 30%|โโโ       | 1054/3487 [3:27:02<6:22:04,  9.42s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4862.96 ms /    24 tokens (  202.62 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.59 ms /     3 runs   (  881.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7509.55 ms /    27 tokens\n",
      " 30%|โโโ       | 1055/3487 [3:27:10<5:58:46,  8.85s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3115.94 ms /    13 tokens (  239.69 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.63 ms /     3 runs   (  873.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5740.15 ms /    16 tokens\n",
      " 30%|โโโ       | 1056/3487 [3:27:16<5:20:53,  7.92s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6392.57 ms /    32 tokens (  199.77 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.65 ms /     3 runs   (  886.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9056.19 ms /    35 tokens\n",
      " 30%|โโโ       | 1057/3487 [3:27:25<5:34:39,  8.26s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3560.41 ms /    15 tokens (  237.36 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.97 ms /     3 runs   (  898.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6260.25 ms /    18 tokens\n",
      " 30%|โโโ       | 1058/3487 [3:27:31<5:10:18,  7.67s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10029.35 ms /    51 tokens (  196.65 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.14 ms /     3 runs   (  874.71 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12656.14 ms /    54 tokens\n",
      " 30%|โโโ       | 1059/3487 [3:27:44<6:10:51,  9.16s/it]Llama.generate: 313 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3577.34 ms /    16 tokens (  223.58 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.09 ms /     3 runs   (  889.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6248.16 ms /    19 tokens\n",
      " 30%|โโโ       | 1060/3487 [3:27:50<5:35:24,  8.29s/it]Llama.generate: 313 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3312.30 ms /    15 tokens (  220.82 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.53 ms /     3 runs   (  880.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5954.79 ms /    18 tokens\n",
      " 30%|โโโ       | 1061/3487 [3:27:56<5:07:00,  7.59s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8183.64 ms /    41 tokens (  199.60 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.86 ms /     3 runs   (  870.95 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10799.03 ms /    44 tokens\n",
      " 30%|โโโ       | 1062/3487 [3:28:07<5:45:51,  8.56s/it]Llama.generate: 307 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12105.92 ms /    61 tokens (  198.46 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.98 ms /     3 runs   (  913.33 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   14847.93 ms /    64 tokens\n",
      " 30%|โโโ       | 1063/3487 [3:28:21<7:02:04, 10.45s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7371.45 ms /    34 tokens (  216.81 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.54 ms /     3 runs   (  901.51 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10079.50 ms /    37 tokens\n",
      " 31%|โโโ       | 1064/3487 [3:28:31<6:57:33, 10.34s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5658.29 ms /    27 tokens (  209.57 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.85 ms /     3 runs   (  891.95 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8336.67 ms /    30 tokens\n",
      " 31%|โโโ       | 1065/3487 [3:28:40<6:33:38,  9.75s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5763.87 ms /    29 tokens (  198.75 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.47 ms /     3 runs   (  899.16 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8464.19 ms /    32 tokens\n",
      " 31%|โโโ       | 1066/3487 [3:28:48<6:17:59,  9.37s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3818.08 ms /    18 tokens (  212.12 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2607.33 ms /     3 runs   (  869.11 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6427.81 ms /    21 tokens\n",
      " 31%|โโโ       | 1067/3487 [3:28:55<5:42:21,  8.49s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4813.26 ms /    23 tokens (  209.27 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.14 ms /     3 runs   (  893.05 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7494.48 ms /    26 tokens\n",
      " 31%|โโโ       | 1068/3487 [3:29:02<5:30:17,  8.19s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6323.61 ms /    31 tokens (  203.99 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.62 ms /     3 runs   (  874.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8951.02 ms /    34 tokens\n",
      " 31%|โโโ       | 1069/3487 [3:29:11<5:39:27,  8.42s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1974.91 ms /     8 tokens (  246.86 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.08 ms /     3 runs   (  879.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4614.63 ms /    11 tokens\n",
      " 31%|โโโ       | 1070/3487 [3:29:16<4:53:22,  7.28s/it]Llama.generate: 310 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13516.55 ms /    68 tokens (  198.77 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.36 ms /     3 runs   (  886.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16178.41 ms /    71 tokens\n",
      " 31%|โโโ       | 1071/3487 [3:29:32<6:40:50,  9.95s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3783.52 ms /    17 tokens (  222.56 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.83 ms /     3 runs   (  887.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6448.83 ms /    20 tokens\n",
      " 31%|โโโ       | 1072/3487 [3:29:39<5:58:27,  8.91s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2524.62 ms /    10 tokens (  252.46 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.08 ms /     3 runs   (  878.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5161.99 ms /    13 tokens\n",
      " 31%|โโโ       | 1073/3487 [3:29:44<5:13:13,  7.79s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5798.68 ms /    27 tokens (  214.77 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.33 ms /     3 runs   (  879.44 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8440.80 ms /    30 tokens\n",
      " 31%|โโโ       | 1074/3487 [3:29:52<5:21:07,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3293.93 ms /    15 tokens (  219.60 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.46 ms /     3 runs   (  882.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5943.45 ms /    18 tokens\n",
      " 31%|โโโ       | 1075/3487 [3:29:58<4:56:30,  7.38s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2595.93 ms /    11 tokens (  235.99 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.88 ms /     3 runs   (  885.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5255.56 ms /    14 tokens\n",
      " 31%|โโโ       | 1076/3487 [3:30:03<4:31:17,  6.75s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3221.21 ms /    14 tokens (  230.09 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.35 ms /     3 runs   (  880.12 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5864.06 ms /    17 tokens\n",
      " 31%|โโโ       | 1077/3487 [3:30:09<4:20:35,  6.49s/it]Llama.generate: 307 prefix-match hit, remaining 101 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19331.03 ms /   101 tokens (  191.40 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.70 ms /     3 runs   (  873.90 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21955.35 ms /   104 tokens\n",
      " 31%|โโโ       | 1078/3487 [3:30:31<7:26:53, 11.13s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10434.74 ms /    53 tokens (  196.88 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.12 ms /     3 runs   (  874.71 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13060.45 ms /    56 tokens\n",
      " 31%|โโโ       | 1079/3487 [3:30:44<7:50:26, 11.72s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5984.88 ms /    30 tokens (  199.50 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.86 ms /     3 runs   (  903.95 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8699.00 ms /    33 tokens\n",
      " 31%|โโโ       | 1080/3487 [3:30:53<7:13:57, 10.82s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3569.35 ms /    16 tokens (  223.08 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.11 ms /     3 runs   (  877.37 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6203.92 ms /    19 tokens\n",
      " 31%|โโโ       | 1081/3487 [3:30:59<6:18:24,  9.44s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7141.25 ms /    33 tokens (  216.40 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.43 ms /     3 runs   (  875.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9769.01 ms /    36 tokens\n",
      " 31%|โโโ       | 1082/3487 [3:31:09<6:22:19,  9.54s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2650.90 ms /    11 tokens (  240.99 ms per token,     4.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.38 ms /     3 runs   (  875.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5280.58 ms /    14 tokens\n",
      " 31%|โโโ       | 1083/3487 [3:31:14<5:31:05,  8.26s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13033.49 ms /    65 tokens (  200.52 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.40 ms /     3 runs   (  876.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15696.77 ms /    68 tokens\n",
      " 31%|โโโ       | 1084/3487 [3:31:30<7:00:24, 10.50s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2674.03 ms /    11 tokens (  243.09 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.81 ms /     3 runs   (  883.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5328.89 ms /    14 tokens\n",
      " 31%|โโโ       | 1085/3487 [3:31:35<5:58:16,  8.95s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6151.85 ms /    31 tokens (  198.45 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.61 ms /     3 runs   (  893.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8834.19 ms /    34 tokens\n",
      " 31%|โโโ       | 1086/3487 [3:31:44<5:56:49,  8.92s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3046.10 ms /    13 tokens (  234.32 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.83 ms /     3 runs   (  889.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5718.38 ms /    16 tokens\n",
      " 31%|โโโ       | 1087/3487 [3:31:50<5:18:23,  7.96s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2833.01 ms /    13 tokens (  217.92 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.07 ms /     3 runs   (  891.69 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5510.09 ms /    16 tokens\n",
      " 31%|โโโ       | 1088/3487 [3:31:55<4:48:58,  7.23s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4304.27 ms /    20 tokens (  215.21 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2768.87 ms /     3 runs   (  922.96 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7075.51 ms /    23 tokens\n",
      " 31%|โโโ       | 1089/3487 [3:32:03<4:47:08,  7.18s/it]Llama.generate: 306 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13505.64 ms /    65 tokens (  207.78 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.09 ms /     3 runs   (  876.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16136.66 ms /    68 tokens\n",
      " 31%|โโโโ      | 1090/3487 [3:32:19<6:34:25,  9.87s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5091.67 ms /    25 tokens (  203.67 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.74 ms /     3 runs   (  891.25 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7768.22 ms /    28 tokens\n",
      " 31%|โโโโ      | 1091/3487 [3:32:26<6:09:08,  9.24s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3615.36 ms /    16 tokens (  225.96 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.86 ms /     3 runs   (  888.29 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6282.95 ms /    19 tokens\n",
      " 31%|โโโโ      | 1092/3487 [3:32:33<5:33:36,  8.36s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9582.03 ms /    48 tokens (  199.63 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4242.63 ms /     3 runs   ( 1414.21 ms per token,     0.71 tokens per second)\n",
      "llama_perf_context_print:       total time =   13827.70 ms /    51 tokens\n",
      " 31%|โโโโ      | 1093/3487 [3:32:47<6:39:04, 10.00s/it]Llama.generate: 307 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26049.41 ms /   103 tokens (  252.91 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4031.72 ms /     3 runs   ( 1343.91 ms per token,     0.74 tokens per second)\n",
      "llama_perf_context_print:       total time =   30084.72 ms /   106 tokens\n",
      " 31%|โโโโ      | 1094/3487 [3:33:17<10:39:21, 16.03s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8415.26 ms /    37 tokens (  227.44 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2773.58 ms /     3 runs   (  924.53 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   11191.72 ms /    40 tokens\n",
      " 31%|โโโโ      | 1095/3487 [3:33:28<9:41:20, 14.58s/it] Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13476.64 ms /    69 tokens (  195.31 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.92 ms /     3 runs   (  879.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16117.60 ms /    72 tokens\n",
      " 31%|โโโโ      | 1096/3487 [3:33:44<9:59:34, 15.05s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4689.71 ms /    23 tokens (  203.90 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.79 ms /     3 runs   (  887.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7355.24 ms /    26 tokens\n",
      " 31%|โโโโ      | 1097/3487 [3:33:51<8:27:30, 12.74s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11845.22 ms /    62 tokens (  191.05 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.11 ms /     3 runs   (  883.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14496.43 ms /    65 tokens\n",
      " 31%|โโโโ      | 1098/3487 [3:34:06<8:48:23, 13.27s/it]Llama.generate: 313 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14257.39 ms /    75 tokens (  190.10 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.21 ms /     3 runs   (  878.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16895.51 ms /    78 tokens\n",
      " 32%|โโโโ      | 1099/3487 [3:34:23<9:31:34, 14.36s/it]Llama.generate: 307 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15136.28 ms /    77 tokens (  196.58 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.97 ms /     3 runs   (  882.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17786.69 ms /    80 tokens\n",
      " 32%|โโโโ      | 1100/3487 [3:34:41<10:12:17, 15.39s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5163.39 ms /    25 tokens (  206.54 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.72 ms /     3 runs   (  891.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7839.58 ms /    28 tokens\n",
      " 32%|โโโโ      | 1101/3487 [3:34:48<8:42:03, 13.13s/it] Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4162.64 ms /    20 tokens (  208.13 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.90 ms /     3 runs   (  884.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6818.04 ms /    23 tokens\n",
      " 32%|โโโโ      | 1102/3487 [3:34:55<7:26:40, 11.24s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5064.54 ms /    24 tokens (  211.02 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2749.26 ms /     3 runs   (  916.42 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7815.85 ms /    27 tokens\n",
      " 32%|โโโโ      | 1103/3487 [3:35:03<6:45:48, 10.21s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9310.60 ms /    47 tokens (  198.10 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.18 ms /     3 runs   (  882.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11959.99 ms /    50 tokens\n",
      " 32%|โโโโ      | 1104/3487 [3:35:15<7:06:34, 10.74s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4168.98 ms /    21 tokens (  198.52 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.96 ms /     3 runs   (  893.32 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6851.58 ms /    24 tokens\n",
      " 32%|โโโโ      | 1105/3487 [3:35:22<6:20:09,  9.58s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11724.43 ms /    62 tokens (  189.10 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.77 ms /     3 runs   (  873.26 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14347.13 ms /    65 tokens\n",
      " 32%|โโโโ      | 1106/3487 [3:35:36<7:16:54, 11.01s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11127.72 ms /    59 tokens (  188.61 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.84 ms /     3 runs   (  877.28 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13761.57 ms /    62 tokens\n",
      " 32%|โโโโ      | 1107/3487 [3:35:50<7:49:33, 11.84s/it]Llama.generate: 308 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3601.58 ms /    17 tokens (  211.86 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.80 ms /     3 runs   (  882.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6251.11 ms /    20 tokens\n",
      " 32%|โโโโ      | 1108/3487 [3:35:56<6:43:00, 10.16s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10356.82 ms /    54 tokens (  191.79 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.45 ms /     3 runs   (  886.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13017.90 ms /    57 tokens\n",
      " 32%|โโโโ      | 1109/3487 [3:36:09<7:16:53, 11.02s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12872.58 ms /    67 tokens (  192.13 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.12 ms /     3 runs   (  876.37 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15504.65 ms /    70 tokens\n",
      " 32%|โโโโ      | 1110/3487 [3:36:25<8:10:04, 12.37s/it]Llama.generate: 307 prefix-match hit, remaining 145 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26794.52 ms /   145 tokens (  184.79 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.58 ms /     3 runs   (  878.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   29431.88 ms /   148 tokens\n",
      " 32%|โโโโ      | 1111/3487 [3:36:54<11:32:38, 17.49s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7203.97 ms /    35 tokens (  205.83 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.87 ms /     3 runs   (  873.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9828.11 ms /    38 tokens\n",
      " 32%|โโโโ      | 1112/3487 [3:37:04<10:01:28, 15.20s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8552.80 ms /    45 tokens (  190.06 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.03 ms /     3 runs   (  874.01 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11177.37 ms /    48 tokens\n",
      " 32%|โโโโ      | 1113/3487 [3:37:15<9:13:37, 13.99s/it] Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5638.91 ms /    27 tokens (  208.85 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.33 ms /     3 runs   (  877.44 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8273.58 ms /    30 tokens\n",
      " 32%|โโโโ      | 1114/3487 [3:37:24<8:05:37, 12.28s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13026.44 ms /    69 tokens (  188.79 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.13 ms /     3 runs   (  875.71 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15656.21 ms /    72 tokens\n",
      " 32%|โโโโ      | 1115/3487 [3:37:39<8:45:34, 13.29s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3973.51 ms /    19 tokens (  209.13 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2757.15 ms /     3 runs   (  919.05 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6733.35 ms /    22 tokens\n",
      " 32%|โโโโ      | 1116/3487 [3:37:46<7:27:41, 11.33s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5836.64 ms /    30 tokens (  194.55 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.27 ms /     3 runs   (  881.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8483.38 ms /    33 tokens\n",
      " 32%|โโโโ      | 1117/3487 [3:37:54<6:53:52, 10.48s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5290.07 ms /    27 tokens (  195.93 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2745.84 ms /     3 runs   (  915.28 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8038.87 ms /    30 tokens\n",
      " 32%|โโโโ      | 1118/3487 [3:38:03<6:24:55,  9.75s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4226.51 ms /    20 tokens (  211.33 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.24 ms /     3 runs   (  911.75 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6964.38 ms /    23 tokens\n",
      " 32%|โโโโ      | 1119/3487 [3:38:09<5:51:51,  8.92s/it]Llama.generate: 307 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14261.67 ms /    76 tokens (  187.65 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.15 ms /     3 runs   (  882.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16912.74 ms /    79 tokens\n",
      " 32%|โโโโ      | 1120/3487 [3:38:26<7:26:28, 11.32s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3048.19 ms /    15 tokens (  203.21 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.68 ms /     3 runs   (  878.56 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5686.37 ms /    18 tokens\n",
      " 32%|โโโโ      | 1121/3487 [3:38:32<6:19:45,  9.63s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4520.05 ms /    22 tokens (  205.46 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.09 ms /     3 runs   (  887.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7184.97 ms /    25 tokens\n",
      " 32%|โโโโ      | 1122/3487 [3:38:39<5:50:48,  8.90s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5086.11 ms /    25 tokens (  203.44 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.49 ms /     3 runs   (  877.16 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7720.00 ms /    28 tokens\n",
      " 32%|โโโโ      | 1123/3487 [3:38:47<5:36:46,  8.55s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7936.17 ms /    41 tokens (  193.57 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.91 ms /     3 runs   (  891.64 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10613.88 ms /    44 tokens\n",
      " 32%|โโโโ      | 1124/3487 [3:38:58<6:01:09,  9.17s/it]Llama.generate: 307 prefix-match hit, remaining 220 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   40066.74 ms /   220 tokens (  182.12 ms per token,     5.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2862.92 ms /     3 runs   (  954.31 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   42932.38 ms /   223 tokens\n",
      " 32%|โโโโ      | 1125/3487 [3:39:41<12:39:50, 19.30s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8037.37 ms /    41 tokens (  196.03 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.95 ms /     3 runs   (  874.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10664.82 ms /    44 tokens\n",
      " 32%|โโโโ      | 1126/3487 [3:39:51<10:57:38, 16.71s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8604.34 ms /    44 tokens (  195.55 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.21 ms /     3 runs   (  877.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11240.39 ms /    47 tokens\n",
      " 32%|โโโโ      | 1127/3487 [3:40:03<9:52:54, 15.07s/it] Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2176.74 ms /     9 tokens (  241.86 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.63 ms /     3 runs   (  897.21 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4870.81 ms /    12 tokens\n",
      " 32%|โโโโ      | 1128/3487 [3:40:07<7:52:24, 12.02s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2556.08 ms /    12 tokens (  213.01 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.62 ms /     3 runs   (  888.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5223.13 ms /    15 tokens\n",
      " 32%|โโโโ      | 1129/3487 [3:40:13<6:32:13,  9.98s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9187.80 ms /    48 tokens (  191.41 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.93 ms /     3 runs   (  877.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11822.77 ms /    51 tokens\n",
      " 32%|โโโโ      | 1130/3487 [3:40:24<6:53:52, 10.54s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9404.89 ms /    49 tokens (  191.94 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.43 ms /     3 runs   (  875.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12035.54 ms /    52 tokens\n",
      " 32%|โโโโ      | 1131/3487 [3:40:36<7:11:27, 10.99s/it]Llama.generate: 321 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5550.97 ms /    25 tokens (  222.04 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.52 ms /     3 runs   (  877.17 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8185.29 ms /    28 tokens\n",
      " 32%|โโโโ      | 1132/3487 [3:40:45<6:38:22, 10.15s/it]Llama.generate: 308 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13560.13 ms /    73 tokens (  185.76 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.82 ms /     3 runs   (  886.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16222.10 ms /    76 tokens\n",
      " 32%|โโโโ      | 1133/3487 [3:41:01<7:50:08, 11.98s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10327.27 ms /    54 tokens (  191.25 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.29 ms /     3 runs   (  875.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12955.97 ms /    57 tokens\n",
      " 33%|โโโโ      | 1134/3487 [3:41:14<8:01:28, 12.28s/it]Llama.generate: 307 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15800.15 ms /    86 tokens (  183.72 ms per token,     5.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.12 ms /     3 runs   (  874.04 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18424.77 ms /    89 tokens\n",
      " 33%|โโโโ      | 1135/3487 [3:41:32<9:13:40, 14.12s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6992.95 ms /    34 tokens (  205.67 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.15 ms /     3 runs   (  876.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9625.17 ms /    37 tokens\n",
      " 33%|โโโโ      | 1136/3487 [3:41:42<8:20:38, 12.78s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7736.39 ms /    40 tokens (  193.41 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.58 ms /     3 runs   (  886.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10399.93 ms /    43 tokens\n",
      " 33%|โโโโ      | 1137/3487 [3:41:52<7:52:34, 12.07s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5662.51 ms /    29 tokens (  195.26 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.54 ms /     3 runs   (  877.85 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8298.43 ms /    32 tokens\n",
      " 33%|โโโโ      | 1138/3487 [3:42:01<7:08:13, 10.94s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9869.51 ms /    52 tokens (  189.80 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.11 ms /     3 runs   (  877.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12505.15 ms /    55 tokens\n",
      " 33%|โโโโ      | 1139/3487 [3:42:13<7:26:31, 11.41s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3944.97 ms /    19 tokens (  207.63 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.13 ms /     3 runs   (  880.71 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6591.08 ms /    22 tokens\n",
      " 33%|โโโโ      | 1140/3487 [3:42:20<6:29:53,  9.97s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4346.08 ms /    22 tokens (  197.55 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.54 ms /     3 runs   (  879.85 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6987.94 ms /    25 tokens\n",
      " 33%|โโโโ      | 1141/3487 [3:42:27<5:54:52,  9.08s/it]Llama.generate: 306 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14554.84 ms /    78 tokens (  186.60 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.83 ms /     3 runs   (  879.61 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17196.61 ms /    81 tokens\n",
      " 33%|โโโโ      | 1142/3487 [3:42:44<7:30:02, 11.52s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2567.10 ms /    12 tokens (  213.92 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2952.89 ms /     3 runs   (  984.30 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    5522.79 ms /    15 tokens\n",
      " 33%|โโโโ      | 1143/3487 [3:42:50<6:19:42,  9.72s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3605.49 ms /    17 tokens (  212.09 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.30 ms /     3 runs   (  878.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6243.39 ms /    20 tokens\n",
      " 33%|โโโโ      | 1144/3487 [3:42:56<5:38:55,  8.68s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5457.24 ms /    23 tokens (  237.27 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3105.56 ms /     3 runs   ( 1035.19 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    8565.62 ms /    26 tokens\n",
      " 33%|โโโโ      | 1145/3487 [3:43:04<5:37:32,  8.65s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4701.15 ms /    23 tokens (  204.40 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.17 ms /     3 runs   (  889.39 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7371.75 ms /    26 tokens\n",
      " 33%|โโโโ      | 1146/3487 [3:43:12<5:22:34,  8.27s/it]Llama.generate: 306 prefix-match hit, remaining 97 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18424.03 ms /    97 tokens (  189.94 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.74 ms /     3 runs   (  874.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21050.60 ms /   100 tokens\n",
      " 33%|โโโโ      | 1147/3487 [3:43:33<7:52:04, 12.10s/it]Llama.generate: 307 prefix-match hit, remaining 144 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26304.10 ms /   144 tokens (  182.67 ms per token,     5.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.29 ms /     3 runs   (  881.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   28949.98 ms /   147 tokens\n",
      " 33%|โโโโ      | 1148/3487 [3:44:02<11:09:12, 17.17s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7558.88 ms /    38 tokens (  198.92 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.71 ms /     3 runs   (  881.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10206.72 ms /    41 tokens\n",
      " 33%|โโโโ      | 1149/3487 [3:44:12<9:47:38, 15.08s/it] Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9733.92 ms /    49 tokens (  198.65 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2726.21 ms /     3 runs   (  908.74 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   12462.58 ms /    52 tokens\n",
      " 33%|โโโโ      | 1150/3487 [3:44:24<9:16:53, 14.30s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4509.51 ms /    22 tokens (  204.98 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3072.33 ms /     3 runs   ( 1024.11 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    7584.71 ms /    25 tokens\n",
      " 33%|โโโโ      | 1151/3487 [3:44:32<7:58:22, 12.29s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9368.88 ms /    46 tokens (  203.67 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.15 ms /     3 runs   (  889.05 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12039.15 ms /    49 tokens\n",
      " 33%|โโโโ      | 1152/3487 [3:44:44<7:55:22, 12.22s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4323.24 ms /    22 tokens (  196.51 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.68 ms /     3 runs   (  882.89 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6974.87 ms /    25 tokens\n",
      " 33%|โโโโ      | 1153/3487 [3:44:51<6:54:06, 10.65s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3208.25 ms /    15 tokens (  213.88 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.86 ms /     3 runs   (  878.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5845.83 ms /    18 tokens\n",
      " 33%|โโโโ      | 1154/3487 [3:44:57<5:58:02,  9.21s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3489.91 ms /    16 tokens (  218.12 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.99 ms /     3 runs   (  880.66 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6134.67 ms /    19 tokens\n",
      " 33%|โโโโ      | 1155/3487 [3:45:03<5:22:07,  8.29s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2571.14 ms /    12 tokens (  214.26 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.91 ms /     3 runs   (  885.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5228.99 ms /    15 tokens\n",
      " 33%|โโโโ      | 1156/3487 [3:45:08<4:46:25,  7.37s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7269.48 ms /    36 tokens (  201.93 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.04 ms /     3 runs   (  881.68 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9917.02 ms /    39 tokens\n",
      " 33%|โโโโ      | 1157/3487 [3:45:18<5:16:01,  8.14s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13565.45 ms /    72 tokens (  188.41 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.36 ms /     3 runs   (  876.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16197.55 ms /    75 tokens\n",
      " 33%|โโโโ      | 1158/3487 [3:45:34<6:49:50, 10.56s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8131.63 ms /    42 tokens (  193.61 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.48 ms /     3 runs   (  876.16 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10762.24 ms /    45 tokens\n",
      " 33%|โโโโ      | 1159/3487 [3:45:45<6:52:06, 10.62s/it]Llama.generate: 307 prefix-match hit, remaining 172 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   31247.49 ms /   172 tokens (  181.67 ms per token,     5.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.64 ms /     3 runs   (  876.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   33878.93 ms /   175 tokens\n",
      " 33%|โโโโ      | 1160/3487 [3:46:19<11:22:59, 17.61s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7924.97 ms /    41 tokens (  193.29 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.03 ms /     3 runs   (  873.01 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10547.05 ms /    44 tokens\n",
      " 33%|โโโโ      | 1161/3487 [3:46:30<10:00:39, 15.49s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9306.36 ms /    50 tokens (  186.13 ms per token,     5.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.06 ms /     3 runs   (  875.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11934.18 ms /    53 tokens\n",
      " 33%|โโโโ      | 1162/3487 [3:46:42<9:19:05, 14.43s/it] Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5624.46 ms /    29 tokens (  193.95 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.34 ms /     3 runs   (  880.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8269.06 ms /    32 tokens\n",
      " 33%|โโโโ      | 1163/3487 [3:46:50<8:07:22, 12.58s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10926.93 ms /    59 tokens (  185.20 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.97 ms /     3 runs   (  873.66 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13550.40 ms /    62 tokens\n",
      " 33%|โโโโ      | 1164/3487 [3:47:03<8:18:28, 12.87s/it]Llama.generate: 306 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13854.16 ms /    72 tokens (  192.42 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.79 ms /     3 runs   (  892.26 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16533.45 ms /    75 tokens\n",
      " 33%|โโโโ      | 1165/3487 [3:47:20<9:00:50, 13.98s/it]Llama.generate: 306 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17415.46 ms /    94 tokens (  185.27 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.11 ms /     3 runs   (  886.37 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20077.60 ms /    97 tokens\n",
      " 33%|โโโโ      | 1166/3487 [3:47:40<10:11:31, 15.81s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8320.28 ms /    44 tokens (  189.10 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.40 ms /     3 runs   (  883.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10973.50 ms /    47 tokens\n",
      " 33%|โโโโ      | 1167/3487 [3:47:51<9:15:17, 14.36s/it] Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2942.90 ms /    14 tokens (  210.21 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.24 ms /     3 runs   (  890.75 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5617.87 ms /    17 tokens\n",
      " 33%|โโโโ      | 1168/3487 [3:47:57<7:33:45, 11.74s/it]Llama.generate: 306 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11569.35 ms /    58 tokens (  199.47 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.36 ms /     3 runs   (  902.45 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   14280.05 ms /    61 tokens\n",
      " 34%|โโโโ      | 1169/3487 [3:48:11<8:03:06, 12.50s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3306.29 ms /    15 tokens (  220.42 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2703.82 ms /     3 runs   (  901.27 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6012.85 ms /    18 tokens\n",
      " 34%|โโโโ      | 1170/3487 [3:48:17<6:47:46, 10.56s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8845.58 ms /    46 tokens (  192.30 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.99 ms /     3 runs   (  881.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11493.00 ms /    49 tokens\n",
      " 34%|โโโโ      | 1171/3487 [3:48:29<6:58:29, 10.84s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4549.59 ms /    22 tokens (  206.80 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.06 ms /     3 runs   (  893.35 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7232.27 ms /    25 tokens\n",
      " 34%|โโโโ      | 1172/3487 [3:48:36<6:16:36,  9.76s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8113.04 ms /    40 tokens (  202.83 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.65 ms /     3 runs   (  881.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10759.44 ms /    43 tokens\n",
      " 34%|โโโโ      | 1173/3487 [3:48:47<6:28:05, 10.06s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5056.51 ms /    25 tokens (  202.26 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2826.86 ms /     3 runs   (  942.29 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7886.07 ms /    28 tokens\n",
      " 34%|โโโโ      | 1174/3487 [3:48:54<6:02:50,  9.41s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3959.71 ms /    19 tokens (  208.41 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2810.81 ms /     3 runs   (  936.94 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6773.21 ms /    22 tokens\n",
      " 34%|โโโโ      | 1175/3487 [3:49:01<5:32:16,  8.62s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3472.70 ms /    17 tokens (  204.28 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2796.27 ms /     3 runs   (  932.09 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6271.27 ms /    20 tokens\n",
      " 34%|โโโโ      | 1176/3487 [3:49:07<5:05:01,  7.92s/it]Llama.generate: 306 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15429.64 ms /    83 tokens (  185.90 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.77 ms /     3 runs   (  883.92 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18084.17 ms /    86 tokens\n",
      " 34%|โโโโ      | 1177/3487 [3:49:26<7:02:25, 10.97s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2097.23 ms /     8 tokens (  262.15 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.75 ms /     3 runs   (  889.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4768.84 ms /    11 tokens\n",
      " 34%|โโโโ      | 1178/3487 [3:49:30<5:50:43,  9.11s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2121.95 ms /     8 tokens (  265.24 ms per token,     3.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.83 ms /     3 runs   (  884.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4779.66 ms /    11 tokens\n",
      " 34%|โโโโ      | 1179/3487 [3:49:35<5:00:39,  7.82s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3217.24 ms /    15 tokens (  214.48 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.32 ms /     3 runs   (  880.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5862.33 ms /    18 tokens\n",
      " 34%|โโโโ      | 1180/3487 [3:49:41<4:38:04,  7.23s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1575.49 ms /     6 tokens (  262.58 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2975.82 ms /     3 runs   (  991.94 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    4554.07 ms /     9 tokens\n",
      " 34%|โโโโ      | 1181/3487 [3:49:46<4:07:09,  6.43s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2580.88 ms /    12 tokens (  215.07 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.67 ms /     3 runs   (  880.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5224.09 ms /    15 tokens\n",
      " 34%|โโโโ      | 1182/3487 [3:49:51<3:53:16,  6.07s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3221.26 ms /    15 tokens (  214.75 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.42 ms /     3 runs   (  877.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5857.38 ms /    18 tokens\n",
      " 34%|โโโโ      | 1183/3487 [3:49:57<3:50:46,  6.01s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1760.13 ms /     6 tokens (  293.36 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.15 ms /     3 runs   (  887.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4424.67 ms /     9 tokens\n",
      " 34%|โโโโ      | 1184/3487 [3:50:01<3:32:31,  5.54s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1977.00 ms /     7 tokens (  282.43 ms per token,     3.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.12 ms /     3 runs   (  885.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4635.82 ms /    10 tokens\n",
      " 34%|โโโโ      | 1185/3487 [3:50:06<3:22:07,  5.27s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2110.04 ms /     8 tokens (  263.76 ms per token,     3.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.62 ms /     3 runs   (  877.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4745.36 ms /    11 tokens\n",
      " 34%|โโโโ      | 1186/3487 [3:50:10<3:16:08,  5.11s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4860.30 ms /    24 tokens (  202.51 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.25 ms /     3 runs   (  885.08 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7518.01 ms /    27 tokens\n",
      " 34%|โโโโ      | 1187/3487 [3:50:18<3:43:46,  5.84s/it]Llama.generate: 306 prefix-match hit, remaining 97 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18669.64 ms /    97 tokens (  192.47 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.64 ms /     3 runs   (  894.21 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   21354.85 ms /   100 tokens\n",
      " 34%|โโโโ      | 1188/3487 [3:50:39<6:42:08, 10.50s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3160.60 ms /    12 tokens (  263.38 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.92 ms /     3 runs   (  876.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5792.20 ms /    15 tokens\n",
      " 34%|โโโโ      | 1189/3487 [3:50:45<5:48:02,  9.09s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2764.49 ms /    12 tokens (  230.37 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2727.16 ms /     3 runs   (  909.05 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5493.88 ms /    15 tokens\n",
      " 34%|โโโโ      | 1190/3487 [3:50:51<5:06:42,  8.01s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6238.09 ms /    32 tokens (  194.94 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.88 ms /     3 runs   (  890.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8912.23 ms /    35 tokens\n",
      " 34%|โโโโ      | 1191/3487 [3:51:00<5:16:59,  8.28s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7238.40 ms /    34 tokens (  212.89 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.98 ms /     3 runs   (  883.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9891.72 ms /    37 tokens\n",
      " 34%|โโโโ      | 1192/3487 [3:51:10<5:35:25,  8.77s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7159.48 ms /    35 tokens (  204.56 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.22 ms /     3 runs   (  896.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9852.35 ms /    38 tokens\n",
      " 34%|โโโโ      | 1193/3487 [3:51:19<5:47:49,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3786.34 ms /    18 tokens (  210.35 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2786.14 ms /     3 runs   (  928.71 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6575.12 ms /    21 tokens\n",
      " 34%|โโโโ      | 1194/3487 [3:51:26<5:18:51,  8.34s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8029.09 ms /    39 tokens (  205.87 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.07 ms /     3 runs   (  879.36 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10669.95 ms /    42 tokens\n",
      " 34%|โโโโ      | 1195/3487 [3:51:37<5:45:28,  9.04s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4719.14 ms /    24 tokens (  196.63 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.09 ms /     3 runs   (  882.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7368.90 ms /    27 tokens\n",
      " 34%|โโโโ      | 1196/3487 [3:51:44<5:26:14,  8.54s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7308.41 ms /    36 tokens (  203.01 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.29 ms /     3 runs   (  887.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9972.49 ms /    39 tokens\n",
      " 34%|โโโโ      | 1197/3487 [3:51:54<5:42:32,  8.97s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7101.58 ms /    34 tokens (  208.87 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.50 ms /     3 runs   (  879.17 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9741.49 ms /    37 tokens\n",
      " 34%|โโโโ      | 1198/3487 [3:52:04<5:51:15,  9.21s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8931.22 ms /    47 tokens (  190.03 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.42 ms /     3 runs   (  879.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11572.58 ms /    50 tokens\n",
      " 34%|โโโโ      | 1199/3487 [3:52:15<6:18:15,  9.92s/it]Llama.generate: 306 prefix-match hit, remaining 111 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20420.25 ms /   111 tokens (  183.97 ms per token,     5.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.12 ms /     3 runs   (  883.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23074.12 ms /   114 tokens\n",
      " 34%|โโโโ      | 1200/3487 [3:52:38<8:48:36, 13.87s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3058.84 ms /    14 tokens (  218.49 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.10 ms /     3 runs   (  890.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5731.82 ms /    17 tokens\n",
      " 34%|โโโโ      | 1201/3487 [3:52:44<7:15:27, 11.43s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10158.18 ms /    54 tokens (  188.11 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.96 ms /     3 runs   (  883.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12810.58 ms /    57 tokens\n",
      " 34%|โโโโ      | 1202/3487 [3:52:57<7:31:08, 11.85s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5515.48 ms /    28 tokens (  196.98 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.95 ms /     3 runs   (  903.65 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8229.36 ms /    31 tokens\n",
      " 34%|โโโโ      | 1203/3487 [3:53:05<6:49:43, 10.76s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4154.18 ms /    20 tokens (  207.71 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2799.09 ms /     3 runs   (  933.03 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6955.64 ms /    23 tokens\n",
      " 35%|โโโโ      | 1204/3487 [3:53:12<6:06:11,  9.62s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3299.74 ms /    15 tokens (  219.98 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.05 ms /     3 runs   (  899.68 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6001.60 ms /    18 tokens\n",
      " 35%|โโโโ      | 1205/3487 [3:53:18<5:24:46,  8.54s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3999.72 ms /    19 tokens (  210.51 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.99 ms /     3 runs   (  878.33 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6637.08 ms /    22 tokens\n",
      " 35%|โโโโ      | 1206/3487 [3:53:25<5:03:02,  7.97s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3496.68 ms /    16 tokens (  218.54 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.37 ms /     3 runs   (  881.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6143.85 ms /    19 tokens\n",
      " 35%|โโโโ      | 1207/3487 [3:53:31<4:42:09,  7.43s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4678.11 ms /    21 tokens (  222.77 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.03 ms /     3 runs   (  890.34 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7351.20 ms /    24 tokens\n",
      " 35%|โโโโ      | 1208/3487 [3:53:38<4:41:16,  7.41s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3428.51 ms /    16 tokens (  214.28 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.33 ms /     3 runs   (  888.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6095.94 ms /    19 tokens\n",
      " 35%|โโโโ      | 1209/3487 [3:53:44<4:26:41,  7.02s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2073.71 ms /     8 tokens (  259.21 ms per token,     3.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.42 ms /     3 runs   (  884.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4728.46 ms /    11 tokens\n",
      " 35%|โโโโ      | 1210/3487 [3:53:49<4:00:32,  6.34s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8403.58 ms /    44 tokens (  190.99 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.15 ms /     3 runs   (  889.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11073.90 ms /    47 tokens\n",
      " 35%|โโโโ      | 1211/3487 [3:54:00<4:54:25,  7.76s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4634.19 ms /    23 tokens (  201.49 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.00 ms /     3 runs   (  881.00 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7279.80 ms /    26 tokens\n",
      " 35%|โโโโ      | 1212/3487 [3:54:08<4:48:53,  7.62s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4743.15 ms /    24 tokens (  197.63 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.58 ms /     3 runs   (  889.19 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7412.97 ms /    27 tokens\n",
      " 35%|โโโโ      | 1213/3487 [3:54:15<4:46:30,  7.56s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3106.59 ms /    14 tokens (  221.90 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.50 ms /     3 runs   (  888.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5775.76 ms /    17 tokens\n",
      " 35%|โโโโ      | 1214/3487 [3:54:21<4:26:12,  7.03s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3979.56 ms /    19 tokens (  209.45 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.37 ms /     3 runs   (  888.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6648.10 ms /    22 tokens\n",
      " 35%|โโโโ      | 1215/3487 [3:54:27<4:21:52,  6.92s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3263.91 ms /    15 tokens (  217.59 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.10 ms /     3 runs   (  888.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5932.77 ms /    18 tokens\n",
      " 35%|โโโโ      | 1216/3487 [3:54:33<4:10:40,  6.62s/it]Llama.generate: 307 prefix-match hit, remaining 145 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27397.32 ms /   145 tokens (  188.95 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.97 ms /     3 runs   (  887.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   30061.74 ms /   148 tokens\n",
      " 35%|โโโโ      | 1217/3487 [3:55:03<8:36:41, 13.66s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4609.45 ms /    23 tokens (  200.41 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.67 ms /     3 runs   (  889.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7281.73 ms /    26 tokens\n",
      " 35%|โโโโ      | 1218/3487 [3:55:11<7:24:13, 11.75s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3067.14 ms /    14 tokens (  219.08 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.76 ms /     3 runs   (  884.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5723.61 ms /    17 tokens\n",
      " 35%|โโโโ      | 1219/3487 [3:55:16<6:15:49,  9.94s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2172.07 ms /     9 tokens (  241.34 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.66 ms /     3 runs   (  884.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4826.78 ms /    12 tokens\n",
      " 35%|โโโโ      | 1220/3487 [3:55:21<5:17:46,  8.41s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2938.25 ms /    13 tokens (  226.02 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.99 ms /     3 runs   (  884.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5592.94 ms /    16 tokens\n",
      " 35%|โโโโ      | 1221/3487 [3:55:27<4:45:47,  7.57s/it]Llama.generate: 312 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2171.37 ms /     9 tokens (  241.26 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.82 ms /     3 runs   (  896.94 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4864.75 ms /    12 tokens\n",
      " 35%|โโโโ      | 1222/3487 [3:55:32<4:15:09,  6.76s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4881.95 ms /    24 tokens (  203.41 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.80 ms /     3 runs   (  881.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7528.29 ms /    27 tokens\n",
      " 35%|โโโโ      | 1223/3487 [3:55:39<4:23:51,  6.99s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2020.51 ms /     8 tokens (  252.56 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.68 ms /     3 runs   (  882.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4671.21 ms /    11 tokens\n",
      " 35%|โโโโ      | 1224/3487 [3:55:44<3:57:53,  6.31s/it]Llama.generate: 307 prefix-match hit, remaining 328 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   60062.36 ms /   328 tokens (  183.12 ms per token,     5.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.99 ms /     3 runs   (  884.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   62719.54 ms /   331 tokens\n",
      " 35%|โโโโ      | 1225/3487 [3:56:47<14:35:56, 23.23s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7687.30 ms /    39 tokens (  197.11 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.37 ms /     3 runs   (  882.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10338.36 ms /    42 tokens\n",
      " 35%|โโโโ      | 1226/3487 [3:56:57<12:09:51, 19.37s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9264.23 ms /    48 tokens (  193.00 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.41 ms /     3 runs   (  883.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11916.54 ms /    51 tokens\n",
      " 35%|โโโโ      | 1227/3487 [3:57:09<10:45:24, 17.13s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3174.15 ms /    15 tokens (  211.61 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.23 ms /     3 runs   (  882.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5825.17 ms /    18 tokens\n",
      " 35%|โโโโ      | 1228/3487 [3:57:15<8:37:28, 13.74s/it] Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1900.63 ms /     7 tokens (  271.52 ms per token,     3.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.82 ms /     3 runs   (  888.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4568.90 ms /    10 tokens\n",
      " 35%|โโโโ      | 1229/3487 [3:57:19<6:53:46, 10.99s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5136.60 ms /    26 tokens (  197.56 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.78 ms /     3 runs   (  880.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7781.27 ms /    29 tokens\n",
      " 35%|โโโโ      | 1230/3487 [3:57:27<6:17:24, 10.03s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3061.22 ms /    14 tokens (  218.66 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.83 ms /     3 runs   (  883.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5715.76 ms /    17 tokens\n",
      " 35%|โโโโ      | 1231/3487 [3:57:33<5:28:37,  8.74s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7115.09 ms /    34 tokens (  209.27 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.49 ms /     3 runs   (  886.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9777.15 ms /    37 tokens\n",
      " 35%|โโโโ      | 1232/3487 [3:57:43<5:40:18,  9.05s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7010.55 ms /    33 tokens (  212.44 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.18 ms /     3 runs   (  882.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9660.51 ms /    36 tokens\n",
      " 35%|โโโโ      | 1233/3487 [3:57:52<5:47:04,  9.24s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3028.24 ms /    14 tokens (  216.30 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.09 ms /     3 runs   (  882.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5677.49 ms /    17 tokens\n",
      " 35%|โโโโ      | 1234/3487 [3:57:58<5:06:53,  8.17s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7115.27 ms /    34 tokens (  209.27 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.02 ms /     3 runs   (  884.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9771.25 ms /    37 tokens\n",
      " 35%|โโโโ      | 1235/3487 [3:58:08<5:24:50,  8.65s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9617.64 ms /    49 tokens (  196.28 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2759.49 ms /     3 runs   (  919.83 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   12379.88 ms /    52 tokens\n",
      " 35%|โโโโ      | 1236/3487 [3:58:20<6:06:42,  9.77s/it]Llama.generate: 307 prefix-match hit, remaining 328 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   59837.18 ms /   328 tokens (  182.43 ms per token,     5.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.09 ms /     3 runs   (  896.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   62529.18 ms /   331 tokens\n",
      " 35%|โโโโ      | 1237/3487 [3:59:23<16:00:05, 25.60s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2074.63 ms /     7 tokens (  296.38 ms per token,     3.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.21 ms /     3 runs   (  907.74 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4800.72 ms /    10 tokens\n",
      " 36%|โโโโ      | 1238/3487 [3:59:28<12:05:52, 19.37s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9381.71 ms /    50 tokens (  187.63 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.02 ms /     3 runs   (  883.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12035.08 ms /    53 tokens\n",
      " 36%|โโโโ      | 1239/3487 [3:59:40<10:43:14, 17.17s/it]Llama.generate: 306 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18771.38 ms /    98 tokens (  191.54 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.47 ms /     3 runs   (  885.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   21431.70 ms /   101 tokens\n",
      " 36%|โโโโ      | 1240/3487 [4:00:01<11:30:56, 18.45s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13024.76 ms /    69 tokens (  188.76 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.61 ms /     3 runs   (  894.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15710.65 ms /    72 tokens\n",
      " 36%|โโโโ      | 1241/3487 [4:00:17<11:00:20, 17.64s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7491.41 ms /    35 tokens (  214.04 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.21 ms /     3 runs   (  877.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10126.75 ms /    38 tokens\n",
      " 36%|โโโโ      | 1242/3487 [4:00:27<9:35:47, 15.39s/it] Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8378.01 ms /    44 tokens (  190.41 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.94 ms /     3 runs   (  884.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11034.60 ms /    47 tokens\n",
      " 36%|โโโโ      | 1243/3487 [4:00:38<8:46:46, 14.08s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5956.40 ms /    31 tokens (  192.14 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.49 ms /     3 runs   (  872.16 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8575.73 ms /    34 tokens\n",
      " 36%|โโโโ      | 1244/3487 [4:00:47<7:44:51, 12.43s/it]Llama.generate: 309 prefix-match hit, remaining 138 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25323.61 ms /   138 tokens (  183.50 ms per token,     5.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.34 ms /     3 runs   (  880.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27968.38 ms /   141 tokens\n",
      " 36%|โโโโ      | 1245/3487 [4:01:15<10:38:51, 17.10s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11688.29 ms /    63 tokens (  185.53 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.04 ms /     3 runs   (  876.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14320.53 ms /    66 tokens\n",
      " 36%|โโโโ      | 1246/3487 [4:01:29<10:07:54, 16.28s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7773.42 ms /    40 tokens (  194.34 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.35 ms /     3 runs   (  874.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10399.08 ms /    43 tokens\n",
      " 36%|โโโโ      | 1247/3487 [4:01:39<9:01:54, 14.52s/it] Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7581.63 ms /    39 tokens (  194.40 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.06 ms /     3 runs   (  878.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10218.00 ms /    42 tokens\n",
      " 36%|โโโโ      | 1248/3487 [4:01:50<8:13:41, 13.23s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13807.48 ms /    74 tokens (  186.59 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.67 ms /     3 runs   (  878.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16445.14 ms /    77 tokens\n",
      " 36%|โโโโ      | 1249/3487 [4:02:06<8:49:31, 14.20s/it]Llama.generate: 306 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14959.52 ms /    80 tokens (  186.99 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2795.60 ms /     3 runs   (  931.87 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   17757.79 ms /    83 tokens\n",
      " 36%|โโโโ      | 1250/3487 [4:02:24<9:29:12, 15.27s/it]Llama.generate: 307 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11927.02 ms /    64 tokens (  186.36 ms per token,     5.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.15 ms /     3 runs   (  876.05 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14557.35 ms /    67 tokens\n",
      " 36%|โโโโ      | 1251/3487 [4:02:38<9:21:07, 15.06s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3050.59 ms /    14 tokens (  217.90 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.64 ms /     3 runs   (  880.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5695.41 ms /    17 tokens\n",
      " 36%|โโโโ      | 1252/3487 [4:02:44<7:36:19, 12.25s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10279.21 ms /    53 tokens (  193.95 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.31 ms /     3 runs   (  878.10 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12916.31 ms /    56 tokens\n",
      " 36%|โโโโ      | 1253/3487 [4:02:57<7:43:39, 12.45s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4467.17 ms /    22 tokens (  203.05 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.54 ms /     3 runs   (  873.85 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7091.00 ms /    25 tokens\n",
      " 36%|โโโโ      | 1254/3487 [4:03:04<6:43:39, 10.85s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5184.79 ms /    26 tokens (  199.41 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.23 ms /     3 runs   (  875.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7812.91 ms /    29 tokens\n",
      " 36%|โโโโ      | 1255/3487 [4:03:12<6:09:42,  9.94s/it]Llama.generate: 307 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10499.13 ms /    55 tokens (  190.89 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.89 ms /     3 runs   (  874.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13124.88 ms /    58 tokens\n",
      " 36%|โโโโ      | 1256/3487 [4:03:25<6:45:11, 10.90s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5767.65 ms /    30 tokens (  192.26 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.88 ms /     3 runs   (  878.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8406.90 ms /    33 tokens\n",
      " 36%|โโโโ      | 1257/3487 [4:03:33<6:17:21, 10.15s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6965.25 ms /    33 tokens (  211.07 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.11 ms /     3 runs   (  875.04 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9593.21 ms /    36 tokens\n",
      " 36%|โโโโ      | 1258/3487 [4:03:43<6:11:03,  9.99s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3026.83 ms /    14 tokens (  216.20 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.97 ms /     3 runs   (  876.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5660.26 ms /    17 tokens\n",
      " 36%|โโโโ      | 1259/3487 [4:03:49<5:22:45,  8.69s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3686.28 ms /    18 tokens (  204.79 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.02 ms /     3 runs   (  874.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6313.15 ms /    21 tokens\n",
      " 36%|โโโโ      | 1260/3487 [4:03:55<4:56:12,  7.98s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11418.82 ms /    59 tokens (  193.54 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.65 ms /     3 runs   (  897.55 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   14113.66 ms /    62 tokens\n",
      " 36%|โโโโ      | 1261/3487 [4:04:09<6:04:25,  9.82s/it]Llama.generate: 314 prefix-match hit, remaining 95 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17556.98 ms /    95 tokens (  184.81 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.44 ms /     3 runs   (  875.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   20186.30 ms /    98 tokens\n",
      " 36%|โโโโ      | 1262/3487 [4:04:29<7:59:39, 12.93s/it]Llama.generate: 307 prefix-match hit, remaining 304 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   55114.55 ms /   304 tokens (  181.30 ms per token,     5.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.38 ms /     3 runs   (  880.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   57792.22 ms /   307 tokens\n",
      " 36%|โโโโ      | 1263/3487 [4:05:27<16:18:41, 26.40s/it]Llama.generate: 307 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13878.85 ms /    74 tokens (  187.55 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.67 ms /     3 runs   (  872.89 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   16500.08 ms /    77 tokens\n",
      " 36%|โโโโ      | 1264/3487 [4:05:44<14:28:17, 23.44s/it]Llama.generate: 311 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4082.72 ms /    20 tokens (  204.14 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.84 ms /     3 runs   (  882.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6734.31 ms /    23 tokens\n",
      " 36%|โโโโ      | 1265/3487 [4:05:50<11:22:25, 18.43s/it]Llama.generate: 310 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4921.16 ms /    25 tokens (  196.85 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.82 ms /     3 runs   (  882.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7571.30 ms /    28 tokens\n",
      " 36%|โโโโ      | 1266/3487 [4:05:58<9:21:39, 15.17s/it] Llama.generate: 313 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4997.86 ms /    25 tokens (  199.91 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.66 ms /     3 runs   (  874.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7623.12 ms /    28 tokens\n",
      " 36%|โโโโ      | 1267/3487 [4:06:06<7:57:42, 12.91s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4638.42 ms /    24 tokens (  193.27 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.58 ms /     3 runs   (  882.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7288.31 ms /    27 tokens\n",
      " 36%|โโโโ      | 1268/3487 [4:06:13<6:55:11, 11.23s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1939.28 ms /     7 tokens (  277.04 ms per token,     3.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.76 ms /     3 runs   (  879.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4581.17 ms /    10 tokens\n",
      " 36%|โโโโ      | 1269/3487 [4:06:18<5:41:24,  9.24s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2008.36 ms /     8 tokens (  251.04 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.19 ms /     3 runs   (  877.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4643.90 ms /    11 tokens\n",
      " 36%|โโโโ      | 1270/3487 [4:06:22<4:50:25,  7.86s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4494.91 ms /    22 tokens (  204.31 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.90 ms /     3 runs   (  873.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7119.27 ms /    25 tokens\n",
      " 36%|โโโโ      | 1271/3487 [4:06:29<4:42:10,  7.64s/it]Llama.generate: 307 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14266.53 ms /    76 tokens (  187.72 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.83 ms /     3 runs   (  876.28 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16897.94 ms /    79 tokens\n",
      " 36%|โโโโ      | 1272/3487 [4:06:46<6:24:39, 10.42s/it]Llama.generate: 306 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10829.49 ms /    58 tokens (  186.72 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.34 ms /     3 runs   (  879.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13472.11 ms /    61 tokens\n",
      " 37%|โโโโ      | 1273/3487 [4:07:00<6:58:21, 11.34s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3868.38 ms /    19 tokens (  203.60 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.22 ms /     3 runs   (  883.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6520.19 ms /    22 tokens\n",
      " 37%|โโโโ      | 1274/3487 [4:07:06<6:04:58,  9.90s/it]Llama.generate: 307 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17076.85 ms /    93 tokens (  183.62 ms per token,     5.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.23 ms /     3 runs   (  875.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19706.85 ms /    96 tokens\n",
      " 37%|โโโโ      | 1275/3487 [4:07:26<7:53:24, 12.84s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4026.01 ms /    20 tokens (  201.30 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.92 ms /     3 runs   (  879.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6666.57 ms /    23 tokens\n",
      " 37%|โโโโ      | 1276/3487 [4:07:33<6:45:01, 10.99s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7203.38 ms /    36 tokens (  200.09 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.73 ms /     3 runs   (  875.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9833.60 ms /    39 tokens\n",
      " 37%|โโโโ      | 1277/3487 [4:07:42<6:32:07, 10.65s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2370.73 ms /    10 tokens (  237.07 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.26 ms /     3 runs   (  900.42 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5074.44 ms /    13 tokens\n",
      " 37%|โโโโ      | 1278/3487 [4:07:48<5:30:29,  8.98s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5610.92 ms /    26 tokens (  215.80 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.10 ms /     3 runs   (  880.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8253.26 ms /    29 tokens\n",
      " 37%|โโโโ      | 1279/3487 [4:07:56<5:22:25,  8.76s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5236.80 ms /    27 tokens (  193.96 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.21 ms /     3 runs   (  877.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7872.14 ms /    30 tokens\n",
      " 37%|โโโโ      | 1280/3487 [4:08:04<5:12:34,  8.50s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13571.84 ms /    72 tokens (  188.50 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2851.85 ms /     3 runs   (  950.62 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   16426.52 ms /    75 tokens\n",
      " 37%|โโโโ      | 1281/3487 [4:08:20<6:39:59, 10.88s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7105.04 ms /    35 tokens (  203.00 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.40 ms /     3 runs   (  883.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9757.11 ms /    38 tokens\n",
      " 37%|โโโโ      | 1282/3487 [4:08:30<6:27:32, 10.55s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5151.06 ms /    26 tokens (  198.12 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.07 ms /     3 runs   (  882.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7800.23 ms /    29 tokens\n",
      " 37%|โโโโ      | 1283/3487 [4:08:38<5:57:11,  9.72s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3458.47 ms /    16 tokens (  216.15 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.71 ms /     3 runs   (  876.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6091.23 ms /    19 tokens\n",
      " 37%|โโโโ      | 1284/3487 [4:08:44<5:17:05,  8.64s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5178.08 ms /    26 tokens (  199.16 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.68 ms /     3 runs   (  885.23 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7835.70 ms /    29 tokens\n",
      " 37%|โโโโ      | 1285/3487 [4:08:52<5:08:13,  8.40s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5231.56 ms /    27 tokens (  193.76 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.96 ms /     3 runs   (  892.65 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7911.70 ms /    30 tokens\n",
      " 37%|โโโโ      | 1286/3487 [4:09:00<5:02:49,  8.26s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2631.87 ms /    11 tokens (  239.26 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.74 ms /     3 runs   (  882.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5280.55 ms /    14 tokens\n",
      " 37%|โโโโ      | 1287/3487 [4:09:05<4:30:03,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4133.29 ms /    20 tokens (  206.66 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.07 ms /     3 runs   (  874.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6759.26 ms /    23 tokens\n",
      " 37%|โโโโ      | 1288/3487 [4:09:12<4:23:21,  7.19s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4207.13 ms /    21 tokens (  200.34 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.59 ms /     3 runs   (  883.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6860.17 ms /    24 tokens\n",
      " 37%|โโโโ      | 1289/3487 [4:09:18<4:19:45,  7.09s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4531.87 ms /    22 tokens (  205.99 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.96 ms /     3 runs   (  877.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7168.18 ms /    25 tokens\n",
      " 37%|โโโโ      | 1290/3487 [4:09:26<4:20:35,  7.12s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4006.22 ms /    19 tokens (  210.85 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.90 ms /     3 runs   (  885.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6665.54 ms /    22 tokens\n",
      " 37%|โโโโ      | 1291/3487 [4:09:32<4:15:57,  6.99s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2925.02 ms /    13 tokens (  225.00 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.19 ms /     3 runs   (  880.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5569.89 ms /    16 tokens\n",
      " 37%|โโโโ      | 1292/3487 [4:09:38<4:00:17,  6.57s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4210.19 ms /    21 tokens (  200.49 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.23 ms /     3 runs   (  878.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6848.57 ms /    24 tokens\n",
      " 37%|โโโโ      | 1293/3487 [4:09:45<4:03:20,  6.65s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5800.88 ms /    30 tokens (  193.36 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.07 ms /     3 runs   (  902.69 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8511.75 ms /    33 tokens\n",
      " 37%|โโโโ      | 1294/3487 [4:09:53<4:23:40,  7.21s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7338.17 ms /    31 tokens (  236.72 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.62 ms /     3 runs   (  881.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9986.34 ms /    34 tokens\n",
      " 37%|โโโโ      | 1295/3487 [4:10:03<4:54:03,  8.05s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3566.51 ms /    17 tokens (  209.79 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.26 ms /     3 runs   (  892.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6245.07 ms /    20 tokens\n",
      " 37%|โโโโ      | 1296/3487 [4:10:10<4:34:16,  7.51s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5946.41 ms /    30 tokens (  198.21 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.58 ms /     3 runs   (  888.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8614.51 ms /    33 tokens\n",
      " 37%|โโโโ      | 1297/3487 [4:10:18<4:46:19,  7.84s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6128.56 ms /    32 tokens (  191.52 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.98 ms /     3 runs   (  876.33 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8759.55 ms /    35 tokens\n",
      " 37%|โโโโ      | 1298/3487 [4:10:27<4:56:17,  8.12s/it]Llama.generate: 306 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10938.68 ms /    58 tokens (  188.60 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.20 ms /     3 runs   (  890.07 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13610.95 ms /    61 tokens\n",
      " 37%|โโโโ      | 1299/3487 [4:10:41<5:56:18,  9.77s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3485.07 ms /    16 tokens (  217.82 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.37 ms /     3 runs   (  879.79 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6127.24 ms /    19 tokens\n",
      " 37%|โโโโ      | 1300/3487 [4:10:47<5:16:22,  8.68s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2553.54 ms /    11 tokens (  232.14 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.08 ms /     3 runs   (  876.69 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5185.91 ms /    14 tokens\n",
      " 37%|โโโโ      | 1301/3487 [4:10:52<4:38:07,  7.63s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6102.94 ms /    31 tokens (  196.87 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.54 ms /     3 runs   (  884.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8759.76 ms /    34 tokens\n",
      " 37%|โโโโ      | 1302/3487 [4:11:01<4:50:23,  7.97s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4504.93 ms /    22 tokens (  204.77 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.15 ms /     3 runs   (  876.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7136.94 ms /    25 tokens\n",
      " 37%|โโโโ      | 1303/3487 [4:11:08<4:41:12,  7.73s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7670.10 ms /    39 tokens (  196.67 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.65 ms /     3 runs   (  874.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10297.38 ms /    42 tokens\n",
      " 37%|โโโโ      | 1304/3487 [4:11:18<5:09:14,  8.50s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5609.48 ms /    29 tokens (  193.43 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.16 ms /     3 runs   (  885.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8269.25 ms /    32 tokens\n",
      " 37%|โโโโ      | 1305/3487 [4:11:26<5:06:40,  8.43s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4726.59 ms /    24 tokens (  196.94 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.71 ms /     3 runs   (  885.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7385.44 ms /    27 tokens\n",
      " 37%|โโโโ      | 1306/3487 [4:11:34<4:55:11,  8.12s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7376.48 ms /    38 tokens (  194.12 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.51 ms /     3 runs   (  882.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10028.49 ms /    41 tokens\n",
      " 37%|โโโโ      | 1307/3487 [4:11:44<5:15:56,  8.70s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2711.49 ms /    12 tokens (  225.96 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.79 ms /     3 runs   (  884.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5369.11 ms /    15 tokens\n",
      " 38%|โโโโ      | 1308/3487 [4:11:49<4:39:38,  7.70s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5841.72 ms /    30 tokens (  194.72 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.78 ms /     3 runs   (  885.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8502.41 ms /    33 tokens\n",
      " 38%|โโโโ      | 1309/3487 [4:11:58<4:48:21,  7.94s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3641.23 ms /    17 tokens (  214.19 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.36 ms /     3 runs   (  888.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6339.53 ms /    20 tokens\n",
      " 38%|โโโโ      | 1310/3487 [4:12:04<4:30:51,  7.47s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9067.10 ms /    45 tokens (  201.49 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.54 ms /     3 runs   (  883.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11719.09 ms /    48 tokens\n",
      " 38%|โโโโ      | 1311/3487 [4:12:16<5:17:06,  8.74s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3350.30 ms /    15 tokens (  223.35 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.15 ms /     3 runs   (  883.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6002.66 ms /    18 tokens\n",
      " 38%|โโโโ      | 1312/3487 [4:12:22<4:47:13,  7.92s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7253.45 ms /    33 tokens (  219.80 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.36 ms /     3 runs   (  884.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9909.18 ms /    36 tokens\n",
      " 38%|โโโโ      | 1313/3487 [4:12:32<5:08:45,  8.52s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4584.72 ms /    23 tokens (  199.34 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.37 ms /     3 runs   (  880.79 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7229.56 ms /    26 tokens\n",
      " 38%|โโโโ      | 1314/3487 [4:12:39<4:54:39,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3476.35 ms /    16 tokens (  217.27 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.50 ms /     3 runs   (  885.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6135.55 ms /    19 tokens\n",
      " 38%|โโโโ      | 1315/3487 [4:12:45<4:32:53,  7.54s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7850.89 ms /    40 tokens (  196.27 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.41 ms /     3 runs   (  881.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10497.73 ms /    43 tokens\n",
      " 38%|โโโโ      | 1316/3487 [4:12:56<5:04:59,  8.43s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9982.93 ms /    53 tokens (  188.36 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.53 ms /     3 runs   (  877.84 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12619.15 ms /    56 tokens\n",
      " 38%|โโโโ      | 1317/3487 [4:13:08<5:50:23,  9.69s/it]Llama.generate: 307 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15300.32 ms /    80 tokens (  191.25 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.60 ms /     3 runs   (  887.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17966.06 ms /    83 tokens\n",
      " 38%|โโโโ      | 1318/3487 [4:13:26<7:20:06, 12.17s/it]Llama.generate: 311 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4572.91 ms /    23 tokens (  198.82 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.61 ms /     3 runs   (  895.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7262.73 ms /    26 tokens\n",
      " 38%|โโโโ      | 1319/3487 [4:13:33<6:26:45, 10.70s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4184.04 ms /    21 tokens (  199.24 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.06 ms /     3 runs   (  882.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6832.50 ms /    24 tokens\n",
      " 38%|โโโโ      | 1320/3487 [4:13:40<5:44:43,  9.54s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2919.95 ms /    13 tokens (  224.61 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.95 ms /     3 runs   (  887.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5585.91 ms /    16 tokens\n",
      " 38%|โโโโ      | 1321/3487 [4:13:46<5:01:47,  8.36s/it]Llama.generate: 307 prefix-match hit, remaining 141 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26131.68 ms /   141 tokens (  185.33 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.17 ms /     3 runs   (  883.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   28785.17 ms /   144 tokens\n",
      " 38%|โโโโ      | 1322/3487 [4:14:15<8:42:50, 14.49s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4358.33 ms /    21 tokens (  207.54 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3281.50 ms /     3 runs   ( 1093.83 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =    7643.66 ms /    24 tokens\n",
      " 38%|โโโโ      | 1323/3487 [4:14:22<7:28:38, 12.44s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10049.27 ms /    43 tokens (  233.70 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3032.04 ms /     3 runs   ( 1010.68 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   13084.51 ms /    46 tokens\n",
      " 38%|โโโโ      | 1324/3487 [4:14:35<7:35:30, 12.64s/it]Llama.generate: 306 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16037.15 ms /    75 tokens (  213.83 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.74 ms /     3 runs   (  911.91 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   18776.34 ms /    78 tokens\n",
      " 38%|โโโโ      | 1325/3487 [4:14:54<8:41:47, 14.48s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5154.05 ms /    25 tokens (  206.16 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.83 ms /     3 runs   (  894.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7842.01 ms /    28 tokens\n",
      " 38%|โโโโ      | 1326/3487 [4:15:02<7:29:54, 12.49s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9330.05 ms /    47 tokens (  198.51 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2829.06 ms /     3 runs   (  943.02 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   12161.80 ms /    50 tokens\n",
      " 38%|โโโโ      | 1327/3487 [4:15:14<7:26:11, 12.39s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7031.79 ms /    33 tokens (  213.08 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.24 ms /     3 runs   (  882.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9682.19 ms /    36 tokens\n",
      " 38%|โโโโ      | 1328/3487 [4:15:24<6:56:47, 11.58s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4121.66 ms /    20 tokens (  206.08 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2814.03 ms /     3 runs   (  938.01 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6938.49 ms /    23 tokens\n",
      " 38%|โโโโ      | 1329/3487 [4:15:31<6:06:35, 10.19s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6207.35 ms /    31 tokens (  200.24 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.71 ms /     3 runs   (  893.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8889.84 ms /    34 tokens\n",
      " 38%|โโโโ      | 1330/3487 [4:15:40<5:52:27,  9.80s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4283.85 ms /    21 tokens (  203.99 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.80 ms /     3 runs   (  889.60 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6954.94 ms /    24 tokens\n",
      " 38%|โโโโ      | 1331/3487 [4:15:47<5:21:40,  8.95s/it]Llama.generate: 308 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3473.56 ms /    16 tokens (  217.10 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.89 ms /     3 runs   (  891.63 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6150.71 ms /    19 tokens\n",
      " 38%|โโโโ      | 1332/3487 [4:15:53<4:51:24,  8.11s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7807.80 ms /    39 tokens (  200.20 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.12 ms /     3 runs   (  882.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10456.13 ms /    42 tokens\n",
      " 38%|โโโโ      | 1333/3487 [4:16:03<5:16:36,  8.82s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2910.49 ms /    13 tokens (  223.88 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.39 ms /     3 runs   (  886.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5571.75 ms /    16 tokens\n",
      " 38%|โโโโ      | 1334/3487 [4:16:09<4:41:36,  7.85s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2580.32 ms /    11 tokens (  234.57 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.09 ms /     3 runs   (  893.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5263.28 ms /    14 tokens\n",
      " 38%|โโโโ      | 1335/3487 [4:16:14<4:13:43,  7.07s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4250.29 ms /    21 tokens (  202.39 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.11 ms /     3 runs   (  886.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6910.81 ms /    24 tokens\n",
      " 38%|โโโโ      | 1336/3487 [4:16:21<4:11:57,  7.03s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3962.34 ms /    19 tokens (  208.54 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.94 ms /     3 runs   (  885.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6622.63 ms /    22 tokens\n",
      " 38%|โโโโ      | 1337/3487 [4:16:28<4:07:34,  6.91s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2039.02 ms /     8 tokens (  254.88 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.76 ms /     3 runs   (  889.25 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4709.10 ms /    11 tokens\n",
      " 38%|โโโโ      | 1338/3487 [4:16:33<3:43:54,  6.25s/it]Llama.generate: 306 prefix-match hit, remaining 155 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28408.10 ms /   155 tokens (  183.28 ms per token,     5.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.46 ms /     3 runs   (  893.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   31090.68 ms /   158 tokens\n",
      " 38%|โโโโ      | 1339/3487 [4:17:04<8:10:40, 13.71s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7996.67 ms /    40 tokens (  199.92 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.39 ms /     3 runs   (  889.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10668.68 ms /    43 tokens\n",
      " 38%|โโโโ      | 1340/3487 [4:17:14<7:37:56, 12.80s/it]Llama.generate: 306 prefix-match hit, remaining 96 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18195.90 ms /    96 tokens (  189.54 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.71 ms /     3 runs   (  880.57 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   20840.21 ms /    99 tokens\n",
      " 38%|โโโโ      | 1341/3487 [4:17:35<9:04:07, 15.21s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3260.39 ms /    15 tokens (  217.36 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2728.01 ms /     3 runs   (  909.34 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5991.04 ms /    18 tokens\n",
      " 38%|โโโโ      | 1342/3487 [4:17:41<7:25:04, 12.45s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4824.05 ms /    24 tokens (  201.00 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.47 ms /     3 runs   (  903.16 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7536.27 ms /    27 tokens\n",
      " 39%|โโโโ      | 1343/3487 [4:17:49<6:32:17, 10.98s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3628.44 ms /    15 tokens (  241.90 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.39 ms /     3 runs   (  881.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6274.64 ms /    18 tokens\n",
      " 39%|โโโโ      | 1344/3487 [4:17:55<5:41:48,  9.57s/it]Llama.generate: 307 prefix-match hit, remaining 186 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   34135.12 ms /   186 tokens (  183.52 ms per token,     5.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.35 ms /     3 runs   (  890.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   36809.13 ms /   189 tokens\n",
      " 39%|โโโโ      | 1345/3487 [4:18:32<10:33:29, 17.74s/it]Llama.generate: 306 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   30472.49 ms /   133 tokens (  229.12 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.12 ms /     3 runs   (  910.38 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   33206.71 ms /   136 tokens\n",
      " 39%|โโโโ      | 1346/3487 [4:19:05<13:18:49, 22.39s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13431.61 ms /    69 tokens (  194.66 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.33 ms /     3 runs   (  896.11 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16122.30 ms /    72 tokens\n",
      " 39%|โโโโ      | 1347/3487 [4:19:21<12:11:30, 20.51s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4209.87 ms /    20 tokens (  210.49 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2805.59 ms /     3 runs   (  935.20 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7017.92 ms /    23 tokens\n",
      " 39%|โโโโ      | 1348/3487 [4:19:28<9:46:58, 16.47s/it] Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3381.56 ms /    15 tokens (  225.44 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3869.84 ms /     3 runs   ( 1289.94 ms per token,     0.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    7253.97 ms /    18 tokens\n",
      " 39%|โโโโ      | 1349/3487 [4:19:35<8:08:21, 13.71s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9982.81 ms /    42 tokens (  237.69 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2796.57 ms /     3 runs   (  932.19 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12781.85 ms /    45 tokens\n",
      " 39%|โโโโ      | 1350/3487 [4:19:48<7:58:22, 13.43s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4313.90 ms /    21 tokens (  205.42 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.11 ms /     3 runs   (  891.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6990.95 ms /    24 tokens\n",
      " 39%|โโโโ      | 1351/3487 [4:19:55<6:49:27, 11.50s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2215.28 ms /     9 tokens (  246.14 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.37 ms /     3 runs   (  885.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4875.96 ms /    12 tokens\n",
      " 39%|โโโโ      | 1352/3487 [4:20:00<5:38:38,  9.52s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4546.40 ms /    22 tokens (  206.65 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.67 ms /     3 runs   (  895.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7234.96 ms /    25 tokens\n",
      " 39%|โโโโ      | 1353/3487 [4:20:07<5:14:14,  8.84s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9907.98 ms /    50 tokens (  198.16 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.79 ms /     3 runs   (  901.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   12616.24 ms /    53 tokens\n",
      " 39%|โโโโ      | 1354/3487 [4:20:20<5:54:30,  9.97s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5250.96 ms /    27 tokens (  194.48 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.04 ms /     3 runs   (  893.68 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7934.73 ms /    30 tokens\n",
      " 39%|โโโโ      | 1355/3487 [4:20:28<5:32:43,  9.36s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4595.14 ms /    22 tokens (  208.87 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.58 ms /     3 runs   (  903.86 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7309.55 ms /    25 tokens\n",
      " 39%|โโโโ      | 1356/3487 [4:20:35<5:10:47,  8.75s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2625.07 ms /    10 tokens (  262.51 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2751.11 ms /     3 runs   (  917.04 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5379.05 ms /    13 tokens\n",
      " 39%|โโโโ      | 1357/3487 [4:20:41<4:34:50,  7.74s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5426.43 ms /    26 tokens (  208.71 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.07 ms /     3 runs   (  908.36 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8154.28 ms /    29 tokens\n",
      " 39%|โโโโ      | 1358/3487 [4:20:49<4:39:11,  7.87s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1754.08 ms /     6 tokens (  292.35 ms per token,     3.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.10 ms /     3 runs   (  897.03 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4448.11 ms /     9 tokens\n",
      " 39%|โโโโ      | 1359/3487 [4:20:53<4:02:45,  6.84s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13021.59 ms /    66 tokens (  197.30 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.43 ms /     3 runs   (  880.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15664.79 ms /    69 tokens\n",
      " 39%|โโโโ      | 1360/3487 [4:21:09<5:36:32,  9.49s/it]Llama.generate: 309 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9722.74 ms /    48 tokens (  202.56 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.19 ms /     3 runs   (  883.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12374.19 ms /    51 tokens\n",
      " 39%|โโโโ      | 1361/3487 [4:21:21<6:07:04, 10.36s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4320.50 ms /    21 tokens (  205.74 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.18 ms /     3 runs   (  894.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7005.88 ms /    24 tokens\n",
      " 39%|โโโโ      | 1362/3487 [4:21:28<5:31:21,  9.36s/it]Llama.generate: 308 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12922.59 ms /    65 tokens (  198.81 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.27 ms /     3 runs   (  887.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15587.49 ms /    68 tokens\n",
      " 39%|โโโโ      | 1363/3487 [4:21:44<6:37:28, 11.23s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3035.35 ms /    14 tokens (  216.81 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.10 ms /     3 runs   (  884.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5691.45 ms /    17 tokens\n",
      " 39%|โโโโ      | 1364/3487 [4:21:50<5:38:35,  9.57s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4210.18 ms /    21 tokens (  200.48 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.16 ms /     3 runs   (  891.05 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6885.91 ms /    24 tokens\n",
      " 39%|โโโโ      | 1365/3487 [4:21:56<5:10:02,  8.77s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13699.52 ms /    72 tokens (  190.27 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.38 ms /     3 runs   (  884.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16355.45 ms /    75 tokens\n",
      " 39%|โโโโ      | 1366/3487 [4:22:13<6:30:29, 11.05s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4217.68 ms /    21 tokens (  200.84 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.73 ms /     3 runs   (  883.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6872.04 ms /    24 tokens\n",
      " 39%|โโโโ      | 1367/3487 [4:22:20<5:46:09,  9.80s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2931.61 ms /    13 tokens (  225.51 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2714.76 ms /     3 runs   (  904.92 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5649.40 ms /    16 tokens\n",
      " 39%|โโโโ      | 1368/3487 [4:22:25<5:02:09,  8.56s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2980.23 ms /    13 tokens (  229.25 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.83 ms /     3 runs   (  888.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5650.24 ms /    16 tokens\n",
      " 39%|โโโโ      | 1369/3487 [4:22:31<4:31:20,  7.69s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1703.96 ms /     6 tokens (  283.99 ms per token,     3.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.27 ms /     3 runs   (  883.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4357.68 ms /     9 tokens\n",
      " 39%|โโโโ      | 1370/3487 [4:22:35<3:56:03,  6.69s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10695.42 ms /    56 tokens (  190.99 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.93 ms /     3 runs   (  887.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13361.86 ms /    59 tokens\n",
      " 39%|โโโโ      | 1371/3487 [4:22:49<5:06:36,  8.69s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3631.41 ms /    17 tokens (  213.61 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.04 ms /     3 runs   (  885.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6289.53 ms /    20 tokens\n",
      " 39%|โโโโ      | 1372/3487 [4:22:55<4:41:07,  7.97s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5078.44 ms /    25 tokens (  203.14 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.76 ms /     3 runs   (  887.92 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7744.23 ms /    28 tokens\n",
      " 39%|โโโโ      | 1373/3487 [4:23:03<4:38:39,  7.91s/it]Llama.generate: 307 prefix-match hit, remaining 85 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15653.86 ms /    85 tokens (  184.16 ms per token,     5.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.16 ms /     3 runs   (  875.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18282.00 ms /    88 tokens\n",
      " 39%|โโโโ      | 1374/3487 [4:23:21<6:28:12, 11.02s/it]Llama.generate: 307 prefix-match hit, remaining 186 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   34616.18 ms /   186 tokens (  186.11 ms per token,     5.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.57 ms /     3 runs   (  907.19 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   37340.18 ms /   189 tokens\n",
      " 39%|โโโโ      | 1375/3487 [4:23:58<11:06:00, 18.92s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4202.18 ms /    21 tokens (  200.10 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.88 ms /     3 runs   (  905.63 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6921.63 ms /    24 tokens\n",
      " 39%|โโโโ      | 1376/3487 [4:24:05<8:59:10, 15.32s/it] Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4648.18 ms /    22 tokens (  211.28 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.20 ms /     3 runs   (  878.07 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7284.90 ms /    25 tokens\n",
      " 39%|โโโโ      | 1377/3487 [4:24:13<7:34:09, 12.91s/it]Llama.generate: 315 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3420.64 ms /    13 tokens (  263.13 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.00 ms /     3 runs   (  898.67 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6118.60 ms /    16 tokens\n",
      " 40%|โโโโ      | 1378/3487 [4:24:19<6:22:22, 10.88s/it]Llama.generate: 307 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14958.85 ms /    77 tokens (  194.27 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2840.28 ms /     3 runs   (  946.76 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   17802.73 ms /    80 tokens\n",
      " 40%|โโโโ      | 1379/3487 [4:24:37<7:35:15, 12.96s/it]Llama.generate: 307 prefix-match hit, remaining 114 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21617.56 ms /   114 tokens (  189.63 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.81 ms /     3 runs   (  882.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   24269.27 ms /   117 tokens\n",
      " 40%|โโโโ      | 1380/3487 [4:25:01<9:34:18, 16.35s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4130.19 ms /    19 tokens (  217.38 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.11 ms /     3 runs   (  881.37 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6776.85 ms /    22 tokens\n",
      " 40%|โโโโ      | 1381/3487 [4:25:08<7:53:16, 13.48s/it]Llama.generate: 308 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10194.15 ms /    54 tokens (  188.78 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.09 ms /     3 runs   (  881.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12840.22 ms /    57 tokens\n",
      " 40%|โโโโ      | 1382/3487 [4:25:21<7:46:21, 13.29s/it]Llama.generate: 306 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17344.81 ms /    93 tokens (  186.50 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.85 ms /     3 runs   (  880.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   20020.07 ms /    96 tokens\n",
      " 40%|โโโโ      | 1383/3487 [4:25:41<8:56:58, 15.31s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4156.75 ms /    21 tokens (  197.94 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.05 ms /     3 runs   (  892.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6835.53 ms /    24 tokens\n",
      " 40%|โโโโ      | 1384/3487 [4:25:47<7:27:39, 12.77s/it]Llama.generate: 307 prefix-match hit, remaining 88 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16313.42 ms /    88 tokens (  185.38 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.54 ms /     3 runs   (  875.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18941.84 ms /    91 tokens\n",
      " 40%|โโโโ      | 1385/3487 [4:26:06<8:32:22, 14.63s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4503.93 ms /    23 tokens (  195.82 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.35 ms /     3 runs   (  882.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7154.61 ms /    26 tokens\n",
      " 40%|โโโโ      | 1386/3487 [4:26:14<7:13:45, 12.39s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10381.70 ms /    56 tokens (  185.39 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.14 ms /     3 runs   (  880.72 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13026.48 ms /    59 tokens\n",
      " 40%|โโโโ      | 1387/3487 [4:26:27<7:20:21, 12.58s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7755.67 ms /    40 tokens (  193.89 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.45 ms /     3 runs   (  875.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10384.84 ms /    43 tokens\n",
      " 40%|โโโโ      | 1388/3487 [4:26:37<6:57:10, 11.93s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3707.31 ms /    18 tokens (  205.96 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.41 ms /     3 runs   (  877.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6341.90 ms /    21 tokens\n",
      " 40%|โโโโ      | 1389/3487 [4:26:43<5:58:28, 10.25s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5061.68 ms /    25 tokens (  202.47 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3525.75 ms /     4 runs   (  881.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8591.09 ms /    29 tokens\n",
      " 40%|โโโโ      | 1390/3487 [4:26:52<5:40:57,  9.76s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2543.04 ms /    11 tokens (  231.19 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.17 ms /     3 runs   (  896.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5233.98 ms /    14 tokens\n",
      " 40%|โโโโ      | 1391/3487 [4:26:57<4:53:29,  8.40s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7517.37 ms /    35 tokens (  214.78 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.56 ms /     3 runs   (  876.85 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10150.48 ms /    38 tokens\n",
      " 40%|โโโโ      | 1392/3487 [4:27:07<5:11:44,  8.93s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3743.31 ms /    18 tokens (  207.96 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.20 ms /     3 runs   (  883.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6394.97 ms /    21 tokens\n",
      " 40%|โโโโ      | 1393/3487 [4:27:14<4:45:10,  8.17s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7440.92 ms /    38 tokens (  195.81 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.58 ms /     3 runs   (  875.53 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10069.91 ms /    41 tokens\n",
      " 40%|โโโโ      | 1394/3487 [4:27:24<5:05:00,  8.74s/it]Llama.generate: 308 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4767.75 ms /    24 tokens (  198.66 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.49 ms /     3 runs   (  879.16 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7407.71 ms /    27 tokens\n",
      " 40%|โโโโ      | 1395/3487 [4:27:31<4:50:59,  8.35s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4561.11 ms /    23 tokens (  198.31 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.73 ms /     3 runs   (  877.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7197.17 ms /    26 tokens\n",
      " 40%|โโโโ      | 1396/3487 [4:27:38<4:38:55,  8.00s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3318.63 ms /    15 tokens (  221.24 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.61 ms /     3 runs   (  905.87 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6038.77 ms /    18 tokens\n",
      " 40%|โโโโ      | 1397/3487 [4:27:44<4:18:20,  7.42s/it]Llama.generate: 315 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3130.21 ms /    13 tokens (  240.79 ms per token,     4.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2765.53 ms /     3 runs   (  921.84 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5897.79 ms /    16 tokens\n",
      " 40%|โโโโ      | 1398/3487 [4:27:50<4:02:28,  6.96s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2618.37 ms /    10 tokens (  261.84 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.68 ms /     3 runs   (  893.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5302.90 ms /    13 tokens\n",
      " 40%|โโโโ      | 1399/3487 [4:27:56<3:45:06,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7408.20 ms /    37 tokens (  200.22 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.75 ms /     3 runs   (  887.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10073.48 ms /    40 tokens\n",
      " 40%|โโโโ      | 1400/3487 [4:28:06<4:22:42,  7.55s/it]Llama.generate: 306 prefix-match hit, remaining 128 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23526.81 ms /   128 tokens (  183.80 ms per token,     5.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.26 ms /     3 runs   (  880.75 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   26171.76 ms /   131 tokens\n",
      " 40%|โโโโ      | 1401/3487 [4:28:32<7:36:51, 13.14s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5751.51 ms /    29 tokens (  198.33 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.38 ms /     3 runs   (  898.79 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8450.32 ms /    32 tokens\n",
      " 40%|โโโโ      | 1402/3487 [4:28:40<6:47:49, 11.74s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4503.64 ms /    22 tokens (  204.71 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.45 ms /     3 runs   (  903.48 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7216.43 ms /    25 tokens\n",
      " 40%|โโโโ      | 1403/3487 [4:28:48<6:00:37, 10.38s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5273.40 ms /    26 tokens (  202.82 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.90 ms /     3 runs   (  876.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7905.07 ms /    29 tokens\n",
      " 40%|โโโโ      | 1404/3487 [4:28:56<5:34:45,  9.64s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2769.20 ms /    12 tokens (  230.77 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.85 ms /     3 runs   (  894.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5455.50 ms /    15 tokens\n",
      " 40%|โโโโ      | 1405/3487 [4:29:01<4:51:05,  8.39s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7642.59 ms /    39 tokens (  195.96 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.27 ms /     3 runs   (  885.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10300.54 ms /    42 tokens\n",
      " 40%|โโโโ      | 1406/3487 [4:29:11<5:10:55,  8.96s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3014.90 ms /    14 tokens (  215.35 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2823.54 ms /     3 runs   (  941.18 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5841.33 ms /    17 tokens\n",
      " 40%|โโโโ      | 1407/3487 [4:29:17<4:38:22,  8.03s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7207.34 ms /    35 tokens (  205.92 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.78 ms /     3 runs   (  872.26 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9826.47 ms /    38 tokens\n",
      " 40%|โโโโ      | 1408/3487 [4:29:27<4:56:59,  8.57s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4458.56 ms /    22 tokens (  202.66 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.46 ms /     3 runs   (  877.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7092.38 ms /    25 tokens\n",
      " 40%|โโโโ      | 1409/3487 [4:29:34<4:41:33,  8.13s/it]Llama.generate: 306 prefix-match hit, remaining 113 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21010.58 ms /   113 tokens (  185.93 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4060.43 ms /     3 runs   ( 1353.48 ms per token,     0.74 tokens per second)\n",
      "llama_perf_context_print:       total time =   25074.05 ms /   116 tokens\n",
      " 40%|โโโโ      | 1410/3487 [4:29:59<7:37:29, 13.22s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6821.01 ms /    10 tokens (  682.10 ms per token,     1.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =   18325.30 ms /     3 runs   ( 6108.43 ms per token,     0.16 tokens per second)\n",
      "llama_perf_context_print:       total time =   25156.72 ms /    13 tokens\n",
      " 40%|โโโโ      | 1411/3487 [4:30:24<9:41:27, 16.81s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4162.59 ms /    14 tokens (  297.33 ms per token,     3.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3887.85 ms /     3 runs   ( 1295.95 ms per token,     0.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    8054.68 ms /    17 tokens\n",
      " 40%|โโโโ      | 1412/3487 [4:30:32<8:10:43, 14.19s/it]Llama.generate: 307 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15031.42 ms /    68 tokens (  221.05 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.82 ms /     3 runs   (  900.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   17736.03 ms /    71 tokens\n",
      " 41%|โโโโ      | 1413/3487 [4:30:50<8:47:21, 15.26s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8002.83 ms /    40 tokens (  200.07 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.87 ms /     3 runs   (  910.62 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   10736.94 ms /    43 tokens\n",
      " 41%|โโโโ      | 1414/3487 [4:31:01<8:00:21, 13.90s/it]Llama.generate: 309 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7591.76 ms /    37 tokens (  205.18 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.47 ms /     3 runs   (  893.82 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10276.14 ms /    40 tokens\n",
      " 41%|โโโโ      | 1415/3487 [4:31:11<7:22:38, 12.82s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10375.07 ms /    54 tokens (  192.13 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.79 ms /     3 runs   (  892.93 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13056.79 ms /    57 tokens\n",
      " 41%|โโโโ      | 1416/3487 [4:31:24<7:25:01, 12.89s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7219.20 ms /    34 tokens (  212.33 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.10 ms /     3 runs   (  886.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9880.17 ms /    37 tokens\n",
      " 41%|โโโโ      | 1417/3487 [4:31:34<6:53:44, 11.99s/it]Llama.generate: 316 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9249.46 ms /    49 tokens (  188.76 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.84 ms /     3 runs   (  873.28 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11871.61 ms /    52 tokens\n",
      " 41%|โโโโ      | 1418/3487 [4:31:46<6:52:21, 11.96s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6128.31 ms /    32 tokens (  191.51 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.64 ms /     3 runs   (  882.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8779.18 ms /    35 tokens\n",
      " 41%|โโโโ      | 1419/3487 [4:31:55<6:19:23, 11.01s/it]Llama.generate: 306 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15101.02 ms /    82 tokens (  184.16 ms per token,     5.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.72 ms /     3 runs   (  881.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17748.51 ms /    85 tokens\n",
      " 41%|โโโโ      | 1420/3487 [4:32:13<7:28:59, 13.03s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3119.64 ms /    15 tokens (  207.98 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.12 ms /     3 runs   (  886.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5782.10 ms /    18 tokens\n",
      " 41%|โโโโ      | 1421/3487 [4:32:18<6:13:57, 10.86s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9845.65 ms /    42 tokens (  234.42 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2867.75 ms /     3 runs   (  955.92 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   12715.59 ms /    45 tokens\n",
      " 41%|โโโโ      | 1422/3487 [4:32:31<6:33:00, 11.42s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2550.97 ms /    11 tokens (  231.91 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.49 ms /     3 runs   (  884.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5205.60 ms /    14 tokens\n",
      " 41%|โโโโ      | 1423/3487 [4:32:36<5:28:46,  9.56s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1542.02 ms /     6 tokens (  257.00 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2775.56 ms /     3 runs   (  925.19 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    4319.77 ms /     9 tokens\n",
      " 41%|โโโโ      | 1424/3487 [4:32:41<4:34:41,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4254.98 ms /    21 tokens (  202.62 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.77 ms /     3 runs   (  874.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6882.27 ms /    24 tokens\n",
      " 41%|โโโโ      | 1425/3487 [4:32:48<4:23:14,  7.66s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4702.08 ms /    24 tokens (  195.92 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.22 ms /     3 runs   (  878.41 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7339.55 ms /    27 tokens\n",
      " 41%|โโโโ      | 1426/3487 [4:32:55<4:19:54,  7.57s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4221.19 ms /    21 tokens (  201.01 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.16 ms /     3 runs   (  877.05 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6855.22 ms /    24 tokens\n",
      " 41%|โโโโ      | 1427/3487 [4:33:02<4:12:31,  7.36s/it]Llama.generate: 314 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1336.02 ms /     4 tokens (  334.00 ms per token,     2.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2784.72 ms /     3 runs   (  928.24 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    4123.38 ms /     7 tokens\n",
      " 41%|โโโโ      | 1428/3487 [4:33:06<3:39:13,  6.39s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6136.26 ms /    31 tokens (  197.94 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.37 ms /     3 runs   (  895.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8825.89 ms /    34 tokens\n",
      " 41%|โโโโ      | 1429/3487 [4:33:15<4:04:17,  7.12s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2055.57 ms /     8 tokens (  256.95 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.63 ms /     3 runs   (  881.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4702.80 ms /    11 tokens\n",
      " 41%|โโโโ      | 1430/3487 [4:33:19<3:39:23,  6.40s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4186.06 ms /    20 tokens (  209.30 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.07 ms /     3 runs   (  881.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6833.44 ms /    23 tokens\n",
      " 41%|โโโโ      | 1431/3487 [4:33:26<3:43:49,  6.53s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5166.11 ms /    26 tokens (  198.70 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.50 ms /     3 runs   (  879.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7808.05 ms /    29 tokens\n",
      " 41%|โโโโ      | 1432/3487 [4:33:34<3:56:54,  6.92s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5224.74 ms /    27 tokens (  193.51 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.70 ms /     3 runs   (  882.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7875.04 ms /    30 tokens\n",
      " 41%|โโโโ      | 1433/3487 [4:33:42<4:06:43,  7.21s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4161.04 ms /    21 tokens (  198.14 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.92 ms /     3 runs   (  879.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6802.21 ms /    24 tokens\n",
      " 41%|โโโโ      | 1434/3487 [4:33:49<4:02:50,  7.10s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2028.96 ms /     8 tokens (  253.62 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.67 ms /     3 runs   (  887.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4694.02 ms /    11 tokens\n",
      " 41%|โโโโ      | 1435/3487 [4:33:54<3:38:10,  6.38s/it]Llama.generate: 306 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11289.79 ms /    61 tokens (  185.08 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.16 ms /     3 runs   (  882.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13940.41 ms /    64 tokens\n",
      " 41%|โโโโ      | 1436/3487 [4:34:07<4:55:39,  8.65s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4429.46 ms /    22 tokens (  201.34 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.51 ms /     3 runs   (  884.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7085.44 ms /    25 tokens\n",
      " 41%|โโโโ      | 1437/3487 [4:34:15<4:39:35,  8.18s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4426.52 ms /    19 tokens (  232.97 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.64 ms /     3 runs   (  907.55 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7151.51 ms /    22 tokens\n",
      " 41%|โโโโ      | 1438/3487 [4:34:22<4:28:58,  7.88s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5854.33 ms /    29 tokens (  201.87 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.93 ms /     3 runs   (  882.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8504.38 ms /    32 tokens\n",
      " 41%|โโโโโ     | 1439/3487 [4:34:30<4:35:20,  8.07s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4386.20 ms /    21 tokens (  208.87 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2827.27 ms /     3 runs   (  942.42 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7216.03 ms /    24 tokens\n",
      " 41%|โโโโโ     | 1440/3487 [4:34:37<4:26:35,  7.81s/it]Llama.generate: 307 prefix-match hit, remaining 126 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23104.46 ms /   126 tokens (  183.37 ms per token,     5.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.70 ms /     3 runs   (  880.23 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   25748.27 ms /   129 tokens\n",
      " 41%|โโโโโ     | 1441/3487 [4:35:03<7:30:21, 13.21s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9034.21 ms /    48 tokens (  188.21 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.74 ms /     3 runs   (  875.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11662.59 ms /    51 tokens\n",
      " 41%|โโโโโ     | 1442/3487 [4:35:15<7:14:24, 12.75s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1992.99 ms /     7 tokens (  284.71 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2826.56 ms /     3 runs   (  942.19 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4821.86 ms /    10 tokens\n",
      " 41%|โโโโโ     | 1443/3487 [4:35:20<5:53:18, 10.37s/it]Llama.generate: 306 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13141.22 ms /    70 tokens (  187.73 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.07 ms /     3 runs   (  880.69 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15785.87 ms /    73 tokens\n",
      " 41%|โโโโโ     | 1444/3487 [4:35:36<6:48:31, 12.00s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4788.01 ms /    22 tokens (  217.64 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.31 ms /     3 runs   (  908.10 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7514.93 ms /    25 tokens\n",
      " 41%|โโโโโ     | 1445/3487 [4:35:43<6:02:37, 10.66s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7075.41 ms /    33 tokens (  214.41 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.74 ms /     3 runs   (  884.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9731.22 ms /    36 tokens\n",
      " 41%|โโโโโ     | 1446/3487 [4:35:53<5:53:05, 10.38s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2949.18 ms /    13 tokens (  226.86 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.00 ms /     3 runs   (  883.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5602.45 ms /    16 tokens\n",
      " 41%|โโโโโ     | 1447/3487 [4:35:58<5:04:16,  8.95s/it]Llama.generate: 306 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13424.12 ms /    71 tokens (  189.07 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.44 ms /     3 runs   (  880.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16068.59 ms /    74 tokens\n",
      " 42%|โโโโโ     | 1448/3487 [4:36:15<6:16:47, 11.09s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10507.24 ms /    56 tokens (  187.63 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2834.26 ms /     3 runs   (  944.75 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   13344.32 ms /    59 tokens\n",
      " 42%|โโโโโ     | 1449/3487 [4:36:28<6:39:42, 11.77s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11425.60 ms /    62 tokens (  184.28 ms per token,     5.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.59 ms /     3 runs   (  874.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14052.60 ms /    65 tokens\n",
      " 42%|โโโโโ     | 1450/3487 [4:36:42<7:02:52, 12.46s/it]Llama.generate: 308 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14705.48 ms /    80 tokens (  183.82 ms per token,     5.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.91 ms /     3 runs   (  883.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17358.22 ms /    83 tokens\n",
      " 42%|โโโโโ     | 1451/3487 [4:36:59<7:52:39, 13.93s/it]Llama.generate: 308 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8256.45 ms /    43 tokens (  192.01 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.21 ms /     3 runs   (  876.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10888.17 ms /    46 tokens\n",
      " 42%|โโโโโ     | 1452/3487 [4:37:10<7:21:34, 13.02s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7876.73 ms /    41 tokens (  192.12 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.38 ms /     3 runs   (  875.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10505.48 ms /    44 tokens\n",
      " 42%|โโโโโ     | 1453/3487 [4:37:21<6:55:51, 12.27s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2809.24 ms /    10 tokens (  280.92 ms per token,     3.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.60 ms /     3 runs   (  896.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5500.40 ms /    13 tokens\n",
      " 42%|โโโโโ     | 1454/3487 [4:37:26<5:46:57, 10.24s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8234.06 ms /    43 tokens (  191.49 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.50 ms /     3 runs   (  873.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10857.83 ms /    46 tokens\n",
      " 42%|โโโโโ     | 1455/3487 [4:37:37<5:53:09, 10.43s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8213.52 ms /    43 tokens (  191.01 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.20 ms /     3 runs   (  897.73 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10908.91 ms /    46 tokens\n",
      " 42%|โโโโโ     | 1456/3487 [4:37:48<5:57:56, 10.57s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1910.63 ms /     7 tokens (  272.95 ms per token,     3.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.88 ms /     3 runs   (  898.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4609.70 ms /    10 tokens\n",
      " 42%|โโโโโ     | 1457/3487 [4:37:53<4:57:18,  8.79s/it]Llama.generate: 307 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14321.93 ms /    75 tokens (  190.96 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.22 ms /     3 runs   (  873.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16945.49 ms /    78 tokens\n",
      " 42%|โโโโโ     | 1458/3487 [4:38:10<6:20:01, 11.24s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8245.89 ms /    43 tokens (  191.76 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.70 ms /     3 runs   (  885.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10905.92 ms /    46 tokens\n",
      " 42%|โโโโโ     | 1459/3487 [4:38:20<6:16:33, 11.14s/it]Llama.generate: 308 prefix-match hit, remaining 170 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   31021.77 ms /   170 tokens (  182.48 ms per token,     5.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.00 ms /     3 runs   (  889.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   33693.17 ms /   173 tokens\n",
      " 42%|โโโโโ     | 1460/3487 [4:38:54<10:05:02, 17.91s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6152.07 ms /    32 tokens (  192.25 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.45 ms /     3 runs   (  881.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8797.98 ms /    35 tokens\n",
      " 42%|โโโโโ     | 1461/3487 [4:39:03<8:32:31, 15.18s/it] Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9696.49 ms /    51 tokens (  190.13 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.35 ms /     3 runs   (  882.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12347.86 ms /    54 tokens\n",
      " 42%|โโโโโ     | 1462/3487 [4:39:15<8:03:40, 14.33s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8658.48 ms /    46 tokens (  188.23 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3511.42 ms /     4 runs   (  877.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12204.21 ms /    50 tokens\n",
      " 42%|โโโโโ     | 1463/3487 [4:39:28<7:41:58, 13.70s/it]Llama.generate: 307 prefix-match hit, remaining 117 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21411.65 ms /   117 tokens (  183.01 ms per token,     5.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.95 ms /     3 runs   (  883.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   24065.84 ms /   120 tokens\n",
      " 42%|โโโโโ     | 1464/3487 [4:39:52<9:26:43, 16.81s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7602.45 ms /    39 tokens (  194.93 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.55 ms /     3 runs   (  881.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10249.60 ms /    42 tokens\n",
      " 42%|โโโโโ     | 1465/3487 [4:40:02<8:20:13, 14.84s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5019.08 ms /    25 tokens (  200.76 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.47 ms /     3 runs   (  882.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7670.73 ms /    28 tokens\n",
      " 42%|โโโโโ     | 1466/3487 [4:40:10<7:07:35, 12.69s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4214.45 ms /    21 tokens (  200.69 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.35 ms /     3 runs   (  887.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6877.92 ms /    24 tokens\n",
      " 42%|โโโโโ     | 1467/3487 [4:40:16<6:08:42, 10.95s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5111.36 ms /    24 tokens (  212.97 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.01 ms /     3 runs   (  892.34 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7790.56 ms /    27 tokens\n",
      " 42%|โโโโโ     | 1468/3487 [4:40:24<5:36:42, 10.01s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3980.68 ms /    18 tokens (  221.15 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.14 ms /     3 runs   (  907.38 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6705.55 ms /    21 tokens\n",
      " 42%|โโโโโ     | 1469/3487 [4:40:31<5:03:20,  9.02s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4631.88 ms /    23 tokens (  201.39 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.93 ms /     3 runs   (  903.31 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7343.59 ms /    26 tokens\n",
      " 42%|โโโโโ     | 1470/3487 [4:40:38<4:46:22,  8.52s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5293.88 ms /    25 tokens (  211.76 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.24 ms /     3 runs   (  888.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7962.37 ms /    28 tokens\n",
      " 42%|โโโโโ     | 1471/3487 [4:40:46<4:40:42,  8.35s/it]Llama.generate: 306 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16704.60 ms /    90 tokens (  185.61 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.69 ms /     3 runs   (  892.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   19386.21 ms /    93 tokens\n",
      " 42%|โโโโโ     | 1472/3487 [4:41:06<6:31:47, 11.67s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7186.84 ms /    36 tokens (  199.63 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.49 ms /     3 runs   (  878.50 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9824.82 ms /    39 tokens\n",
      " 42%|โโโโโ     | 1473/3487 [4:41:16<6:13:08, 11.12s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7034.37 ms /    35 tokens (  200.98 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.76 ms /     3 runs   (  880.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9679.95 ms /    38 tokens\n",
      " 42%|โโโโโ     | 1474/3487 [4:41:25<5:58:34, 10.69s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2670.48 ms /    12 tokens (  222.54 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.99 ms /     3 runs   (  888.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5337.11 ms /    15 tokens\n",
      " 42%|โโโโโ     | 1475/3487 [4:41:31<5:04:38,  9.08s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4061.23 ms /    19 tokens (  213.75 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.29 ms /     3 runs   (  886.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6722.21 ms /    22 tokens\n",
      " 42%|โโโโโ     | 1476/3487 [4:41:37<4:40:50,  8.38s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8010.07 ms /    41 tokens (  195.37 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.60 ms /     3 runs   (  902.87 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10722.06 ms /    44 tokens\n",
      " 42%|โโโโโ     | 1477/3487 [4:41:48<5:04:21,  9.09s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4826.90 ms /    23 tokens (  209.87 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2759.21 ms /     3 runs   (  919.74 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7588.72 ms /    26 tokens\n",
      " 42%|โโโโโ     | 1478/3487 [4:41:56<4:49:16,  8.64s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3995.02 ms /    19 tokens (  210.26 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.91 ms /     3 runs   (  880.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6638.47 ms /    22 tokens\n",
      " 42%|โโโโโ     | 1479/3487 [4:42:02<4:29:07,  8.04s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7917.17 ms /    40 tokens (  197.93 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.81 ms /     3 runs   (  880.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10560.33 ms /    43 tokens\n",
      " 42%|โโโโโ     | 1480/3487 [4:42:13<4:54:21,  8.80s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3098.84 ms /    14 tokens (  221.35 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.32 ms /     3 runs   (  876.11 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5729.68 ms /    17 tokens\n",
      " 42%|โโโโโ     | 1481/3487 [4:42:19<4:23:30,  7.88s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7585.05 ms /    37 tokens (  205.00 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.08 ms /     3 runs   (  871.69 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10202.43 ms /    40 tokens\n",
      " 43%|โโโโโ     | 1482/3487 [4:42:29<4:46:43,  8.58s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7268.86 ms /    37 tokens (  196.46 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.45 ms /     3 runs   (  883.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9921.11 ms /    40 tokens\n",
      " 43%|โโโโโ     | 1483/3487 [4:42:39<5:00:05,  8.98s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6957.93 ms /    33 tokens (  210.85 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.73 ms /     3 runs   (  884.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9615.71 ms /    36 tokens\n",
      " 43%|โโโโโ     | 1484/3487 [4:42:48<5:06:21,  9.18s/it]Llama.generate: 306 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12680.68 ms /    67 tokens (  189.26 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.48 ms /     3 runs   (  883.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15332.59 ms /    70 tokens\n",
      " 43%|โโโโโ     | 1485/3487 [4:43:04<6:07:53, 11.03s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8756.33 ms /    47 tokens (  186.30 ms per token,     5.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.90 ms /     3 runs   (  882.97 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11407.68 ms /    50 tokens\n",
      " 43%|โโโโโ     | 1486/3487 [4:43:15<6:11:36, 11.14s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7174.47 ms /    37 tokens (  193.90 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.25 ms /     3 runs   (  880.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9817.19 ms /    40 tokens\n",
      " 43%|โโโโโ     | 1487/3487 [4:43:25<5:58:16, 10.75s/it]Llama.generate: 311 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13911.69 ms /    75 tokens (  185.49 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.94 ms /     3 runs   (  873.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16534.96 ms /    78 tokens\n",
      " 43%|โโโโโ     | 1488/3487 [4:43:41<6:56:00, 12.49s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8680.81 ms /    47 tokens (  184.70 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.85 ms /     3 runs   (  883.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11334.06 ms /    50 tokens\n",
      " 43%|โโโโโ     | 1489/3487 [4:43:53<6:44:22, 12.14s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4440.64 ms /    22 tokens (  201.85 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.68 ms /     3 runs   (  899.56 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7141.61 ms /    25 tokens\n",
      " 43%|โโโโโ     | 1490/3487 [4:44:00<5:54:18, 10.65s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7010.47 ms /    35 tokens (  200.30 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.89 ms /     3 runs   (  877.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9645.36 ms /    38 tokens\n",
      " 43%|โโโโโ     | 1491/3487 [4:44:10<5:44:13, 10.35s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10375.88 ms /    50 tokens (  207.52 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.61 ms /     3 runs   (  884.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13032.50 ms /    53 tokens\n",
      " 43%|โโโโโ     | 1492/3487 [4:44:23<6:10:53, 11.15s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7793.44 ms /    36 tokens (  216.48 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.86 ms /     3 runs   (  901.62 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10500.76 ms /    39 tokens\n",
      " 43%|โโโโโ     | 1493/3487 [4:44:33<6:04:15, 10.96s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11027.02 ms /    56 tokens (  196.91 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.87 ms /     3 runs   (  886.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13689.35 ms /    59 tokens\n",
      " 43%|โโโโโ     | 1494/3487 [4:44:47<6:31:20, 11.78s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9231.84 ms /    49 tokens (  188.40 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.24 ms /     3 runs   (  884.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11887.38 ms /    52 tokens\n",
      " 43%|โโโโโ     | 1495/3487 [4:44:59<6:32:17, 11.82s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5169.92 ms /    24 tokens (  215.41 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2734.03 ms /     3 runs   (  911.34 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7906.21 ms /    27 tokens\n",
      " 43%|โโโโโ     | 1496/3487 [4:45:07<5:53:15, 10.65s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4863.06 ms /    24 tokens (  202.63 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.73 ms /     3 runs   (  903.91 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7576.70 ms /    27 tokens\n",
      " 43%|โโโโโ     | 1497/3487 [4:45:14<5:22:37,  9.73s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18597.64 ms /    74 tokens (  251.32 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3043.19 ms /     3 runs   ( 1014.40 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   21643.29 ms /    77 tokens\n",
      " 43%|โโโโโ     | 1498/3487 [4:45:36<7:21:02, 13.30s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13613.45 ms /    67 tokens (  203.19 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.05 ms /     3 runs   (  880.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16259.45 ms /    70 tokens\n",
      " 43%|โโโโโ     | 1499/3487 [4:45:52<7:50:17, 14.19s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13181.10 ms /    69 tokens (  191.03 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.80 ms /     3 runs   (  886.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15843.57 ms /    72 tokens\n",
      " 43%|โโโโโ     | 1500/3487 [4:46:08<8:06:32, 14.69s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7072.74 ms /    35 tokens (  202.08 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.60 ms /     3 runs   (  876.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9703.69 ms /    38 tokens\n",
      " 43%|โโโโโ     | 1501/3487 [4:46:18<7:16:50, 13.20s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10710.75 ms /    57 tokens (  187.91 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.44 ms /     3 runs   (  915.81 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   13462.12 ms /    60 tokens\n",
      " 43%|โโโโโ     | 1502/3487 [4:46:31<7:19:19, 13.28s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6156.70 ms /    29 tokens (  212.30 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2901.58 ms /     3 runs   (  967.19 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    9061.87 ms /    32 tokens\n",
      " 43%|โโโโโ     | 1503/3487 [4:46:40<6:37:23, 12.02s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5234.56 ms /    24 tokens (  218.11 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2851.72 ms /     3 runs   (  950.57 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    8088.84 ms /    27 tokens\n",
      " 43%|โโโโโ     | 1504/3487 [4:46:48<5:58:19, 10.84s/it]Llama.generate: 308 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6188.50 ms /    29 tokens (  213.40 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2738.69 ms /     3 runs   (  912.90 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8929.56 ms /    32 tokens\n",
      " 43%|โโโโโ     | 1505/3487 [4:46:57<5:39:18, 10.27s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7846.66 ms /    39 tokens (  201.20 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.80 ms /     3 runs   (  882.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10501.70 ms /    42 tokens\n",
      " 43%|โโโโโ     | 1506/3487 [4:47:08<5:41:40, 10.35s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2546.82 ms /    11 tokens (  231.53 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.20 ms /     3 runs   (  894.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5232.15 ms /    14 tokens\n",
      " 43%|โโโโโ     | 1507/3487 [4:47:13<4:50:56,  8.82s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4204.46 ms /    21 tokens (  200.21 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.31 ms /     3 runs   (  891.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6880.79 ms /    24 tokens\n",
      " 43%|โโโโโ     | 1508/3487 [4:47:20<4:31:42,  8.24s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9757.23 ms /    51 tokens (  191.32 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.23 ms /     3 runs   (  886.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12419.57 ms /    54 tokens\n",
      " 43%|โโโโโ     | 1509/3487 [4:47:32<5:13:00,  9.49s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9521.40 ms /    47 tokens (  202.58 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.01 ms /     3 runs   (  881.00 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12167.09 ms /    50 tokens\n",
      " 43%|โโโโโ     | 1510/3487 [4:47:45<5:39:21, 10.30s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2190.19 ms /     9 tokens (  243.35 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.45 ms /     3 runs   (  889.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4860.03 ms /    12 tokens\n",
      " 43%|โโโโโ     | 1511/3487 [4:47:49<4:45:31,  8.67s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8868.40 ms /    46 tokens (  192.79 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.16 ms /     3 runs   (  894.72 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11555.53 ms /    49 tokens\n",
      " 43%|โโโโโ     | 1512/3487 [4:48:01<5:13:57,  9.54s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8306.72 ms /    41 tokens (  202.60 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3453.51 ms /     3 runs   ( 1151.17 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =   11762.85 ms /    44 tokens\n",
      " 43%|โโโโโ     | 1513/3487 [4:48:13<5:35:51, 10.21s/it]Llama.generate: 307 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18061.24 ms /    73 tokens (  247.41 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2751.51 ms /     3 runs   (  917.17 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   20815.46 ms /    76 tokens\n",
      " 43%|โโโโโ     | 1514/3487 [4:48:34<7:20:25, 13.39s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9438.59 ms /    48 tokens (  196.64 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.03 ms /     3 runs   (  896.01 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12129.80 ms /    51 tokens\n",
      " 43%|โโโโโ     | 1515/3487 [4:48:46<7:07:48, 13.02s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7456.23 ms /    36 tokens (  207.12 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.74 ms /     3 runs   (  885.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10116.77 ms /    39 tokens\n",
      " 43%|โโโโโ     | 1516/3487 [4:48:56<6:39:04, 12.15s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3284.73 ms /    15 tokens (  218.98 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.67 ms /     3 runs   (  895.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5972.68 ms /    18 tokens\n",
      " 44%|โโโโโ     | 1517/3487 [4:49:02<5:38:08, 10.30s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7479.22 ms /    36 tokens (  207.76 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.72 ms /     3 runs   (  884.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10134.40 ms /    39 tokens\n",
      " 44%|โโโโโ     | 1518/3487 [4:49:12<5:36:26, 10.25s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7294.24 ms /    37 tokens (  197.14 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4395.36 ms /     3 runs   ( 1465.12 ms per token,     0.68 tokens per second)\n",
      "llama_perf_context_print:       total time =   11692.48 ms /    40 tokens\n",
      " 44%|โโโโโ     | 1519/3487 [4:49:24<5:50:32, 10.69s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9230.19 ms /    38 tokens (  242.90 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2940.26 ms /     3 runs   (  980.09 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =   12174.50 ms /    41 tokens\n",
      " 44%|โโโโโ     | 1520/3487 [4:49:36<6:05:06, 11.14s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6147.87 ms /    28 tokens (  219.57 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2785.77 ms /     3 runs   (  928.59 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8936.16 ms /    31 tokens\n",
      " 44%|โโโโโ     | 1521/3487 [4:49:45<5:43:22, 10.48s/it]Llama.generate: 307 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13515.13 ms /    68 tokens (  198.75 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.55 ms /     3 runs   (  886.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16178.18 ms /    71 tokens\n",
      " 44%|โโโโโ     | 1522/3487 [4:50:01<6:39:16, 12.19s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9366.64 ms /    45 tokens (  208.15 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2760.32 ms /     3 runs   (  920.11 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   12129.11 ms /    48 tokens\n",
      " 44%|โโโโโ     | 1523/3487 [4:50:13<6:38:32, 12.18s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7179.39 ms /    33 tokens (  217.56 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.92 ms /     3 runs   (  899.31 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9879.88 ms /    36 tokens\n",
      " 44%|โโโโโ     | 1524/3487 [4:50:23<6:15:53, 11.49s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2507.92 ms /     8 tokens (  313.49 ms per token,     3.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.95 ms /     3 runs   (  891.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5186.68 ms /    11 tokens\n",
      " 44%|โโโโโ     | 1525/3487 [4:50:28<5:13:56,  9.60s/it]Llama.generate: 307 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13270.64 ms /    68 tokens (  195.16 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.80 ms /     3 runs   (  886.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15933.29 ms /    71 tokens\n",
      " 44%|โโโโโ     | 1526/3487 [4:50:44<6:15:57, 11.50s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9619.42 ms /    50 tokens (  192.39 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.78 ms /     3 runs   (  886.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12281.54 ms /    53 tokens\n",
      " 44%|โโโโโ     | 1527/3487 [4:50:56<6:23:29, 11.74s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8931.84 ms /    45 tokens (  198.49 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.31 ms /     3 runs   (  885.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11589.34 ms /    48 tokens\n",
      " 44%|โโโโโ     | 1528/3487 [4:51:08<6:21:53, 11.70s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5220.72 ms /    27 tokens (  193.36 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.70 ms /     3 runs   (  895.23 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7908.78 ms /    30 tokens\n",
      " 44%|โโโโโ     | 1529/3487 [4:51:16<5:44:41, 10.56s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7279.37 ms /    35 tokens (  207.98 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.16 ms /     3 runs   (  895.39 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9968.72 ms /    38 tokens\n",
      " 44%|โโโโโ     | 1530/3487 [4:51:26<5:38:48, 10.39s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13044.25 ms /    65 tokens (  200.68 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2787.99 ms /     3 runs   (  929.33 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   15835.18 ms /    68 tokens\n",
      " 44%|โโโโโ     | 1531/3487 [4:51:42<6:31:59, 12.02s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4635.12 ms /    21 tokens (  220.72 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.09 ms /     3 runs   (  899.36 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7335.82 ms /    24 tokens\n",
      " 44%|โโโโโ     | 1532/3487 [4:51:49<5:46:02, 10.62s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8998.02 ms /    46 tokens (  195.61 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2880.51 ms /     3 runs   (  960.17 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   11881.84 ms /    49 tokens\n",
      " 44%|โโโโโ     | 1533/3487 [4:52:01<5:58:16, 11.00s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3979.90 ms /    19 tokens (  209.47 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2758.99 ms /     3 runs   (  919.66 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6741.57 ms /    22 tokens\n",
      " 44%|โโโโโ     | 1534/3487 [4:52:08<5:16:35,  9.73s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11338.99 ms /    60 tokens (  188.98 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.33 ms /     3 runs   (  881.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13986.16 ms /    63 tokens\n",
      " 44%|โโโโโ     | 1535/3487 [4:52:22<5:58:04, 11.01s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7123.18 ms /    34 tokens (  209.51 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.39 ms /     3 runs   (  890.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9797.14 ms /    37 tokens\n",
      " 44%|โโโโโ     | 1536/3487 [4:52:32<5:46:10, 10.65s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3716.97 ms /    18 tokens (  206.50 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.95 ms /     3 runs   (  887.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6383.38 ms /    21 tokens\n",
      " 44%|โโโโโ     | 1537/3487 [4:52:38<5:04:32,  9.37s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7449.58 ms /    38 tokens (  196.04 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.95 ms /     3 runs   (  881.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10097.03 ms /    41 tokens\n",
      " 44%|โโโโโ     | 1538/3487 [4:52:48<5:11:31,  9.59s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5787.93 ms /    30 tokens (  192.93 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.26 ms /     3 runs   (  887.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8453.48 ms /    33 tokens\n",
      " 44%|โโโโโ     | 1539/3487 [4:52:57<5:00:21,  9.25s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4487.35 ms /    19 tokens (  236.18 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.97 ms /     3 runs   (  902.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7198.67 ms /    22 tokens\n",
      " 44%|โโโโโ     | 1540/3487 [4:53:04<4:40:17,  8.64s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3483.00 ms /    16 tokens (  217.69 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2741.72 ms /     3 runs   (  913.91 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6226.84 ms /    19 tokens\n",
      " 44%|โโโโโ     | 1541/3487 [4:53:10<4:16:45,  7.92s/it]Llama.generate: 308 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7546.71 ms /    38 tokens (  198.60 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.00 ms /     3 runs   (  883.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10199.72 ms /    41 tokens\n",
      " 44%|โโโโโ     | 1542/3487 [4:53:20<4:38:54,  8.60s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9012.97 ms /    47 tokens (  191.77 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.88 ms /     3 runs   (  894.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11699.88 ms /    50 tokens\n",
      " 44%|โโโโโ     | 1543/3487 [4:53:32<5:08:56,  9.54s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3471.91 ms /    16 tokens (  216.99 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.74 ms /     3 runs   (  895.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6161.37 ms /    19 tokens\n",
      " 44%|โโโโโ     | 1544/3487 [4:53:38<4:36:04,  8.53s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5558.03 ms /    28 tokens (  198.50 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.62 ms /     3 runs   (  903.88 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8272.15 ms /    31 tokens\n",
      " 44%|โโโโโ     | 1545/3487 [4:53:46<4:33:32,  8.45s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4877.00 ms /    24 tokens (  203.21 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.95 ms /     3 runs   (  906.98 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7600.18 ms /    27 tokens\n",
      " 44%|โโโโโ     | 1546/3487 [4:53:54<4:25:13,  8.20s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7074.98 ms /    34 tokens (  208.09 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.46 ms /     3 runs   (  889.82 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9747.00 ms /    37 tokens\n",
      " 44%|โโโโโ     | 1547/3487 [4:54:04<4:40:12,  8.67s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3274.64 ms /    15 tokens (  218.31 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.28 ms /     3 runs   (  880.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5918.82 ms /    18 tokens\n",
      " 44%|โโโโโ     | 1548/3487 [4:54:10<4:13:30,  7.84s/it]Llama.generate: 314 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4244.21 ms /    21 tokens (  202.11 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.98 ms /     3 runs   (  887.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6910.79 ms /    24 tokens\n",
      " 44%|โโโโโ     | 1549/3487 [4:54:17<4:04:24,  7.57s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12926.32 ms /    67 tokens (  192.93 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.53 ms /     3 runs   (  889.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15598.51 ms /    70 tokens\n",
      " 44%|โโโโโ     | 1550/3487 [4:54:32<5:22:08,  9.98s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5956.48 ms /    30 tokens (  198.55 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.99 ms /     3 runs   (  902.00 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8664.84 ms /    33 tokens\n",
      " 44%|โโโโโ     | 1551/3487 [4:54:41<5:09:19,  9.59s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8236.36 ms /    42 tokens (  196.10 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.44 ms /     3 runs   (  882.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10886.89 ms /    45 tokens\n",
      " 45%|โโโโโ     | 1552/3487 [4:54:52<5:21:50,  9.98s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5338.38 ms /    27 tokens (  197.72 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.68 ms /     3 runs   (  888.23 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8005.69 ms /    30 tokens\n",
      " 45%|โโโโโ     | 1553/3487 [4:55:00<5:02:39,  9.39s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7431.31 ms /    35 tokens (  212.32 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.41 ms /     3 runs   (  893.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10112.80 ms /    38 tokens\n",
      " 45%|โโโโโ     | 1554/3487 [4:55:10<5:09:33,  9.61s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3530.58 ms /    16 tokens (  220.66 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.20 ms /     3 runs   (  894.07 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6215.25 ms /    19 tokens\n",
      " 45%|โโโโโ     | 1555/3487 [4:55:16<4:36:41,  8.59s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4172.38 ms /    20 tokens (  208.62 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.18 ms /     3 runs   (  884.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6829.45 ms /    23 tokens\n",
      " 45%|โโโโโ     | 1556/3487 [4:55:23<4:19:37,  8.07s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7510.12 ms /    38 tokens (  197.63 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.24 ms /     3 runs   (  889.75 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10181.56 ms /    41 tokens\n",
      " 45%|โโโโโ     | 1557/3487 [4:55:33<4:40:17,  8.71s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2513.49 ms /    10 tokens (  251.35 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.60 ms /     3 runs   (  891.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5190.60 ms /    13 tokens\n",
      " 45%|โโโโโ     | 1558/3487 [4:55:38<4:06:14,  7.66s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4737.40 ms /    23 tokens (  205.97 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.84 ms /     3 runs   (  898.28 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7434.98 ms /    26 tokens\n",
      " 45%|โโโโโ     | 1559/3487 [4:55:46<4:04:01,  7.59s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5881.81 ms /    30 tokens (  196.06 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.89 ms /     3 runs   (  897.63 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8576.89 ms /    33 tokens\n",
      " 45%|โโโโโ     | 1560/3487 [4:55:54<4:13:26,  7.89s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7368.88 ms /    36 tokens (  204.69 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.85 ms /     3 runs   (  888.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10036.98 ms /    39 tokens\n",
      " 45%|โโโโโ     | 1561/3487 [4:56:04<4:34:03,  8.54s/it]Llama.generate: 307 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17571.21 ms /    93 tokens (  188.94 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.29 ms /     3 runs   (  899.76 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   20273.14 ms /    96 tokens\n",
      " 45%|โโโโโ     | 1562/3487 [4:56:25<6:26:56, 12.06s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7166.57 ms /    34 tokens (  210.78 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.46 ms /     3 runs   (  884.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9823.97 ms /    37 tokens\n",
      " 45%|โโโโโ     | 1563/3487 [4:56:35<6:05:18, 11.39s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8966.21 ms /    47 tokens (  190.77 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.79 ms /     3 runs   (  880.60 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11610.63 ms /    50 tokens\n",
      " 45%|โโโโโ     | 1564/3487 [4:56:46<6:07:18, 11.46s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5599.78 ms /    28 tokens (  199.99 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.86 ms /     3 runs   (  889.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8270.71 ms /    31 tokens\n",
      " 45%|โโโโโ     | 1565/3487 [4:56:54<5:36:32, 10.51s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3172.69 ms /    15 tokens (  211.51 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.00 ms /     3 runs   (  902.33 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5881.64 ms /    18 tokens\n",
      " 45%|โโโโโ     | 1566/3487 [4:57:00<4:52:01,  9.12s/it]Llama.generate: 310 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2769.78 ms /    10 tokens (  276.98 ms per token,     3.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.79 ms /     3 runs   (  887.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5435.38 ms /    13 tokens\n",
      " 45%|โโโโโ     | 1567/3487 [4:57:06<4:16:33,  8.02s/it]Llama.generate: 310 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2558.55 ms /    11 tokens (  232.60 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2918.35 ms /     3 runs   (  972.78 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    5479.83 ms /    14 tokens\n",
      " 45%|โโโโโ     | 1568/3487 [4:57:11<3:52:08,  7.26s/it]Llama.generate: 309 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2827.64 ms /    13 tokens (  217.51 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.57 ms /     3 runs   (  896.19 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5519.05 ms /    16 tokens\n",
      " 45%|โโโโโ     | 1569/3487 [4:57:17<3:35:25,  6.74s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3096.68 ms /    14 tokens (  221.19 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.49 ms /     3 runs   (  890.16 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5768.75 ms /    17 tokens\n",
      " 45%|โโโโโ     | 1570/3487 [4:57:23<3:26:05,  6.45s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9090.50 ms /    47 tokens (  193.41 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2789.37 ms /     3 runs   (  929.79 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   11882.04 ms /    50 tokens\n",
      " 45%|โโโโโ     | 1571/3487 [4:57:34<4:18:05,  8.08s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4904.69 ms /    22 tokens (  222.94 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2749.58 ms /     3 runs   (  916.53 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7657.09 ms /    25 tokens\n",
      " 45%|โโโโโ     | 1572/3487 [4:57:42<4:13:58,  7.96s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5849.95 ms /    30 tokens (  195.00 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.14 ms /     3 runs   (  887.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8515.48 ms /    33 tokens\n",
      " 45%|โโโโโ     | 1573/3487 [4:57:51<4:19:17,  8.13s/it]Llama.generate: 314 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3731.43 ms /    18 tokens (  207.30 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.80 ms /     3 runs   (  895.27 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6418.80 ms /    21 tokens\n",
      " 45%|โโโโโ     | 1574/3487 [4:57:57<4:02:53,  7.62s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4248.95 ms /    21 tokens (  202.33 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.34 ms /     3 runs   (  887.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6912.59 ms /    24 tokens\n",
      " 45%|โโโโโ     | 1575/3487 [4:58:04<3:56:05,  7.41s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5635.40 ms /    28 tokens (  201.26 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.90 ms /     3 runs   (  891.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8314.06 ms /    31 tokens\n",
      " 45%|โโโโโ     | 1576/3487 [4:58:12<4:04:42,  7.68s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2418.12 ms /    10 tokens (  241.81 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.51 ms /     3 runs   (  887.17 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5081.96 ms /    13 tokens\n",
      " 45%|โโโโโ     | 1577/3487 [4:58:17<3:39:47,  6.90s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3084.79 ms /    14 tokens (  220.34 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.48 ms /     3 runs   (  881.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5732.86 ms /    17 tokens\n",
      " 45%|โโโโโ     | 1578/3487 [4:58:23<3:28:36,  6.56s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4153.10 ms /    20 tokens (  207.65 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.07 ms /     3 runs   (  883.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6805.59 ms /    23 tokens\n",
      " 45%|โโโโโ     | 1579/3487 [4:58:30<3:30:57,  6.63s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3963.93 ms /    19 tokens (  208.63 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.90 ms /     3 runs   (  890.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6639.47 ms /    22 tokens\n",
      " 45%|โโโโโ     | 1580/3487 [4:58:37<3:30:59,  6.64s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2159.05 ms /     9 tokens (  239.89 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.62 ms /     3 runs   (  884.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4814.22 ms /    12 tokens\n",
      " 45%|โโโโโ     | 1581/3487 [4:58:41<3:13:34,  6.09s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5432.85 ms /    25 tokens (  217.31 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.22 ms /     3 runs   (  881.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8079.69 ms /    28 tokens\n",
      " 45%|โโโโโ     | 1582/3487 [4:58:50<3:32:27,  6.69s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9178.42 ms /    45 tokens (  203.96 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2996.46 ms /     3 runs   (  998.82 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =   12177.42 ms /    48 tokens\n",
      " 45%|โโโโโ     | 1583/3487 [4:59:02<4:24:39,  8.34s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10038.73 ms /    51 tokens (  196.84 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.23 ms /     3 runs   (  878.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12678.28 ms /    54 tokens\n",
      " 45%|โโโโโ     | 1584/3487 [4:59:14<5:05:52,  9.64s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12994.90 ms /    66 tokens (  196.89 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.91 ms /     3 runs   (  874.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15622.69 ms /    69 tokens\n",
      " 45%|โโโโโ     | 1585/3487 [4:59:30<6:02:38, 11.44s/it]Llama.generate: 306 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13501.59 ms /    72 tokens (  187.52 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.51 ms /     3 runs   (  878.84 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16141.11 ms /    75 tokens\n",
      " 45%|โโโโโ     | 1586/3487 [4:59:46<6:47:13, 12.85s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7584.67 ms /    39 tokens (  194.48 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.62 ms /     3 runs   (  878.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10222.62 ms /    42 tokens\n",
      " 46%|โโโโโ     | 1587/3487 [4:59:56<6:22:05, 12.07s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2064.23 ms /     8 tokens (  258.03 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.78 ms /     3 runs   (  898.59 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4762.87 ms /    11 tokens\n",
      " 46%|โโโโโ     | 1588/3487 [5:00:01<5:12:37,  9.88s/it]Llama.generate: 307 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14311.78 ms /    76 tokens (  188.31 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.72 ms /     3 runs   (  893.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16994.06 ms /    79 tokens\n",
      " 46%|โโโโโ     | 1589/3487 [5:00:18<6:20:03, 12.01s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9477.32 ms /    49 tokens (  193.41 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.94 ms /     3 runs   (  875.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12105.36 ms /    52 tokens\n",
      " 46%|โโโโโ     | 1590/3487 [5:00:30<6:20:48, 12.04s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4616.39 ms /    23 tokens (  200.71 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.31 ms /     3 runs   (  880.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7261.38 ms /    26 tokens\n",
      " 46%|โโโโโ     | 1591/3487 [5:00:38<5:35:20, 10.61s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9852.99 ms /    52 tokens (  189.48 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.82 ms /     3 runs   (  882.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12503.36 ms /    55 tokens\n",
      " 46%|โโโโโ     | 1592/3487 [5:00:50<5:53:09, 11.18s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7352.81 ms /    37 tokens (  198.72 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.80 ms /     3 runs   (  886.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10014.09 ms /    40 tokens\n",
      " 46%|โโโโโ     | 1593/3487 [5:01:00<5:41:58, 10.83s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6085.17 ms /    31 tokens (  196.30 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.44 ms /     3 runs   (  892.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8766.22 ms /    34 tokens\n",
      " 46%|โโโโโ     | 1594/3487 [5:01:09<5:22:18, 10.22s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4456.02 ms /    20 tokens (  222.80 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.23 ms /     3 runs   (  877.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7089.39 ms /    23 tokens\n",
      " 46%|โโโโโ     | 1595/3487 [5:01:16<4:52:37,  9.28s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5628.48 ms /    29 tokens (  194.09 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.36 ms /     3 runs   (  883.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8282.76 ms /    32 tokens\n",
      " 46%|โโโโโ     | 1596/3487 [5:01:24<4:43:07,  8.98s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5595.00 ms /    27 tokens (  207.22 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.58 ms /     3 runs   (  883.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8249.31 ms /    30 tokens\n",
      " 46%|โโโโโ     | 1597/3487 [5:01:33<4:36:07,  8.77s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3307.59 ms /    16 tokens (  206.72 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.85 ms /     3 runs   (  886.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5970.07 ms /    19 tokens\n",
      " 46%|โโโโโ     | 1598/3487 [5:01:38<4:09:39,  7.93s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2529.99 ms /    11 tokens (  230.00 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.27 ms /     3 runs   (  888.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5198.78 ms /    14 tokens\n",
      " 46%|โโโโโ     | 1599/3487 [5:01:44<3:43:49,  7.11s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7878.15 ms /    40 tokens (  196.95 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.39 ms /     3 runs   (  881.80 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10525.69 ms /    43 tokens\n",
      " 46%|โโโโโ     | 1600/3487 [5:01:54<4:15:59,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4103.87 ms /    20 tokens (  205.19 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.33 ms /     3 runs   (  897.44 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6799.19 ms /    23 tokens\n",
      " 46%|โโโโโ     | 1601/3487 [5:02:01<4:03:16,  7.74s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2635.82 ms /    11 tokens (  239.62 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.02 ms /     3 runs   (  898.01 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5332.63 ms /    14 tokens\n",
      " 46%|โโโโโ     | 1602/3487 [5:02:06<3:40:32,  7.02s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1666.95 ms /     6 tokens (  277.82 ms per token,     3.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.73 ms /     3 runs   (  881.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4314.94 ms /     9 tokens\n",
      " 46%|โโโโโ     | 1603/3487 [5:02:11<3:15:01,  6.21s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2681.94 ms /    12 tokens (  223.49 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.66 ms /     3 runs   (  891.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5359.18 ms /    15 tokens\n",
      " 46%|โโโโโ     | 1604/3487 [5:02:16<3:06:58,  5.96s/it]Llama.generate: 306 prefix-match hit, remaining 119 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   22273.48 ms /   119 tokens (  187.17 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.32 ms /     3 runs   (  878.11 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   24910.89 ms /   122 tokens\n",
      " 46%|โโโโโ     | 1605/3487 [5:02:41<6:05:18, 11.65s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7618.88 ms /    38 tokens (  200.50 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.57 ms /     3 runs   (  882.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10269.82 ms /    41 tokens\n",
      " 46%|โโโโโ     | 1606/3487 [5:02:51<5:52:15, 11.24s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4126.36 ms /    20 tokens (  206.32 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.39 ms /     3 runs   (  895.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6816.50 ms /    23 tokens\n",
      " 46%|โโโโโ     | 1607/3487 [5:02:58<5:10:35,  9.91s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5833.61 ms /    29 tokens (  201.16 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.99 ms /     3 runs   (  881.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8480.33 ms /    32 tokens\n",
      " 46%|โโโโโ     | 1608/3487 [5:03:07<4:57:02,  9.49s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2145.02 ms /     6 tokens (  357.50 ms per token,     2.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.31 ms /     3 runs   (  890.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4819.62 ms /     9 tokens\n",
      " 46%|โโโโโ     | 1609/3487 [5:03:11<4:13:08,  8.09s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2066.13 ms /     8 tokens (  258.27 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.67 ms /     3 runs   (  885.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4725.05 ms /    11 tokens\n",
      " 46%|โโโโโ     | 1610/3487 [5:03:16<3:41:31,  7.08s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2640.57 ms /    12 tokens (  220.05 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.84 ms /     3 runs   (  888.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5308.95 ms /    15 tokens\n",
      " 46%|โโโโโ     | 1611/3487 [5:03:21<3:24:51,  6.55s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7141.02 ms /    34 tokens (  210.03 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.57 ms /     3 runs   (  881.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9788.08 ms /    37 tokens\n",
      " 46%|โโโโโ     | 1612/3487 [5:03:31<3:55:27,  7.53s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4174.52 ms /    21 tokens (  198.79 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.33 ms /     3 runs   (  882.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6825.12 ms /    24 tokens\n",
      " 46%|โโโโโ     | 1613/3487 [5:03:38<3:48:46,  7.32s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2161.14 ms /     9 tokens (  240.13 ms per token,     4.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.50 ms /     3 runs   (  897.83 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4856.62 ms /    12 tokens\n",
      " 46%|โโโโโ     | 1614/3487 [5:03:43<3:25:36,  6.59s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4312.59 ms /    21 tokens (  205.36 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.04 ms /     3 runs   (  893.68 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6995.74 ms /    24 tokens\n",
      " 46%|โโโโโ     | 1615/3487 [5:03:50<3:29:41,  6.72s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1683.42 ms /     6 tokens (  280.57 ms per token,     3.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2742.65 ms /     3 runs   (  914.22 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4428.35 ms /     9 tokens\n",
      " 46%|โโโโโ     | 1616/3487 [5:03:54<3:08:13,  6.04s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8115.60 ms /    41 tokens (  197.94 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.93 ms /     3 runs   (  876.98 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10749.39 ms /    44 tokens\n",
      " 46%|โโโโโ     | 1617/3487 [5:04:05<3:52:16,  7.45s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3480.30 ms /    16 tokens (  217.52 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.36 ms /     3 runs   (  881.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6128.37 ms /    19 tokens\n",
      " 46%|โโโโโ     | 1618/3487 [5:04:11<3:39:50,  7.06s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3071.10 ms /    14 tokens (  219.36 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.57 ms /     3 runs   (  882.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5722.78 ms /    17 tokens\n",
      " 46%|โโโโโ     | 1619/3487 [5:04:17<3:27:20,  6.66s/it]Llama.generate: 307 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12196.64 ms /    64 tokens (  190.57 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2899.85 ms /     3 runs   (  966.62 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   15099.19 ms /    67 tokens\n",
      " 46%|โโโโโ     | 1620/3487 [5:04:32<4:46:05,  9.19s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4516.32 ms /    21 tokens (  215.06 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.10 ms /     3 runs   (  908.37 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7243.93 ms /    24 tokens\n",
      " 46%|โโโโโ     | 1621/3487 [5:04:39<4:27:49,  8.61s/it]Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8979.15 ms /    44 tokens (  204.07 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.82 ms /     3 runs   (  895.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11669.23 ms /    47 tokens\n",
      " 47%|โโโโโ     | 1622/3487 [5:04:51<4:56:16,  9.53s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3953.31 ms /    16 tokens (  247.08 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.44 ms /     3 runs   (  905.81 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6673.31 ms /    19 tokens\n",
      " 47%|โโโโโ     | 1623/3487 [5:04:58<4:29:32,  8.68s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3511.25 ms /    16 tokens (  219.45 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.28 ms /     3 runs   (  896.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6202.04 ms /    19 tokens\n",
      " 47%|โโโโโ     | 1624/3487 [5:05:04<4:06:26,  7.94s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8904.85 ms /    47 tokens (  189.46 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.34 ms /     3 runs   (  874.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11531.97 ms /    50 tokens\n",
      " 47%|โโโโโ     | 1625/3487 [5:05:16<4:39:51,  9.02s/it]Llama.generate: 314 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2916.17 ms /    13 tokens (  224.32 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.38 ms /     3 runs   (  878.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5552.94 ms /    16 tokens\n",
      " 47%|โโโโโ     | 1626/3487 [5:05:21<4:07:32,  7.98s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3159.89 ms /    15 tokens (  210.66 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.06 ms /     3 runs   (  883.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5811.14 ms /    18 tokens\n",
      " 47%|โโโโโ     | 1627/3487 [5:05:27<3:47:18,  7.33s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2726.94 ms /    12 tokens (  227.24 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.06 ms /     3 runs   (  883.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5379.82 ms /    15 tokens\n",
      " 47%|โโโโโ     | 1628/3487 [5:05:32<3:29:05,  6.75s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3251.86 ms /    15 tokens (  216.79 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.93 ms /     3 runs   (  892.31 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5931.54 ms /    18 tokens\n",
      " 47%|โโโโโ     | 1629/3487 [5:05:38<3:21:28,  6.51s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3493.87 ms /    16 tokens (  218.37 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.97 ms /     3 runs   (  903.32 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6206.57 ms /    19 tokens\n",
      " 47%|โโโโโ     | 1630/3487 [5:05:44<3:18:40,  6.42s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8942.13 ms /    46 tokens (  194.39 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.97 ms /     3 runs   (  902.66 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11652.90 ms /    49 tokens\n",
      " 47%|โโโโโ     | 1631/3487 [5:05:56<4:07:14,  7.99s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2807.35 ms /    12 tokens (  233.95 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2741.24 ms /     3 runs   (  913.75 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5551.15 ms /    15 tokens\n",
      " 47%|โโโโโ     | 1632/3487 [5:06:02<3:44:31,  7.26s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3322.17 ms /    15 tokens (  221.48 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.60 ms /     3 runs   (  892.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6001.41 ms /    18 tokens\n",
      " 47%|โโโโโ     | 1633/3487 [5:06:08<3:32:47,  6.89s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4849.34 ms /    23 tokens (  210.84 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2740.28 ms /     3 runs   (  913.43 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7592.00 ms /    26 tokens\n",
      " 47%|โโโโโ     | 1634/3487 [5:06:15<3:39:17,  7.10s/it]Llama.generate: 314 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1468.85 ms /     4 tokens (  367.21 ms per token,     2.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.54 ms /     3 runs   (  889.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4139.54 ms /     7 tokens\n",
      " 47%|โโโโโ     | 1635/3487 [5:06:19<3:11:50,  6.21s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8366.05 ms /    43 tokens (  194.56 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.76 ms /     3 runs   (  885.92 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11025.99 ms /    46 tokens\n",
      " 47%|โโโโโ     | 1636/3487 [5:06:30<3:56:19,  7.66s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2468.98 ms /     8 tokens (  308.62 ms per token,     3.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.28 ms /     3 runs   (  882.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5118.85 ms /    11 tokens\n",
      " 47%|โโโโโ     | 1637/3487 [5:06:36<3:32:45,  6.90s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3160.23 ms /    13 tokens (  243.09 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.56 ms /     3 runs   (  900.19 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5862.60 ms /    16 tokens\n",
      " 47%|โโโโโ     | 1638/3487 [5:06:41<3:23:07,  6.59s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4244.89 ms /    21 tokens (  202.14 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.94 ms /     3 runs   (  880.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6889.93 ms /    24 tokens\n",
      " 47%|โโโโโ     | 1639/3487 [5:06:48<3:25:50,  6.68s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3645.19 ms /    16 tokens (  227.82 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.60 ms /     3 runs   (  894.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6331.30 ms /    19 tokens\n",
      " 47%|โโโโโ     | 1640/3487 [5:06:55<3:22:33,  6.58s/it]Llama.generate: 306 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9986.33 ms /    53 tokens (  188.42 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.11 ms /     3 runs   (  882.37 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12636.31 ms /    56 tokens\n",
      " 47%|โโโโโ     | 1641/3487 [5:07:07<4:18:24,  8.40s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4035.13 ms /    19 tokens (  212.38 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.75 ms /     3 runs   (  907.92 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6761.06 ms /    22 tokens\n",
      " 47%|โโโโโ     | 1642/3487 [5:07:14<4:03:12,  7.91s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7314.92 ms /    37 tokens (  197.70 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.60 ms /     3 runs   (  883.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9966.79 ms /    40 tokens\n",
      " 47%|โโโโโ     | 1643/3487 [5:07:24<4:22:07,  8.53s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7538.88 ms /    34 tokens (  221.73 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2862.56 ms /     3 runs   (  954.19 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   10404.51 ms /    37 tokens\n",
      " 47%|โโโโโ     | 1644/3487 [5:07:35<4:39:20,  9.09s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7243.30 ms /    36 tokens (  201.20 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.73 ms /     3 runs   (  879.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9884.45 ms /    39 tokens\n",
      " 47%|โโโโโ     | 1645/3487 [5:07:44<4:46:32,  9.33s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3447.18 ms /    16 tokens (  215.45 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.02 ms /     3 runs   (  891.01 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6122.14 ms /    19 tokens\n",
      " 47%|โโโโโ     | 1646/3487 [5:07:51<4:16:53,  8.37s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4971.57 ms /    25 tokens (  198.86 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.38 ms /     3 runs   (  884.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7626.51 ms /    28 tokens\n",
      " 47%|โโโโโ     | 1647/3487 [5:07:58<4:09:58,  8.15s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7223.55 ms /    34 tokens (  212.46 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.75 ms /     3 runs   (  883.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9877.04 ms /    37 tokens\n",
      " 47%|โโโโโ     | 1648/3487 [5:08:08<4:25:47,  8.67s/it]Llama.generate: 307 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11877.84 ms /    64 tokens (  185.59 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.99 ms /     3 runs   (  879.00 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14517.13 ms /    67 tokens\n",
      " 47%|โโโโโ     | 1649/3487 [5:08:23<5:19:25, 10.43s/it]Llama.generate: 307 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10631.01 ms /    55 tokens (  193.29 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.89 ms /     3 runs   (  876.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13264.64 ms /    58 tokens\n",
      " 47%|โโโโโ     | 1650/3487 [5:08:36<5:45:23, 11.28s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10896.12 ms /    59 tokens (  184.68 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.30 ms /     3 runs   (  879.10 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13536.10 ms /    62 tokens\n",
      " 47%|โโโโโ     | 1651/3487 [5:08:49<6:05:59, 11.96s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9468.52 ms /    50 tokens (  189.37 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2771.52 ms /     3 runs   (  923.84 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   12242.81 ms /    53 tokens\n",
      " 47%|โโโโโ     | 1652/3487 [5:09:02<6:08:26, 12.05s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4906.11 ms /    24 tokens (  204.42 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.01 ms /     3 runs   (  880.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7550.31 ms /    27 tokens\n",
      " 47%|โโโโโ     | 1653/3487 [5:09:09<5:27:05, 10.70s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2071.13 ms /     8 tokens (  258.89 ms per token,     3.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.27 ms /     3 runs   (  888.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4738.64 ms /    11 tokens\n",
      " 47%|โโโโโ     | 1654/3487 [5:09:14<4:32:20,  8.91s/it]Llama.generate: 308 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3035.64 ms /    13 tokens (  233.51 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.88 ms /     3 runs   (  880.63 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5680.11 ms /    16 tokens\n",
      " 47%|โโโโโ     | 1655/3487 [5:09:20<4:02:38,  7.95s/it]Llama.generate: 307 prefix-match hit, remaining 175 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   32071.91 ms /   175 tokens (  183.27 ms per token,     5.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2764.95 ms /     3 runs   (  921.65 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   34840.00 ms /   178 tokens\n",
      " 47%|โโโโโ     | 1656/3487 [5:09:55<8:08:47, 16.02s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8395.73 ms /    42 tokens (  199.90 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.87 ms /     3 runs   (  877.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11030.87 ms /    45 tokens\n",
      " 48%|โโโโโ     | 1657/3487 [5:10:06<7:22:58, 14.52s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2778.07 ms /    12 tokens (  231.51 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2749.78 ms /     3 runs   (  916.59 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5530.51 ms /    15 tokens\n",
      " 48%|โโโโโ     | 1658/3487 [5:10:11<6:00:34, 11.83s/it]Llama.generate: 314 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3044.48 ms /    13 tokens (  234.19 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.16 ms /     3 runs   (  884.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5700.84 ms /    16 tokens\n",
      " 48%|โโโโโ     | 1659/3487 [5:10:17<5:04:26,  9.99s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4274.59 ms /    21 tokens (  203.55 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.37 ms /     3 runs   (  881.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6920.41 ms /    24 tokens\n",
      " 48%|โโโโโ     | 1660/3487 [5:10:24<4:36:16,  9.07s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2757.08 ms /    12 tokens (  229.76 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.16 ms /     3 runs   (  902.39 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5467.12 ms /    15 tokens\n",
      " 48%|โโโโโ     | 1661/3487 [5:10:29<4:03:17,  7.99s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10324.08 ms /    51 tokens (  202.43 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.23 ms /     3 runs   (  891.08 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12999.27 ms /    54 tokens\n",
      " 48%|โโโโโ     | 1662/3487 [5:10:42<4:48:55,  9.50s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2904.22 ms /    13 tokens (  223.40 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.73 ms /     3 runs   (  884.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5560.98 ms /    16 tokens\n",
      " 48%|โโโโโ     | 1663/3487 [5:10:48<4:12:55,  8.32s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2721.72 ms /    12 tokens (  226.81 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.98 ms /     3 runs   (  888.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5389.33 ms /    15 tokens\n",
      " 48%|โโโโโ     | 1664/3487 [5:10:53<3:46:07,  7.44s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2224.74 ms /     9 tokens (  247.19 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.49 ms /     3 runs   (  888.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4893.61 ms /    12 tokens\n",
      " 48%|โโโโโ     | 1665/3487 [5:10:58<3:22:51,  6.68s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3252.71 ms /    15 tokens (  216.85 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.12 ms /     3 runs   (  889.04 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5922.28 ms /    18 tokens\n",
      " 48%|โโโโโ     | 1666/3487 [5:11:04<3:15:56,  6.46s/it]Llama.generate: 308 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4794.29 ms /    24 tokens (  199.76 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.51 ms /     3 runs   (  887.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7460.17 ms /    27 tokens\n",
      " 48%|โโโโโ     | 1667/3487 [5:11:11<3:25:02,  6.76s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1757.51 ms /     6 tokens (  292.92 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2746.66 ms /     3 runs   (  915.55 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4506.41 ms /     9 tokens\n",
      " 48%|โโโโโ     | 1668/3487 [5:11:16<3:04:29,  6.09s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2783.22 ms /    12 tokens (  231.94 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.70 ms /     3 runs   (  892.23 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5462.25 ms /    15 tokens\n",
      " 48%|โโโโโ     | 1669/3487 [5:11:21<2:58:48,  5.90s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2788.57 ms /    11 tokens (  253.51 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2815.66 ms /     3 runs   (  938.55 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5607.15 ms /    14 tokens\n",
      " 48%|โโโโโ     | 1670/3487 [5:11:27<2:56:07,  5.82s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2761.01 ms /    12 tokens (  230.08 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2797.30 ms /     3 runs   (  932.43 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5560.26 ms /    15 tokens\n",
      " 48%|โโโโโ     | 1671/3487 [5:11:33<2:53:46,  5.74s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2344.78 ms /     8 tokens (  293.10 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2995.74 ms /     3 runs   (  998.58 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    5344.21 ms /    11 tokens\n",
      " 48%|โโโโโ     | 1672/3487 [5:11:38<2:50:09,  5.62s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3224.55 ms /    13 tokens (  248.04 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2714.86 ms /     3 runs   (  904.95 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5942.84 ms /    16 tokens\n",
      " 48%|โโโโโ     | 1673/3487 [5:11:44<2:53:02,  5.72s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2970.68 ms /    12 tokens (  247.56 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.66 ms /     3 runs   (  894.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5655.90 ms /    15 tokens\n",
      " 48%|โโโโโ     | 1674/3487 [5:11:50<2:52:24,  5.71s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3740.64 ms /    15 tokens (  249.38 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.25 ms /     3 runs   (  899.75 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6442.24 ms /    18 tokens\n",
      " 48%|โโโโโ     | 1675/3487 [5:11:56<2:59:03,  5.93s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2718.48 ms /    12 tokens (  226.54 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.53 ms /     3 runs   (  891.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5395.65 ms /    15 tokens\n",
      " 48%|โโโโโ     | 1676/3487 [5:12:01<2:54:13,  5.77s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6132.07 ms /    31 tokens (  197.81 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.22 ms /     3 runs   (  883.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8784.86 ms /    34 tokens\n",
      " 48%|โโโโโ     | 1677/3487 [5:12:10<3:21:27,  6.68s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9324.83 ms /    49 tokens (  190.30 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.99 ms /     3 runs   (  882.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11975.63 ms /    52 tokens\n",
      " 48%|โโโโโ     | 1678/3487 [5:12:22<4:09:19,  8.27s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3956.39 ms /    19 tokens (  208.23 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.54 ms /     3 runs   (  889.18 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6626.47 ms /    22 tokens\n",
      " 48%|โโโโโ     | 1679/3487 [5:12:29<3:54:24,  7.78s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3724.73 ms /    18 tokens (  206.93 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.96 ms /     3 runs   (  896.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6417.84 ms /    21 tokens\n",
      " 48%|โโโโโ     | 1680/3487 [5:12:35<3:42:03,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3482.06 ms /    16 tokens (  217.63 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2852.15 ms /     3 runs   (  950.72 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    6336.67 ms /    19 tokens\n",
      " 48%|โโโโโ     | 1681/3487 [5:12:42<3:32:38,  7.06s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3191.57 ms /    14 tokens (  227.97 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.37 ms /     3 runs   (  908.12 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5918.41 ms /    17 tokens\n",
      " 48%|โโโโโ     | 1682/3487 [5:12:48<3:22:16,  6.72s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3127.05 ms /    14 tokens (  223.36 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.31 ms /     3 runs   (  887.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5790.80 ms /    17 tokens\n",
      " 48%|โโโโโ     | 1683/3487 [5:12:53<3:13:48,  6.45s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3510.51 ms /    16 tokens (  219.41 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.53 ms /     3 runs   (  893.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6194.10 ms /    19 tokens\n",
      " 48%|โโโโโ     | 1684/3487 [5:13:00<3:11:30,  6.37s/it]Llama.generate: 310 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2543.24 ms /    10 tokens (  254.32 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2768.11 ms /     3 runs   (  922.70 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5314.25 ms /    13 tokens\n",
      " 48%|โโโโโ     | 1685/3487 [5:13:05<3:01:56,  6.06s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7404.91 ms /    34 tokens (  217.79 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.33 ms /     3 runs   (  883.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10058.24 ms /    37 tokens\n",
      " 48%|โโโโโ     | 1686/3487 [5:13:15<3:37:56,  7.26s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4315.91 ms /    21 tokens (  205.52 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.18 ms /     3 runs   (  890.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6988.55 ms /    24 tokens\n",
      " 48%|โโโโโ     | 1687/3487 [5:13:22<3:35:27,  7.18s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3222.62 ms /    15 tokens (  214.84 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.68 ms /     3 runs   (  894.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5908.73 ms /    18 tokens\n",
      " 48%|โโโโโ     | 1688/3487 [5:13:28<3:23:57,  6.80s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3142.39 ms /    12 tokens (  261.87 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3269.78 ms /     3 runs   ( 1089.93 ms per token,     0.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    6414.71 ms /    15 tokens\n",
      " 48%|โโโโโ     | 1689/3487 [5:13:34<3:20:26,  6.69s/it]Llama.generate: 306 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17433.26 ms /    80 tokens (  217.92 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2973.54 ms /     3 runs   (  991.18 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   20409.26 ms /    83 tokens\n",
      " 48%|โโโโโ     | 1690/3487 [5:13:55<5:23:41, 10.81s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6072.13 ms /    27 tokens (  224.89 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2788.72 ms /     3 runs   (  929.57 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8863.55 ms /    30 tokens\n",
      " 48%|โโโโโ     | 1691/3487 [5:14:04<5:06:09, 10.23s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5809.07 ms /    29 tokens (  200.31 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.53 ms /     3 runs   (  889.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8481.09 ms /    32 tokens\n",
      " 49%|โโโโโ     | 1692/3487 [5:14:12<4:50:22,  9.71s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4302.46 ms /    21 tokens (  204.88 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.94 ms /     3 runs   (  891.31 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6978.91 ms /    24 tokens\n",
      " 49%|โโโโโ     | 1693/3487 [5:14:19<4:25:49,  8.89s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7482.73 ms /    36 tokens (  207.85 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.11 ms /     3 runs   (  896.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10176.21 ms /    39 tokens\n",
      " 49%|โโโโโ     | 1694/3487 [5:14:29<4:37:16,  9.28s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2558.85 ms /    11 tokens (  232.62 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2774.35 ms /     3 runs   (  924.78 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5336.11 ms /    14 tokens\n",
      " 49%|โโโโโ     | 1695/3487 [5:14:35<4:01:54,  8.10s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5760.51 ms /    26 tokens (  221.56 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2757.33 ms /     3 runs   (  919.11 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8521.13 ms /    29 tokens\n",
      " 49%|โโโโโ     | 1696/3487 [5:14:43<4:05:37,  8.23s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3615.30 ms /    17 tokens (  212.66 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.76 ms /     3 runs   (  892.92 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6297.08 ms /    20 tokens\n",
      " 49%|โโโโโ     | 1697/3487 [5:14:49<3:48:17,  7.65s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6305.67 ms /    32 tokens (  197.05 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.12 ms /     3 runs   (  899.04 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9005.46 ms /    35 tokens\n",
      " 49%|โโโโโ     | 1698/3487 [5:14:58<4:00:20,  8.06s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7957.53 ms /    41 tokens (  194.09 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.68 ms /     3 runs   (  886.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10619.88 ms /    44 tokens\n",
      " 49%|โโโโโ     | 1699/3487 [5:15:09<4:23:09,  8.83s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2140.95 ms /     9 tokens (  237.88 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.73 ms /     3 runs   (  887.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4805.10 ms /    12 tokens\n",
      " 49%|โโโโโ     | 1700/3487 [5:15:14<3:47:07,  7.63s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4410.93 ms /    19 tokens (  232.15 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.90 ms /     3 runs   (  897.30 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7105.29 ms /    22 tokens\n",
      " 49%|โโโโโ     | 1701/3487 [5:15:21<3:42:23,  7.47s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2100.08 ms /     8 tokens (  262.51 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.44 ms /     3 runs   (  892.48 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4780.22 ms /    11 tokens\n",
      " 49%|โโโโโ     | 1702/3487 [5:15:26<3:18:19,  6.67s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3506.03 ms /    16 tokens (  219.13 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.25 ms /     3 runs   (  885.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6164.67 ms /    19 tokens\n",
      " 49%|โโโโโ     | 1703/3487 [5:15:32<3:13:49,  6.52s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5351.63 ms /    27 tokens (  198.21 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.74 ms /     3 runs   (  888.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8021.02 ms /    30 tokens\n",
      " 49%|โโโโโ     | 1704/3487 [5:15:40<3:27:11,  6.97s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1933.42 ms /     7 tokens (  276.20 ms per token,     3.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.39 ms /     3 runs   (  886.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4594.74 ms /    10 tokens\n",
      " 49%|โโโโโ     | 1705/3487 [5:15:45<3:05:57,  6.26s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2210.99 ms /     9 tokens (  245.67 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.36 ms /     3 runs   (  892.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4891.30 ms /    12 tokens\n",
      " 49%|โโโโโ     | 1706/3487 [5:15:50<2:53:43,  5.85s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4102.45 ms /    20 tokens (  205.12 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.38 ms /     3 runs   (  890.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6776.94 ms /    23 tokens\n",
      " 49%|โโโโโ     | 1707/3487 [5:15:56<3:01:54,  6.13s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2193.48 ms /     9 tokens (  243.72 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.39 ms /     3 runs   (  889.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4864.92 ms /    12 tokens\n",
      " 49%|โโโโโ     | 1708/3487 [5:16:01<2:50:36,  5.75s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3761.52 ms /    18 tokens (  208.97 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.16 ms /     3 runs   (  889.72 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6433.25 ms /    21 tokens\n",
      " 49%|โโโโโ     | 1709/3487 [5:16:08<2:56:36,  5.96s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2948.31 ms /    13 tokens (  226.79 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.66 ms /     3 runs   (  886.89 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5611.58 ms /    16 tokens\n",
      " 49%|โโโโโ     | 1710/3487 [5:16:13<2:53:29,  5.86s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4741.61 ms /    24 tokens (  197.57 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.52 ms /     3 runs   (  883.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7395.65 ms /    27 tokens\n",
      " 49%|โโโโโ     | 1711/3487 [5:16:21<3:07:08,  6.32s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7444.04 ms /    38 tokens (  195.90 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.30 ms /     3 runs   (  888.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10112.65 ms /    41 tokens\n",
      " 49%|โโโโโ     | 1712/3487 [5:16:31<3:40:44,  7.46s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13147.83 ms /    70 tokens (  187.83 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.97 ms /     3 runs   (  882.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15796.96 ms /    73 tokens\n",
      " 49%|โโโโโ     | 1713/3487 [5:16:47<4:54:37,  9.96s/it]Llama.generate: 307 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16930.51 ms /    86 tokens (  196.87 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2732.48 ms /     3 runs   (  910.83 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   19665.38 ms /    89 tokens\n",
      " 49%|โโโโโ     | 1714/3487 [5:17:06<6:20:30, 12.88s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4920.97 ms /    24 tokens (  205.04 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2733.78 ms /     3 runs   (  911.26 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7657.36 ms /    27 tokens\n",
      " 49%|โโโโโ     | 1715/3487 [5:17:14<5:34:07, 11.31s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3231.13 ms /    15 tokens (  215.41 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.32 ms /     3 runs   (  882.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5879.68 ms /    18 tokens\n",
      " 49%|โโโโโ     | 1716/3487 [5:17:20<4:45:54,  9.69s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2926.02 ms /    13 tokens (  225.08 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.36 ms /     3 runs   (  890.45 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5600.50 ms /    16 tokens\n",
      " 49%|โโโโโ     | 1717/3487 [5:17:25<4:09:39,  8.46s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11863.51 ms /    63 tokens (  188.31 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.95 ms /     3 runs   (  882.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14515.33 ms /    66 tokens\n",
      " 49%|โโโโโ     | 1718/3487 [5:17:40<5:03:07, 10.28s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4577.25 ms /    21 tokens (  217.96 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.37 ms /     3 runs   (  891.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7253.04 ms /    24 tokens\n",
      " 49%|โโโโโ     | 1719/3487 [5:17:47<4:36:14,  9.37s/it]Llama.generate: 315 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3002.39 ms /    13 tokens (  230.95 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.73 ms /     3 runs   (  888.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5670.73 ms /    16 tokens\n",
      " 49%|โโโโโ     | 1720/3487 [5:17:53<4:03:25,  8.27s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5580.71 ms /    28 tokens (  199.31 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.89 ms /     3 runs   (  896.30 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8272.37 ms /    31 tokens\n",
      " 49%|โโโโโ     | 1721/3487 [5:18:01<4:03:24,  8.27s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4151.68 ms /    20 tokens (  207.58 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.76 ms /     3 runs   (  904.59 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6867.97 ms /    23 tokens\n",
      " 49%|โโโโโ     | 1722/3487 [5:18:08<3:50:58,  7.85s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2993.90 ms /    13 tokens (  230.30 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.08 ms /     3 runs   (  889.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5664.45 ms /    16 tokens\n",
      " 49%|โโโโโ     | 1723/3487 [5:18:14<3:31:37,  7.20s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4351.22 ms /    21 tokens (  207.20 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.28 ms /     3 runs   (  891.76 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7029.32 ms /    24 tokens\n",
      " 49%|โโโโโ     | 1724/3487 [5:18:21<3:30:05,  7.15s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12967.18 ms /    67 tokens (  193.54 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.72 ms /     3 runs   (  885.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15626.68 ms /    70 tokens\n",
      " 49%|โโโโโ     | 1725/3487 [5:18:36<4:44:43,  9.70s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9573.69 ms /    50 tokens (  191.47 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.61 ms /     3 runs   (  886.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12237.34 ms /    53 tokens\n",
      " 49%|โโโโโ     | 1726/3487 [5:18:49<5:07:03, 10.46s/it]Llama.generate: 315 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4032.35 ms /    17 tokens (  237.20 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.85 ms /     3 runs   (  889.95 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6705.53 ms /    20 tokens\n",
      " 50%|โโโโโ     | 1727/3487 [5:18:55<4:33:54,  9.34s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2984.55 ms /    13 tokens (  229.58 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.76 ms /     3 runs   (  906.59 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5707.24 ms /    16 tokens\n",
      " 50%|โโโโโ     | 1728/3487 [5:19:01<4:01:54,  8.25s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4186.17 ms /    20 tokens (  209.31 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.74 ms /     3 runs   (  890.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6860.27 ms /    23 tokens\n",
      " 50%|โโโโโ     | 1729/3487 [5:19:08<3:49:36,  7.84s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5018.36 ms /    25 tokens (  200.73 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.27 ms /     3 runs   (  895.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7706.71 ms /    28 tokens\n",
      " 50%|โโโโโ     | 1730/3487 [5:19:16<3:48:24,  7.80s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2943.42 ms /    13 tokens (  226.42 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.73 ms /     3 runs   (  889.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5615.18 ms /    16 tokens\n",
      " 50%|โโโโโ     | 1731/3487 [5:19:21<3:29:08,  7.15s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1971.14 ms /     7 tokens (  281.59 ms per token,     3.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.91 ms /     3 runs   (  891.30 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4647.01 ms /    10 tokens\n",
      " 50%|โโโโโ     | 1732/3487 [5:19:26<3:07:10,  6.40s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5393.41 ms /    27 tokens (  199.76 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.72 ms /     3 runs   (  903.57 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8106.42 ms /    30 tokens\n",
      " 50%|โโโโโ     | 1733/3487 [5:19:34<3:22:06,  6.91s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3096.49 ms /    14 tokens (  221.18 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.91 ms /     3 runs   (  893.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5780.83 ms /    17 tokens\n",
      " 50%|โโโโโ     | 1734/3487 [5:19:40<3:12:08,  6.58s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8001.94 ms /    41 tokens (  195.17 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2824.61 ms /     3 runs   (  941.54 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   10829.20 ms /    44 tokens\n",
      " 50%|โโโโโ     | 1735/3487 [5:19:51<3:49:21,  7.85s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2669.16 ms /    10 tokens (  266.92 ms per token,     3.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2738.22 ms /     3 runs   (  912.74 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5409.48 ms /    13 tokens\n",
      " 50%|โโโโโ     | 1736/3487 [5:19:56<3:27:54,  7.12s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4210.96 ms /    20 tokens (  210.55 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2726.98 ms /     3 runs   (  908.99 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6940.05 ms /    23 tokens\n",
      " 50%|โโโโโ     | 1737/3487 [5:20:03<3:26:15,  7.07s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4603.35 ms /    22 tokens (  209.24 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.50 ms /     3 runs   (  894.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7289.91 ms /    25 tokens\n",
      " 50%|โโโโโ     | 1738/3487 [5:20:10<3:28:07,  7.14s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5026.89 ms /    25 tokens (  201.08 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.66 ms /     3 runs   (  890.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7700.32 ms /    28 tokens\n",
      " 50%|โโโโโ     | 1739/3487 [5:20:18<3:32:58,  7.31s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3196.77 ms /    12 tokens (  266.40 ms per token,     3.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.01 ms /     3 runs   (  894.00 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5881.49 ms /    15 tokens\n",
      " 50%|โโโโโ     | 1740/3487 [5:20:24<3:20:26,  6.88s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14091.09 ms /    74 tokens (  190.42 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.11 ms /     3 runs   (  882.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16742.03 ms /    77 tokens\n",
      " 50%|โโโโโ     | 1741/3487 [5:20:41<4:46:27,  9.84s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3011.02 ms /    13 tokens (  231.62 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2714.36 ms /     3 runs   (  904.79 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5728.02 ms /    16 tokens\n",
      " 50%|โโโโโ     | 1742/3487 [5:20:46<4:10:28,  8.61s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2694.32 ms /    12 tokens (  224.53 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.15 ms /     3 runs   (  883.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5346.12 ms /    15 tokens\n",
      " 50%|โโโโโ     | 1743/3487 [5:20:52<3:41:55,  7.64s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1728.94 ms /     6 tokens (  288.16 ms per token,     3.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.89 ms /     3 runs   (  904.63 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4445.28 ms /     9 tokens\n",
      " 50%|โโโโโ     | 1744/3487 [5:20:56<3:14:03,  6.68s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5302.12 ms /    26 tokens (  203.93 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.95 ms /     3 runs   (  887.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7967.61 ms /    29 tokens\n",
      " 50%|โโโโโ     | 1745/3487 [5:21:04<3:25:14,  7.07s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2703.48 ms /    12 tokens (  225.29 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.30 ms /     3 runs   (  899.10 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5403.29 ms /    15 tokens\n",
      " 50%|โโโโโ     | 1746/3487 [5:21:10<3:10:40,  6.57s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7118.24 ms /    33 tokens (  215.70 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.41 ms /     3 runs   (  879.80 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9760.00 ms /    36 tokens\n",
      " 50%|โโโโโ     | 1747/3487 [5:21:19<3:38:23,  7.53s/it]Llama.generate: 308 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6058.66 ms /    30 tokens (  201.96 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2789.46 ms /     3 runs   (  929.82 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8850.43 ms /    33 tokens\n",
      " 50%|โโโโโ     | 1748/3487 [5:21:28<3:49:49,  7.93s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2713.90 ms /    12 tokens (  226.16 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.72 ms /     3 runs   (  893.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5395.59 ms /    15 tokens\n",
      " 50%|โโโโโ     | 1749/3487 [5:21:34<3:27:45,  7.17s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3013.96 ms /    13 tokens (  231.84 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.35 ms /     3 runs   (  896.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5705.10 ms /    16 tokens\n",
      " 50%|โโโโโ     | 1750/3487 [5:21:39<3:14:57,  6.73s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7227.42 ms /    35 tokens (  206.50 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.37 ms /     3 runs   (  885.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9886.81 ms /    38 tokens\n",
      " 50%|โโโโโ     | 1751/3487 [5:21:49<3:42:16,  7.68s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5095.51 ms /    25 tokens (  203.82 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.67 ms /     3 runs   (  889.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7767.60 ms /    28 tokens\n",
      " 50%|โโโโโ     | 1752/3487 [5:21:57<3:42:56,  7.71s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7722.89 ms /    33 tokens (  234.03 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.92 ms /     3 runs   (  886.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10385.06 ms /    36 tokens\n",
      " 50%|โโโโโ     | 1753/3487 [5:22:07<4:06:04,  8.51s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4182.36 ms /    20 tokens (  209.12 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.67 ms /     3 runs   (  896.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6875.86 ms /    23 tokens\n",
      " 50%|โโโโโ     | 1754/3487 [5:22:14<3:51:48,  8.03s/it]Llama.generate: 308 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5617.17 ms /    28 tokens (  200.61 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.46 ms /     3 runs   (  887.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8280.67 ms /    31 tokens\n",
      " 50%|โโโโโ     | 1755/3487 [5:22:23<3:53:57,  8.10s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5247.27 ms /    27 tokens (  194.34 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.35 ms /     3 runs   (  893.45 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7930.96 ms /    30 tokens\n",
      " 50%|โโโโโ     | 1756/3487 [5:22:31<3:52:24,  8.06s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3067.01 ms /    14 tokens (  219.07 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.32 ms /     3 runs   (  888.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5735.80 ms /    17 tokens\n",
      " 50%|โโโโโ     | 1757/3487 [5:22:36<3:32:16,  7.36s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2950.33 ms /    13 tokens (  226.95 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.74 ms /     3 runs   (  892.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5630.25 ms /    16 tokens\n",
      " 50%|โโโโโ     | 1758/3487 [5:22:42<3:17:15,  6.85s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3087.06 ms /    14 tokens (  220.50 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.63 ms /     3 runs   (  880.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5729.88 ms /    17 tokens\n",
      " 50%|โโโโโ     | 1759/3487 [5:22:48<3:07:34,  6.51s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9772.38 ms /    50 tokens (  195.45 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2894.49 ms /     3 runs   (  964.83 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   12668.90 ms /    53 tokens\n",
      " 50%|โโโโโ     | 1760/3487 [5:23:00<4:00:41,  8.36s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4540.83 ms /    22 tokens (  206.40 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.15 ms /     3 runs   (  884.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7197.59 ms /    25 tokens\n",
      " 51%|โโโโโ     | 1761/3487 [5:23:08<3:50:34,  8.02s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8885.51 ms /    47 tokens (  189.05 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.86 ms /     3 runs   (  882.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11536.74 ms /    50 tokens\n",
      " 51%|โโโโโ     | 1762/3487 [5:23:19<4:20:53,  9.07s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4749.28 ms /    24 tokens (  197.89 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.89 ms /     3 runs   (  886.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7410.93 ms /    27 tokens\n",
      " 51%|โโโโโ     | 1763/3487 [5:23:26<4:06:27,  8.58s/it]Llama.generate: 306 prefix-match hit, remaining 111 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20903.62 ms /   111 tokens (  188.32 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.24 ms /     3 runs   (  883.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23557.35 ms /   114 tokens\n",
      " 51%|โโโโโ     | 1764/3487 [5:23:50<6:15:26, 13.07s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11405.43 ms /    60 tokens (  190.09 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.91 ms /     3 runs   (  894.64 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14091.61 ms /    63 tokens\n",
      " 51%|โโโโโ     | 1765/3487 [5:24:04<6:24:02, 13.38s/it]Llama.generate: 307 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15245.47 ms /    79 tokens (  192.98 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.02 ms /     3 runs   (  903.01 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   17957.64 ms /    82 tokens\n",
      " 51%|โโโโโ     | 1766/3487 [5:24:22<7:03:16, 14.76s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4719.99 ms /    21 tokens (  224.76 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2746.80 ms /     3 runs   (  915.60 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7469.53 ms /    24 tokens\n",
      " 51%|โโโโโ     | 1767/3487 [5:24:30<6:00:25, 12.57s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5077.84 ms /    24 tokens (  211.58 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3672.31 ms /     4 runs   (  918.08 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8753.61 ms /    28 tokens\n",
      " 51%|โโโโโ     | 1768/3487 [5:24:38<5:27:28, 11.43s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3026.08 ms /    13 tokens (  232.78 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.71 ms /     3 runs   (  894.57 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5712.37 ms /    16 tokens\n",
      " 51%|โโโโโ     | 1769/3487 [5:24:44<4:38:13,  9.72s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5528.60 ms /    27 tokens (  204.76 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2744.33 ms /     3 runs   (  914.78 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8275.32 ms /    30 tokens\n",
      " 51%|โโโโโ     | 1770/3487 [5:24:52<4:25:45,  9.29s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9500.57 ms /    49 tokens (  193.89 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.21 ms /     3 runs   (  879.07 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12140.62 ms /    52 tokens\n",
      " 51%|โโโโโ     | 1771/3487 [5:25:04<4:50:10, 10.15s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8899.11 ms /    47 tokens (  189.34 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.88 ms /     3 runs   (  878.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11536.62 ms /    50 tokens\n",
      " 51%|โโโโโ     | 1772/3487 [5:25:16<5:01:59, 10.57s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4168.71 ms /    20 tokens (  208.44 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.37 ms /     3 runs   (  887.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6832.43 ms /    23 tokens\n",
      " 51%|โโโโโ     | 1773/3487 [5:25:23<4:29:53,  9.45s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9689.27 ms /    50 tokens (  193.79 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.75 ms /     3 runs   (  879.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12330.13 ms /    53 tokens\n",
      " 51%|โโโโโ     | 1774/3487 [5:25:35<4:54:30, 10.32s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3174.14 ms /    15 tokens (  211.61 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.90 ms /     3 runs   (  891.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5852.62 ms /    18 tokens\n",
      " 51%|โโโโโ     | 1775/3487 [5:25:41<4:16:13,  8.98s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4169.32 ms /    21 tokens (  198.54 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.29 ms /     3 runs   (  877.76 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6807.97 ms /    24 tokens\n",
      " 51%|โโโโโ     | 1776/3487 [5:25:48<3:57:34,  8.33s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4429.76 ms /    19 tokens (  233.15 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.35 ms /     3 runs   (  879.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7070.19 ms /    22 tokens\n",
      " 51%|โโโโโ     | 1777/3487 [5:25:55<3:46:42,  7.95s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4080.95 ms /    19 tokens (  214.79 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.98 ms /     3 runs   (  889.33 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6751.50 ms /    22 tokens\n",
      " 51%|โโโโโ     | 1778/3487 [5:26:02<3:36:21,  7.60s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7176.84 ms /    35 tokens (  205.05 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.44 ms /     3 runs   (  884.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9833.00 ms /    38 tokens\n",
      " 51%|โโโโโ     | 1779/3487 [5:26:12<3:55:23,  8.27s/it]Llama.generate: 306 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14207.67 ms /    75 tokens (  189.44 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.39 ms /     3 runs   (  879.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16847.62 ms /    78 tokens\n",
      " 51%|โโโโโ     | 1780/3487 [5:26:28<5:08:32, 10.85s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10121.82 ms /    54 tokens (  187.44 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.03 ms /     3 runs   (  885.68 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12781.64 ms /    57 tokens\n",
      " 51%|โโโโโ     | 1781/3487 [5:26:41<5:24:57, 11.43s/it]Llama.generate: 306 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13199.07 ms /    70 tokens (  188.56 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.46 ms /     3 runs   (  882.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15850.00 ms /    73 tokens\n",
      " 51%|โโโโโ     | 1782/3487 [5:26:57<6:02:31, 12.76s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7257.43 ms /    36 tokens (  201.60 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.99 ms /     3 runs   (  878.66 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9895.54 ms /    39 tokens\n",
      " 51%|โโโโโ     | 1783/3487 [5:27:07<5:38:00, 11.90s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9777.61 ms /    48 tokens (  203.70 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.22 ms /     3 runs   (  894.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12463.09 ms /    51 tokens\n",
      " 51%|โโโโโ     | 1784/3487 [5:27:19<5:42:39, 12.07s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7805.37 ms /    40 tokens (  195.13 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.20 ms /     3 runs   (  885.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10463.30 ms /    43 tokens\n",
      " 51%|โโโโโ     | 1785/3487 [5:27:30<5:28:50, 11.59s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4488.92 ms /    19 tokens (  236.26 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2812.95 ms /     3 runs   (  937.65 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7304.66 ms /    22 tokens\n",
      " 51%|โโโโโ     | 1786/3487 [5:27:37<4:52:15, 10.31s/it]Llama.generate: 307 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16097.79 ms /    84 tokens (  191.64 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.66 ms /     3 runs   (  885.89 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18758.25 ms /    87 tokens\n",
      " 51%|โโโโโ     | 1787/3487 [5:27:56<6:03:59, 12.85s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3085.87 ms /    13 tokens (  237.37 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.60 ms /     3 runs   (  904.20 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5801.25 ms /    16 tokens\n",
      " 51%|โโโโโโ    | 1788/3487 [5:28:02<5:04:00, 10.74s/it]Llama.generate: 307 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13700.76 ms /    71 tokens (  192.97 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.83 ms /     3 runs   (  877.28 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16335.55 ms /    74 tokens\n",
      " 51%|โโโโโโ    | 1789/3487 [5:28:18<5:51:41, 12.43s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2406.59 ms /     7 tokens (  343.80 ms per token,     2.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.59 ms /     3 runs   (  880.53 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5050.76 ms /    10 tokens\n",
      " 51%|โโโโโโ    | 1790/3487 [5:28:23<4:48:58, 10.22s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3961.26 ms /    19 tokens (  208.49 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.49 ms /     3 runs   (  894.16 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6646.47 ms /    22 tokens\n",
      " 51%|โโโโโโ    | 1791/3487 [5:28:30<4:18:35,  9.15s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3730.40 ms /    18 tokens (  207.24 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.77 ms /     3 runs   (  884.26 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6385.51 ms /    21 tokens\n",
      " 51%|โโโโโโ    | 1792/3487 [5:28:36<3:55:06,  8.32s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1759.08 ms /     6 tokens (  293.18 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.90 ms /     3 runs   (  881.97 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4407.21 ms /     9 tokens\n",
      " 51%|โโโโโโ    | 1793/3487 [5:28:41<3:21:53,  7.15s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4541.05 ms /    22 tokens (  206.41 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.01 ms /     3 runs   (  884.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7195.34 ms /    25 tokens\n",
      " 51%|โโโโโโ    | 1794/3487 [5:28:48<3:22:12,  7.17s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6043.53 ms /    31 tokens (  194.95 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.95 ms /     3 runs   (  885.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8701.89 ms /    34 tokens\n",
      " 51%|โโโโโโ    | 1795/3487 [5:28:57<3:35:08,  7.63s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6072.62 ms /    30 tokens (  202.42 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.38 ms /     3 runs   (  889.13 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8742.73 ms /    33 tokens\n",
      " 52%|โโโโโโ    | 1796/3487 [5:29:05<3:44:45,  7.97s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5831.75 ms /    30 tokens (  194.39 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.93 ms /     3 runs   (  895.31 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8520.74 ms /    33 tokens\n",
      " 52%|โโโโโโ    | 1797/3487 [5:29:14<3:49:18,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1954.53 ms /     7 tokens (  279.22 ms per token,     3.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.04 ms /     3 runs   (  898.68 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4653.05 ms /    10 tokens\n",
      " 52%|โโโโโโ    | 1798/3487 [5:29:19<3:19:46,  7.10s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3256.02 ms /    14 tokens (  232.57 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.29 ms /     3 runs   (  906.43 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5978.04 ms /    17 tokens\n",
      " 52%|โโโโโโ    | 1799/3487 [5:29:25<3:10:15,  6.76s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5759.16 ms /    29 tokens (  198.59 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.22 ms /     3 runs   (  884.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8414.65 ms /    32 tokens\n",
      " 52%|โโโโโโ    | 1800/3487 [5:29:33<3:24:09,  7.26s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3021.98 ms /    13 tokens (  232.46 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.41 ms /     3 runs   (  890.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5695.46 ms /    16 tokens\n",
      " 52%|โโโโโโ    | 1801/3487 [5:29:39<3:10:54,  6.79s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4071.37 ms /    17 tokens (  239.49 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.89 ms /     3 runs   (  880.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6715.46 ms /    20 tokens\n",
      " 52%|โโโโโโ    | 1802/3487 [5:29:45<3:10:12,  6.77s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7105.17 ms /    33 tokens (  215.31 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2732.11 ms /     3 runs   (  910.70 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    9840.12 ms /    36 tokens\n",
      " 52%|โโโโโโ    | 1803/3487 [5:29:55<3:35:58,  7.70s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4088.72 ms /    19 tokens (  215.20 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2726.95 ms /     3 runs   (  908.98 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6818.67 ms /    22 tokens\n",
      " 52%|โโโโโโ    | 1804/3487 [5:30:02<3:28:32,  7.43s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3330.90 ms /    15 tokens (  222.06 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2761.74 ms /     3 runs   (  920.58 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6095.55 ms /    18 tokens\n",
      " 52%|โโโโโโ    | 1805/3487 [5:30:08<3:17:14,  7.04s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9448.81 ms /    49 tokens (  192.83 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3363.88 ms /     3 runs   ( 1121.29 ms per token,     0.89 tokens per second)\n",
      "llama_perf_context_print:       total time =   12815.32 ms /    52 tokens\n",
      " 52%|โโโโโโ    | 1806/3487 [5:30:21<4:05:48,  8.77s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5977.95 ms /    23 tokens (  259.91 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3055.32 ms /     3 runs   ( 1018.44 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    9036.63 ms /    26 tokens\n",
      " 52%|โโโโโโ    | 1807/3487 [5:30:30<4:07:56,  8.86s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3887.06 ms /    18 tokens (  215.95 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.64 ms /     3 runs   (  886.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6549.29 ms /    21 tokens\n",
      " 52%|โโโโโโ    | 1808/3487 [5:30:37<3:48:30,  8.17s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5802.61 ms /    29 tokens (  200.09 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.93 ms /     3 runs   (  889.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8474.92 ms /    32 tokens\n",
      " 52%|โโโโโโ    | 1809/3487 [5:30:45<3:51:02,  8.26s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9423.70 ms /    49 tokens (  192.32 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2746.42 ms /     3 runs   (  915.47 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   12172.55 ms /    52 tokens\n",
      " 52%|โโโโโโ    | 1810/3487 [5:30:57<4:23:45,  9.44s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3045.67 ms /    13 tokens (  234.28 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.19 ms /     3 runs   (  880.06 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5688.61 ms /    16 tokens\n",
      " 52%|โโโโโโ    | 1811/3487 [5:31:03<3:52:15,  8.31s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7291.09 ms /    36 tokens (  202.53 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.68 ms /     3 runs   (  883.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9944.01 ms /    39 tokens\n",
      " 52%|โโโโโโ    | 1812/3487 [5:31:13<4:05:49,  8.81s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5631.12 ms /    29 tokens (  194.18 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.60 ms /     3 runs   (  898.87 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8329.96 ms /    32 tokens\n",
      " 52%|โโโโโโ    | 1813/3487 [5:31:21<4:01:46,  8.67s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3058.19 ms /    12 tokens (  254.85 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.95 ms /     3 runs   (  878.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5696.44 ms /    15 tokens\n",
      " 52%|โโโโโโ    | 1814/3487 [5:31:27<3:36:51,  7.78s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3631.18 ms /    17 tokens (  213.60 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.19 ms /     3 runs   (  891.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6307.58 ms /    20 tokens\n",
      " 52%|โโโโโโ    | 1815/3487 [5:31:33<3:24:30,  7.34s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1759.16 ms /     6 tokens (  293.19 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.48 ms /     3 runs   (  877.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4393.73 ms /     9 tokens\n",
      " 52%|โโโโโโ    | 1816/3487 [5:31:38<2:59:51,  6.46s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2719.10 ms /    12 tokens (  226.59 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.42 ms /     3 runs   (  890.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5394.31 ms /    15 tokens\n",
      " 52%|โโโโโโ    | 1817/3487 [5:31:43<2:50:56,  6.14s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7464.47 ms /    38 tokens (  196.43 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.34 ms /     3 runs   (  883.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10116.66 ms /    41 tokens\n",
      " 52%|โโโโโโ    | 1818/3487 [5:31:53<3:24:04,  7.34s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11026.44 ms /    59 tokens (  186.89 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.93 ms /     3 runs   (  876.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13657.73 ms /    62 tokens\n",
      " 52%|โโโโโโ    | 1819/3487 [5:32:07<4:16:43,  9.23s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3216.80 ms /    15 tokens (  214.45 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.14 ms /     3 runs   (  883.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5868.36 ms /    18 tokens\n",
      " 52%|โโโโโโ    | 1820/3487 [5:32:13<3:48:35,  8.23s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1485.01 ms /     5 tokens (  297.00 ms per token,     3.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2773.57 ms /     3 runs   (  924.52 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    4261.37 ms /     8 tokens\n",
      " 52%|โโโโโโ    | 1821/3487 [5:32:17<3:15:29,  7.04s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5664.68 ms /    29 tokens (  195.33 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.68 ms /     3 runs   (  878.56 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8302.76 ms /    32 tokens\n",
      " 52%|โโโโโโ    | 1822/3487 [5:32:25<3:25:56,  7.42s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7553.31 ms /    37 tokens (  204.14 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.21 ms /     3 runs   (  872.40 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10172.76 ms /    40 tokens\n",
      " 52%|โโโโโโ    | 1823/3487 [5:32:36<3:48:47,  8.25s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8930.07 ms /    47 tokens (  190.00 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.01 ms /     3 runs   (  883.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11583.54 ms /    50 tokens\n",
      " 52%|โโโโโโ    | 1824/3487 [5:32:47<4:16:26,  9.25s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3906.61 ms /    18 tokens (  217.03 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.91 ms /     3 runs   (  913.30 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6648.92 ms /    21 tokens\n",
      " 52%|โโโโโโ    | 1825/3487 [5:32:54<3:54:42,  8.47s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9088.14 ms /    47 tokens (  193.36 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.12 ms /     3 runs   (  893.04 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11769.28 ms /    50 tokens\n",
      " 52%|โโโโโโ    | 1826/3487 [5:33:06<4:22:00,  9.46s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3861.41 ms /    16 tokens (  241.34 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.99 ms /     3 runs   (  892.00 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6540.02 ms /    19 tokens\n",
      " 52%|โโโโโโ    | 1827/3487 [5:33:12<3:57:39,  8.59s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1730.46 ms /     6 tokens (  288.41 ms per token,     3.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2742.20 ms /     3 runs   (  914.07 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4474.81 ms /     9 tokens\n",
      " 52%|โโโโโโ    | 1828/3487 [5:33:17<3:23:27,  7.36s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3046.07 ms /    13 tokens (  234.31 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.26 ms /     3 runs   (  886.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5709.11 ms /    16 tokens\n",
      " 52%|โโโโโโ    | 1829/3487 [5:33:22<3:09:44,  6.87s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4125.00 ms /    20 tokens (  206.25 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.61 ms /     3 runs   (  881.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6771.08 ms /    23 tokens\n",
      " 52%|โโโโโโ    | 1830/3487 [5:33:29<3:08:55,  6.84s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2465.69 ms /    10 tokens (  246.57 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.74 ms /     3 runs   (  887.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5130.92 ms /    13 tokens\n",
      " 53%|โโโโโโ    | 1831/3487 [5:33:34<2:54:42,  6.33s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15878.57 ms /    86 tokens (  184.63 ms per token,     5.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.29 ms /     3 runs   (  885.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18538.11 ms /    89 tokens\n",
      " 53%|โโโโโโ    | 1832/3487 [5:33:53<4:35:41,  9.99s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4511.53 ms /    22 tokens (  205.07 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.74 ms /     3 runs   (  899.25 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7211.20 ms /    25 tokens\n",
      " 53%|โโโโโโ    | 1833/3487 [5:34:00<4:12:33,  9.16s/it]Llama.generate: 308 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3930.20 ms /    18 tokens (  218.34 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.59 ms /     3 runs   (  893.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6613.10 ms /    21 tokens\n",
      " 53%|โโโโโโ    | 1834/3487 [5:34:07<3:51:24,  8.40s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2538.44 ms /    10 tokens (  253.84 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.59 ms /     3 runs   (  883.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5190.82 ms /    13 tokens\n",
      " 53%|โโโโโโ    | 1835/3487 [5:34:12<3:24:49,  7.44s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9209.69 ms /    48 tokens (  191.87 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.74 ms /     3 runs   (  885.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11868.06 ms /    51 tokens\n",
      " 53%|โโโโโโ    | 1836/3487 [5:34:24<4:01:20,  8.77s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1999.99 ms /     8 tokens (  250.00 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.90 ms /     3 runs   (  886.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4661.42 ms /    11 tokens\n",
      " 53%|โโโโโโ    | 1837/3487 [5:34:28<3:27:20,  7.54s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2989.41 ms /    13 tokens (  229.95 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.81 ms /     3 runs   (  905.60 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5708.91 ms /    16 tokens\n",
      " 53%|โโโโโโ    | 1838/3487 [5:34:34<3:12:11,  6.99s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2408.33 ms /     8 tokens (  301.04 ms per token,     3.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.30 ms /     3 runs   (  883.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5060.54 ms /    11 tokens\n",
      " 53%|โโโโโโ    | 1839/3487 [5:34:39<2:56:14,  6.42s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2725.62 ms /    12 tokens (  227.13 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.38 ms /     3 runs   (  879.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5366.30 ms /    15 tokens\n",
      " 53%|โโโโโโ    | 1840/3487 [5:34:45<2:47:33,  6.10s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7214.36 ms /    35 tokens (  206.12 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2814.91 ms /     3 runs   (  938.30 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   10031.17 ms /    38 tokens\n",
      " 53%|โโโโโโ    | 1841/3487 [5:34:55<3:19:51,  7.29s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4885.87 ms /    24 tokens (  203.58 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2803.81 ms /     3 runs   (  934.60 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7692.44 ms /    27 tokens\n",
      " 53%|โโโโโโ    | 1842/3487 [5:35:02<3:23:09,  7.41s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5238.10 ms /    26 tokens (  201.47 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2770.19 ms /     3 runs   (  923.40 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8011.75 ms /    29 tokens\n",
      " 53%|โโโโโโ    | 1843/3487 [5:35:10<3:28:02,  7.59s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3027.61 ms /    13 tokens (  232.89 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.42 ms /     3 runs   (  886.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5688.68 ms /    16 tokens\n",
      " 53%|โโโโโโ    | 1844/3487 [5:35:16<3:12:20,  7.02s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4036.74 ms /    19 tokens (  212.46 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.16 ms /     3 runs   (  880.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6680.96 ms /    22 tokens\n",
      " 53%|โโโโโโ    | 1845/3487 [5:35:23<3:09:44,  6.93s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2988.50 ms /    13 tokens (  229.88 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.03 ms /     3 runs   (  876.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5621.69 ms /    16 tokens\n",
      " 53%|โโโโโโ    | 1846/3487 [5:35:28<2:58:56,  6.54s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5525.89 ms /    28 tokens (  197.35 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.76 ms /     3 runs   (  877.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8160.38 ms /    31 tokens\n",
      " 53%|โโโโโโ    | 1847/3487 [5:35:37<3:12:10,  7.03s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7421.46 ms /    36 tokens (  206.15 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.55 ms /     3 runs   (  879.85 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10063.04 ms /    39 tokens\n",
      " 53%|โโโโโโ    | 1848/3487 [5:35:47<3:36:59,  7.94s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3714.03 ms /    18 tokens (  206.34 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.44 ms /     3 runs   (  890.48 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6388.64 ms /    21 tokens\n",
      " 53%|โโโโโโ    | 1849/3487 [5:35:53<3:24:12,  7.48s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3634.05 ms /    17 tokens (  213.77 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.32 ms /     3 runs   (  886.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6295.52 ms /    20 tokens\n",
      " 53%|โโโโโโ    | 1850/3487 [5:35:59<3:14:27,  7.13s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2325.82 ms /     7 tokens (  332.26 ms per token,     3.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.89 ms /     3 runs   (  883.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4979.33 ms /    10 tokens\n",
      " 53%|โโโโโโ    | 1851/3487 [5:36:04<2:56:50,  6.49s/it]Llama.generate: 306 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11746.11 ms /    63 tokens (  186.45 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.45 ms /     3 runs   (  874.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14373.30 ms /    66 tokens\n",
      " 53%|โโโโโโ    | 1852/3487 [5:36:19<4:01:16,  8.85s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2151.43 ms /     9 tokens (  239.05 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.18 ms /     3 runs   (  884.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4805.47 ms /    12 tokens\n",
      " 53%|โโโโโโ    | 1853/3487 [5:36:24<3:28:22,  7.65s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2242.95 ms /     9 tokens (  249.22 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.88 ms /     3 runs   (  890.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4917.14 ms /    12 tokens\n",
      " 53%|โโโโโโ    | 1854/3487 [5:36:28<3:05:59,  6.83s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2064.40 ms /     8 tokens (  258.05 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.44 ms /     3 runs   (  886.81 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4727.43 ms /    11 tokens\n",
      " 53%|โโโโโโ    | 1855/3487 [5:36:33<2:48:44,  6.20s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2669.78 ms /    11 tokens (  242.71 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.57 ms /     3 runs   (  893.52 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5352.89 ms /    14 tokens\n",
      " 53%|โโโโโโ    | 1856/3487 [5:36:39<2:41:46,  5.95s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1623.08 ms /     5 tokens (  324.62 ms per token,     3.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.94 ms /     3 runs   (  891.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4302.32 ms /     8 tokens\n",
      " 53%|โโโโโโ    | 1857/3487 [5:36:43<2:28:18,  5.46s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1646.55 ms /     5 tokens (  329.31 ms per token,     3.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.11 ms /     3 runs   (  882.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4296.82 ms /     8 tokens\n",
      " 53%|โโโโโโ    | 1858/3487 [5:36:47<2:18:48,  5.11s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3524.51 ms /    16 tokens (  220.28 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.20 ms /     3 runs   (  905.73 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6244.25 ms /    19 tokens\n",
      " 53%|โโโโโโ    | 1859/3487 [5:36:53<2:28:00,  5.46s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5541.94 ms /    28 tokens (  197.93 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.37 ms /     3 runs   (  900.79 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8247.18 ms /    31 tokens\n",
      " 53%|โโโโโโ    | 1860/3487 [5:37:02<2:50:42,  6.30s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7859.24 ms /    40 tokens (  196.48 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.64 ms /     3 runs   (  882.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10509.08 ms /    43 tokens\n",
      " 53%|โโโโโโ    | 1861/3487 [5:37:12<3:24:55,  7.56s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3131.78 ms /    14 tokens (  223.70 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.54 ms /     3 runs   (  892.18 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5810.84 ms /    17 tokens\n",
      " 53%|โโโโโโ    | 1862/3487 [5:37:18<3:10:38,  7.04s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4931.64 ms /    22 tokens (  224.17 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.43 ms /     3 runs   (  882.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7581.33 ms /    25 tokens\n",
      " 53%|โโโโโโ    | 1863/3487 [5:37:26<3:14:59,  7.20s/it]Llama.generate: 327 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3833.98 ms /     4 runs   (  958.49 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    3837.32 ms /     5 tokens\n",
      " 53%|โโโโโโ    | 1864/3487 [5:37:29<2:47:36,  6.20s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4120.36 ms /    19 tokens (  216.86 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.28 ms /     3 runs   (  881.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6766.15 ms /    22 tokens\n",
      " 53%|โโโโโโ    | 1865/3487 [5:37:36<2:52:12,  6.37s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2680.68 ms /    12 tokens (  223.39 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.13 ms /     3 runs   (  884.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5336.87 ms /    15 tokens\n",
      " 54%|โโโโโโ    | 1866/3487 [5:37:42<2:43:48,  6.06s/it]Llama.generate: 310 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2535.12 ms /    10 tokens (  253.51 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.73 ms /     3 runs   (  888.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5203.57 ms /    13 tokens\n",
      " 54%|โโโโโโ    | 1867/3487 [5:37:47<2:36:48,  5.81s/it]Llama.generate: 306 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16337.35 ms /    83 tokens (  196.84 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.91 ms /     3 runs   (  880.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18983.05 ms /    86 tokens\n",
      " 54%|โโโโโโ    | 1868/3487 [5:38:06<4:23:26,  9.76s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5091.33 ms /    25 tokens (  203.65 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.04 ms /     3 runs   (  882.01 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7740.02 ms /    28 tokens\n",
      " 54%|โโโโโโ    | 1869/3487 [5:38:14<4:06:59,  9.16s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2484.33 ms /    10 tokens (  248.43 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.91 ms /     3 runs   (  882.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5133.24 ms /    13 tokens\n",
      " 54%|โโโโโโ    | 1870/3487 [5:38:19<3:34:21,  7.95s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3562.04 ms /    16 tokens (  222.63 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2877.76 ms /     3 runs   (  959.25 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    6442.33 ms /    19 tokens\n",
      " 54%|โโโโโโ    | 1871/3487 [5:38:25<3:22:04,  7.50s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2686.83 ms /    12 tokens (  223.90 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.45 ms /     3 runs   (  880.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5331.71 ms /    15 tokens\n",
      " 54%|โโโโโโ    | 1872/3487 [5:38:30<3:04:28,  6.85s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2497.41 ms /    10 tokens (  249.74 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.84 ms /     3 runs   (  885.28 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5155.84 ms /    13 tokens\n",
      " 54%|โโโโโโ    | 1873/3487 [5:38:36<2:50:44,  6.35s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7743.71 ms /    39 tokens (  198.56 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.90 ms /     3 runs   (  880.63 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10388.40 ms /    42 tokens\n",
      " 54%|โโโโโโ    | 1874/3487 [5:38:46<3:23:17,  7.56s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3304.12 ms /    13 tokens (  254.16 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.53 ms /     3 runs   (  883.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5958.01 ms /    16 tokens\n",
      " 54%|โโโโโโ    | 1875/3487 [5:38:52<3:10:19,  7.08s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3225.08 ms /    15 tokens (  215.01 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.68 ms /     3 runs   (  888.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5894.30 ms /    18 tokens\n",
      " 54%|โโโโโโ    | 1876/3487 [5:38:58<3:00:41,  6.73s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9149.76 ms /    47 tokens (  194.68 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.64 ms /     3 runs   (  877.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11784.12 ms /    50 tokens\n",
      " 54%|โโโโโโ    | 1877/3487 [5:39:10<3:41:19,  8.25s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3177.59 ms /    14 tokens (  226.97 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.83 ms /     3 runs   (  895.61 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5866.91 ms /    17 tokens\n",
      " 54%|โโโโโโ    | 1878/3487 [5:39:16<3:22:05,  7.54s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8772.39 ms /    45 tokens (  194.94 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.40 ms /     3 runs   (  882.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11421.32 ms /    48 tokens\n",
      " 54%|โโโโโโ    | 1879/3487 [5:39:27<3:53:17,  8.71s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2569.96 ms /    11 tokens (  233.63 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2703.72 ms /     3 runs   (  901.24 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5275.84 ms /    14 tokens\n",
      " 54%|โโโโโโ    | 1880/3487 [5:39:32<3:25:40,  7.68s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1985.20 ms /     7 tokens (  283.60 ms per token,     3.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.61 ms /     3 runs   (  887.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4650.23 ms /    10 tokens\n",
      " 54%|โโโโโโ    | 1881/3487 [5:39:37<3:01:18,  6.77s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1957.42 ms /     7 tokens (  279.63 ms per token,     3.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.86 ms /     3 runs   (  884.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4613.98 ms /    10 tokens\n",
      " 54%|โโโโโโ    | 1882/3487 [5:39:42<2:43:56,  6.13s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3663.91 ms /    17 tokens (  215.52 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.13 ms /     3 runs   (  880.71 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6308.64 ms /    20 tokens\n",
      " 54%|โโโโโโ    | 1883/3487 [5:39:48<2:45:20,  6.18s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2737.26 ms /    12 tokens (  228.10 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.05 ms /     3 runs   (  881.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5382.51 ms /    15 tokens\n",
      " 54%|โโโโโโ    | 1884/3487 [5:39:53<2:38:51,  5.95s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9358.65 ms /    39 tokens (  239.97 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2755.03 ms /     3 runs   (  918.34 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   12116.88 ms /    42 tokens\n",
      " 54%|โโโโโโ    | 1885/3487 [5:40:05<3:28:17,  7.80s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12550.10 ms /    62 tokens (  202.42 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.19 ms /     3 runs   (  883.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15203.23 ms /    65 tokens\n",
      " 54%|โโโโโโ    | 1886/3487 [5:40:21<4:27:29, 10.02s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4656.72 ms /    21 tokens (  221.75 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.70 ms /     3 runs   (  896.57 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7349.36 ms /    24 tokens\n",
      " 54%|โโโโโโ    | 1887/3487 [5:40:28<4:05:58,  9.22s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2784.19 ms /    12 tokens (  232.02 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.96 ms /     3 runs   (  901.65 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5491.40 ms /    15 tokens\n",
      " 54%|โโโโโโ    | 1888/3487 [5:40:33<3:36:02,  8.11s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5893.28 ms /    30 tokens (  196.44 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.40 ms /     3 runs   (  884.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8547.94 ms /    33 tokens\n",
      " 54%|โโโโโโ    | 1889/3487 [5:40:42<3:39:30,  8.24s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10209.33 ms /    54 tokens (  189.06 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.66 ms /     3 runs   (  892.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12890.86 ms /    57 tokens\n",
      " 54%|โโโโโโ    | 1890/3487 [5:40:55<4:16:32,  9.64s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7259.87 ms /    36 tokens (  201.66 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4781.01 ms /     3 runs   ( 1593.67 ms per token,     0.63 tokens per second)\n",
      "llama_perf_context_print:       total time =   12043.38 ms /    39 tokens\n",
      " 54%|โโโโโโ    | 1891/3487 [5:41:07<4:35:39, 10.36s/it]Llama.generate: 308 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10372.43 ms /    42 tokens (  246.96 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2885.98 ms /     3 runs   (  961.99 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   13261.51 ms /    45 tokens\n",
      " 54%|โโโโโโ    | 1892/3487 [5:41:20<4:58:40, 11.24s/it]Llama.generate: 307 prefix-match hit, remaining 136 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25472.31 ms /   136 tokens (  187.30 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.80 ms /     3 runs   (  881.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   28118.87 ms /   139 tokens\n",
      " 54%|โโโโโโ    | 1893/3487 [5:41:48<7:13:07, 16.30s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9588.52 ms /    50 tokens (  191.77 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.64 ms /     3 runs   (  886.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12250.96 ms /    53 tokens\n",
      " 54%|โโโโโโ    | 1894/3487 [5:42:01<6:40:39, 15.09s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3996.08 ms /    19 tokens (  210.32 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.06 ms /     3 runs   (  890.35 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6669.64 ms /    22 tokens\n",
      " 54%|โโโโโโ    | 1895/3487 [5:42:07<5:33:27, 12.57s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3712.15 ms /    17 tokens (  218.36 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.30 ms /     3 runs   (  902.77 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6422.73 ms /    20 tokens\n",
      " 54%|โโโโโโ    | 1896/3487 [5:42:14<4:44:25, 10.73s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3198.87 ms /    12 tokens (  266.57 ms per token,     3.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.41 ms /     3 runs   (  883.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5852.22 ms /    15 tokens\n",
      " 54%|โโโโโโ    | 1897/3487 [5:42:20<4:05:33,  9.27s/it]Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8561.35 ms /    44 tokens (  194.58 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.29 ms /     3 runs   (  881.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11207.22 ms /    47 tokens\n",
      " 54%|โโโโโโ    | 1898/3487 [5:42:31<4:20:52,  9.85s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2739.61 ms /    12 tokens (  228.30 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.83 ms /     3 runs   (  897.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5435.25 ms /    15 tokens\n",
      " 54%|โโโโโโ    | 1899/3487 [5:42:36<3:45:43,  8.53s/it]Llama.generate: 306 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11013.22 ms /    58 tokens (  189.88 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.45 ms /     3 runs   (  879.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13653.94 ms /    61 tokens\n",
      " 54%|โโโโโโ    | 1900/3487 [5:42:50<4:26:19, 10.07s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4762.63 ms /    23 tokens (  207.07 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.72 ms /     3 runs   (  902.57 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7472.57 ms /    26 tokens\n",
      " 55%|โโโโโโ    | 1901/3487 [5:42:57<4:05:37,  9.29s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7837.89 ms /    40 tokens (  195.95 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.75 ms /     3 runs   (  889.92 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10510.26 ms /    43 tokens\n",
      " 55%|โโโโโโ    | 1902/3487 [5:43:08<4:15:11,  9.66s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7188.85 ms /    35 tokens (  205.40 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.34 ms /     3 runs   (  877.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9825.32 ms /    38 tokens\n",
      " 55%|โโโโโโ    | 1903/3487 [5:43:18<4:16:23,  9.71s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4253.88 ms /    20 tokens (  212.69 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.28 ms /     3 runs   (  896.76 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6947.07 ms /    23 tokens\n",
      " 55%|โโโโโโ    | 1904/3487 [5:43:25<3:54:26,  8.89s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8887.62 ms /    44 tokens (  201.99 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.73 ms /     3 runs   (  882.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11537.48 ms /    47 tokens\n",
      " 55%|โโโโโโ    | 1905/3487 [5:43:36<4:15:21,  9.68s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7188.97 ms /    34 tokens (  211.44 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.41 ms /     3 runs   (  887.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9853.84 ms /    37 tokens\n",
      " 55%|โโโโโโ    | 1906/3487 [5:43:46<4:16:34,  9.74s/it]Llama.generate: 308 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2562.77 ms /    11 tokens (  232.98 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.33 ms /     3 runs   (  887.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5227.74 ms /    14 tokens\n",
      " 55%|โโโโโโ    | 1907/3487 [5:43:51<3:40:51,  8.39s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7917.04 ms /    40 tokens (  197.93 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.49 ms /     3 runs   (  879.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10559.48 ms /    43 tokens\n",
      " 55%|โโโโโโ    | 1908/3487 [5:44:02<3:57:56,  9.04s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2644.32 ms /     9 tokens (  293.81 ms per token,     3.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.21 ms /     3 runs   (  886.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5304.46 ms /    12 tokens\n",
      " 55%|โโโโโโ    | 1909/3487 [5:44:07<3:28:22,  7.92s/it]Llama.generate: 307 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13934.48 ms /    73 tokens (  190.88 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.46 ms /     3 runs   (  876.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16568.23 ms /    76 tokens\n",
      " 55%|โโโโโโ    | 1910/3487 [5:44:24<4:36:27, 10.52s/it]Llama.generate: 307 prefix-match hit, remaining 180 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   33128.06 ms /   180 tokens (  184.04 ms per token,     5.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.64 ms /     3 runs   (  883.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   35782.32 ms /   183 tokens\n",
      " 55%|โโโโโโ    | 1911/3487 [5:45:00<7:55:28, 18.10s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12989.36 ms /    65 tokens (  199.84 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.65 ms /     3 runs   (  880.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15633.93 ms /    68 tokens\n",
      " 55%|โโโโโโ    | 1912/3487 [5:45:15<7:35:48, 17.36s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9217.15 ms /    48 tokens (  192.02 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.38 ms /     3 runs   (  883.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11871.45 ms /    51 tokens\n",
      " 55%|โโโโโโ    | 1913/3487 [5:45:27<6:52:21, 15.72s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4278.28 ms /    21 tokens (  203.73 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.97 ms /     3 runs   (  890.32 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6951.96 ms /    24 tokens\n",
      " 55%|โโโโโโ    | 1914/3487 [5:45:34<5:43:12, 13.09s/it]Llama.generate: 306 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13164.96 ms /    70 tokens (  188.07 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.33 ms /     3 runs   (  884.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15821.58 ms /    73 tokens\n",
      " 55%|โโโโโโ    | 1915/3487 [5:45:50<6:04:30, 13.91s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5157.17 ms /    26 tokens (  198.35 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.08 ms /     3 runs   (  900.03 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7860.00 ms /    29 tokens\n",
      " 55%|โโโโโโ    | 1916/3487 [5:45:58<5:16:48, 12.10s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9026.67 ms /    46 tokens (  196.23 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.50 ms /     3 runs   (  898.83 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11726.09 ms /    49 tokens\n",
      " 55%|โโโโโโ    | 1917/3487 [5:46:10<5:13:44, 11.99s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3370.69 ms /    15 tokens (  224.71 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.61 ms /     3 runs   (  905.87 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6090.91 ms /    18 tokens\n",
      " 55%|โโโโโโ    | 1918/3487 [5:46:16<4:27:18, 10.22s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8709.93 ms /    45 tokens (  193.55 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.09 ms /     3 runs   (  891.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11386.44 ms /    48 tokens\n",
      " 55%|โโโโโโ    | 1919/3487 [5:46:27<4:36:20, 10.57s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5100.84 ms /    25 tokens (  204.03 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.49 ms /     3 runs   (  905.83 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7821.23 ms /    28 tokens\n",
      " 55%|โโโโโโ    | 1920/3487 [5:46:35<4:14:39,  9.75s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4426.11 ms /    19 tokens (  232.95 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2762.48 ms /     3 runs   (  920.83 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7191.73 ms /    22 tokens\n",
      " 55%|โโโโโโ    | 1921/3487 [5:46:42<3:54:31,  8.99s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3574.77 ms /    16 tokens (  223.42 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.59 ms /     3 runs   (  889.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6245.73 ms /    19 tokens\n",
      " 55%|โโโโโโ    | 1922/3487 [5:46:48<3:33:00,  8.17s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1785.66 ms /     6 tokens (  297.61 ms per token,     3.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.27 ms /     3 runs   (  893.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4467.72 ms /     9 tokens\n",
      " 55%|โโโโโโ    | 1923/3487 [5:46:53<3:04:00,  7.06s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3606.71 ms /    16 tokens (  225.42 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.40 ms /     3 runs   (  902.47 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6316.25 ms /    19 tokens\n",
      " 55%|โโโโโโ    | 1924/3487 [5:46:59<2:58:08,  6.84s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4679.16 ms /    23 tokens (  203.44 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.17 ms /     3 runs   (  881.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7330.69 ms /    26 tokens\n",
      " 55%|โโโโโโ    | 1925/3487 [5:47:06<3:01:57,  6.99s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3997.47 ms /    19 tokens (  210.39 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.66 ms /     3 runs   (  906.89 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6720.79 ms /    22 tokens\n",
      " 55%|โโโโโโ    | 1926/3487 [5:47:13<2:59:48,  6.91s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3153.87 ms /    14 tokens (  225.28 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.28 ms /     3 runs   (  893.43 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5836.73 ms /    17 tokens\n",
      " 55%|โโโโโโ    | 1927/3487 [5:47:19<2:51:23,  6.59s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15986.93 ms /    86 tokens (  185.89 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.08 ms /     3 runs   (  897.36 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   18681.98 ms /    89 tokens\n",
      " 55%|โโโโโโ    | 1928/3487 [5:47:38<4:25:35, 10.22s/it]Llama.generate: 311 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2733.37 ms /    12 tokens (  227.78 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.81 ms /     3 runs   (  899.27 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5433.71 ms /    15 tokens\n",
      " 55%|โโโโโโ    | 1929/3487 [5:47:43<3:48:11,  8.79s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6328.49 ms /    31 tokens (  204.14 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.24 ms /     3 runs   (  898.75 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9028.00 ms /    34 tokens\n",
      " 55%|โโโโโโ    | 1930/3487 [5:47:52<3:49:59,  8.86s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8596.74 ms /    43 tokens (  199.92 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.09 ms /     3 runs   (  883.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11248.34 ms /    46 tokens\n",
      " 55%|โโโโโโ    | 1931/3487 [5:48:03<4:08:27,  9.58s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5078.08 ms /    25 tokens (  203.12 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2763.74 ms /     3 runs   (  921.25 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7845.14 ms /    28 tokens\n",
      " 55%|โโโโโโ    | 1932/3487 [5:48:11<3:54:53,  9.06s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7491.40 ms /    33 tokens (  227.01 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2762.54 ms /     3 runs   (  920.85 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10256.64 ms /    36 tokens\n",
      " 55%|โโโโโโ    | 1933/3487 [5:48:22<4:04:04,  9.42s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7780.82 ms /    36 tokens (  216.13 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.59 ms /     3 runs   (  888.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10448.73 ms /    39 tokens\n",
      " 55%|โโโโโโ    | 1934/3487 [5:48:32<4:11:55,  9.73s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4333.37 ms /    21 tokens (  206.35 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.57 ms /     3 runs   (  893.86 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7017.65 ms /    24 tokens\n",
      " 55%|โโโโโโ    | 1935/3487 [5:48:39<3:50:45,  8.92s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5097.76 ms /    24 tokens (  212.41 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2728.63 ms /     3 runs   (  909.54 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7829.44 ms /    27 tokens\n",
      " 56%|โโโโโโ    | 1936/3487 [5:48:47<3:42:14,  8.60s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3505.14 ms /    16 tokens (  219.07 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.15 ms /     3 runs   (  900.38 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6208.71 ms /    19 tokens\n",
      " 56%|โโโโโโ    | 1937/3487 [5:48:53<3:23:38,  7.88s/it]Llama.generate: 306 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11109.76 ms /    58 tokens (  191.55 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.51 ms /     3 runs   (  890.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13785.68 ms /    61 tokens\n",
      " 56%|โโโโโโ    | 1938/3487 [5:49:07<4:09:17,  9.66s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3159.94 ms /    14 tokens (  225.71 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2727.64 ms /     3 runs   (  909.21 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5889.95 ms /    17 tokens\n",
      " 56%|โโโโโโ    | 1939/3487 [5:49:13<3:40:03,  8.53s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13217.11 ms /    69 tokens (  191.55 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.35 ms /     3 runs   (  890.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15889.68 ms /    72 tokens\n",
      " 56%|โโโโโโ    | 1940/3487 [5:49:29<4:36:54, 10.74s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2041.42 ms /     8 tokens (  255.18 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.94 ms /     3 runs   (  896.65 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4734.10 ms /    11 tokens\n",
      " 56%|โโโโโโ    | 1941/3487 [5:49:33<3:50:22,  8.94s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7486.32 ms /    37 tokens (  202.33 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.49 ms /     3 runs   (  891.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10164.13 ms /    40 tokens\n",
      " 56%|โโโโโโ    | 1942/3487 [5:49:44<3:59:44,  9.31s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2034.68 ms /     7 tokens (  290.67 ms per token,     3.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.00 ms /     3 runs   (  905.67 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4753.98 ms /    10 tokens\n",
      " 56%|โโโโโโ    | 1943/3487 [5:49:48<3:24:28,  7.95s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8497.73 ms /    44 tokens (  193.13 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.63 ms /     3 runs   (  885.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11156.80 ms /    47 tokens\n",
      " 56%|โโโโโโ    | 1944/3487 [5:50:00<3:49:09,  8.91s/it]Llama.generate: 310 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4319.71 ms /    18 tokens (  239.98 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2875.98 ms /     3 runs   (  958.66 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    7198.32 ms /    21 tokens\n",
      " 56%|โโโโโโ    | 1945/3487 [5:50:07<3:35:52,  8.40s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2630.58 ms /    11 tokens (  239.14 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2703.99 ms /     3 runs   (  901.33 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5337.36 ms /    14 tokens\n",
      " 56%|โโโโโโ    | 1946/3487 [5:50:12<3:12:12,  7.48s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4969.42 ms /    23 tokens (  216.06 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.44 ms /     3 runs   (  893.48 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7652.82 ms /    26 tokens\n",
      " 56%|โโโโโโ    | 1947/3487 [5:50:20<3:13:26,  7.54s/it]Llama.generate: 307 prefix-match hit, remaining 104 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19627.98 ms /   104 tokens (  188.73 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.99 ms /     3 runs   (  886.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   22291.92 ms /   107 tokens\n",
      " 56%|โโโโโโ    | 1948/3487 [5:50:42<5:06:55, 11.97s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3696.41 ms /    17 tokens (  217.44 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.46 ms /     3 runs   (  893.49 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6379.42 ms /    20 tokens\n",
      " 56%|โโโโโโ    | 1949/3487 [5:50:48<4:23:50, 10.29s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5168.34 ms /    26 tokens (  198.78 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.34 ms /     3 runs   (  895.45 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7857.54 ms /    29 tokens\n",
      " 56%|โโโโโโ    | 1950/3487 [5:50:56<4:05:01,  9.57s/it]Llama.generate: 310 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4718.46 ms /    22 tokens (  214.48 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.77 ms /     3 runs   (  900.59 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7422.90 ms /    25 tokens\n",
      " 56%|โโโโโโ    | 1951/3487 [5:51:04<3:48:29,  8.93s/it]Llama.generate: 321 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2792.52 ms /    12 tokens (  232.71 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.92 ms /     3 runs   (  901.64 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5500.18 ms /    15 tokens\n",
      " 56%|โโโโโโ    | 1952/3487 [5:51:09<3:22:06,  7.90s/it]Llama.generate: 306 prefix-match hit, remaining 89 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16700.03 ms /    89 tokens (  187.64 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.36 ms /     3 runs   (  894.45 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   19386.22 ms /    92 tokens\n",
      " 56%|โโโโโโ    | 1953/3487 [5:51:29<4:50:08, 11.35s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7542.63 ms /    37 tokens (  203.85 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.00 ms /     3 runs   (  883.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10195.25 ms /    40 tokens\n",
      " 56%|โโโโโโ    | 1954/3487 [5:51:39<4:41:11, 11.01s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5204.66 ms /    26 tokens (  200.18 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.65 ms /     3 runs   (  890.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7879.28 ms /    29 tokens\n",
      " 56%|โโโโโโ    | 1955/3487 [5:51:47<4:17:06, 10.07s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7283.26 ms /    34 tokens (  214.21 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2753.67 ms /     3 runs   (  917.89 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10040.08 ms /    37 tokens\n",
      " 56%|โโโโโโ    | 1956/3487 [5:51:57<4:17:02, 10.07s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2862.91 ms /     9 tokens (  318.10 ms per token,     3.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2809.57 ms /     3 runs   (  936.52 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5675.22 ms /    12 tokens\n",
      " 56%|โโโโโโ    | 1957/3487 [5:52:02<3:43:16,  8.76s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8385.91 ms /    42 tokens (  199.66 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.72 ms /     3 runs   (  896.57 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11077.77 ms /    45 tokens\n",
      " 56%|โโโโโโ    | 1958/3487 [5:52:14<4:00:56,  9.45s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1944.34 ms /     7 tokens (  277.76 ms per token,     3.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.72 ms /     3 runs   (  894.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4631.40 ms /    10 tokens\n",
      " 56%|โโโโโโ    | 1959/3487 [5:52:18<3:23:59,  8.01s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3999.28 ms /    19 tokens (  210.49 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.32 ms /     3 runs   (  892.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6678.54 ms /    22 tokens\n",
      " 56%|โโโโโโ    | 1960/3487 [5:52:25<3:13:45,  7.61s/it]Llama.generate: 309 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2069.56 ms /     8 tokens (  258.70 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.25 ms /     3 runs   (  886.08 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4730.38 ms /    11 tokens\n",
      " 56%|โโโโโโ    | 1961/3487 [5:52:30<2:51:41,  6.75s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3660.91 ms /    17 tokens (  215.35 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.71 ms /     3 runs   (  886.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6323.08 ms /    20 tokens\n",
      " 56%|โโโโโโ    | 1962/3487 [5:52:36<2:48:22,  6.62s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2722.49 ms /    12 tokens (  226.87 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.37 ms /     3 runs   (  887.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5387.06 ms /    15 tokens\n",
      " 56%|โโโโโโ    | 1963/3487 [5:52:41<2:38:53,  6.26s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2489.90 ms /    10 tokens (  248.99 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.13 ms /     3 runs   (  891.71 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5167.63 ms /    13 tokens\n",
      " 56%|โโโโโโ    | 1964/3487 [5:52:47<2:30:34,  5.93s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2218.93 ms /     9 tokens (  246.55 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.83 ms /     3 runs   (  894.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4904.11 ms /    12 tokens\n",
      " 56%|โโโโโโ    | 1965/3487 [5:52:51<2:22:43,  5.63s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3231.34 ms /    15 tokens (  215.42 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2768.80 ms /     3 runs   (  922.93 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6002.30 ms /    18 tokens\n",
      " 56%|โโโโโโ    | 1966/3487 [5:52:57<2:25:33,  5.74s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4250.41 ms /    19 tokens (  223.71 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.99 ms /     3 runs   (  903.66 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6964.28 ms /    22 tokens\n",
      " 56%|โโโโโโ    | 1967/3487 [5:53:04<2:34:48,  6.11s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2191.54 ms /     9 tokens (  243.50 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.37 ms /     3 runs   (  885.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4851.70 ms /    12 tokens\n",
      " 56%|โโโโโโ    | 1968/3487 [5:53:09<2:25:12,  5.74s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2981.04 ms /    10 tokens (  298.10 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.85 ms /     3 runs   (  889.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5651.33 ms /    13 tokens\n",
      " 56%|โโโโโโ    | 1969/3487 [5:53:15<2:24:31,  5.71s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4228.72 ms /    20 tokens (  211.44 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.72 ms /     3 runs   (  888.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6898.35 ms /    23 tokens\n",
      " 56%|โโโโโโ    | 1970/3487 [5:53:22<2:33:29,  6.07s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4595.45 ms /    22 tokens (  208.88 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.18 ms /     3 runs   (  880.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7239.97 ms /    25 tokens\n",
      " 57%|โโโโโโ    | 1971/3487 [5:53:29<2:42:18,  6.42s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2585.20 ms /    10 tokens (  258.52 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2959.00 ms /     3 runs   (  986.33 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    5547.16 ms /    13 tokens\n",
      " 57%|โโโโโโ    | 1972/3487 [5:53:35<2:35:38,  6.16s/it]Llama.generate: 306 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16147.89 ms /    84 tokens (  192.24 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.25 ms /     3 runs   (  886.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18811.25 ms /    87 tokens\n",
      " 57%|โโโโโโ    | 1973/3487 [5:53:53<4:11:20,  9.96s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2612.02 ms /    10 tokens (  261.20 ms per token,     3.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.52 ms /     3 runs   (  894.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5298.87 ms /    13 tokens\n",
      " 57%|โโโโโโ    | 1974/3487 [5:53:59<3:35:57,  8.56s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2774.95 ms /    12 tokens (  231.25 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2732.12 ms /     3 runs   (  910.71 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5509.91 ms /    15 tokens\n",
      " 57%|โโโโโโ    | 1975/3487 [5:54:04<3:12:48,  7.65s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2217.60 ms /     9 tokens (  246.40 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.55 ms /     3 runs   (  889.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4889.33 ms /    12 tokens\n",
      " 57%|โโโโโโ    | 1976/3487 [5:54:09<2:51:51,  6.82s/it]Llama.generate: 308 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2104.90 ms /     8 tokens (  263.11 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.96 ms /     3 runs   (  885.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4764.07 ms /    11 tokens\n",
      " 57%|โโโโโโ    | 1977/3487 [5:54:14<2:36:14,  6.21s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3721.59 ms /    17 tokens (  218.92 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.60 ms /     3 runs   (  890.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6395.84 ms /    20 tokens\n",
      " 57%|โโโโโโ    | 1978/3487 [5:54:20<2:37:37,  6.27s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1734.82 ms /     6 tokens (  289.14 ms per token,     3.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.88 ms /     3 runs   (  890.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4407.97 ms /     9 tokens\n",
      " 57%|โโโโโโ    | 1979/3487 [5:54:25<2:23:33,  5.71s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5377.04 ms /    27 tokens (  199.15 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.39 ms /     3 runs   (  905.13 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8095.63 ms /    30 tokens\n",
      " 57%|โโโโโโ    | 1980/3487 [5:54:33<2:41:29,  6.43s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7786.26 ms /    35 tokens (  222.46 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.74 ms /     3 runs   (  886.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10447.45 ms /    38 tokens\n",
      " 57%|โโโโโโ    | 1981/3487 [5:54:43<3:11:41,  7.64s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2673.16 ms /    10 tokens (  267.32 ms per token,     3.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3192.53 ms /     3 runs   ( 1064.18 ms per token,     0.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    5868.58 ms /    13 tokens\n",
      " 57%|โโโโโโ    | 1982/3487 [5:54:49<2:58:18,  7.11s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12635.77 ms /    30 tokens (  421.19 ms per token,     2.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11490.00 ms /     3 runs   ( 3830.00 ms per token,     0.26 tokens per second)\n",
      "llama_perf_context_print:       total time =   24132.04 ms /    33 tokens\n",
      " 57%|โโโโโโ    | 1983/3487 [5:55:13<5:06:25, 12.22s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4104.23 ms /    11 tokens (  373.11 ms per token,     2.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3459.25 ms /     3 runs   ( 1153.08 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =    7568.31 ms /    14 tokens\n",
      " 57%|โโโโโโ    | 1984/3487 [5:55:21<4:31:26, 10.84s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2909.62 ms /    10 tokens (  290.96 ms per token,     3.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3246.38 ms /     3 runs   ( 1082.13 ms per token,     0.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    6159.38 ms /    13 tokens\n",
      " 57%|โโโโโโ    | 1985/3487 [5:55:27<3:56:13,  9.44s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2894.87 ms /    10 tokens (  289.49 ms per token,     3.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.99 ms /     3 runs   (  890.33 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5568.85 ms /    13 tokens\n",
      " 57%|โโโโโโ    | 1986/3487 [5:55:33<3:27:07,  8.28s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9667.90 ms /    50 tokens (  193.36 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.52 ms /     3 runs   (  888.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12337.22 ms /    53 tokens\n",
      " 57%|โโโโโโ    | 1987/3487 [5:55:45<3:57:28,  9.50s/it]Llama.generate: 307 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11448.12 ms /    60 tokens (  190.80 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.32 ms /     3 runs   (  897.44 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   14143.21 ms /    63 tokens\n",
      " 57%|โโโโโโ    | 1988/3487 [5:55:59<4:32:12, 10.90s/it]Llama.generate: 307 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19072.05 ms /   102 tokens (  186.98 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.14 ms /     3 runs   (  884.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   21766.66 ms /   105 tokens\n",
      " 57%|โโโโโโ    | 1989/3487 [5:56:21<5:53:30, 14.16s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2700.48 ms /    12 tokens (  225.04 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.28 ms /     3 runs   (  890.43 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5374.51 ms /    15 tokens\n",
      " 57%|โโโโโโ    | 1990/3487 [5:56:26<4:47:35, 11.53s/it]Llama.generate: 308 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9084.08 ms /    37 tokens (  245.52 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2857.95 ms /     3 runs   (  952.65 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   11944.30 ms /    40 tokens\n",
      " 57%|โโโโโโ    | 1991/3487 [5:56:38<4:50:34, 11.65s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8343.23 ms /    42 tokens (  198.65 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.33 ms /     3 runs   (  883.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10997.29 ms /    45 tokens\n",
      " 57%|โโโโโโ    | 1992/3487 [5:56:49<4:45:31, 11.46s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2553.72 ms /    10 tokens (  255.37 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.42 ms /     3 runs   (  889.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5224.78 ms /    13 tokens\n",
      " 57%|โโโโโโ    | 1993/3487 [5:56:55<3:58:50,  9.59s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5146.09 ms /    25 tokens (  205.84 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.33 ms /     3 runs   (  901.44 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7853.20 ms /    28 tokens\n",
      " 57%|โโโโโโ    | 1994/3487 [5:57:02<3:45:44,  9.07s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3001.32 ms /    13 tokens (  230.87 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.95 ms /     3 runs   (  888.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5669.52 ms /    16 tokens\n",
      " 57%|โโโโโโ    | 1995/3487 [5:57:08<3:20:16,  8.05s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4149.12 ms /    19 tokens (  218.37 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.10 ms /     3 runs   (  899.37 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6849.72 ms /    22 tokens\n",
      " 57%|โโโโโโ    | 1996/3487 [5:57:15<3:11:14,  7.70s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8320.18 ms /    42 tokens (  198.10 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.09 ms /     3 runs   (  890.03 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10993.45 ms /    45 tokens\n",
      " 57%|โโโโโโ    | 1997/3487 [5:57:26<3:35:43,  8.69s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5265.49 ms /    27 tokens (  195.02 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.23 ms /     3 runs   (  893.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7949.31 ms /    30 tokens\n",
      " 57%|โโโโโโ    | 1998/3487 [5:57:34<3:30:09,  8.47s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4122.52 ms /    20 tokens (  206.13 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.69 ms /     3 runs   (  888.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6790.58 ms /    23 tokens\n",
      " 57%|โโโโโโ    | 1999/3487 [5:57:41<3:17:36,  7.97s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5077.04 ms /    25 tokens (  203.08 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.30 ms /     3 runs   (  881.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7724.49 ms /    28 tokens\n",
      " 57%|โโโโโโ    | 2000/3487 [5:57:48<3:15:43,  7.90s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2280.38 ms /     9 tokens (  253.38 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.79 ms /     3 runs   (  889.93 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4952.67 ms /    12 tokens\n",
      " 57%|โโโโโโ    | 2001/3487 [5:57:53<2:53:47,  7.02s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4443.41 ms /    19 tokens (  233.86 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.97 ms /     3 runs   (  879.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7086.51 ms /    22 tokens\n",
      " 57%|โโโโโโ    | 2002/3487 [5:58:01<2:54:15,  7.04s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6237.69 ms /    32 tokens (  194.93 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.64 ms /     3 runs   (  880.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8883.34 ms /    35 tokens\n",
      " 57%|โโโโโโ    | 2003/3487 [5:58:09<3:07:51,  7.60s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2937.45 ms /    13 tokens (  225.96 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.38 ms /     3 runs   (  878.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5574.38 ms /    16 tokens\n",
      " 57%|โโโโโโ    | 2004/3487 [5:58:15<2:52:49,  6.99s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2598.21 ms /    11 tokens (  236.20 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.58 ms /     3 runs   (  880.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5243.00 ms /    14 tokens\n",
      " 57%|โโโโโโ    | 2005/3487 [5:58:20<2:39:48,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2732.87 ms /    12 tokens (  227.74 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.40 ms /     3 runs   (  883.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5384.73 ms /    15 tokens\n",
      " 58%|โโโโโโ    | 2006/3487 [5:58:26<2:31:42,  6.15s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5928.72 ms /    30 tokens (  197.62 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.78 ms /     3 runs   (  895.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8617.82 ms /    33 tokens\n",
      " 58%|โโโโโโ    | 2007/3487 [5:58:34<2:49:58,  6.89s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2413.27 ms /     8 tokens (  301.66 ms per token,     3.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.82 ms /     3 runs   (  889.61 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5084.78 ms /    11 tokens\n",
      " 58%|โโโโโโ    | 2008/3487 [5:58:39<2:36:33,  6.35s/it]Llama.generate: 307 prefix-match hit, remaining 113 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21157.55 ms /   113 tokens (  187.23 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.55 ms /     3 runs   (  883.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23810.83 ms /   116 tokens\n",
      " 58%|โโโโโโ    | 2009/3487 [5:59:03<4:45:32, 11.59s/it]Llama.generate: 307 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14466.30 ms /    75 tokens (  192.88 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.72 ms /     3 runs   (  885.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17125.11 ms /    78 tokens\n",
      " 58%|โโโโโโ    | 2010/3487 [5:59:20<5:26:17, 13.25s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7453.56 ms /    37 tokens (  201.45 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.57 ms /     3 runs   (  880.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10096.89 ms /    40 tokens\n",
      " 58%|โโโโโโ    | 2011/3487 [5:59:30<5:02:49, 12.31s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3089.16 ms /    14 tokens (  220.65 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.31 ms /     3 runs   (  880.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5733.69 ms /    17 tokens\n",
      " 58%|โโโโโโ    | 2012/3487 [5:59:36<4:14:10, 10.34s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9369.19 ms /    46 tokens (  203.68 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2749.38 ms /     3 runs   (  916.46 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   12121.11 ms /    49 tokens\n",
      " 58%|โโโโโโ    | 2013/3487 [5:59:48<4:27:12, 10.88s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2276.55 ms /     9 tokens (  252.95 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.48 ms /     3 runs   (  887.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4942.73 ms /    12 tokens\n",
      " 58%|โโโโโโ    | 2014/3487 [5:59:53<3:43:22,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2479.67 ms /    10 tokens (  247.97 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.97 ms /     3 runs   (  889.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5152.27 ms /    13 tokens\n",
      " 58%|โโโโโโ    | 2015/3487 [5:59:58<3:14:14,  7.92s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4880.37 ms /    24 tokens (  203.35 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.52 ms /     3 runs   (  879.84 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7522.37 ms /    27 tokens\n",
      " 58%|โโโโโโ    | 2016/3487 [6:00:06<3:11:16,  7.80s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4643.68 ms /    23 tokens (  201.90 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.98 ms /     3 runs   (  892.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7325.59 ms /    26 tokens\n",
      " 58%|โโโโโโ    | 2017/3487 [6:00:13<3:07:41,  7.66s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2282.74 ms /     9 tokens (  253.64 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2860.05 ms /     3 runs   (  953.35 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    5144.83 ms /    12 tokens\n",
      " 58%|โโโโโโ    | 2018/3487 [6:00:18<2:49:08,  6.91s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11617.20 ms /    59 tokens (  196.90 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.44 ms /     3 runs   (  913.15 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   14358.55 ms /    62 tokens\n",
      " 58%|โโโโโโ    | 2019/3487 [6:00:33<3:43:47,  9.15s/it]Llama.generate: 306 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13178.04 ms /    68 tokens (  193.79 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.36 ms /     3 runs   (  883.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15831.54 ms /    71 tokens\n",
      " 58%|โโโโโโ    | 2020/3487 [6:00:49<4:32:43, 11.15s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2608.75 ms /    11 tokens (  237.16 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.72 ms /     3 runs   (  878.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5246.44 ms /    14 tokens\n",
      " 58%|โโโโโโ    | 2021/3487 [6:00:54<3:49:17,  9.38s/it]Llama.generate: 306 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11970.38 ms /    63 tokens (  190.01 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.89 ms /     3 runs   (  888.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14639.36 ms /    66 tokens\n",
      " 58%|โโโโโโ    | 2022/3487 [6:01:09<4:27:42, 10.96s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8374.53 ms /    43 tokens (  194.76 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.78 ms /     3 runs   (  877.59 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11009.50 ms /    46 tokens\n",
      " 58%|โโโโโโ    | 2023/3487 [6:01:20<4:27:54, 10.98s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3241.58 ms /    13 tokens (  249.35 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.51 ms /     3 runs   (  880.17 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5884.45 ms /    16 tokens\n",
      " 58%|โโโโโโ    | 2024/3487 [6:01:25<3:50:31,  9.45s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5676.48 ms /    29 tokens (  195.74 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.01 ms /     3 runs   (  885.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8334.61 ms /    32 tokens\n",
      " 58%|โโโโโโ    | 2025/3487 [6:01:34<3:42:14,  9.12s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3762.41 ms /    18 tokens (  209.02 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.80 ms /     3 runs   (  882.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6412.94 ms /    21 tokens\n",
      " 58%|โโโโโโ    | 2026/3487 [6:01:40<3:22:21,  8.31s/it]Llama.generate: 307 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13565.66 ms /    73 tokens (  185.83 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.01 ms /     3 runs   (  878.34 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16204.01 ms /    76 tokens\n",
      " 58%|โโโโโโ    | 2027/3487 [6:01:56<4:19:53, 10.68s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1569.28 ms /     5 tokens (  313.86 ms per token,     3.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.15 ms /     3 runs   (  887.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4234.01 ms /     8 tokens\n",
      " 58%|โโโโโโ    | 2028/3487 [6:02:01<3:32:45,  8.75s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11738.15 ms /    62 tokens (  189.32 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.18 ms /     3 runs   (  886.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14400.05 ms /    65 tokens\n",
      " 58%|โโโโโโ    | 2029/3487 [6:02:15<4:13:51, 10.45s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2532.78 ms /    11 tokens (  230.25 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.45 ms /     3 runs   (  881.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5180.19 ms /    14 tokens\n",
      " 58%|โโโโโโ    | 2030/3487 [6:02:20<3:35:22,  8.87s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2457.51 ms /    10 tokens (  245.75 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.49 ms /     3 runs   (  887.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5122.05 ms /    13 tokens\n",
      " 58%|โโโโโโ    | 2031/3487 [6:02:25<3:08:00,  7.75s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2682.13 ms /    12 tokens (  223.51 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.46 ms /     3 runs   (  884.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5336.95 ms /    15 tokens\n",
      " 58%|โโโโโโ    | 2032/3487 [6:02:31<2:50:23,  7.03s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2951.42 ms /    13 tokens (  227.03 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.88 ms /     3 runs   (  891.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5629.50 ms /    16 tokens\n",
      " 58%|โโโโโโ    | 2033/3487 [6:02:36<2:40:11,  6.61s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2972.59 ms /    13 tokens (  228.66 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.28 ms /     3 runs   (  880.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5617.54 ms /    16 tokens\n",
      " 58%|โโโโโโ    | 2034/3487 [6:02:42<2:32:55,  6.32s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2976.78 ms /    13 tokens (  228.98 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.47 ms /     3 runs   (  879.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5618.83 ms /    16 tokens\n",
      " 58%|โโโโโโ    | 2035/3487 [6:02:48<2:27:50,  6.11s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5221.80 ms /    24 tokens (  217.57 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.43 ms /     3 runs   (  881.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7870.63 ms /    27 tokens\n",
      " 58%|โโโโโโ    | 2036/3487 [6:02:56<2:40:33,  6.64s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4578.27 ms /    22 tokens (  208.10 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.44 ms /     3 runs   (  883.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7229.97 ms /    25 tokens\n",
      " 58%|โโโโโโ    | 2037/3487 [6:03:03<2:44:47,  6.82s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3490.32 ms /    16 tokens (  218.15 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.38 ms /     3 runs   (  885.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6150.08 ms /    19 tokens\n",
      " 58%|โโโโโโ    | 2038/3487 [6:03:09<2:39:54,  6.62s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2574.64 ms /    11 tokens (  234.06 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.67 ms /     3 runs   (  883.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5226.77 ms /    14 tokens\n",
      " 58%|โโโโโโ    | 2039/3487 [6:03:14<2:29:44,  6.21s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3716.36 ms /    18 tokens (  206.46 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.79 ms /     3 runs   (  883.26 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6368.62 ms /    21 tokens\n",
      " 59%|โโโโโโ    | 2040/3487 [6:03:21<2:30:52,  6.26s/it]Llama.generate: 306 prefix-match hit, remaining 140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26001.67 ms /   140 tokens (  185.73 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.00 ms /     3 runs   (  887.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   28666.31 ms /   143 tokens\n",
      " 59%|โโโโโโ    | 2041/3487 [6:03:49<5:12:51, 12.98s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5658.62 ms /    30 tokens (  188.62 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.33 ms /     3 runs   (  892.11 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8337.45 ms /    33 tokens\n",
      " 59%|โโโโโโ    | 2042/3487 [6:03:58<4:39:10, 11.59s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5163.20 ms /    26 tokens (  198.58 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.17 ms /     3 runs   (  881.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7809.81 ms /    29 tokens\n",
      " 59%|โโโโโโ    | 2043/3487 [6:04:05<4:11:44, 10.46s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10210.60 ms /    54 tokens (  189.09 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.16 ms /     3 runs   (  884.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12866.61 ms /    57 tokens\n",
      " 59%|โโโโโโ    | 2044/3487 [6:04:18<4:28:59, 11.18s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8835.47 ms /    46 tokens (  192.08 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.01 ms /     3 runs   (  882.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11484.53 ms /    49 tokens\n",
      " 59%|โโโโโโ    | 2045/3487 [6:04:30<4:31:14, 11.29s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13382.56 ms /    70 tokens (  191.18 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.16 ms /     3 runs   (  886.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16044.36 ms /    73 tokens\n",
      " 59%|โโโโโโ    | 2046/3487 [6:04:46<5:05:23, 12.72s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3175.55 ms /    15 tokens (  211.70 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.82 ms /     3 runs   (  888.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5846.07 ms /    18 tokens\n",
      " 59%|โโโโโโ    | 2047/3487 [6:04:52<4:15:46, 10.66s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3040.72 ms /    11 tokens (  276.43 ms per token,     3.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.65 ms /     3 runs   (  887.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5706.64 ms /    14 tokens\n",
      " 59%|โโโโโโ    | 2048/3487 [6:04:57<3:40:01,  9.17s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8442.22 ms /    43 tokens (  196.33 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2887.75 ms /     3 runs   (  962.58 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   11332.77 ms /    46 tokens\n",
      " 59%|โโโโโโ    | 2049/3487 [6:05:09<3:55:27,  9.82s/it]Llama.generate: 307 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20455.91 ms /   107 tokens (  191.18 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.58 ms /     3 runs   (  881.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23104.24 ms /   110 tokens\n",
      " 59%|โโโโโโ    | 2050/3487 [6:05:32<5:30:46, 13.81s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1687.18 ms /     6 tokens (  281.20 ms per token,     3.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.13 ms /     3 runs   (  890.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4360.72 ms /     9 tokens\n",
      " 59%|โโโโโโ    | 2051/3487 [6:05:36<4:22:45, 10.98s/it]Llama.generate: 312 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3843.12 ms /     4 runs   (  960.78 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    3845.20 ms /     5 tokens\n",
      " 59%|โโโโโโ    | 2052/3487 [6:05:40<3:31:27,  8.84s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3551.48 ms /    16 tokens (  221.97 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.57 ms /     3 runs   (  884.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6207.75 ms /    19 tokens\n",
      " 59%|โโโโโโ    | 2053/3487 [6:05:46<3:12:29,  8.05s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1735.47 ms /     6 tokens (  289.25 ms per token,     3.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.26 ms /     3 runs   (  887.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4399.59 ms /     9 tokens\n",
      " 59%|โโโโโโ    | 2054/3487 [6:05:51<2:46:13,  6.96s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5724.85 ms /    29 tokens (  197.41 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.79 ms /     3 runs   (  882.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8376.64 ms /    32 tokens\n",
      " 59%|โโโโโโ    | 2055/3487 [6:05:59<2:56:19,  7.39s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8960.16 ms /    46 tokens (  194.79 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.11 ms /     3 runs   (  874.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11586.97 ms /    49 tokens\n",
      " 59%|โโโโโโ    | 2056/3487 [6:06:11<3:26:16,  8.65s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7123.37 ms /    34 tokens (  209.51 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.29 ms /     3 runs   (  876.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9755.36 ms /    37 tokens\n",
      " 59%|โโโโโโ    | 2057/3487 [6:06:20<3:34:07,  8.98s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3092.20 ms /    14 tokens (  220.87 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.60 ms /     3 runs   (  879.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5734.48 ms /    17 tokens\n",
      " 59%|โโโโโโ    | 2058/3487 [6:06:26<3:10:48,  8.01s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4517.77 ms /    20 tokens (  225.89 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.84 ms /     3 runs   (  879.95 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7160.20 ms /    23 tokens\n",
      " 59%|โโโโโโ    | 2059/3487 [6:06:33<3:04:38,  7.76s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7530.05 ms /    38 tokens (  198.16 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.90 ms /     3 runs   (  877.63 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10166.31 ms /    41 tokens\n",
      " 59%|โโโโโโ    | 2060/3487 [6:06:44<3:21:45,  8.48s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4986.08 ms /    25 tokens (  199.44 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.99 ms /     3 runs   (  886.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7647.33 ms /    28 tokens\n",
      " 59%|โโโโโโ    | 2061/3487 [6:06:51<3:15:42,  8.23s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7136.33 ms /    33 tokens (  216.25 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.63 ms /     3 runs   (  879.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9777.70 ms /    36 tokens\n",
      " 59%|โโโโโโ    | 2062/3487 [6:07:01<3:26:36,  8.70s/it]Llama.generate: 308 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8470.35 ms /    44 tokens (  192.51 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.51 ms /     3 runs   (  897.17 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11164.60 ms /    47 tokens\n",
      " 59%|โโโโโโ    | 2063/3487 [6:07:12<3:44:05,  9.44s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1682.61 ms /     6 tokens (  280.43 ms per token,     3.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.56 ms /     3 runs   (  886.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4345.43 ms /     9 tokens\n",
      " 59%|โโโโโโ    | 2064/3487 [6:07:16<3:07:44,  7.92s/it]Llama.generate: 308 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1737.35 ms /     6 tokens (  289.56 ms per token,     3.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.61 ms /     3 runs   (  881.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4385.43 ms /     9 tokens\n",
      " 59%|โโโโโโ    | 2065/3487 [6:07:21<2:42:34,  6.86s/it]Llama.generate: 308 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1604.05 ms /     5 tokens (  320.81 ms per token,     3.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.08 ms /     3 runs   (  882.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4254.59 ms /     8 tokens\n",
      " 59%|โโโโโโ    | 2066/3487 [6:07:25<2:24:00,  6.08s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3766.05 ms /    18 tokens (  209.22 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.48 ms /     3 runs   (  883.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6420.33 ms /    21 tokens\n",
      " 59%|โโโโโโ    | 2067/3487 [6:07:32<2:26:21,  6.18s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1937.58 ms /     7 tokens (  276.80 ms per token,     3.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.87 ms /     3 runs   (  885.96 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4598.32 ms /    10 tokens\n",
      " 59%|โโโโโโ    | 2068/3487 [6:07:36<2:15:03,  5.71s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1621.74 ms /     5 tokens (  324.35 ms per token,     3.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.66 ms /     3 runs   (  886.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4284.09 ms /     8 tokens\n",
      " 59%|โโโโโโ    | 2069/3487 [6:07:40<2:05:07,  5.29s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10809.47 ms /    54 tokens (  200.18 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.72 ms /     3 runs   (  879.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13450.32 ms /    57 tokens\n",
      " 59%|โโโโโโ    | 2070/3487 [6:07:54<3:02:52,  7.74s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4050.77 ms /    19 tokens (  213.20 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.00 ms /     3 runs   (  897.33 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6745.76 ms /    22 tokens\n",
      " 59%|โโโโโโ    | 2071/3487 [6:08:01<2:55:57,  7.46s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1675.56 ms /     5 tokens (  335.11 ms per token,     2.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.99 ms /     3 runs   (  884.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4330.28 ms /     8 tokens\n",
      " 59%|โโโโโโ    | 2072/3487 [6:08:05<2:33:47,  6.52s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6025.56 ms /    31 tokens (  194.37 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.35 ms /     3 runs   (  886.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8687.55 ms /    34 tokens\n",
      " 59%|โโโโโโ    | 2073/3487 [6:08:14<2:49:02,  7.17s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15962.41 ms /    86 tokens (  185.61 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.89 ms /     3 runs   (  884.96 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18620.41 ms /    89 tokens\n",
      " 59%|โโโโโโ    | 2074/3487 [6:08:32<4:09:51, 10.61s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2445.36 ms /    10 tokens (  244.54 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.57 ms /     3 runs   (  885.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5104.14 ms /    13 tokens\n",
      " 60%|โโโโโโ    | 2075/3487 [6:08:38<3:30:52,  8.96s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2847.53 ms /    12 tokens (  237.29 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.93 ms /     3 runs   (  887.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5512.68 ms /    15 tokens\n",
      " 60%|โโโโโโ    | 2076/3487 [6:08:43<3:06:27,  7.93s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3140.45 ms /    14 tokens (  224.32 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.28 ms /     3 runs   (  887.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5804.03 ms /    17 tokens\n",
      " 60%|โโโโโโ    | 2077/3487 [6:08:49<2:51:23,  7.29s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2706.13 ms /    12 tokens (  225.51 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.92 ms /     3 runs   (  888.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5375.24 ms /    15 tokens\n",
      " 60%|โโโโโโ    | 2078/3487 [6:08:54<2:37:49,  6.72s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3766.94 ms /    18 tokens (  209.27 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2718.04 ms /     3 runs   (  906.01 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6487.81 ms /    21 tokens\n",
      " 60%|โโโโโโ    | 2079/3487 [6:09:01<2:36:07,  6.65s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2988.73 ms /    13 tokens (  229.90 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.35 ms /     3 runs   (  879.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5629.61 ms /    16 tokens\n",
      " 60%|โโโโโโ    | 2080/3487 [6:09:06<2:28:52,  6.35s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2065.40 ms /     6 tokens (  344.23 ms per token,     2.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.16 ms /     3 runs   (  881.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4712.48 ms /     9 tokens\n",
      " 60%|โโโโโโ    | 2081/3487 [6:09:11<2:17:18,  5.86s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3119.04 ms /    14 tokens (  222.79 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.51 ms /     3 runs   (  885.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5778.81 ms /    17 tokens\n",
      " 60%|โโโโโโ    | 2082/3487 [6:09:17<2:16:41,  5.84s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3770.24 ms /    18 tokens (  209.46 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.82 ms /     3 runs   (  888.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6439.76 ms /    21 tokens\n",
      " 60%|โโโโโโ    | 2083/3487 [6:09:23<2:20:52,  6.02s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5778.94 ms /    30 tokens (  192.63 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.86 ms /     3 runs   (  879.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8419.48 ms /    33 tokens\n",
      " 60%|โโโโโโ    | 2084/3487 [6:09:32<2:37:40,  6.74s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4560.64 ms /    22 tokens (  207.30 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.29 ms /     3 runs   (  885.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7218.26 ms /    25 tokens\n",
      " 60%|โโโโโโ    | 2085/3487 [6:09:39<2:40:57,  6.89s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3701.57 ms /    18 tokens (  205.64 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.63 ms /     3 runs   (  885.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6360.95 ms /    21 tokens\n",
      " 60%|โโโโโโ    | 2086/3487 [6:09:45<2:37:12,  6.73s/it]Llama.generate: 308 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1503.58 ms /     5 tokens (  300.72 ms per token,     3.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.54 ms /     3 runs   (  887.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4169.69 ms /     8 tokens\n",
      " 60%|โโโโโโ    | 2087/3487 [6:09:50<2:19:12,  5.97s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2026.74 ms /     8 tokens (  253.34 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.68 ms /     3 runs   (  896.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4719.47 ms /    11 tokens\n",
      " 60%|โโโโโโ    | 2088/3487 [6:09:54<2:10:27,  5.60s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9929.58 ms /    50 tokens (  198.59 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.35 ms /     3 runs   (  913.12 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   12672.41 ms /    53 tokens\n",
      " 60%|โโโโโโ    | 2089/3487 [6:10:07<2:59:54,  7.72s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3885.86 ms /    18 tokens (  215.88 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.76 ms /     3 runs   (  891.92 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6564.62 ms /    21 tokens\n",
      " 60%|โโโโโโ    | 2090/3487 [6:10:14<2:51:45,  7.38s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5047.70 ms /    23 tokens (  219.47 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.60 ms /     3 runs   (  904.53 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7763.54 ms /    26 tokens\n",
      " 60%|โโโโโโ    | 2091/3487 [6:10:21<2:54:24,  7.50s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5415.05 ms /    27 tokens (  200.56 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2911.23 ms /     3 runs   (  970.41 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    8329.02 ms /    30 tokens\n",
      " 60%|โโโโโโ    | 2092/3487 [6:10:30<3:00:08,  7.75s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5798.91 ms /    29 tokens (  199.96 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2703.72 ms /     3 runs   (  901.24 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8505.00 ms /    32 tokens\n",
      " 60%|โโโโโโ    | 2093/3487 [6:10:38<3:05:20,  7.98s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2148.27 ms /     8 tokens (  268.53 ms per token,     3.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.70 ms /     3 runs   (  907.90 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4874.38 ms /    11 tokens\n",
      " 60%|โโโโโโ    | 2094/3487 [6:10:43<2:43:38,  7.05s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1919.42 ms /     7 tokens (  274.20 ms per token,     3.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.78 ms /     3 runs   (  905.59 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4638.30 ms /    10 tokens\n",
      " 60%|โโโโโโ    | 2095/3487 [6:10:48<2:26:48,  6.33s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3627.34 ms /    16 tokens (  226.71 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.19 ms /     3 runs   (  896.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6317.91 ms /    19 tokens\n",
      " 60%|โโโโโโ    | 2096/3487 [6:10:54<2:26:41,  6.33s/it]Llama.generate: 307 prefix-match hit, remaining 200 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   36939.84 ms /   200 tokens (  184.70 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.82 ms /     3 runs   (  894.27 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   39624.90 ms /   203 tokens\n",
      " 60%|โโโโโโ    | 2097/3487 [6:11:34<6:18:04, 16.32s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5928.81 ms /    30 tokens (  197.63 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.07 ms /     3 runs   (  893.69 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8612.33 ms /    33 tokens\n",
      " 60%|โโโโโโ    | 2098/3487 [6:11:42<5:24:19, 14.01s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1680.55 ms /     6 tokens (  280.09 ms per token,     3.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.09 ms /     3 runs   (  892.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4361.25 ms /     9 tokens\n",
      " 60%|โโโโโโ    | 2099/3487 [6:11:47<4:17:10, 11.12s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4024.78 ms /    19 tokens (  211.83 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.59 ms /     3 runs   (  893.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6707.68 ms /    22 tokens\n",
      " 60%|โโโโโโ    | 2100/3487 [6:11:53<3:46:28,  9.80s/it]Llama.generate: 307 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16601.47 ms /    87 tokens (  190.82 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.30 ms /     3 runs   (  888.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19268.43 ms /    90 tokens\n",
      " 60%|โโโโโโ    | 2101/3487 [6:12:13<4:52:00, 12.64s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9245.10 ms /    48 tokens (  192.61 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.70 ms /     3 runs   (  886.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11908.60 ms /    51 tokens\n",
      " 60%|โโโโโโ    | 2102/3487 [6:12:25<4:46:47, 12.42s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4455.40 ms /    22 tokens (  202.52 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.96 ms /     3 runs   (  884.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7112.48 ms /    25 tokens\n",
      " 60%|โโโโโโ    | 2103/3487 [6:12:32<4:09:53, 10.83s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3730.50 ms /    18 tokens (  207.25 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.41 ms /     3 runs   (  891.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6407.73 ms /    21 tokens\n",
      " 60%|โโโโโโ    | 2104/3487 [6:12:38<3:39:10,  9.51s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4767.81 ms /    24 tokens (  198.66 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2732.64 ms /     3 runs   (  910.88 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7503.21 ms /    27 tokens\n",
      " 60%|โโโโโโ    | 2105/3487 [6:12:46<3:25:12,  8.91s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9489.84 ms /    49 tokens (  193.67 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.16 ms /     3 runs   (  881.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12137.51 ms /    52 tokens\n",
      " 60%|โโโโโโ    | 2106/3487 [6:12:58<3:47:24,  9.88s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1742.43 ms /     6 tokens (  290.41 ms per token,     3.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.75 ms /     3 runs   (  886.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4404.71 ms /     9 tokens\n",
      " 60%|โโโโโโ    | 2107/3487 [6:13:02<3:09:31,  8.24s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3996.77 ms /    19 tokens (  210.36 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.89 ms /     3 runs   (  887.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6662.33 ms /    22 tokens\n",
      " 60%|โโโโโโ    | 2108/3487 [6:13:09<2:58:33,  7.77s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4705.07 ms /    23 tokens (  204.57 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.98 ms /     3 runs   (  886.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7367.58 ms /    26 tokens\n",
      " 60%|โโโโโโ    | 2109/3487 [6:13:16<2:55:43,  7.65s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2603.58 ms /    11 tokens (  236.69 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.99 ms /     3 runs   (  888.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5269.78 ms /    14 tokens\n",
      " 61%|โโโโโโ    | 2110/3487 [6:13:21<2:39:15,  6.94s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2069.46 ms /     8 tokens (  258.68 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.53 ms /     3 runs   (  890.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4743.69 ms /    11 tokens\n",
      " 61%|โโโโโโ    | 2111/3487 [6:13:26<2:24:05,  6.28s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8760.24 ms /    43 tokens (  203.73 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.12 ms /     3 runs   (  889.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11431.13 ms /    46 tokens\n",
      " 61%|โโโโโโ    | 2112/3487 [6:13:38<2:59:26,  7.83s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2518.06 ms /    10 tokens (  251.81 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.95 ms /     3 runs   (  903.32 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5231.18 ms /    13 tokens\n",
      " 61%|โโโโโโ    | 2113/3487 [6:13:43<2:41:30,  7.05s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2869.81 ms /    11 tokens (  260.89 ms per token,     3.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.67 ms /     3 runs   (  889.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5541.06 ms /    14 tokens\n",
      " 61%|โโโโโโ    | 2114/3487 [6:13:48<2:31:03,  6.60s/it]Llama.generate: 306 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19363.03 ms /   103 tokens (  187.99 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.63 ms /     3 runs   (  892.54 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   22043.33 ms /   106 tokens\n",
      " 61%|โโโโโโ    | 2115/3487 [6:14:10<4:16:57, 11.24s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2529.48 ms /    10 tokens (  252.95 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.16 ms /     3 runs   (  886.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5191.97 ms /    13 tokens\n",
      " 61%|โโโโโโ    | 2116/3487 [6:14:16<3:35:23,  9.43s/it]Llama.generate: 306 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15143.76 ms /    80 tokens (  189.30 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.59 ms /     3 runs   (  888.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17813.21 ms /    83 tokens\n",
      " 61%|โโโโโโ    | 2117/3487 [6:14:34<4:32:43, 11.94s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5246.04 ms /    24 tokens (  218.59 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3073.46 ms /     3 runs   ( 1024.49 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    8322.85 ms /    27 tokens\n",
      " 61%|โโโโโโ    | 2118/3487 [6:14:42<4:07:48, 10.86s/it]Llama.generate: 311 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7715.21 ms /    28 tokens (  275.54 ms per token,     3.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2872.99 ms /     3 runs   (  957.66 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   10591.31 ms /    31 tokens\n",
      " 61%|โโโโโโ    | 2119/3487 [6:14:52<4:05:50, 10.78s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2255.66 ms /     8 tokens (  281.96 ms per token,     3.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2730.27 ms /     3 runs   (  910.09 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4988.75 ms /    11 tokens\n",
      " 61%|โโโโโโ    | 2120/3487 [6:14:57<3:26:07,  9.05s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2855.88 ms /    11 tokens (  259.63 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4653.75 ms /     3 runs   ( 1551.25 ms per token,     0.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    7512.18 ms /    14 tokens\n",
      " 61%|โโโโโโ    | 2121/3487 [6:15:05<3:15:33,  8.59s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2933.12 ms /    12 tokens (  244.43 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2750.88 ms /     3 runs   (  916.96 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5687.08 ms /    15 tokens\n",
      " 61%|โโโโโโ    | 2122/3487 [6:15:11<2:55:40,  7.72s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4393.55 ms /    21 tokens (  209.22 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.98 ms /     3 runs   (  896.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7086.99 ms /    24 tokens\n",
      " 61%|โโโโโโ    | 2123/3487 [6:15:18<2:51:17,  7.53s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2951.45 ms /    12 tokens (  245.95 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.25 ms /     3 runs   (  901.42 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5658.11 ms /    15 tokens\n",
      " 61%|โโโโโโ    | 2124/3487 [6:15:23<2:38:25,  6.97s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3190.92 ms /    14 tokens (  227.92 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2842.73 ms /     3 runs   (  947.58 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    6036.21 ms /    17 tokens\n",
      " 61%|โโโโโโ    | 2125/3487 [6:15:29<2:31:58,  6.70s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7427.67 ms /    35 tokens (  212.22 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.74 ms /     3 runs   (  893.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10111.23 ms /    38 tokens\n",
      " 61%|โโโโโโ    | 2126/3487 [6:15:40<2:55:11,  7.72s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5418.55 ms /    27 tokens (  200.69 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.67 ms /     3 runs   (  889.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8090.83 ms /    30 tokens\n",
      " 61%|โโโโโโ    | 2127/3487 [6:15:48<2:57:37,  7.84s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5659.95 ms /    28 tokens (  202.14 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.26 ms /     3 runs   (  897.09 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8353.92 ms /    31 tokens\n",
      " 61%|โโโโโโ    | 2128/3487 [6:15:56<3:01:03,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12972.59 ms /    65 tokens (  199.58 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.03 ms /     3 runs   (  887.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15636.71 ms /    68 tokens\n",
      " 61%|โโโโโโ    | 2129/3487 [6:16:12<3:52:52, 10.29s/it]Llama.generate: 308 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4070.01 ms /    19 tokens (  214.21 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.16 ms /     3 runs   (  900.39 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6773.31 ms /    22 tokens\n",
      " 61%|โโโโโโ    | 2130/3487 [6:16:18<3:28:54,  9.24s/it]Llama.generate: 318 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2004.92 ms /     4 tokens (  501.23 ms per token,     2.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.44 ms /     3 runs   (  903.81 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4718.57 ms /     7 tokens\n",
      " 61%|โโโโโโ    | 2131/3487 [6:16:23<2:58:10,  7.88s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3558.21 ms /    16 tokens (  222.39 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.07 ms /     3 runs   (  896.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6249.35 ms /    19 tokens\n",
      " 61%|โโโโโโ    | 2132/3487 [6:16:29<2:47:02,  7.40s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8954.42 ms /    43 tokens (  208.24 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.25 ms /     3 runs   (  898.42 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11652.39 ms /    46 tokens\n",
      " 61%|โโโโโโ    | 2133/3487 [6:16:41<3:15:47,  8.68s/it]Llama.generate: 307 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16426.67 ms /    82 tokens (  200.33 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3010.98 ms /     3 runs   ( 1003.66 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =   19440.17 ms /    85 tokens\n",
      " 61%|โโโโโโ    | 2134/3487 [6:17:01<4:28:31, 11.91s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5613.81 ms /    25 tokens (  224.55 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2718.14 ms /     3 runs   (  906.05 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8334.43 ms /    28 tokens\n",
      " 61%|โโโโโโ    | 2135/3487 [6:17:09<4:04:13, 10.84s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4195.99 ms /    20 tokens (  209.80 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.10 ms /     3 runs   (  895.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6884.94 ms /    23 tokens\n",
      " 61%|โโโโโโโ   | 2136/3487 [6:17:16<3:37:23,  9.65s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4242.98 ms /    20 tokens (  212.15 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.44 ms /     3 runs   (  900.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6946.53 ms /    23 tokens\n",
      " 61%|โโโโโโโ   | 2137/3487 [6:17:23<3:19:00,  8.84s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9005.19 ms /    46 tokens (  195.76 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2764.57 ms /     3 runs   (  921.52 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   11771.31 ms /    49 tokens\n",
      " 61%|โโโโโโโ   | 2138/3487 [6:17:35<3:38:39,  9.73s/it]Llama.generate: 307 prefix-match hit, remaining 208 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   38731.00 ms /   208 tokens (  186.21 ms per token,     5.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3315.95 ms /     3 runs   ( 1105.32 ms per token,     0.90 tokens per second)\n",
      "llama_perf_context_print:       total time =   42049.58 ms /   211 tokens\n",
      " 61%|โโโโโโโ   | 2139/3487 [6:18:17<7:16:25, 19.43s/it]Llama.generate: 307 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21269.09 ms /   100 tokens (  212.69 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3099.48 ms /     3 runs   ( 1033.16 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =   24371.33 ms /   103 tokens\n",
      " 61%|โโโโโโโ   | 2140/3487 [6:18:41<7:49:29, 20.91s/it]Llama.generate: 307 prefix-match hit, remaining 198 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   39077.91 ms /   198 tokens (  197.36 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2799.37 ms /     3 runs   (  933.12 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   41879.78 ms /   201 tokens\n",
      " 61%|โโโโโโโ   | 2141/3487 [6:19:23<10:10:20, 27.21s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4684.55 ms /    19 tokens (  246.56 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2749.12 ms /     3 runs   (  916.37 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7437.43 ms /    22 tokens\n",
      " 61%|โโโโโโโ   | 2142/3487 [6:19:30<7:56:59, 21.28s/it] Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5880.44 ms /    28 tokens (  210.02 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2788.54 ms /     3 runs   (  929.51 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8671.86 ms /    31 tokens\n",
      " 61%|โโโโโโโ   | 2143/3487 [6:19:39<6:31:59, 17.50s/it]Llama.generate: 307 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11147.07 ms /    58 tokens (  192.19 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.10 ms /     3 runs   (  889.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13818.68 ms /    61 tokens\n",
      " 61%|โโโโโโโ   | 2144/3487 [6:19:53<6:07:02, 16.40s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7137.59 ms /    34 tokens (  209.93 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.06 ms /     3 runs   (  886.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9799.79 ms /    37 tokens\n",
      " 62%|โโโโโโโ   | 2145/3487 [6:20:03<5:22:33, 14.42s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5622.49 ms /    28 tokens (  200.80 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.85 ms /     3 runs   (  895.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8311.13 ms /    31 tokens\n",
      " 62%|โโโโโโโ   | 2146/3487 [6:20:11<4:41:49, 12.61s/it]Llama.generate: 306 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13132.49 ms /    68 tokens (  193.12 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.51 ms /     3 runs   (  885.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15791.99 ms /    71 tokens\n",
      " 62%|โโโโโโโ   | 2147/3487 [6:20:27<5:02:59, 13.57s/it]Llama.generate: 308 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2937.26 ms /    13 tokens (  225.94 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2809.92 ms /     3 runs   (  936.64 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5749.63 ms /    16 tokens\n",
      " 62%|โโโโโโโ   | 2148/3487 [6:20:33<4:10:28, 11.22s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3070.33 ms /    13 tokens (  236.18 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.33 ms /     3 runs   (  907.11 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5794.06 ms /    16 tokens\n",
      " 62%|โโโโโโโ   | 2149/3487 [6:20:38<3:34:01,  9.60s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13399.84 ms /    69 tokens (  194.20 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2770.62 ms /     3 runs   (  923.54 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   16173.24 ms /    72 tokens\n",
      " 62%|โโโโโโโ   | 2150/3487 [6:20:55<4:17:53, 11.57s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2003.74 ms /     7 tokens (  286.25 ms per token,     3.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.40 ms /     3 runs   (  895.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4692.79 ms /    10 tokens\n",
      " 62%|โโโโโโโ   | 2151/3487 [6:20:59<3:31:47,  9.51s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2220.37 ms /     9 tokens (  246.71 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.96 ms /     3 runs   (  897.65 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4915.47 ms /    12 tokens\n",
      " 62%|โโโโโโโ   | 2152/3487 [6:21:04<3:01:00,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3580.27 ms /    14 tokens (  255.73 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2905.05 ms /     3 runs   (  968.35 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6487.88 ms /    17 tokens\n",
      " 62%|โโโโโโโ   | 2153/3487 [6:21:11<2:49:56,  7.64s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7558.40 ms /    36 tokens (  209.96 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.03 ms /     3 runs   (  885.01 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10215.79 ms /    39 tokens\n",
      " 62%|โโโโโโโ   | 2154/3487 [6:21:21<3:07:00,  8.42s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2214.97 ms /     9 tokens (  246.11 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.01 ms /     3 runs   (  900.00 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4917.74 ms /    12 tokens\n",
      " 62%|โโโโโโโ   | 2155/3487 [6:21:26<2:43:37,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13246.41 ms /    69 tokens (  191.98 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.17 ms /     3 runs   (  890.39 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15920.25 ms /    72 tokens\n",
      " 62%|โโโโโโโ   | 2156/3487 [6:21:42<3:40:27,  9.94s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5227.62 ms /    26 tokens (  201.06 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.53 ms /     3 runs   (  896.18 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7918.54 ms /    29 tokens\n",
      " 62%|โโโโโโโ   | 2157/3487 [6:21:50<3:26:54,  9.33s/it]Llama.generate: 312 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13195.71 ms /    70 tokens (  188.51 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.09 ms /     3 runs   (  881.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15843.27 ms /    73 tokens\n",
      " 62%|โโโโโโโ   | 2158/3487 [6:22:06<4:10:03, 11.29s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5041.54 ms /    25 tokens (  201.66 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.92 ms /     3 runs   (  885.97 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7702.70 ms /    28 tokens\n",
      " 62%|โโโโโโโ   | 2159/3487 [6:22:13<3:46:06, 10.22s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2175.99 ms /     9 tokens (  241.78 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.93 ms /     3 runs   (  886.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4836.85 ms /    12 tokens\n",
      " 62%|โโโโโโโ   | 2160/3487 [6:22:18<3:10:18,  8.60s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4141.04 ms /    20 tokens (  207.05 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.95 ms /     3 runs   (  886.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6805.21 ms /    23 tokens\n",
      " 62%|โโโโโโโ   | 2161/3487 [6:22:25<2:58:16,  8.07s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4726.81 ms /    24 tokens (  196.95 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.75 ms /     3 runs   (  885.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7385.75 ms /    27 tokens\n",
      " 62%|โโโโโโโ   | 2162/3487 [6:22:32<2:53:40,  7.86s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3162.35 ms /    15 tokens (  210.82 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.08 ms /     3 runs   (  881.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5807.40 ms /    18 tokens\n",
      " 62%|โโโโโโโ   | 2163/3487 [6:22:38<2:39:59,  7.25s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3590.33 ms /    14 tokens (  256.45 ms per token,     3.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.09 ms /     3 runs   (  886.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6253.21 ms /    17 tokens\n",
      " 62%|โโโโโโโ   | 2164/3487 [6:22:44<2:33:19,  6.95s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2508.09 ms /    10 tokens (  250.81 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.82 ms /     3 runs   (  898.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5206.08 ms /    13 tokens\n",
      " 62%|โโโโโโโ   | 2165/3487 [6:22:50<2:21:42,  6.43s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7474.94 ms /    37 tokens (  202.03 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.87 ms /     3 runs   (  879.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10115.56 ms /    40 tokens\n",
      " 62%|โโโโโโโ   | 2166/3487 [6:23:00<2:45:59,  7.54s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2700.49 ms /    12 tokens (  225.04 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.09 ms /     3 runs   (  892.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5381.01 ms /    15 tokens\n",
      " 62%|โโโโโโโ   | 2167/3487 [6:23:05<2:31:41,  6.89s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2187.56 ms /     9 tokens (  243.06 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.64 ms /     3 runs   (  885.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4845.52 ms /    12 tokens\n",
      " 62%|โโโโโโโ   | 2168/3487 [6:23:10<2:18:07,  6.28s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2447.52 ms /    10 tokens (  244.75 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.46 ms /     3 runs   (  897.82 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5143.09 ms /    13 tokens\n",
      " 62%|โโโโโโโ   | 2169/3487 [6:23:15<2:10:32,  5.94s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2691.50 ms /    12 tokens (  224.29 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.32 ms /     3 runs   (  888.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5359.63 ms /    15 tokens\n",
      " 62%|โโโโโโโ   | 2170/3487 [6:23:20<2:06:39,  5.77s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2176.37 ms /     9 tokens (  241.82 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.06 ms /     3 runs   (  886.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4837.21 ms /    12 tokens\n",
      " 62%|โโโโโโโ   | 2171/3487 [6:23:25<2:00:28,  5.49s/it]Llama.generate: 311 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2969.69 ms /    13 tokens (  228.44 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.06 ms /     3 runs   (  886.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5630.04 ms /    16 tokens\n",
      " 62%|โโโโโโโ   | 2172/3487 [6:23:31<2:01:19,  5.54s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2570.30 ms /    11 tokens (  233.66 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.50 ms /     3 runs   (  887.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5235.28 ms /    14 tokens\n",
      " 62%|โโโโโโโ   | 2173/3487 [6:23:36<1:59:19,  5.45s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2496.76 ms /     9 tokens (  277.42 ms per token,     3.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.86 ms /     3 runs   (  884.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5153.64 ms /    12 tokens\n",
      " 62%|โโโโโโโ   | 2174/3487 [6:23:41<1:57:20,  5.36s/it]Llama.generate: 314 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3903.88 ms /     4 runs   (  975.97 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    3907.14 ms /     5 tokens\n",
      " 62%|โโโโโโโ   | 2175/3487 [6:23:45<1:47:45,  4.93s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2152.48 ms /     8 tokens (  269.06 ms per token,     3.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.93 ms /     3 runs   (  894.64 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4838.96 ms /    11 tokens\n",
      " 62%|โโโโโโโ   | 2176/3487 [6:23:50<1:47:08,  4.90s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1603.98 ms /     5 tokens (  320.80 ms per token,     3.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2703.42 ms /     3 runs   (  901.14 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4310.14 ms /     8 tokens\n",
      " 62%|โโโโโโโ   | 2177/3487 [6:23:54<1:43:14,  4.73s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7835.74 ms /    35 tokens (  223.88 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.76 ms /     3 runs   (  881.92 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10484.15 ms /    38 tokens\n",
      " 62%|โโโโโโโ   | 2178/3487 [6:24:05<2:20:53,  6.46s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4613.02 ms /    22 tokens (  209.68 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.27 ms /     3 runs   (  888.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7281.30 ms /    25 tokens\n",
      " 62%|โโโโโโโ   | 2179/3487 [6:24:12<2:26:12,  6.71s/it]Llama.generate: 306 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14420.61 ms /    61 tokens (  236.40 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4336.59 ms /     3 runs   ( 1445.53 ms per token,     0.69 tokens per second)\n",
      "llama_perf_context_print:       total time =   18760.40 ms /    64 tokens\n",
      " 63%|โโโโโโโ   | 2180/3487 [6:24:31<3:44:56, 10.33s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6194.24 ms /    25 tokens (  247.77 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3856.00 ms /     3 runs   ( 1285.33 ms per token,     0.78 tokens per second)\n",
      "llama_perf_context_print:       total time =   10053.71 ms /    28 tokens\n",
      " 63%|โโโโโโโ   | 2181/3487 [6:24:41<3:43:03, 10.25s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7065.92 ms /    32 tokens (  220.81 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3513.95 ms /     3 runs   ( 1171.32 ms per token,     0.85 tokens per second)\n",
      "llama_perf_context_print:       total time =   10583.12 ms /    35 tokens\n",
      " 63%|โโโโโโโ   | 2182/3487 [6:24:52<3:45:08, 10.35s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2882.83 ms /     9 tokens (  320.31 ms per token,     3.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.44 ms /     3 runs   (  905.48 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5601.56 ms /    12 tokens\n",
      " 63%|โโโโโโโ   | 2183/3487 [6:24:57<3:14:03,  8.93s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2385.48 ms /     5 tokens (  477.10 ms per token,     2.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2799.53 ms /     3 runs   (  933.18 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5187.47 ms /     8 tokens\n",
      " 63%|โโโโโโโ   | 2184/3487 [6:25:02<2:49:36,  7.81s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4030.14 ms /    18 tokens (  223.90 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.22 ms /     3 runs   (  896.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6722.86 ms /    21 tokens\n",
      " 63%|โโโโโโโ   | 2185/3487 [6:25:09<2:42:28,  7.49s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9613.59 ms /    49 tokens (  196.20 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.64 ms /     3 runs   (  895.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12302.35 ms /    52 tokens\n",
      " 63%|โโโโโโโ   | 2186/3487 [6:25:22<3:13:43,  8.93s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11206.26 ms /    57 tokens (  196.60 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3104.82 ms /     3 runs   ( 1034.94 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =   14314.04 ms /    60 tokens\n",
      " 63%|โโโโโโโ   | 2187/3487 [6:25:36<3:48:35, 10.55s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3484.45 ms /    14 tokens (  248.89 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2823.78 ms /     3 runs   (  941.26 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    6311.01 ms /    17 tokens\n",
      " 63%|โโโโโโโ   | 2188/3487 [6:25:42<3:20:56,  9.28s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11101.32 ms /    57 tokens (  194.76 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.11 ms /     3 runs   (  876.37 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13733.27 ms /    60 tokens\n",
      " 63%|โโโโโโโ   | 2189/3487 [6:25:56<3:49:44, 10.62s/it]Llama.generate: 307 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19537.79 ms /   103 tokens (  189.69 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.99 ms /     3 runs   (  897.33 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   22232.34 ms /   106 tokens\n",
      " 63%|โโโโโโโ   | 2190/3487 [6:26:18<5:04:56, 14.11s/it]Llama.generate: 307 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19061.16 ms /    98 tokens (  194.50 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.92 ms /     3 runs   (  903.97 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   21775.77 ms /   101 tokens\n",
      " 63%|โโโโโโโ   | 2191/3487 [6:26:40<5:54:27, 16.41s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12820.20 ms /    65 tokens (  197.23 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.82 ms /     3 runs   (  880.61 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15464.22 ms /    68 tokens\n",
      " 63%|โโโโโโโ   | 2192/3487 [6:26:55<5:48:07, 16.13s/it]Llama.generate: 308 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4661.25 ms /    21 tokens (  221.96 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.43 ms /     3 runs   (  879.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7301.05 ms /    24 tokens\n",
      " 63%|โโโโโโโ   | 2193/3487 [6:27:03<4:50:47, 13.48s/it]Llama.generate: 307 prefix-match hit, remaining 81 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15220.87 ms /    81 tokens (  187.91 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.15 ms /     3 runs   (  892.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   17900.78 ms /    84 tokens\n",
      " 63%|โโโโโโโ   | 2194/3487 [6:27:21<5:19:10, 14.81s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13094.12 ms /    69 tokens (  189.77 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.37 ms /     3 runs   (  882.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15743.03 ms /    72 tokens\n",
      " 63%|โโโโโโโ   | 2195/3487 [6:27:36<5:25:00, 15.09s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2671.96 ms /    12 tokens (  222.66 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.78 ms /     3 runs   (  894.93 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5359.03 ms /    15 tokens\n",
      " 63%|โโโโโโโ   | 2196/3487 [6:27:42<4:21:58, 12.18s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4741.57 ms /    23 tokens (  206.16 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.83 ms /     3 runs   (  885.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7402.25 ms /    26 tokens\n",
      " 63%|โโโโโโโ   | 2197/3487 [6:27:49<3:51:01, 10.75s/it]Llama.generate: 307 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11408.27 ms /    61 tokens (  187.02 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.34 ms /     3 runs   (  884.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14064.23 ms /    64 tokens\n",
      " 63%|โโโโโโโ   | 2198/3487 [6:28:03<4:12:18, 11.74s/it]Llama.generate: 307 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14380.07 ms /    77 tokens (  186.75 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.09 ms /     3 runs   (  889.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   17051.28 ms /    80 tokens\n",
      " 63%|โโโโโโโ   | 2199/3487 [6:28:20<4:46:20, 13.34s/it]Llama.generate: 307 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26751.16 ms /   107 tokens (  250.01 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3533.83 ms /     3 runs   ( 1177.94 ms per token,     0.85 tokens per second)\n",
      "llama_perf_context_print:       total time =   30287.46 ms /   110 tokens\n",
      " 63%|โโโโโโโ   | 2200/3487 [6:28:51<6:35:14, 18.43s/it]Llama.generate: 307 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21091.30 ms /    82 tokens (  257.21 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2919.89 ms /     3 runs   (  973.30 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   24015.13 ms /    85 tokens\n",
      " 63%|โโโโโโโ   | 2201/3487 [6:29:15<7:10:56, 20.11s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2364.87 ms /     9 tokens (  262.76 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2742.72 ms /     3 runs   (  914.24 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5110.95 ms /    12 tokens\n",
      " 63%|โโโโโโโ   | 2202/3487 [6:29:20<5:34:20, 15.61s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5762.82 ms /    25 tokens (  230.51 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.64 ms /     3 runs   (  896.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8454.99 ms /    28 tokens\n",
      " 63%|โโโโโโโ   | 2203/3487 [6:29:28<4:48:11, 13.47s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2254.50 ms /     9 tokens (  250.50 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2781.52 ms /     3 runs   (  927.17 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5038.51 ms /    12 tokens\n",
      " 63%|โโโโโโโ   | 2204/3487 [6:29:33<3:53:57, 10.94s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3767.03 ms /    17 tokens (  221.59 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.08 ms /     3 runs   (  882.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6418.14 ms /    20 tokens\n",
      " 63%|โโโโโโโ   | 2205/3487 [6:29:40<3:24:50,  9.59s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5015.90 ms /    24 tokens (  209.00 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2727.51 ms /     3 runs   (  909.17 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7746.05 ms /    27 tokens\n",
      " 63%|โโโโโโโ   | 2206/3487 [6:29:47<3:12:56,  9.04s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8153.16 ms /    40 tokens (  203.83 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.18 ms /     3 runs   (  884.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10809.68 ms /    43 tokens\n",
      " 63%|โโโโโโโ   | 2207/3487 [6:29:58<3:24:12,  9.57s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2740.62 ms /    12 tokens (  228.38 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.88 ms /     3 runs   (  899.29 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5440.76 ms /    15 tokens\n",
      " 63%|โโโโโโโ   | 2208/3487 [6:30:04<2:57:40,  8.34s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6187.07 ms /    31 tokens (  199.58 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.02 ms /     3 runs   (  883.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8840.33 ms /    34 tokens\n",
      " 63%|โโโโโโโ   | 2209/3487 [6:30:13<3:00:48,  8.49s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7457.73 ms /    37 tokens (  201.56 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.07 ms /     3 runs   (  884.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10112.73 ms /    40 tokens\n",
      " 63%|โโโโโโโ   | 2210/3487 [6:30:23<3:11:05,  8.98s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2347.11 ms /     9 tokens (  260.79 ms per token,     3.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.21 ms /     3 runs   (  891.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5023.44 ms /    12 tokens\n",
      " 63%|โโโโโโโ   | 2211/3487 [6:30:28<2:45:46,  7.79s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2619.23 ms /    11 tokens (  238.11 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.66 ms /     3 runs   (  897.22 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5316.09 ms /    14 tokens\n",
      " 63%|โโโโโโโ   | 2212/3487 [6:30:33<2:29:53,  7.05s/it]Llama.generate: 316 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4321.42 ms /     4 runs   ( 1080.35 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    4324.26 ms /     5 tokens\n",
      " 63%|โโโโโโโ   | 2213/3487 [6:30:37<2:12:26,  6.24s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3946.62 ms /    13 tokens (  303.59 ms per token,     3.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2805.41 ms /     3 runs   (  935.14 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6754.54 ms /    16 tokens\n",
      " 63%|โโโโโโโ   | 2214/3487 [6:30:44<2:15:40,  6.39s/it]Llama.generate: 306 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16322.97 ms /    83 tokens (  196.66 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.71 ms /     3 runs   (  907.90 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   19048.93 ms /    86 tokens\n",
      " 64%|โโโโโโโ   | 2215/3487 [6:31:03<3:36:05, 10.19s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7962.50 ms /    40 tokens (  199.06 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.29 ms /     3 runs   (  880.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10606.22 ms /    43 tokens\n",
      " 64%|โโโโโโโ   | 2216/3487 [6:31:14<3:38:36, 10.32s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3032.84 ms /    13 tokens (  233.30 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.60 ms /     3 runs   (  894.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5719.60 ms /    16 tokens\n",
      " 64%|โโโโโโโ   | 2217/3487 [6:31:20<3:09:16,  8.94s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6165.33 ms /    31 tokens (  198.88 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.11 ms /     3 runs   (  889.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8837.30 ms /    34 tokens\n",
      " 64%|โโโโโโโ   | 2218/3487 [6:31:28<3:08:30,  8.91s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2548.93 ms /    10 tokens (  254.89 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.36 ms /     3 runs   (  895.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5236.65 ms /    13 tokens\n",
      " 64%|โโโโโโโ   | 2219/3487 [6:31:34<2:45:06,  7.81s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2611.38 ms /    11 tokens (  237.40 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.54 ms /     3 runs   (  897.51 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5306.28 ms /    14 tokens\n",
      " 64%|โโโโโโโ   | 2220/3487 [6:31:39<2:29:08,  7.06s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2693.85 ms /    11 tokens (  244.90 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2753.08 ms /     3 runs   (  917.69 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5449.03 ms /    14 tokens\n",
      " 64%|โโโโโโโ   | 2221/3487 [6:31:44<2:18:52,  6.58s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5965.62 ms /    30 tokens (  198.85 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4047.74 ms /     3 runs   ( 1349.25 ms per token,     0.74 tokens per second)\n",
      "llama_perf_context_print:       total time =   10015.66 ms /    33 tokens\n",
      " 64%|โโโโโโโ   | 2222/3487 [6:31:54<2:40:33,  7.62s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5804.78 ms /    18 tokens (  322.49 ms per token,     3.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3031.40 ms /     3 runs   ( 1010.47 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    8839.08 ms /    21 tokens\n",
      " 64%|โโโโโโโ   | 2223/3487 [6:32:03<2:48:13,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3530.59 ms /    15 tokens (  235.37 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2802.81 ms /     3 runs   (  934.27 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6336.42 ms /    18 tokens\n",
      " 64%|โโโโโโโ   | 2224/3487 [6:32:10<2:37:44,  7.49s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3684.28 ms /    16 tokens (  230.27 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.64 ms /     3 runs   (  895.21 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6372.33 ms /    19 tokens\n",
      " 64%|โโโโโโโ   | 2225/3487 [6:32:16<2:30:35,  7.16s/it]Llama.generate: 310 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3764.18 ms /    18 tokens (  209.12 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.67 ms /     3 runs   (  905.89 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6484.32 ms /    21 tokens\n",
      " 64%|โโโโโโโ   | 2226/3487 [6:32:22<2:26:16,  6.96s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5912.34 ms /    29 tokens (  203.87 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.97 ms /     3 runs   (  902.32 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8621.99 ms /    32 tokens\n",
      " 64%|โโโโโโโ   | 2227/3487 [6:32:31<2:36:41,  7.46s/it]Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8774.14 ms /    44 tokens (  199.41 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.46 ms /     3 runs   (  896.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11465.24 ms /    47 tokens\n",
      " 64%|โโโโโโโ   | 2228/3487 [6:32:43<3:01:49,  8.67s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7006.98 ms /    28 tokens (  250.25 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2840.63 ms /     3 runs   (  946.88 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    9850.43 ms /    31 tokens\n",
      " 64%|โโโโโโโ   | 2229/3487 [6:32:52<3:09:11,  9.02s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3121.81 ms /     7 tokens (  445.97 ms per token,     2.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3501.24 ms /     3 runs   ( 1167.08 ms per token,     0.86 tokens per second)\n",
      "llama_perf_context_print:       total time =    6625.99 ms /    10 tokens\n",
      " 64%|โโโโโโโ   | 2230/3487 [6:32:59<2:54:02,  8.31s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4708.68 ms /    22 tokens (  214.03 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.94 ms /     3 runs   (  888.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7378.26 ms /    25 tokens\n",
      " 64%|โโโโโโโ   | 2231/3487 [6:33:06<2:48:07,  8.03s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7130.99 ms /    33 tokens (  216.09 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.88 ms /     3 runs   (  893.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9814.00 ms /    36 tokens\n",
      " 64%|โโโโโโโ   | 2232/3487 [6:33:16<2:59:13,  8.57s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2207.05 ms /     6 tokens (  367.84 ms per token,     2.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.24 ms /     3 runs   (  882.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4858.50 ms /     9 tokens\n",
      " 64%|โโโโโโโ   | 2233/3487 [6:33:21<2:35:52,  7.46s/it]Llama.generate: 306 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14130.31 ms /    75 tokens (  188.40 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.76 ms /     3 runs   (  880.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16776.01 ms /    78 tokens\n",
      " 64%|โโโโโโโ   | 2234/3487 [6:33:38<3:34:10, 10.26s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4494.28 ms /    22 tokens (  204.29 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.69 ms /     3 runs   (  890.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7169.50 ms /    25 tokens\n",
      " 64%|โโโโโโโ   | 2235/3487 [6:33:45<3:14:44,  9.33s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3439.26 ms /    16 tokens (  214.95 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.13 ms /     3 runs   (  895.71 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6128.96 ms /    19 tokens\n",
      " 64%|โโโโโโโ   | 2236/3487 [6:33:51<2:54:35,  8.37s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4104.59 ms /    19 tokens (  216.03 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.16 ms /     3 runs   (  904.05 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6819.86 ms /    22 tokens\n",
      " 64%|โโโโโโโ   | 2237/3487 [6:33:58<2:44:48,  7.91s/it]Llama.generate: 306 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14029.20 ms /    72 tokens (  194.85 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.39 ms /     3 runs   (  889.13 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16699.42 ms /    75 tokens\n",
      " 64%|โโโโโโโ   | 2238/3487 [6:34:15<3:39:37, 10.55s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4207.44 ms /    20 tokens (  210.37 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.39 ms /     3 runs   (  909.80 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6939.99 ms /    23 tokens\n",
      " 64%|โโโโโโโ   | 2239/3487 [6:34:22<3:16:58,  9.47s/it]Llama.generate: 306 prefix-match hit, remaining 106 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19916.13 ms /   106 tokens (  187.89 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.13 ms /     3 runs   (  891.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   22592.59 ms /   109 tokens\n",
      " 64%|โโโโโโโ   | 2240/3487 [6:34:44<4:38:40, 13.41s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2182.52 ms /     8 tokens (  272.81 ms per token,     3.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2783.76 ms /     3 runs   (  927.92 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    4968.50 ms /    11 tokens\n",
      " 64%|โโโโโโโ   | 2241/3487 [6:34:49<3:45:56, 10.88s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7343.76 ms /    34 tokens (  215.99 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.26 ms /     3 runs   (  880.75 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9988.66 ms /    37 tokens\n",
      " 64%|โโโโโโโ   | 2242/3487 [6:34:59<3:40:15, 10.61s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2164.19 ms /     6 tokens (  360.70 ms per token,     2.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.24 ms /     3 runs   (  883.08 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4815.88 ms /     9 tokens\n",
      " 64%|โโโโโโโ   | 2243/3487 [6:35:04<3:04:03,  8.88s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3257.47 ms /    15 tokens (  217.16 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.66 ms /     3 runs   (  885.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5915.50 ms /    18 tokens\n",
      " 64%|โโโโโโโ   | 2244/3487 [6:35:10<2:45:33,  7.99s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2657.60 ms /    11 tokens (  241.60 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.90 ms /     3 runs   (  887.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5322.91 ms /    14 tokens\n",
      " 64%|โโโโโโโ   | 2245/3487 [6:35:15<2:28:54,  7.19s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3233.89 ms /    14 tokens (  230.99 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2748.31 ms /     3 runs   (  916.10 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5985.00 ms /    17 tokens\n",
      " 64%|โโโโโโโ   | 2246/3487 [6:35:21<2:21:20,  6.83s/it]Llama.generate: 308 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4286.46 ms /    20 tokens (  214.32 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.33 ms /     3 runs   (  879.44 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6927.21 ms /    23 tokens\n",
      " 64%|โโโโโโโ   | 2247/3487 [6:35:28<2:21:51,  6.86s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2626.69 ms /    11 tokens (  238.79 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.77 ms /     3 runs   (  901.92 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5334.81 ms /    14 tokens\n",
      " 64%|โโโโโโโ   | 2248/3487 [6:35:34<2:12:19,  6.41s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2269.54 ms /     9 tokens (  252.17 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.58 ms /     3 runs   (  885.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4929.17 ms /    12 tokens\n",
      " 64%|โโโโโโโ   | 2249/3487 [6:35:39<2:03:06,  5.97s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3408.45 ms /    14 tokens (  243.46 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.24 ms /     3 runs   (  908.41 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6136.95 ms /    17 tokens\n",
      " 65%|โโโโโโโ   | 2250/3487 [6:35:45<2:04:07,  6.02s/it]Llama.generate: 307 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10642.38 ms /    56 tokens (  190.04 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.00 ms /     3 runs   (  889.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13314.45 ms /    59 tokens\n",
      " 65%|โโโโโโโ   | 2251/3487 [6:35:58<2:49:08,  8.21s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3255.51 ms /    15 tokens (  217.03 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.32 ms /     3 runs   (  898.11 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5952.16 ms /    18 tokens\n",
      " 65%|โโโโโโโ   | 2252/3487 [6:36:04<2:35:06,  7.54s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11368.81 ms /    57 tokens (  199.45 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2752.61 ms /     3 runs   (  917.54 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   14123.82 ms /    60 tokens\n",
      " 65%|โโโโโโโ   | 2253/3487 [6:36:18<3:15:40,  9.51s/it]Llama.generate: 306 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13721.68 ms /    71 tokens (  193.26 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.45 ms /     3 runs   (  880.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16366.38 ms /    74 tokens\n",
      " 65%|โโโโโโโ   | 2254/3487 [6:36:35<3:57:48, 11.57s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8436.31 ms /    43 tokens (  196.19 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.42 ms /     3 runs   (  879.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11076.21 ms /    46 tokens\n",
      " 65%|โโโโโโโ   | 2255/3487 [6:36:46<3:54:37, 11.43s/it]Llama.generate: 308 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10901.97 ms /    59 tokens (  184.78 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.38 ms /     3 runs   (  882.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13553.35 ms /    62 tokens\n",
      " 65%|โโโโโโโ   | 2256/3487 [6:36:59<4:07:34, 12.07s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4174.92 ms /    20 tokens (  208.75 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.89 ms /     3 runs   (  894.63 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6861.79 ms /    23 tokens\n",
      " 65%|โโโโโโโ   | 2257/3487 [6:37:06<3:35:24, 10.51s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7234.60 ms /    36 tokens (  200.96 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.41 ms /     3 runs   (  882.80 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9885.84 ms /    39 tokens\n",
      " 65%|โโโโโโโ   | 2258/3487 [6:37:16<3:31:28, 10.32s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3492.22 ms /    16 tokens (  218.26 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.53 ms /     3 runs   (  891.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6170.32 ms /    19 tokens\n",
      " 65%|โโโโโโโ   | 2259/3487 [6:37:22<3:05:50,  9.08s/it]Llama.generate: 306 prefix-match hit, remaining 89 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16490.06 ms /    89 tokens (  185.28 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.09 ms /     3 runs   (  881.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19136.79 ms /    92 tokens\n",
      " 65%|โโโโโโโ   | 2260/3487 [6:37:41<4:07:26, 12.10s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4691.93 ms /    23 tokens (  204.00 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.94 ms /     3 runs   (  890.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7367.46 ms /    26 tokens\n",
      " 65%|โโโโโโโ   | 2261/3487 [6:37:49<3:38:17, 10.68s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2627.63 ms /    11 tokens (  238.88 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.55 ms /     3 runs   (  890.18 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5301.27 ms /    14 tokens\n",
      " 65%|โโโโโโโ   | 2262/3487 [6:37:54<3:05:11,  9.07s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7625.81 ms /    34 tokens (  224.29 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.46 ms /     3 runs   (  896.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10316.55 ms /    37 tokens\n",
      " 65%|โโโโโโโ   | 2263/3487 [6:38:04<3:12:43,  9.45s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5450.34 ms /    27 tokens (  201.86 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.91 ms /     3 runs   (  879.64 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8091.54 ms /    30 tokens\n",
      " 65%|โโโโโโโ   | 2264/3487 [6:38:12<3:04:19,  9.04s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6280.94 ms /    32 tokens (  196.28 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.49 ms /     3 runs   (  897.83 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8977.33 ms /    35 tokens\n",
      " 65%|โโโโโโโ   | 2265/3487 [6:38:21<3:03:49,  9.03s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3215.85 ms /    15 tokens (  214.39 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.78 ms /     3 runs   (  886.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5878.52 ms /    18 tokens\n",
      " 65%|โโโโโโโ   | 2266/3487 [6:38:27<2:44:30,  8.08s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5260.36 ms /    27 tokens (  194.83 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.21 ms /     3 runs   (  883.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7912.96 ms /    30 tokens\n",
      " 65%|โโโโโโโ   | 2267/3487 [6:38:35<2:43:23,  8.04s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7165.40 ms /    33 tokens (  217.13 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.46 ms /     3 runs   (  877.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9800.90 ms /    36 tokens\n",
      " 65%|โโโโโโโ   | 2268/3487 [6:38:45<2:54:03,  8.57s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5279.79 ms /    27 tokens (  195.55 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.99 ms /     3 runs   (  890.66 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7954.23 ms /    30 tokens\n",
      " 65%|โโโโโโโ   | 2269/3487 [6:38:53<2:50:14,  8.39s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4035.31 ms /    19 tokens (  212.38 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2733.95 ms /     3 runs   (  911.32 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6771.55 ms /    22 tokens\n",
      " 65%|โโโโโโโ   | 2270/3487 [6:39:00<2:40:19,  7.90s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3372.86 ms /    15 tokens (  224.86 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2738.31 ms /     3 runs   (  912.77 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6113.65 ms /    18 tokens\n",
      " 65%|โโโโโโโ   | 2271/3487 [6:39:06<2:29:20,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5501.42 ms /    26 tokens (  211.59 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.97 ms /     3 runs   (  881.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8147.61 ms /    29 tokens\n",
      " 65%|โโโโโโโ   | 2272/3487 [6:39:14<2:33:59,  7.60s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2683.17 ms /     9 tokens (  298.13 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.85 ms /     3 runs   (  884.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5339.83 ms /    12 tokens\n",
      " 65%|โโโโโโโ   | 2273/3487 [6:39:19<2:20:11,  6.93s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2129.70 ms /     8 tokens (  266.21 ms per token,     3.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.94 ms /     3 runs   (  890.31 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4803.11 ms /    11 tokens\n",
      " 65%|โโโโโโโ   | 2274/3487 [6:39:24<2:07:13,  6.29s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5244.04 ms /    26 tokens (  201.69 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.10 ms /     3 runs   (  890.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7917.91 ms /    29 tokens\n",
      " 65%|โโโโโโโ   | 2275/3487 [6:39:32<2:17:01,  6.78s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4342.11 ms /    21 tokens (  206.77 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.38 ms /     3 runs   (  895.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7031.09 ms /    24 tokens\n",
      " 65%|โโโโโโโ   | 2276/3487 [6:39:39<2:18:27,  6.86s/it]Llama.generate: 306 prefix-match hit, remaining 232 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   42247.84 ms /   232 tokens (  182.10 ms per token,     5.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.49 ms /     3 runs   (  889.16 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   44918.13 ms /   235 tokens\n",
      " 65%|โโโโโโโ   | 2277/3487 [6:40:24<6:08:38, 18.28s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5435.50 ms /    27 tokens (  201.31 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.07 ms /     3 runs   (  893.69 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8118.83 ms /    30 tokens\n",
      " 65%|โโโโโโโ   | 2278/3487 [6:40:32<5:06:58, 15.23s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13239.13 ms /    67 tokens (  197.60 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.71 ms /     3 runs   (  896.90 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   15932.31 ms /    70 tokens\n",
      " 65%|โโโโโโโ   | 2279/3487 [6:40:48<5:10:58, 15.45s/it]Llama.generate: 307 prefix-match hit, remaining 129 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24387.29 ms /   129 tokens (  189.05 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.72 ms /     3 runs   (  880.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27032.64 ms /   132 tokens\n",
      " 65%|โโโโโโโ   | 2280/3487 [6:41:15<6:20:42, 18.93s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8826.61 ms /    46 tokens (  191.88 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.86 ms /     3 runs   (  885.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11486.07 ms /    49 tokens\n",
      " 65%|โโโโโโโ   | 2281/3487 [6:41:27<5:35:35, 16.70s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9226.80 ms /    45 tokens (  205.04 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.94 ms /     3 runs   (  890.65 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11901.03 ms /    48 tokens\n",
      " 65%|โโโโโโโ   | 2282/3487 [6:41:39<5:06:27, 15.26s/it]Llama.generate: 307 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14031.96 ms /    74 tokens (  189.62 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.81 ms /     3 runs   (  894.60 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16718.47 ms /    77 tokens\n",
      " 65%|โโโโโโโ   | 2283/3487 [6:41:55<5:15:02, 15.70s/it]Llama.generate: 307 prefix-match hit, remaining 120 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23787.31 ms /   120 tokens (  198.23 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.36 ms /     3 runs   (  896.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   26478.40 ms /   123 tokens\n",
      " 66%|โโโโโโโ   | 2284/3487 [6:42:22<6:19:39, 18.94s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3578.02 ms /    14 tokens (  255.57 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2882.80 ms /     3 runs   (  960.93 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    6463.18 ms /    17 tokens\n",
      " 66%|โโโโโโโ   | 2285/3487 [6:42:28<5:04:27, 15.20s/it]Llama.generate: 306 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15527.11 ms /    82 tokens (  189.36 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.76 ms /     3 runs   (  894.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   18213.23 ms /    85 tokens\n",
      " 66%|โโโโโโโ   | 2286/3487 [6:42:46<5:22:21, 16.10s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4262.56 ms /    21 tokens (  202.98 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.87 ms /     3 runs   (  905.62 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6981.80 ms /    24 tokens\n",
      " 66%|โโโโโโโ   | 2287/3487 [6:42:53<4:27:24, 13.37s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6228.39 ms /    32 tokens (  194.64 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.60 ms /     3 runs   (  884.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8885.73 ms /    35 tokens\n",
      " 66%|โโโโโโโ   | 2288/3487 [6:43:02<4:00:20, 12.03s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8864.94 ms /    30 tokens (  295.50 ms per token,     3.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3700.34 ms /     3 runs   ( 1233.45 ms per token,     0.81 tokens per second)\n",
      "llama_perf_context_print:       total time =   12568.36 ms /    33 tokens\n",
      " 66%|โโโโโโโ   | 2289/3487 [6:43:15<4:03:26, 12.19s/it]Llama.generate: 308 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5735.41 ms /    23 tokens (  249.37 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3308.69 ms /     3 runs   ( 1102.90 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =    9047.68 ms /    26 tokens\n",
      " 66%|โโโโโโโ   | 2290/3487 [6:43:24<3:44:28, 11.25s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5640.25 ms /    24 tokens (  235.01 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2877.04 ms /     3 runs   (  959.01 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    8520.31 ms /    27 tokens\n",
      " 66%|โโโโโโโ   | 2291/3487 [6:43:33<3:28:01, 10.44s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4156.05 ms /    16 tokens (  259.75 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2832.35 ms /     3 runs   (  944.12 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    6991.01 ms /    19 tokens\n",
      " 66%|โโโโโโโ   | 2292/3487 [6:43:40<3:07:19,  9.41s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5388.90 ms /    25 tokens (  215.56 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2812.64 ms /     3 runs   (  937.55 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    8204.05 ms /    28 tokens\n",
      " 66%|โโโโโโโ   | 2293/3487 [6:43:48<3:00:03,  9.05s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3508.00 ms /    15 tokens (  233.87 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2803.59 ms /     3 runs   (  934.53 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6314.76 ms /    18 tokens\n",
      " 66%|โโโโโโโ   | 2294/3487 [6:43:54<2:43:39,  8.23s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5280.91 ms /    24 tokens (  220.04 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.74 ms /     3 runs   (  909.91 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8012.50 ms /    27 tokens\n",
      " 66%|โโโโโโโ   | 2295/3487 [6:44:02<2:42:15,  8.17s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7479.68 ms /    35 tokens (  213.71 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2784.18 ms /     3 runs   (  928.06 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   10266.55 ms /    38 tokens\n",
      " 66%|โโโโโโโ   | 2296/3487 [6:44:12<2:54:40,  8.80s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5081.75 ms /    21 tokens (  241.99 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2868.85 ms /     3 runs   (  956.28 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    7953.38 ms /    24 tokens\n",
      " 66%|โโโโโโโ   | 2297/3487 [6:44:20<2:49:33,  8.55s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3545.25 ms /    16 tokens (  221.58 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.77 ms /     3 runs   (  890.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6219.93 ms /    19 tokens\n",
      " 66%|โโโโโโโ   | 2298/3487 [6:44:27<2:35:36,  7.85s/it]Llama.generate: 307 prefix-match hit, remaining 151 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28106.48 ms /   151 tokens (  186.14 ms per token,     5.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.80 ms /     3 runs   (  896.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   30800.13 ms /   154 tokens\n",
      " 66%|โโโโโโโ   | 2299/3487 [6:44:57<4:51:50, 14.74s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4253.85 ms /    21 tokens (  202.56 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.46 ms /     3 runs   (  893.49 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6936.65 ms /    24 tokens\n",
      " 66%|โโโโโโโ   | 2300/3487 [6:45:04<4:05:21, 12.40s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2085.39 ms /     8 tokens (  260.67 ms per token,     3.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.02 ms /     3 runs   (  907.01 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4807.99 ms /    11 tokens\n",
      " 66%|โโโโโโโ   | 2301/3487 [6:45:09<3:20:09, 10.13s/it]Llama.generate: 307 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15089.26 ms /    78 tokens (  193.45 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.73 ms /     3 runs   (  876.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17722.93 ms /    81 tokens\n",
      " 66%|โโโโโโโ   | 2302/3487 [6:45:27<4:05:03, 12.41s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4385.60 ms /    20 tokens (  219.28 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2792.96 ms /     3 runs   (  930.99 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7180.62 ms /    23 tokens\n",
      " 66%|โโโโโโโ   | 2303/3487 [6:45:34<3:33:57, 10.84s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7445.19 ms /    34 tokens (  218.98 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.57 ms /     3 runs   (  897.86 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10141.28 ms /    37 tokens\n",
      " 66%|โโโโโโโ   | 2304/3487 [6:45:44<3:29:40, 10.63s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6184.32 ms /    28 tokens (  220.87 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.52 ms /     3 runs   (  891.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8862.60 ms /    31 tokens\n",
      " 66%|โโโโโโโ   | 2305/3487 [6:45:53<3:19:04, 10.11s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7194.87 ms /    34 tokens (  211.61 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.25 ms /     3 runs   (  896.08 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9885.48 ms /    37 tokens\n",
      " 66%|โโโโโโโ   | 2306/3487 [6:46:03<3:17:38, 10.04s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5031.50 ms /    23 tokens (  218.76 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.37 ms /     3 runs   (  897.12 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7725.75 ms /    26 tokens\n",
      " 66%|โโโโโโโ   | 2307/3487 [6:46:11<3:03:51,  9.35s/it]Llama.generate: 314 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3571.03 ms /    16 tokens (  223.19 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2714.48 ms /     3 runs   (  904.83 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6287.59 ms /    19 tokens\n",
      " 66%|โโโโโโโ   | 2308/3487 [6:46:17<2:45:41,  8.43s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5839.70 ms /    29 tokens (  201.37 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.25 ms /     3 runs   (  896.08 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8530.58 ms /    32 tokens\n",
      " 66%|โโโโโโโ   | 2309/3487 [6:46:26<2:46:11,  8.47s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4051.24 ms /    19 tokens (  213.22 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.67 ms /     3 runs   (  887.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6716.07 ms /    22 tokens\n",
      " 66%|โโโโโโโ   | 2310/3487 [6:46:32<2:35:48,  7.94s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2501.66 ms /    10 tokens (  250.17 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2870.07 ms /     3 runs   (  956.69 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    5373.92 ms /    13 tokens\n",
      " 66%|โโโโโโโ   | 2311/3487 [6:46:38<2:20:36,  7.17s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2846.37 ms /    12 tokens (  237.20 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2754.08 ms /     3 runs   (  918.03 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5603.92 ms /    15 tokens\n",
      " 66%|โโโโโโโ   | 2312/3487 [6:46:43<2:11:20,  6.71s/it]Llama.generate: 307 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15992.17 ms /    84 tokens (  190.38 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.29 ms /     3 runs   (  883.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18644.29 ms /    87 tokens\n",
      " 66%|โโโโโโโ   | 2313/3487 [6:47:02<3:21:21, 10.29s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2597.83 ms /    10 tokens (  259.78 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2766.12 ms /     3 runs   (  922.04 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5366.75 ms /    13 tokens\n",
      " 66%|โโโโโโโ   | 2314/3487 [6:47:07<2:52:22,  8.82s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5822.61 ms /    29 tokens (  200.78 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.56 ms /     3 runs   (  904.52 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8539.13 ms /    32 tokens\n",
      " 66%|โโโโโโโ   | 2315/3487 [6:47:16<2:50:38,  8.74s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3705.28 ms /    16 tokens (  231.58 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.98 ms /     3 runs   (  898.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6405.00 ms /    19 tokens\n",
      " 66%|โโโโโโโ   | 2316/3487 [6:47:22<2:36:53,  8.04s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3227.86 ms /    14 tokens (  230.56 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.00 ms /     3 runs   (  896.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5920.16 ms /    17 tokens\n",
      " 66%|โโโโโโโ   | 2317/3487 [6:47:28<2:24:24,  7.41s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12451.62 ms /    64 tokens (  194.56 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.70 ms /     3 runs   (  893.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15135.40 ms /    67 tokens\n",
      " 66%|โโโโโโโ   | 2318/3487 [6:47:43<3:09:31,  9.73s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3315.77 ms /    15 tokens (  221.05 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2736.98 ms /     3 runs   (  912.33 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6055.51 ms /    18 tokens\n",
      " 67%|โโโโโโโ   | 2319/3487 [6:47:49<2:47:58,  8.63s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3375.67 ms /    15 tokens (  225.04 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.52 ms /     3 runs   (  900.51 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6079.68 ms /    18 tokens\n",
      " 67%|โโโโโโโ   | 2320/3487 [6:47:55<2:33:00,  7.87s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6135.00 ms /    28 tokens (  219.11 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.09 ms /     3 runs   (  894.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8821.92 ms /    31 tokens\n",
      " 67%|โโโโโโโ   | 2321/3487 [6:48:04<2:38:29,  8.16s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3209.55 ms /    14 tokens (  229.25 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.41 ms /     3 runs   (  897.14 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5903.76 ms /    17 tokens\n",
      " 67%|โโโโโโโ   | 2322/3487 [6:48:10<2:25:16,  7.48s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8301.98 ms /    41 tokens (  202.49 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.38 ms /     3 runs   (  879.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10941.87 ms /    44 tokens\n",
      " 67%|โโโโโโโ   | 2323/3487 [6:48:21<2:45:20,  8.52s/it]Llama.generate: 307 prefix-match hit, remaining 141 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26424.67 ms /   141 tokens (  187.41 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.52 ms /     3 runs   (  893.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   29108.82 ms /   144 tokens\n",
      " 67%|โโโโโโโ   | 2324/3487 [6:48:50<4:44:57, 14.70s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3068.94 ms /    12 tokens (  255.74 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3241.10 ms /     3 runs   ( 1080.37 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    6313.34 ms /    15 tokens\n",
      " 67%|โโโโโโโ   | 2325/3487 [6:48:57<3:56:02, 12.19s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5179.89 ms /    24 tokens (  215.83 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.53 ms /     3 runs   (  889.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7850.94 ms /    27 tokens\n",
      " 67%|โโโโโโโ   | 2326/3487 [6:49:04<3:30:42, 10.89s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2022.22 ms /     7 tokens (  288.89 ms per token,     3.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.89 ms /     3 runs   (  890.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4697.75 ms /    10 tokens\n",
      " 67%|โโโโโโโ   | 2327/3487 [6:49:09<2:54:39,  9.03s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2273.78 ms /     9 tokens (  252.64 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.46 ms /     3 runs   (  904.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4988.47 ms /    12 tokens\n",
      " 67%|โโโโโโโ   | 2328/3487 [6:49:14<2:31:07,  7.82s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1653.28 ms /     5 tokens (  330.66 ms per token,     3.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2727.20 ms /     3 runs   (  909.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4383.33 ms /     8 tokens\n",
      " 67%|โโโโโโโ   | 2329/3487 [6:49:19<2:11:07,  6.79s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2258.58 ms /     8 tokens (  282.32 ms per token,     3.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2734.71 ms /     3 runs   (  911.57 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4995.85 ms /    11 tokens\n",
      " 67%|โโโโโโโ   | 2330/3487 [6:49:24<2:00:39,  6.26s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2510.21 ms /     7 tokens (  358.60 ms per token,     2.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.06 ms /     3 runs   (  888.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5176.88 ms /    10 tokens\n",
      " 67%|โโโโโโโ   | 2331/3487 [6:49:29<1:54:21,  5.94s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1983.62 ms /     7 tokens (  283.38 ms per token,     3.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.56 ms /     3 runs   (  887.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4649.08 ms /    10 tokens\n",
      " 67%|โโโโโโโ   | 2332/3487 [6:49:33<1:46:52,  5.55s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2248.93 ms /     9 tokens (  249.88 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.39 ms /     3 runs   (  894.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4936.22 ms /    12 tokens\n",
      " 67%|โโโโโโโ   | 2333/3487 [6:49:38<1:43:16,  5.37s/it]Llama.generate: 311 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4124.41 ms /    19 tokens (  217.07 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.32 ms /     3 runs   (  899.11 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6823.63 ms /    22 tokens\n",
      " 67%|โโโโโโโ   | 2334/3487 [6:49:45<1:51:37,  5.81s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7277.11 ms /    35 tokens (  207.92 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.35 ms /     3 runs   (  889.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9949.05 ms /    38 tokens\n",
      " 67%|โโโโโโโ   | 2335/3487 [6:49:55<2:15:25,  7.05s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2623.00 ms /    11 tokens (  238.45 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.57 ms /     3 runs   (  907.52 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5348.28 ms /    14 tokens\n",
      " 67%|โโโโโโโ   | 2336/3487 [6:50:00<2:05:32,  6.54s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3699.32 ms /    17 tokens (  217.61 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2714.38 ms /     3 runs   (  904.79 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6416.83 ms /    20 tokens\n",
      " 67%|โโโโโโโ   | 2337/3487 [6:50:07<2:04:44,  6.51s/it]Llama.generate: 313 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2465.23 ms /    10 tokens (  246.52 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2733.09 ms /     3 runs   (  911.03 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5201.44 ms /    13 tokens\n",
      " 67%|โโโโโโโ   | 2338/3487 [6:50:12<1:57:10,  6.12s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3482.67 ms /    15 tokens (  232.18 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2885.30 ms /     3 runs   (  961.77 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    6370.20 ms /    18 tokens\n",
      " 67%|โโโโโโโ   | 2339/3487 [6:50:19<1:58:33,  6.20s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6159.60 ms /    29 tokens (  212.40 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2855.56 ms /     3 runs   (  951.85 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    9018.07 ms /    32 tokens\n",
      " 67%|โโโโโโโ   | 2340/3487 [6:50:28<2:14:41,  7.05s/it]Llama.generate: 306 prefix-match hit, remaining 208 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   39384.41 ms /   208 tokens (  189.35 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.73 ms /     3 runs   (  890.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   42070.18 ms /   211 tokens\n",
      " 67%|โโโโโโโ   | 2341/3487 [6:51:10<5:35:28, 17.56s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4315.21 ms /    20 tokens (  215.76 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.00 ms /     3 runs   (  903.00 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7026.46 ms /    23 tokens\n",
      " 67%|โโโโโโโ   | 2342/3487 [6:51:17<4:34:54, 14.41s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5687.71 ms /    24 tokens (  236.99 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2880.17 ms /     3 runs   (  960.06 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    8570.71 ms /    27 tokens\n",
      " 67%|โโโโโโโ   | 2343/3487 [6:51:25<4:01:20, 12.66s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8119.07 ms /    39 tokens (  208.18 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.95 ms /     3 runs   (  891.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10798.65 ms /    42 tokens\n",
      " 67%|โโโโโโโ   | 2344/3487 [6:51:36<3:50:33, 12.10s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8714.46 ms /    45 tokens (  193.65 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.12 ms /     3 runs   (  893.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11397.34 ms /    48 tokens\n",
      " 67%|โโโโโโโ   | 2345/3487 [6:51:47<3:46:23, 11.89s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3108.62 ms /    14 tokens (  222.04 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2746.69 ms /     3 runs   (  915.56 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5857.95 ms /    17 tokens\n",
      " 67%|โโโโโโโ   | 2346/3487 [6:51:53<3:11:47, 10.09s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4131.25 ms /    19 tokens (  217.43 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.98 ms /     3 runs   (  893.66 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6814.26 ms /    22 tokens\n",
      " 67%|โโโโโโโ   | 2347/3487 [6:52:00<2:53:01,  9.11s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10775.28 ms /    54 tokens (  199.54 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2888.69 ms /     3 runs   (  962.90 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   13666.95 ms /    57 tokens\n",
      " 67%|โโโโโโโ   | 2348/3487 [6:52:14<3:18:54, 10.48s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4260.30 ms /    19 tokens (  224.23 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2752.06 ms /     3 runs   (  917.35 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7015.24 ms /    22 tokens\n",
      " 67%|โโโโโโโ   | 2349/3487 [6:52:21<2:59:05,  9.44s/it]Llama.generate: 306 prefix-match hit, remaining 115 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21455.95 ms /   115 tokens (  186.57 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.18 ms /     3 runs   (  892.73 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   24137.66 ms /   118 tokens\n",
      " 67%|โโโโโโโ   | 2350/3487 [6:52:45<4:22:30, 13.85s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3604.39 ms /    14 tokens (  257.46 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.19 ms /     3 runs   (  897.40 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6299.37 ms /    17 tokens\n",
      " 67%|โโโโโโโ   | 2351/3487 [6:52:51<3:39:26, 11.59s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2677.77 ms /    11 tokens (  243.43 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.17 ms /     3 runs   (  896.72 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5370.42 ms /    14 tokens\n",
      " 67%|โโโโโโโ   | 2352/3487 [6:52:57<3:04:00,  9.73s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1783.93 ms /     6 tokens (  297.32 ms per token,     3.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.54 ms /     3 runs   (  894.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4472.19 ms /     9 tokens\n",
      " 67%|โโโโโโโ   | 2353/3487 [6:53:01<2:34:05,  8.15s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2267.61 ms /     9 tokens (  251.96 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.11 ms /     3 runs   (  899.37 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4967.65 ms /    12 tokens\n",
      " 68%|โโโโโโโ   | 2354/3487 [6:53:06<2:15:57,  7.20s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2011.45 ms /     7 tokens (  287.35 ms per token,     3.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.19 ms /     3 runs   (  892.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4690.80 ms /    10 tokens\n",
      " 68%|โโโโโโโ   | 2355/3487 [6:53:11<2:01:41,  6.45s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4248.99 ms /    20 tokens (  212.45 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.55 ms /     3 runs   (  894.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6935.62 ms /    23 tokens\n",
      " 68%|โโโโโโโ   | 2356/3487 [6:53:18<2:04:22,  6.60s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8256.06 ms /    41 tokens (  201.37 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.27 ms /     3 runs   (  884.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10912.94 ms /    44 tokens\n",
      " 68%|โโโโโโโ   | 2357/3487 [6:53:29<2:28:41,  7.89s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7937.11 ms /    40 tokens (  198.43 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.46 ms /     3 runs   (  887.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10600.91 ms /    43 tokens\n",
      " 68%|โโโโโโโ   | 2358/3487 [6:53:39<2:43:52,  8.71s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12874.71 ms /    66 tokens (  195.07 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.72 ms /     3 runs   (  883.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15527.79 ms /    69 tokens\n",
      " 68%|โโโโโโโ   | 2359/3487 [6:53:55<3:22:14, 10.76s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4411.65 ms /    20 tokens (  220.58 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.74 ms /     3 runs   (  906.58 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7134.07 ms /    23 tokens\n",
      " 68%|โโโโโโโ   | 2360/3487 [6:54:02<3:01:41,  9.67s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4216.02 ms /    18 tokens (  234.22 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.18 ms /     3 runs   (  884.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6873.55 ms /    21 tokens\n",
      " 68%|โโโโโโโ   | 2361/3487 [6:54:09<2:45:49,  8.84s/it]Llama.generate: 308 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5285.74 ms /    26 tokens (  203.30 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.23 ms /     3 runs   (  893.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7968.24 ms /    29 tokens\n",
      " 68%|โโโโโโโ   | 2362/3487 [6:54:17<2:40:50,  8.58s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5515.26 ms /    25 tokens (  220.61 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.75 ms /     3 runs   (  900.58 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8219.60 ms /    28 tokens\n",
      " 68%|โโโโโโโ   | 2363/3487 [6:54:25<2:38:43,  8.47s/it]Llama.generate: 306 prefix-match hit, remaining 158 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   29297.79 ms /   158 tokens (  185.43 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.76 ms /     3 runs   (  894.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   31983.72 ms /   161 tokens\n",
      " 68%|โโโโโโโ   | 2364/3487 [6:54:57<4:50:38, 15.53s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3761.90 ms /    17 tokens (  221.29 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2796.89 ms /     3 runs   (  932.30 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6561.23 ms /    20 tokens\n",
      " 68%|โโโโโโโ   | 2365/3487 [6:55:04<4:00:07, 12.84s/it]Llama.generate: 306 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18941.32 ms /   100 tokens (  189.41 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.97 ms /     3 runs   (  888.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   21610.50 ms /   103 tokens\n",
      " 68%|โโโโโโโ   | 2366/3487 [6:55:25<4:49:06, 15.47s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7212.54 ms /    35 tokens (  206.07 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.38 ms /     3 runs   (  891.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9889.00 ms /    38 tokens\n",
      " 68%|โโโโโโโ   | 2367/3487 [6:55:35<4:17:36, 13.80s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11427.96 ms /    60 tokens (  190.47 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.34 ms /     3 runs   (  899.45 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   14129.54 ms /    63 tokens\n",
      " 68%|โโโโโโโ   | 2368/3487 [6:55:49<4:19:16, 13.90s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5906.78 ms /    28 tokens (  210.96 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2808.25 ms /     3 runs   (  936.08 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    8717.68 ms /    31 tokens\n",
      " 68%|โโโโโโโ   | 2369/3487 [6:55:58<3:50:06, 12.35s/it]Llama.generate: 307 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1663.07 ms /     5 tokens (  332.61 ms per token,     3.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.11 ms /     3 runs   (  909.70 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4394.69 ms /     8 tokens\n",
      " 68%|โโโโโโโ   | 2370/3487 [6:56:02<3:05:31,  9.97s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3627.74 ms /    16 tokens (  226.73 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.09 ms /     3 runs   (  911.70 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6365.52 ms /    19 tokens\n",
      " 68%|โโโโโโโ   | 2371/3487 [6:56:09<2:45:18,  8.89s/it]Llama.generate: 306 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19661.76 ms /   105 tokens (  187.25 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2785.94 ms /     3 runs   (  928.65 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   22451.63 ms /   108 tokens\n",
      " 68%|โโโโโโโ   | 2372/3487 [6:56:31<4:00:49, 12.96s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5728.65 ms /    29 tokens (  197.54 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.10 ms /     3 runs   (  891.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8405.25 ms /    32 tokens\n",
      " 68%|โโโโโโโ   | 2373/3487 [6:56:40<3:35:17, 11.60s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4320.64 ms /    21 tokens (  205.74 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.67 ms /     3 runs   (  903.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7034.81 ms /    24 tokens\n",
      " 68%|โโโโโโโ   | 2374/3487 [6:56:47<3:09:45, 10.23s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2106.63 ms /     8 tokens (  263.33 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.75 ms /     3 runs   (  902.92 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4817.88 ms /    11 tokens\n",
      " 68%|โโโโโโโ   | 2375/3487 [6:56:52<2:39:33,  8.61s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5397.77 ms /    27 tokens (  199.92 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.00 ms /     3 runs   (  902.33 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8107.02 ms /    30 tokens\n",
      " 68%|โโโโโโโ   | 2376/3487 [6:57:00<2:36:40,  8.46s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1695.84 ms /     5 tokens (  339.17 ms per token,     2.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.35 ms /     3 runs   (  902.45 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4405.73 ms /     8 tokens\n",
      " 68%|โโโโโโโ   | 2377/3487 [6:57:04<2:14:04,  7.25s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3680.32 ms /    14 tokens (  262.88 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.58 ms /     3 runs   (  898.86 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6379.42 ms /    17 tokens\n",
      " 68%|โโโโโโโ   | 2378/3487 [6:57:10<2:09:11,  6.99s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5477.18 ms /    27 tokens (  202.86 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2728.80 ms /     3 runs   (  909.60 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8208.62 ms /    30 tokens\n",
      " 68%|โโโโโโโ   | 2379/3487 [6:57:19<2:15:52,  7.36s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3623.97 ms /    16 tokens (  226.50 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.38 ms /     3 runs   (  885.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6282.68 ms /    19 tokens\n",
      " 68%|โโโโโโโ   | 2380/3487 [6:57:25<2:09:51,  7.04s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2498.82 ms /    10 tokens (  249.88 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.69 ms /     3 runs   (  887.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5163.59 ms /    13 tokens\n",
      " 68%|โโโโโโโ   | 2381/3487 [6:57:30<1:59:24,  6.48s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9934.59 ms /    52 tokens (  191.05 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.48 ms /     3 runs   (  882.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12583.61 ms /    55 tokens\n",
      " 68%|โโโโโโโ   | 2382/3487 [6:57:43<2:33:05,  8.31s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11157.96 ms /    59 tokens (  189.12 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.54 ms /     3 runs   (  878.85 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13797.13 ms /    62 tokens\n",
      " 68%|โโโโโโโ   | 2383/3487 [6:57:57<3:03:16,  9.96s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2436.67 ms /    10 tokens (  243.67 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.89 ms /     3 runs   (  892.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5118.38 ms /    13 tokens\n",
      " 68%|โโโโโโโ   | 2384/3487 [6:58:02<2:36:26,  8.51s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3308.38 ms /    15 tokens (  220.56 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.31 ms /     3 runs   (  884.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5963.47 ms /    18 tokens\n",
      " 68%|โโโโโโโ   | 2385/3487 [6:58:08<2:22:19,  7.75s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4330.65 ms /    21 tokens (  206.22 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.69 ms /     3 runs   (  882.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6981.73 ms /    24 tokens\n",
      " 68%|โโโโโโโ   | 2386/3487 [6:58:15<2:18:11,  7.53s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3151.57 ms /    14 tokens (  225.11 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.54 ms /     3 runs   (  902.18 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5860.91 ms /    17 tokens\n",
      " 68%|โโโโโโโ   | 2387/3487 [6:58:21<2:08:55,  7.03s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2547.11 ms /     7 tokens (  363.87 ms per token,     2.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.40 ms /     3 runs   (  890.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5220.70 ms /    10 tokens\n",
      " 68%|โโโโโโโ   | 2388/3487 [6:58:26<1:58:53,  6.49s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8426.40 ms /    42 tokens (  200.63 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.86 ms /     3 runs   (  876.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11058.81 ms /    45 tokens\n",
      " 69%|โโโโโโโ   | 2389/3487 [6:58:37<2:23:54,  7.86s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1997.41 ms /     7 tokens (  285.34 ms per token,     3.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.65 ms /     3 runs   (  887.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4661.96 ms /    10 tokens\n",
      " 69%|โโโโโโโ   | 2390/3487 [6:58:42<2:06:15,  6.91s/it]Llama.generate: 313 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3951.66 ms /     4 runs   (  987.92 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    3954.90 ms /     5 tokens\n",
      " 69%|โโโโโโโ   | 2391/3487 [6:58:45<1:50:01,  6.02s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2093.25 ms /     8 tokens (  261.66 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.22 ms /     3 runs   (  906.41 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4815.61 ms /    11 tokens\n",
      " 69%|โโโโโโโ   | 2392/3487 [6:58:50<1:43:21,  5.66s/it]Llama.generate: 306 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13262.01 ms /    65 tokens (  204.03 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.16 ms /     3 runs   (  882.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15910.32 ms /    68 tokens\n",
      " 69%|โโโโโโโ   | 2393/3487 [6:59:06<2:39:22,  8.74s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5196.69 ms /    25 tokens (  207.87 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.97 ms /     3 runs   (  898.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7896.27 ms /    28 tokens\n",
      " 69%|โโโโโโโ   | 2394/3487 [6:59:14<2:34:38,  8.49s/it]Llama.generate: 307 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15646.85 ms /    79 tokens (  198.06 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.81 ms /     3 runs   (  888.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18315.17 ms /    82 tokens\n",
      " 69%|โโโโโโโ   | 2395/3487 [6:59:32<3:28:11, 11.44s/it]Llama.generate: 307 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11940.52 ms /    64 tokens (  186.57 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.60 ms /     3 runs   (  885.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14598.68 ms /    67 tokens\n",
      " 69%|โโโโโโโ   | 2396/3487 [6:59:47<3:45:17, 12.39s/it]Llama.generate: 307 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19355.23 ms /   100 tokens (  193.55 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.18 ms /     3 runs   (  883.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   22007.80 ms /   103 tokens\n",
      " 69%|โโโโโโโ   | 2397/3487 [7:00:09<4:37:33, 15.28s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6530.59 ms /    32 tokens (  204.08 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.46 ms /     3 runs   (  902.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9239.55 ms /    35 tokens\n",
      " 69%|โโโโโโโ   | 2398/3487 [7:00:18<4:04:27, 13.47s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1832.87 ms /     6 tokens (  305.48 ms per token,     3.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.35 ms /     3 runs   (  896.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4524.17 ms /     9 tokens\n",
      " 69%|โโโโโโโ   | 2399/3487 [7:00:23<3:15:36, 10.79s/it]Llama.generate: 306 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15298.79 ms /    80 tokens (  191.23 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.39 ms /     3 runs   (  885.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17957.54 ms /    83 tokens\n",
      " 69%|โโโโโโโ   | 2400/3487 [7:00:41<3:54:26, 12.94s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1694.78 ms /     6 tokens (  282.46 ms per token,     3.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2795.07 ms /     3 runs   (  931.69 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4492.70 ms /     9 tokens\n",
      " 69%|โโโโโโโ   | 2401/3487 [7:00:45<3:08:24, 10.41s/it]Llama.generate: 312 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3979.57 ms /     4 runs   (  994.89 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    3982.20 ms /     5 tokens\n",
      " 69%|โโโโโโโ   | 2402/3487 [7:00:49<2:33:25,  8.48s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3563.59 ms /    16 tokens (  222.72 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.24 ms /     3 runs   (  879.75 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6206.67 ms /    19 tokens\n",
      " 69%|โโโโโโโ   | 2403/3487 [7:00:56<2:20:59,  7.80s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9961.42 ms /    49 tokens (  203.29 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.42 ms /     3 runs   (  902.14 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   12670.13 ms /    52 tokens\n",
      " 69%|โโโโโโโ   | 2404/3487 [7:01:08<2:47:25,  9.28s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2763.07 ms /    11 tokens (  251.19 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.00 ms /     3 runs   (  891.33 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5439.89 ms /    14 tokens\n",
      " 69%|โโโโโโโ   | 2405/3487 [7:01:14<2:26:34,  8.13s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2933.48 ms /    10 tokens (  293.35 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.61 ms /     3 runs   (  889.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5605.72 ms /    13 tokens\n",
      " 69%|โโโโโโโ   | 2406/3487 [7:01:19<2:12:51,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7522.38 ms /    38 tokens (  197.96 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.00 ms /     3 runs   (  879.00 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10162.38 ms /    41 tokens\n",
      " 69%|โโโโโโโ   | 2407/3487 [7:01:29<2:27:50,  8.21s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2612.40 ms /    11 tokens (  237.49 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.25 ms /     3 runs   (  896.42 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5304.15 ms /    14 tokens\n",
      " 69%|โโโโโโโ   | 2408/3487 [7:01:35<2:12:03,  7.34s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7328.23 ms /    33 tokens (  222.07 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.96 ms /     3 runs   (  885.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9986.98 ms /    36 tokens\n",
      " 69%|โโโโโโโ   | 2409/3487 [7:01:45<2:26:13,  8.14s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5243.64 ms /    26 tokens (  201.68 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.22 ms /     3 runs   (  905.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7962.03 ms /    29 tokens\n",
      " 69%|โโโโโโโ   | 2410/3487 [7:01:53<2:25:11,  8.09s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3496.01 ms /    15 tokens (  233.07 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.71 ms /     3 runs   (  894.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6180.70 ms /    18 tokens\n",
      " 69%|โโโโโโโ   | 2411/3487 [7:01:59<2:14:49,  7.52s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1777.16 ms /     6 tokens (  296.19 ms per token,     3.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.86 ms /     3 runs   (  889.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4446.85 ms /     9 tokens\n",
      " 69%|โโโโโโโ   | 2412/3487 [7:02:03<1:58:13,  6.60s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3621.12 ms /    16 tokens (  226.32 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.47 ms /     3 runs   (  887.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6286.63 ms /    19 tokens\n",
      " 69%|โโโโโโโ   | 2413/3487 [7:02:10<1:56:29,  6.51s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7511.17 ms /    38 tokens (  197.66 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.18 ms /     3 runs   (  878.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10149.85 ms /    41 tokens\n",
      " 69%|โโโโโโโ   | 2414/3487 [7:02:20<2:15:57,  7.60s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6234.08 ms /    32 tokens (  194.82 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.73 ms /     3 runs   (  888.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8901.50 ms /    35 tokens\n",
      " 69%|โโโโโโโ   | 2415/3487 [7:02:29<2:22:50,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13372.06 ms /    68 tokens (  196.65 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.53 ms /     3 runs   (  879.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16012.72 ms /    71 tokens\n",
      " 69%|โโโโโโโ   | 2416/3487 [7:02:45<3:05:41, 10.40s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1790.43 ms /     6 tokens (  298.41 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2727.34 ms /     3 runs   (  909.11 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4519.98 ms /     9 tokens\n",
      " 69%|โโโโโโโ   | 2417/3487 [7:02:49<2:34:05,  8.64s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3625.72 ms /    16 tokens (  226.61 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.14 ms /     3 runs   (  900.38 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6329.82 ms /    19 tokens\n",
      " 69%|โโโโโโโ   | 2418/3487 [7:02:56<2:21:38,  7.95s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1384.80 ms /     4 tokens (  346.20 ms per token,     2.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2878.61 ms /     3 runs   (  959.54 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4265.87 ms /     7 tokens\n",
      " 69%|โโโโโโโ   | 2419/3487 [7:03:00<2:01:53,  6.85s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6403.02 ms /    32 tokens (  200.09 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.64 ms /     3 runs   (  899.21 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9103.37 ms /    35 tokens\n",
      " 69%|โโโโโโโ   | 2420/3487 [7:03:09<2:13:51,  7.53s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3556.26 ms /    16 tokens (  222.27 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.09 ms /     3 runs   (  892.03 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6234.96 ms /    19 tokens\n",
      " 69%|โโโโโโโ   | 2421/3487 [7:03:15<2:06:53,  7.14s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11806.82 ms /    62 tokens (  190.43 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.33 ms /     3 runs   (  878.11 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14443.82 ms /    65 tokens\n",
      " 69%|โโโโโโโ   | 2422/3487 [7:03:30<2:45:41,  9.33s/it]Llama.generate: 306 prefix-match hit, remaining 132 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24412.74 ms /   132 tokens (  184.95 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.58 ms /     3 runs   (  884.19 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   27067.89 ms /   135 tokens\n",
      " 69%|โโโโโโโ   | 2423/3487 [7:03:57<4:19:55, 14.66s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5882.88 ms /    28 tokens (  210.10 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.49 ms /     3 runs   (  893.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8567.38 ms /    31 tokens\n",
      " 70%|โโโโโโโ   | 2424/3487 [7:04:05<3:47:21, 12.83s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2550.09 ms /     8 tokens (  318.76 ms per token,     3.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.55 ms /     3 runs   (  883.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5203.64 ms /    11 tokens\n",
      " 70%|โโโโโโโ   | 2425/3487 [7:04:11<3:06:40, 10.55s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4441.95 ms /    21 tokens (  211.52 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.05 ms /     3 runs   (  894.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7126.25 ms /    24 tokens\n",
      " 70%|โโโโโโโ   | 2426/3487 [7:04:18<2:48:23,  9.52s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3588.33 ms /    16 tokens (  224.27 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.51 ms /     3 runs   (  892.17 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6267.10 ms /    19 tokens\n",
      " 70%|โโโโโโโ   | 2427/3487 [7:04:24<2:31:01,  8.55s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4476.53 ms /    19 tokens (  235.61 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.48 ms /     3 runs   (  878.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7114.86 ms /    22 tokens\n",
      " 70%|โโโโโโโ   | 2428/3487 [7:04:31<2:23:20,  8.12s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2712.80 ms /    12 tokens (  226.07 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.88 ms /     3 runs   (  896.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5406.04 ms /    15 tokens\n",
      " 70%|โโโโโโโ   | 2429/3487 [7:04:37<2:08:53,  7.31s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3906.00 ms /    18 tokens (  217.00 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.99 ms /     3 runs   (  888.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6571.46 ms /    21 tokens\n",
      " 70%|โโโโโโโ   | 2430/3487 [7:04:43<2:04:54,  7.09s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3311.94 ms /    15 tokens (  220.80 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.93 ms /     3 runs   (  883.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5965.37 ms /    18 tokens\n",
      " 70%|โโโโโโโ   | 2431/3487 [7:04:49<1:58:53,  6.76s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13408.65 ms /    70 tokens (  191.55 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.73 ms /     3 runs   (  886.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16069.56 ms /    73 tokens\n",
      " 70%|โโโโโโโ   | 2432/3487 [7:05:05<2:47:57,  9.55s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5798.79 ms /    29 tokens (  199.96 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.98 ms /     3 runs   (  887.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8464.13 ms /    32 tokens\n",
      " 70%|โโโโโโโ   | 2433/3487 [7:05:14<2:42:05,  9.23s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5616.24 ms /    26 tokens (  216.01 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.51 ms /     3 runs   (  891.17 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8292.25 ms /    29 tokens\n",
      " 70%|โโโโโโโ   | 2434/3487 [7:05:22<2:37:03,  8.95s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8470.46 ms /    42 tokens (  201.68 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.68 ms /     3 runs   (  878.56 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11108.46 ms /    45 tokens\n",
      " 70%|โโโโโโโ   | 2435/3487 [7:05:33<2:48:17,  9.60s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5248.24 ms /    26 tokens (  201.86 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.69 ms /     3 runs   (  895.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7939.10 ms /    29 tokens\n",
      " 70%|โโโโโโโ   | 2436/3487 [7:05:41<2:39:27,  9.10s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5862.73 ms /    30 tokens (  195.42 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.51 ms /     3 runs   (  888.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8531.89 ms /    33 tokens\n",
      " 70%|โโโโโโโ   | 2437/3487 [7:05:50<2:36:20,  8.93s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8966.56 ms /    47 tokens (  190.78 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.39 ms /     3 runs   (  888.80 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11635.59 ms /    50 tokens\n",
      " 70%|โโโโโโโ   | 2438/3487 [7:06:01<2:50:24,  9.75s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13064.10 ms /    66 tokens (  197.94 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.22 ms /     3 runs   (  880.41 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15708.31 ms /    69 tokens\n",
      " 70%|โโโโโโโ   | 2439/3487 [7:06:17<3:21:31, 11.54s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8246.54 ms /    41 tokens (  201.14 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2842.82 ms /     3 runs   (  947.61 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   11091.80 ms /    44 tokens\n",
      " 70%|โโโโโโโ   | 2440/3487 [7:06:28<3:19:02, 11.41s/it]Llama.generate: 307 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15267.15 ms /    80 tokens (  190.84 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.25 ms /     3 runs   (  880.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17910.80 ms /    83 tokens\n",
      " 70%|โโโโโโโ   | 2441/3487 [7:06:46<3:52:55, 13.36s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4143.62 ms /    20 tokens (  207.18 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.13 ms /     3 runs   (  887.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6809.18 ms /    23 tokens\n",
      " 70%|โโโโโโโ   | 2442/3487 [7:06:53<3:18:30, 11.40s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2048.74 ms /     5 tokens (  409.75 ms per token,     2.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2778.59 ms /     3 runs   (  926.20 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    4829.98 ms /     8 tokens\n",
      " 70%|โโโโโโโ   | 2443/3487 [7:06:58<2:44:04,  9.43s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3722.42 ms /    17 tokens (  218.97 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.16 ms /     3 runs   (  890.05 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6394.54 ms /    20 tokens\n",
      " 70%|โโโโโโโ   | 2444/3487 [7:07:04<2:28:07,  8.52s/it]Llama.generate: 306 prefix-match hit, remaining 158 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28799.60 ms /   158 tokens (  182.28 ms per token,     5.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.12 ms /     3 runs   (  878.37 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   31437.28 ms /   161 tokens\n",
      " 70%|โโโโโโโ   | 2445/3487 [7:07:35<4:27:25, 15.40s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7433.55 ms /    38 tokens (  195.62 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.67 ms /     3 runs   (  878.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10070.50 ms /    41 tokens\n",
      " 70%|โโโโโโโ   | 2446/3487 [7:07:45<3:59:28, 13.80s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3512.86 ms /    16 tokens (  219.55 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.17 ms /     3 runs   (  903.39 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6225.23 ms /    19 tokens\n",
      " 70%|โโโโโโโ   | 2447/3487 [7:07:52<3:19:52, 11.53s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3653.89 ms /    16 tokens (  228.37 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.02 ms /     3 runs   (  889.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6325.69 ms /    19 tokens\n",
      " 70%|โโโโโโโ   | 2448/3487 [7:07:58<2:52:40,  9.97s/it]Llama.generate: 307 prefix-match hit, remaining 130 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24464.02 ms /   130 tokens (  188.18 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.95 ms /     3 runs   (  880.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27108.96 ms /   133 tokens\n",
      " 70%|โโโโโโโ   | 2449/3487 [7:08:25<4:21:29, 15.12s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5372.31 ms /    26 tokens (  206.63 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2733.70 ms /     3 runs   (  911.23 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8108.08 ms /    29 tokens\n",
      " 70%|โโโโโโโ   | 2450/3487 [7:08:33<3:44:56, 13.02s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4740.09 ms /    23 tokens (  206.09 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.00 ms /     3 runs   (  879.33 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7380.54 ms /    26 tokens\n",
      " 70%|โโโโโโโ   | 2451/3487 [7:08:41<3:15:35, 11.33s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4649.63 ms /    20 tokens (  232.48 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2765.79 ms /     3 runs   (  921.93 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7418.27 ms /    23 tokens\n",
      " 70%|โโโโโโโ   | 2452/3487 [7:08:48<2:55:12, 10.16s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7286.01 ms /    33 tokens (  220.79 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.90 ms /     3 runs   (  884.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9941.97 ms /    36 tokens\n",
      " 70%|โโโโโโโ   | 2453/3487 [7:08:58<2:53:57, 10.09s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2274.17 ms /     9 tokens (  252.69 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.00 ms /     3 runs   (  915.67 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5023.96 ms /    12 tokens\n",
      " 70%|โโโโโโโ   | 2454/3487 [7:09:03<2:27:39,  8.58s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7426.91 ms /    37 tokens (  200.73 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.66 ms /     3 runs   (  884.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10083.85 ms /    40 tokens\n",
      " 70%|โโโโโโโ   | 2455/3487 [7:09:13<2:35:20,  9.03s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2198.52 ms /     9 tokens (  244.28 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.67 ms /     3 runs   (  898.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4897.21 ms /    12 tokens\n",
      " 70%|โโโโโโโ   | 2456/3487 [7:09:18<2:13:55,  7.79s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3285.19 ms /    15 tokens (  219.01 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.60 ms /     3 runs   (  888.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5953.04 ms /    18 tokens\n",
      " 70%|โโโโโโโ   | 2457/3487 [7:09:24<2:04:21,  7.24s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14309.10 ms /    74 tokens (  193.37 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.03 ms /     3 runs   (  888.68 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16977.99 ms /    77 tokens\n",
      " 70%|โโโโโโโ   | 2458/3487 [7:09:41<2:54:21, 10.17s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3011.68 ms /    13 tokens (  231.67 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2763.62 ms /     3 runs   (  921.21 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5777.90 ms /    16 tokens\n",
      " 71%|โโโโโโโ   | 2459/3487 [7:09:47<2:31:40,  8.85s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12694.82 ms /    64 tokens (  198.36 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.95 ms /     3 runs   (  906.65 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   15417.71 ms /    67 tokens\n",
      " 71%|โโโโโโโ   | 2460/3487 [7:10:02<3:05:17, 10.83s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9929.39 ms /    49 tokens (  202.64 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.09 ms /     3 runs   (  896.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12622.47 ms /    52 tokens\n",
      " 71%|โโโโโโโ   | 2461/3487 [7:10:15<3:14:22, 11.37s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3210.12 ms /    14 tokens (  229.29 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.93 ms /     3 runs   (  905.98 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5931.04 ms /    17 tokens\n",
      " 71%|โโโโโโโ   | 2462/3487 [7:10:21<2:46:21,  9.74s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4681.43 ms /    22 tokens (  212.79 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.46 ms /     3 runs   (  891.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7357.40 ms /    25 tokens\n",
      " 71%|โโโโโโโ   | 2463/3487 [7:10:28<2:34:02,  9.03s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2133.41 ms /     8 tokens (  266.68 ms per token,     3.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.07 ms /     3 runs   (  895.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4822.07 ms /    11 tokens\n",
      " 71%|โโโโโโโ   | 2464/3487 [7:10:33<2:12:26,  7.77s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3222.07 ms /    14 tokens (  230.15 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.02 ms /     3 runs   (  906.34 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5944.11 ms /    17 tokens\n",
      " 71%|โโโโโโโ   | 2465/3487 [7:10:39<2:03:02,  7.22s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3167.29 ms /    13 tokens (  243.64 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2750.21 ms /     3 runs   (  916.74 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5920.01 ms /    16 tokens\n",
      " 71%|โโโโโโโ   | 2466/3487 [7:10:45<1:56:18,  6.83s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3108.46 ms /    13 tokens (  239.11 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3435.80 ms /     3 runs   ( 1145.27 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =    6547.34 ms /    16 tokens\n",
      " 71%|โโโโโโโ   | 2467/3487 [7:10:51<1:54:46,  6.75s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8408.92 ms /    29 tokens (  289.96 ms per token,     3.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12769.33 ms /     3 runs   ( 4256.44 ms per token,     0.23 tokens per second)\n",
      "llama_perf_context_print:       total time =   21183.78 ms /    32 tokens\n",
      " 71%|โโโโโโโ   | 2468/3487 [7:11:13<3:08:17, 11.09s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10505.75 ms /    14 tokens (  750.41 ms per token,     1.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9897.34 ms /     3 runs   ( 3299.11 ms per token,     0.30 tokens per second)\n",
      "llama_perf_context_print:       total time =   20409.13 ms /    17 tokens\n",
      " 71%|โโโโโโโ   | 2469/3487 [7:11:33<3:55:42, 13.89s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4837.74 ms /    13 tokens (  372.13 ms per token,     2.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3422.57 ms /     3 runs   ( 1140.86 ms per token,     0.88 tokens per second)\n",
      "llama_perf_context_print:       total time =    8265.52 ms /    16 tokens\n",
      " 71%|โโโโโโโ   | 2470/3487 [7:11:41<3:27:02, 12.22s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3589.87 ms /    11 tokens (  326.35 ms per token,     3.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3117.83 ms /     3 runs   ( 1039.28 ms per token,     0.96 tokens per second)\n",
      "llama_perf_context_print:       total time =    6712.21 ms /    14 tokens\n",
      " 71%|โโโโโโโ   | 2471/3487 [7:11:48<2:58:56, 10.57s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3508.04 ms /    15 tokens (  233.87 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2777.68 ms /     3 runs   (  925.89 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6288.64 ms /    18 tokens\n",
      " 71%|โโโโโโโ   | 2472/3487 [7:11:54<2:37:06,  9.29s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2892.00 ms /    12 tokens (  241.00 ms per token,     4.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.74 ms /     3 runs   (  905.25 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5610.03 ms /    15 tokens\n",
      " 71%|โโโโโโโ   | 2473/3487 [7:12:00<2:18:20,  8.19s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2183.56 ms /     9 tokens (  242.62 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.21 ms /     3 runs   (  892.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4864.42 ms /    12 tokens\n",
      " 71%|โโโโโโโ   | 2474/3487 [7:12:05<2:01:25,  7.19s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3088.16 ms /    14 tokens (  220.58 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.67 ms /     3 runs   (  892.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5769.70 ms /    17 tokens\n",
      " 71%|โโโโโโโ   | 2475/3487 [7:12:11<1:54:09,  6.77s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2677.95 ms /    11 tokens (  243.45 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.09 ms /     3 runs   (  899.70 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5378.96 ms /    14 tokens\n",
      " 71%|โโโโโโโ   | 2476/3487 [7:12:16<1:47:02,  6.35s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2138.92 ms /     9 tokens (  237.66 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.33 ms /     3 runs   (  893.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4821.61 ms /    12 tokens\n",
      " 71%|โโโโโโโ   | 2477/3487 [7:12:21<1:39:15,  5.90s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3817.02 ms /    11 tokens (  347.00 ms per token,     2.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2918.11 ms /     3 runs   (  972.70 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6737.28 ms /    14 tokens\n",
      " 71%|โโโโโโโ   | 2478/3487 [7:12:28<1:43:25,  6.15s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3188.01 ms /    13 tokens (  245.23 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.65 ms /     3 runs   (  888.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5856.20 ms /    16 tokens\n",
      " 71%|โโโโโโโ   | 2479/3487 [7:12:34<1:41:53,  6.07s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2560.17 ms /    11 tokens (  232.74 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.68 ms /     3 runs   (  890.23 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5233.05 ms /    14 tokens\n",
      " 71%|โโโโโโโ   | 2480/3487 [7:12:39<1:37:38,  5.82s/it]Llama.generate: 313 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4139.79 ms /    20 tokens (  206.99 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.70 ms /     3 runs   (  894.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6827.35 ms /    23 tokens\n",
      " 71%|โโโโโโโ   | 2481/3487 [7:12:46<1:42:39,  6.12s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2330.85 ms /     9 tokens (  258.98 ms per token,     3.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.90 ms /     3 runs   (  883.97 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4985.46 ms /    12 tokens\n",
      " 71%|โโโโโโโ   | 2482/3487 [7:12:51<1:36:53,  5.78s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5051.27 ms /    25 tokens (  202.05 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2891.46 ms /     3 runs   (  963.82 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    7944.90 ms /    28 tokens\n",
      " 71%|โโโโโโโ   | 2483/3487 [7:12:59<1:47:40,  6.43s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5988.77 ms /    30 tokens (  199.63 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.14 ms /     3 runs   (  900.05 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8691.56 ms /    33 tokens\n",
      " 71%|โโโโโโโ   | 2484/3487 [7:13:07<1:58:55,  7.11s/it]Llama.generate: 315 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1766.27 ms /     6 tokens (  294.38 ms per token,     3.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.39 ms /     3 runs   (  893.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4450.20 ms /     9 tokens\n",
      " 71%|โโโโโโโโ  | 2485/3487 [7:13:12<1:45:30,  6.32s/it]Llama.generate: 306 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25018.36 ms /   133 tokens (  188.11 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.61 ms /     3 runs   (  888.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   27685.93 ms /   136 tokens\n",
      " 71%|โโโโโโโโ  | 2486/3487 [7:13:39<3:32:23, 12.73s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7905.44 ms /    38 tokens (  208.04 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.47 ms /     3 runs   (  884.49 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10561.79 ms /    41 tokens\n",
      " 71%|โโโโโโโโ  | 2487/3487 [7:13:50<3:21:22, 12.08s/it]Llama.generate: 306 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15473.98 ms /    82 tokens (  188.71 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2748.47 ms /     3 runs   (  916.16 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   18225.16 ms /    85 tokens\n",
      " 71%|โโโโโโโโ  | 2488/3487 [7:14:08<3:51:53, 13.93s/it]Llama.generate: 308 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7728.93 ms /    38 tokens (  203.39 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3345.67 ms /     3 runs   ( 1115.22 ms per token,     0.90 tokens per second)\n",
      "llama_perf_context_print:       total time =   11077.26 ms /    41 tokens\n",
      " 71%|โโโโโโโโ  | 2489/3487 [7:14:19<3:37:28, 13.07s/it]Llama.generate: 307 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   22577.87 ms /   100 tokens (  225.78 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3016.51 ms /     3 runs   ( 1005.50 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   25598.69 ms /   103 tokens\n",
      " 71%|โโโโโโโโ  | 2490/3487 [7:14:45<4:39:45, 16.84s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4889.51 ms /    22 tokens (  222.25 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.56 ms /     3 runs   (  909.85 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7621.97 ms /    25 tokens\n",
      " 71%|โโโโโโโโ  | 2491/3487 [7:14:53<3:53:38, 14.07s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5222.20 ms /    25 tokens (  208.89 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.92 ms /     3 runs   (  897.64 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7917.75 ms /    28 tokens\n",
      " 71%|โโโโโโโโ  | 2492/3487 [7:15:00<3:22:48, 12.23s/it]Llama.generate: 306 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17545.05 ms /    94 tokens (  186.65 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.57 ms /     3 runs   (  887.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20209.97 ms /    97 tokens\n",
      " 71%|โโโโโโโโ  | 2493/3487 [7:15:21<4:02:18, 14.63s/it]Llama.generate: 307 prefix-match hit, remaining 120 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23088.68 ms /   120 tokens (  192.41 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.34 ms /     3 runs   (  889.11 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   25758.52 ms /   123 tokens\n",
      " 72%|โโโโโโโโ  | 2494/3487 [7:15:46<4:57:23, 17.97s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4679.49 ms /    21 tokens (  222.83 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.32 ms /     3 runs   (  884.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7336.09 ms /    24 tokens\n",
      " 72%|โโโโโโโโ  | 2495/3487 [7:15:54<4:04:23, 14.78s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5190.55 ms /    25 tokens (  207.62 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.42 ms /     3 runs   (  889.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7861.02 ms /    28 tokens\n",
      " 72%|โโโโโโโโ  | 2496/3487 [7:16:02<3:29:53, 12.71s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4295.00 ms /    21 tokens (  204.52 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.74 ms /     3 runs   (  886.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6958.33 ms /    24 tokens\n",
      " 72%|โโโโโโโโ  | 2497/3487 [7:16:09<3:01:14, 10.98s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8334.37 ms /    42 tokens (  198.44 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.84 ms /     3 runs   (  890.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11008.31 ms /    45 tokens\n",
      " 72%|โโโโโโโโ  | 2498/3487 [7:16:20<3:01:13, 10.99s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9439.95 ms /    49 tokens (  192.65 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.22 ms /     3 runs   (  886.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12100.78 ms /    52 tokens\n",
      " 72%|โโโโโโโโ  | 2499/3487 [7:16:32<3:06:33, 11.33s/it]Llama.generate: 307 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14032.45 ms /    71 tokens (  197.64 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.72 ms /     3 runs   (  888.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16702.17 ms /    74 tokens\n",
      " 72%|โโโโโโโโ  | 2500/3487 [7:16:48<3:32:55, 12.94s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3718.11 ms /    17 tokens (  218.71 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.34 ms /     3 runs   (  892.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6398.54 ms /    20 tokens\n",
      " 72%|โโโโโโโโ  | 2501/3487 [7:16:55<3:00:29, 10.98s/it]Llama.generate: 306 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17401.41 ms /    93 tokens (  187.11 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.00 ms /     3 runs   (  888.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20067.85 ms /    96 tokens\n",
      " 72%|โโโโโโโโ  | 2502/3487 [7:17:15<3:45:05, 13.71s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9881.66 ms /    52 tokens (  190.03 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.41 ms /     3 runs   (  885.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12540.89 ms /    55 tokens\n",
      " 72%|โโโโโโโโ  | 2503/3487 [7:17:27<3:39:08, 13.36s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5165.67 ms /    23 tokens (  224.59 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.53 ms /     3 runs   (  905.18 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7883.97 ms /    26 tokens\n",
      " 72%|โโโโโโโโ  | 2504/3487 [7:17:35<3:12:02, 11.72s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12202.36 ms /    64 tokens (  190.66 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.12 ms /     3 runs   (  886.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14863.68 ms /    67 tokens\n",
      " 72%|โโโโโโโโ  | 2505/3487 [7:17:50<3:27:18, 12.67s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5167.05 ms /    26 tokens (  198.73 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.88 ms /     3 runs   (  892.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7846.82 ms /    29 tokens\n",
      " 72%|โโโโโโโโ  | 2506/3487 [7:17:58<3:03:30, 11.22s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5758.01 ms /    29 tokens (  198.55 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.69 ms /     3 runs   (  891.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8436.20 ms /    32 tokens\n",
      " 72%|โโโโโโโโ  | 2507/3487 [7:18:07<2:49:42, 10.39s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5289.19 ms /    26 tokens (  203.43 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.93 ms /     3 runs   (  886.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7953.58 ms /    29 tokens\n",
      " 72%|โโโโโโโโ  | 2508/3487 [7:18:15<2:37:38,  9.66s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5201.80 ms /    26 tokens (  200.07 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.05 ms /     3 runs   (  900.68 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7905.85 ms /    29 tokens\n",
      " 72%|โโโโโโโโ  | 2509/3487 [7:18:22<2:28:56,  9.14s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6090.65 ms /    31 tokens (  196.47 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.39 ms /     3 runs   (  888.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8757.61 ms /    34 tokens\n",
      " 72%|โโโโโโโโ  | 2510/3487 [7:18:31<2:26:58,  9.03s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9615.70 ms /    49 tokens (  196.24 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.64 ms /     3 runs   (  899.21 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   12315.84 ms /    52 tokens\n",
      " 72%|โโโโโโโโ  | 2511/3487 [7:18:44<2:42:55, 10.02s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5255.07 ms /    11 tokens (  477.73 ms per token,     2.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3718.62 ms /     3 runs   ( 1239.54 ms per token,     0.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    8976.93 ms /    14 tokens\n",
      " 72%|โโโโโโโโ  | 2512/3487 [7:18:53<2:37:45,  9.71s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3452.88 ms /     9 tokens (  383.65 ms per token,     2.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2920.05 ms /     3 runs   (  973.35 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6375.71 ms /    12 tokens\n",
      " 72%|โโโโโโโโ  | 2513/3487 [7:18:59<2:21:24,  8.71s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12554.63 ms /    51 tokens (  246.17 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3134.83 ms /     3 runs   ( 1044.94 ms per token,     0.96 tokens per second)\n",
      "llama_perf_context_print:       total time =   15723.99 ms /    54 tokens\n",
      " 72%|โโโโโโโโ  | 2514/3487 [7:19:15<2:55:25, 10.82s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6364.97 ms /    25 tokens (  254.60 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3287.93 ms /     3 runs   ( 1095.98 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =    9656.21 ms /    28 tokens\n",
      " 72%|โโโโโโโโ  | 2515/3487 [7:19:24<2:49:38, 10.47s/it]Llama.generate: 308 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6007.78 ms /    22 tokens (  273.08 ms per token,     3.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2832.91 ms /     3 runs   (  944.30 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    8843.49 ms /    25 tokens\n",
      " 72%|โโโโโโโโ  | 2516/3487 [7:19:33<2:41:45, 10.00s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2206.06 ms /     7 tokens (  315.15 ms per token,     3.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2911.21 ms /     3 runs   (  970.40 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    5120.17 ms /    10 tokens\n",
      " 72%|โโโโโโโโ  | 2517/3487 [7:19:38<2:18:00,  8.54s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3965.36 ms /    16 tokens (  247.83 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2918.59 ms /     3 runs   (  972.86 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6887.03 ms /    19 tokens\n",
      " 72%|โโโโโโโโ  | 2518/3487 [7:19:45<2:09:55,  8.05s/it]Llama.generate: 307 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25564.62 ms /   133 tokens (  192.22 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.97 ms /     3 runs   (  886.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   28227.26 ms /   136 tokens\n",
      " 72%|โโโโโโโโ  | 2519/3487 [7:20:13<3:47:30, 14.10s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9535.74 ms /    49 tokens (  194.61 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2811.66 ms /     3 runs   (  937.22 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12350.49 ms /    52 tokens\n",
      " 72%|โโโโโโโโ  | 2520/3487 [7:20:26<3:38:51, 13.58s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7436.00 ms /    33 tokens (  225.33 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.46 ms /     3 runs   (  885.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10095.76 ms /    36 tokens\n",
      " 72%|โโโโโโโโ  | 2521/3487 [7:20:36<3:21:50, 12.54s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3753.93 ms /    15 tokens (  250.26 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2801.21 ms /     3 runs   (  933.74 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6557.20 ms /    18 tokens\n",
      " 72%|โโโโโโโโ  | 2522/3487 [7:20:42<2:52:49, 10.75s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4263.90 ms /    21 tokens (  203.04 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.68 ms /     3 runs   (  906.89 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6987.01 ms /    24 tokens\n",
      " 72%|โโโโโโโโ  | 2523/3487 [7:20:49<2:34:34,  9.62s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3849.03 ms /    18 tokens (  213.84 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.27 ms /     3 runs   (  907.76 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6575.06 ms /    21 tokens\n",
      " 72%|โโโโโโโโ  | 2524/3487 [7:20:56<2:19:47,  8.71s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2715.11 ms /    10 tokens (  271.51 ms per token,     3.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2812.08 ms /     3 runs   (  937.36 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5529.61 ms /    13 tokens\n",
      " 72%|โโโโโโโโ  | 2525/3487 [7:21:02<2:04:23,  7.76s/it]Llama.generate: 316 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3949.43 ms /     4 runs   (  987.36 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    3952.14 ms /     5 tokens\n",
      " 72%|โโโโโโโโ  | 2526/3487 [7:21:06<1:46:00,  6.62s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4007.36 ms /    18 tokens (  222.63 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.20 ms /     3 runs   (  915.73 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6757.32 ms /    21 tokens\n",
      " 72%|โโโโโโโโ  | 2527/3487 [7:21:12<1:46:35,  6.66s/it]Llama.generate: 316 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2300.67 ms /     9 tokens (  255.63 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.15 ms /     3 runs   (  895.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4989.72 ms /    12 tokens\n",
      " 72%|โโโโโโโโ  | 2528/3487 [7:21:17<1:38:30,  6.16s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6227.83 ms /    31 tokens (  200.90 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.85 ms /     3 runs   (  889.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8898.34 ms /    34 tokens\n",
      " 73%|โโโโโโโโ  | 2529/3487 [7:21:26<1:51:33,  6.99s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2290.17 ms /     9 tokens (  254.46 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2957.47 ms /     3 runs   (  985.82 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    5250.29 ms /    12 tokens\n",
      " 73%|โโโโโโโโ  | 2530/3487 [7:21:31<1:43:10,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3685.14 ms /    13 tokens (  283.47 ms per token,     3.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.44 ms /     3 runs   (  905.81 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6405.09 ms /    16 tokens\n",
      " 73%|โโโโโโโโ  | 2531/3487 [7:21:38<1:42:47,  6.45s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3220.66 ms /    13 tokens (  247.74 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2734.69 ms /     3 runs   (  911.56 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5958.52 ms /    16 tokens\n",
      " 73%|โโโโโโโโ  | 2532/3487 [7:21:44<1:40:22,  6.31s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2329.14 ms /     7 tokens (  332.73 ms per token,     3.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.86 ms /     3 runs   (  893.95 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5014.23 ms /    10 tokens\n",
      " 73%|โโโโโโโโ  | 2533/3487 [7:21:49<1:34:09,  5.92s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2673.33 ms /    11 tokens (  243.03 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.07 ms /     3 runs   (  901.69 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5380.95 ms /    14 tokens\n",
      " 73%|โโโโโโโโ  | 2534/3487 [7:21:54<1:31:30,  5.76s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4869.95 ms /    24 tokens (  202.91 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.13 ms /     3 runs   (  882.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7518.89 ms /    27 tokens\n",
      " 73%|โโโโโโโโ  | 2535/3487 [7:22:02<1:39:49,  6.29s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4740.22 ms /    23 tokens (  206.10 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.39 ms /     3 runs   (  893.13 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7421.86 ms /    26 tokens\n",
      " 73%|โโโโโโโโ  | 2536/3487 [7:22:09<1:45:07,  6.63s/it]Llama.generate: 308 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3727.88 ms /    17 tokens (  219.29 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.02 ms /     3 runs   (  884.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6384.53 ms /    20 tokens\n",
      " 73%|โโโโโโโโ  | 2537/3487 [7:22:16<1:43:52,  6.56s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3033.73 ms /    13 tokens (  233.36 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.16 ms /     3 runs   (  885.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5691.18 ms /    16 tokens\n",
      " 73%|โโโโโโโโ  | 2538/3487 [7:22:21<1:39:40,  6.30s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3776.05 ms /    18 tokens (  209.78 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.97 ms /     3 runs   (  886.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6440.00 ms /    21 tokens\n",
      " 73%|โโโโโโโโ  | 2539/3487 [7:22:28<1:40:16,  6.35s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4447.13 ms /    19 tokens (  234.06 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.07 ms /     3 runs   (  884.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7101.93 ms /    22 tokens\n",
      " 73%|โโโโโโโโ  | 2540/3487 [7:22:35<1:43:47,  6.58s/it]Llama.generate: 307 prefix-match hit, remaining 101 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19068.01 ms /   101 tokens (  188.79 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.71 ms /     3 runs   (  879.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21708.00 ms /   104 tokens\n",
      " 73%|โโโโโโโโ  | 2541/3487 [7:22:57<2:55:17, 11.12s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1994.96 ms /     7 tokens (  284.99 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.76 ms /     3 runs   (  901.59 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4702.41 ms /    10 tokens\n",
      " 73%|โโโโโโโโ  | 2542/3487 [7:23:01<2:24:49,  9.20s/it]Llama.generate: 306 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10066.52 ms /    53 tokens (  189.93 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.57 ms /     3 runs   (  877.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12701.19 ms /    56 tokens\n",
      " 73%|โโโโโโโโ  | 2543/3487 [7:23:14<2:41:15, 10.25s/it]Llama.generate: 307 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10367.73 ms /    55 tokens (  188.50 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.92 ms /     3 runs   (  881.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13014.53 ms /    58 tokens\n",
      " 73%|โโโโโโโโ  | 2544/3487 [7:23:27<2:54:09, 11.08s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3065.31 ms /    13 tokens (  235.79 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.56 ms /     3 runs   (  897.85 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5761.89 ms /    16 tokens\n",
      " 73%|โโโโโโโโ  | 2545/3487 [7:23:33<2:28:57,  9.49s/it]Llama.generate: 306 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14548.33 ms /    77 tokens (  188.94 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.81 ms /     3 runs   (  879.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17191.52 ms /    80 tokens\n",
      " 73%|โโโโโโโโ  | 2546/3487 [7:23:50<3:05:05, 11.80s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7800.71 ms /    39 tokens (  200.02 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.55 ms /     3 runs   (  884.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10456.61 ms /    42 tokens\n",
      " 73%|โโโโโโโโ  | 2547/3487 [7:24:00<2:58:36, 11.40s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9689.54 ms /    51 tokens (  189.99 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.63 ms /     3 runs   (  875.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12318.37 ms /    54 tokens\n",
      " 73%|โโโโโโโโ  | 2548/3487 [7:24:13<3:02:46, 11.68s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5463.40 ms /    25 tokens (  218.54 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.48 ms /     3 runs   (  886.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8126.06 ms /    28 tokens\n",
      " 73%|โโโโโโโโ  | 2549/3487 [7:24:21<2:45:57, 10.62s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2657.29 ms /    11 tokens (  241.57 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.45 ms /     3 runs   (  898.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5354.46 ms /    14 tokens\n",
      " 73%|โโโโโโโโ  | 2550/3487 [7:24:26<2:21:10,  9.04s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4233.87 ms /    19 tokens (  222.84 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.60 ms /     3 runs   (  884.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6891.55 ms /    22 tokens\n",
      " 73%|โโโโโโโโ  | 2551/3487 [7:24:33<2:11:00,  8.40s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3289.57 ms /    15 tokens (  219.30 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2743.41 ms /     3 runs   (  914.47 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6035.73 ms /    18 tokens\n",
      " 73%|โโโโโโโโ  | 2552/3487 [7:24:39<1:59:51,  7.69s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4283.79 ms /    18 tokens (  237.99 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.66 ms /     3 runs   (  885.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6942.15 ms /    21 tokens\n",
      " 73%|โโโโโโโโ  | 2553/3487 [7:24:46<1:56:16,  7.47s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3749.93 ms /    17 tokens (  220.58 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.21 ms /     3 runs   (  885.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6407.38 ms /    20 tokens\n",
      " 73%|โโโโโโโโ  | 2554/3487 [7:24:53<1:51:14,  7.15s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4880.29 ms /    24 tokens (  203.35 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.39 ms /     3 runs   (  893.13 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7562.45 ms /    27 tokens\n",
      " 73%|โโโโโโโโ  | 2555/3487 [7:25:00<1:53:03,  7.28s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1987.85 ms /     7 tokens (  283.98 ms per token,     3.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.32 ms /     3 runs   (  883.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4642.29 ms /    10 tokens\n",
      " 73%|โโโโโโโโ  | 2556/3487 [7:25:05<1:40:43,  6.49s/it]Llama.generate: 306 prefix-match hit, remaining 125 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23723.89 ms /   125 tokens (  189.79 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.79 ms /     3 runs   (  894.26 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   26409.83 ms /   128 tokens\n",
      " 73%|โโโโโโโโ  | 2557/3487 [7:25:31<3:13:16, 12.47s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9104.40 ms /    46 tokens (  197.92 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.81 ms /     3 runs   (  885.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11763.25 ms /    49 tokens\n",
      " 73%|โโโโโโโโ  | 2558/3487 [7:25:43<3:09:49, 12.26s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7247.11 ms /    35 tokens (  207.06 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.05 ms /     3 runs   (  890.35 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9920.26 ms /    38 tokens\n",
      " 73%|โโโโโโโโ  | 2559/3487 [7:25:53<2:58:47, 11.56s/it]Llama.generate: 308 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19250.13 ms /   102 tokens (  188.73 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.66 ms /     3 runs   (  880.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21894.19 ms /   105 tokens\n",
      " 73%|โโโโโโโโ  | 2560/3487 [7:26:15<3:46:32, 14.66s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5897.06 ms /    30 tokens (  196.57 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.38 ms /     3 runs   (  899.46 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8597.76 ms /    33 tokens\n",
      " 73%|โโโโโโโโ  | 2561/3487 [7:26:23<3:18:15, 12.85s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10149.18 ms /    52 tokens (  195.18 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.18 ms /     3 runs   (  894.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12833.38 ms /    55 tokens\n",
      " 73%|โโโโโโโโ  | 2562/3487 [7:26:36<3:18:01, 12.84s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5948.92 ms /    29 tokens (  205.14 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2778.32 ms /     3 runs   (  926.11 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8730.16 ms /    32 tokens\n",
      " 74%|โโโโโโโโ  | 2563/3487 [7:26:45<2:58:49, 11.61s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6848.82 ms /    31 tokens (  220.93 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.94 ms /     3 runs   (  892.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9530.29 ms /    34 tokens\n",
      " 74%|โโโโโโโโ  | 2564/3487 [7:26:55<2:49:04, 10.99s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4769.18 ms /    23 tokens (  207.36 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.81 ms /     3 runs   (  895.27 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7457.46 ms /    26 tokens\n",
      " 74%|โโโโโโโโ  | 2565/3487 [7:27:02<2:32:38,  9.93s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8054.70 ms /    41 tokens (  196.46 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2825.29 ms /     3 runs   (  941.76 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   10882.72 ms /    44 tokens\n",
      " 74%|โโโโโโโโ  | 2566/3487 [7:27:13<2:36:52, 10.22s/it]Llama.generate: 307 prefix-match hit, remaining 140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25862.72 ms /   140 tokens (  184.73 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2798.07 ms /     3 runs   (  932.69 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   28664.04 ms /   143 tokens\n",
      " 74%|โโโโโโโโ  | 2567/3487 [7:27:42<4:01:35, 15.76s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6382.76 ms /    31 tokens (  205.90 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.22 ms /     3 runs   (  879.41 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9023.41 ms /    34 tokens\n",
      " 74%|โโโโโโโโ  | 2568/3487 [7:27:51<3:30:25, 13.74s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3093.53 ms /    14 tokens (  220.97 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.68 ms /     3 runs   (  883.23 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5745.59 ms /    17 tokens\n",
      " 74%|โโโโโโโโ  | 2569/3487 [7:27:56<2:53:33, 11.34s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8403.72 ms /    43 tokens (  195.44 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2808.11 ms /     3 runs   (  936.03 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   11214.49 ms /    46 tokens\n",
      " 74%|โโโโโโโโ  | 2570/3487 [7:28:08<2:52:48, 11.31s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6158.29 ms /    31 tokens (  198.65 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.30 ms /     3 runs   (  888.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8826.34 ms /    34 tokens\n",
      " 74%|โโโโโโโโ  | 2571/3487 [7:28:16<2:41:17, 10.56s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6165.49 ms /    31 tokens (  198.89 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.19 ms /     3 runs   (  897.73 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8861.57 ms /    34 tokens\n",
      " 74%|โโโโโโโโ  | 2572/3487 [7:28:25<2:33:21, 10.06s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6020.37 ms /    28 tokens (  215.01 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.64 ms /     3 runs   (  878.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8658.31 ms /    31 tokens\n",
      " 74%|โโโโโโโโ  | 2573/3487 [7:28:34<2:26:50,  9.64s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9810.99 ms /    51 tokens (  192.37 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.80 ms /     3 runs   (  878.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12448.14 ms /    54 tokens\n",
      " 74%|โโโโโโโโ  | 2574/3487 [7:28:46<2:39:32, 10.48s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9515.72 ms /    49 tokens (  194.20 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2809.91 ms /     3 runs   (  936.64 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12328.36 ms /    52 tokens\n",
      " 74%|โโโโโโโโ  | 2575/3487 [7:28:59<2:47:49, 11.04s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9037.48 ms /    45 tokens (  200.83 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.66 ms /     3 runs   (  878.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11676.04 ms /    48 tokens\n",
      " 74%|โโโโโโโโ  | 2576/3487 [7:29:10<2:50:34, 11.23s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6036.85 ms /    30 tokens (  201.23 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.28 ms /     3 runs   (  887.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8702.40 ms /    33 tokens\n",
      " 74%|โโโโโโโโ  | 2577/3487 [7:29:19<2:38:54, 10.48s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7977.77 ms /    41 tokens (  194.58 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.27 ms /     3 runs   (  878.09 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10615.57 ms /    44 tokens\n",
      " 74%|โโโโโโโโ  | 2578/3487 [7:29:30<2:39:23, 10.52s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2975.48 ms /    13 tokens (  228.88 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.10 ms /     3 runs   (  895.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5664.13 ms /    16 tokens\n",
      " 74%|โโโโโโโโ  | 2579/3487 [7:29:35<2:17:12,  9.07s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3085.31 ms /    13 tokens (  237.33 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.20 ms /     3 runs   (  885.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5744.83 ms /    16 tokens\n",
      " 74%|โโโโโโโโ  | 2580/3487 [7:29:41<2:02:02,  8.07s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3365.49 ms /    15 tokens (  224.37 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.37 ms /     3 runs   (  904.12 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6080.28 ms /    18 tokens\n",
      " 74%|โโโโโโโโ  | 2581/3487 [7:29:47<1:53:03,  7.49s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5001.64 ms /    22 tokens (  227.35 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2858.82 ms /     3 runs   (  952.94 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    7863.10 ms /    25 tokens\n",
      " 74%|โโโโโโโโ  | 2582/3487 [7:29:55<1:54:40,  7.60s/it]Llama.generate: 312 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1363.18 ms /     4 tokens (  340.80 ms per token,     2.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2831.69 ms /     3 runs   (  943.90 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4197.67 ms /     7 tokens\n",
      " 74%|โโโโโโโโ  | 2583/3487 [7:29:59<1:39:11,  6.58s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3537.59 ms /    16 tokens (  221.10 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.52 ms /     3 runs   (  883.17 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6189.18 ms /    19 tokens\n",
      " 74%|โโโโโโโโ  | 2584/3487 [7:30:06<1:37:20,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3199.47 ms /    15 tokens (  213.30 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.63 ms /     3 runs   (  899.54 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5900.45 ms /    18 tokens\n",
      " 74%|โโโโโโโโ  | 2585/3487 [7:30:12<1:34:42,  6.30s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4345.87 ms /    21 tokens (  206.95 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.84 ms /     3 runs   (  887.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7012.21 ms /    24 tokens\n",
      " 74%|โโโโโโโโ  | 2586/3487 [7:30:19<1:37:51,  6.52s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4807.97 ms /    22 tokens (  218.54 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2768.13 ms /     3 runs   (  922.71 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7578.37 ms /    25 tokens\n",
      " 74%|โโโโโโโโ  | 2587/3487 [7:30:26<1:42:33,  6.84s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4769.45 ms /    23 tokens (  207.37 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.92 ms /     3 runs   (  883.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7423.34 ms /    26 tokens\n",
      " 74%|โโโโโโโโ  | 2588/3487 [7:30:34<1:45:06,  7.01s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3139.57 ms /    14 tokens (  224.25 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.80 ms /     3 runs   (  898.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5838.93 ms /    17 tokens\n",
      " 74%|โโโโโโโโ  | 2589/3487 [7:30:39<1:39:44,  6.66s/it]Llama.generate: 319 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4261.51 ms /     4 runs   ( 1065.38 ms per token,     0.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    4264.07 ms /     5 tokens\n",
      " 74%|โโโโโโโโ  | 2590/3487 [7:30:44<1:28:54,  5.95s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3212.06 ms /    14 tokens (  229.43 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.22 ms /     3 runs   (  883.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5866.45 ms /    17 tokens\n",
      " 74%|โโโโโโโโ  | 2591/3487 [7:30:50<1:28:29,  5.93s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2795.68 ms /    12 tokens (  232.97 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.16 ms /     3 runs   (  886.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5458.32 ms /    15 tokens\n",
      " 74%|โโโโโโโโ  | 2592/3487 [7:30:55<1:26:19,  5.79s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2336.72 ms /     9 tokens (  259.63 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.28 ms /     3 runs   (  886.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4999.62 ms /    12 tokens\n",
      " 74%|โโโโโโโโ  | 2593/3487 [7:31:00<1:22:44,  5.55s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3185.17 ms /    14 tokens (  227.51 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.34 ms /     3 runs   (  886.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5848.51 ms /    17 tokens\n",
      " 74%|โโโโโโโโ  | 2594/3487 [7:31:06<1:24:01,  5.65s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2174.89 ms /     8 tokens (  271.86 ms per token,     3.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.80 ms /     3 runs   (  898.60 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4873.17 ms /    11 tokens\n",
      " 74%|โโโโโโโโ  | 2595/3487 [7:31:11<1:20:31,  5.42s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8477.31 ms /    43 tokens (  197.15 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.35 ms /     3 runs   (  880.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11122.68 ms /    46 tokens\n",
      " 74%|โโโโโโโโ  | 2596/3487 [7:31:22<1:45:53,  7.13s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3017.75 ms /    13 tokens (  232.13 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.13 ms /     3 runs   (  897.04 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5712.00 ms /    16 tokens\n",
      " 74%|โโโโโโโโ  | 2597/3487 [7:31:28<1:39:29,  6.71s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9105.07 ms /    45 tokens (  202.33 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.78 ms /     3 runs   (  888.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11773.08 ms /    48 tokens\n",
      " 75%|โโโโโโโโ  | 2598/3487 [7:31:39<2:01:56,  8.23s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4664.45 ms /    22 tokens (  212.02 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.92 ms /     3 runs   (  906.97 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7388.61 ms /    25 tokens\n",
      " 75%|โโโโโโโโ  | 2599/3487 [7:31:47<1:58:05,  7.98s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5038.93 ms /    23 tokens (  219.08 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2765.79 ms /     3 runs   (  921.93 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7806.58 ms /    26 tokens\n",
      " 75%|โโโโโโโโ  | 2600/3487 [7:31:55<1:57:14,  7.93s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3470.78 ms /    15 tokens (  231.39 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.44 ms /     3 runs   (  889.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6142.91 ms /    18 tokens\n",
      " 75%|โโโโโโโโ  | 2601/3487 [7:32:01<1:49:13,  7.40s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7568.39 ms /    37 tokens (  204.55 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.53 ms /     3 runs   (  885.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10228.87 ms /    40 tokens\n",
      " 75%|โโโโโโโโ  | 2602/3487 [7:32:11<2:01:40,  8.25s/it]Llama.generate: 315 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1348.33 ms /     4 tokens (  337.08 ms per token,     2.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2836.39 ms /     3 runs   (  945.47 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4187.17 ms /     7 tokens\n",
      " 75%|โโโโโโโโ  | 2603/3487 [7:32:15<1:43:36,  7.03s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3131.81 ms /    14 tokens (  223.70 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.29 ms /     3 runs   (  886.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5793.94 ms /    17 tokens\n",
      " 75%|โโโโโโโโ  | 2604/3487 [7:32:21<1:38:04,  6.66s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5755.62 ms /    29 tokens (  198.47 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.59 ms /     3 runs   (  900.20 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8459.34 ms /    32 tokens\n",
      " 75%|โโโโโโโโ  | 2605/3487 [7:32:29<1:45:54,  7.21s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1344.47 ms /     4 tokens (  336.12 ms per token,     2.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2940.80 ms /     3 runs   (  980.27 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    4287.75 ms /     7 tokens\n",
      " 75%|โโโโโโโโ  | 2606/3487 [7:32:34<1:32:59,  6.33s/it]Llama.generate: 311 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4873.24 ms /    24 tokens (  203.05 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.21 ms /     3 runs   (  880.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7517.41 ms /    27 tokens\n",
      " 75%|โโโโโโโโ  | 2607/3487 [7:32:41<1:38:07,  6.69s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3222.41 ms /    15 tokens (  214.83 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.96 ms /     3 runs   (  885.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5880.70 ms /    18 tokens\n",
      " 75%|โโโโโโโโ  | 2608/3487 [7:32:47<1:34:29,  6.45s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1753.61 ms /     6 tokens (  292.27 ms per token,     3.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.96 ms /     3 runs   (  886.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4417.00 ms /     9 tokens\n",
      " 75%|โโโโโโโโ  | 2609/3487 [7:32:52<1:25:30,  5.84s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3811.94 ms /    18 tokens (  211.77 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.81 ms /     3 runs   (  880.60 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6456.84 ms /    21 tokens\n",
      " 75%|โโโโโโโโ  | 2610/3487 [7:32:58<1:28:08,  6.03s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7423.20 ms /    37 tokens (  200.63 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.83 ms /     3 runs   (  885.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10082.55 ms /    40 tokens\n",
      " 75%|โโโโโโโโ  | 2611/3487 [7:33:08<1:45:49,  7.25s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4124.70 ms /    20 tokens (  206.24 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.03 ms /     3 runs   (  896.68 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6816.94 ms /    23 tokens\n",
      " 75%|โโโโโโโโ  | 2612/3487 [7:33:15<1:43:51,  7.12s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2970.37 ms /    13 tokens (  228.49 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.07 ms /     3 runs   (  890.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5643.04 ms /    16 tokens\n",
      " 75%|โโโโโโโโ  | 2613/3487 [7:33:21<1:37:18,  6.68s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6248.92 ms /    30 tokens (  208.30 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.80 ms /     3 runs   (  883.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8903.81 ms /    33 tokens\n",
      " 75%|โโโโโโโโ  | 2614/3487 [7:33:30<1:46:56,  7.35s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3299.18 ms /    15 tokens (  219.95 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.08 ms /     3 runs   (  887.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5964.71 ms /    18 tokens\n",
      " 75%|โโโโโโโโ  | 2615/3487 [7:33:36<1:40:48,  6.94s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7167.50 ms /    33 tokens (  217.20 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.64 ms /     3 runs   (  880.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9811.69 ms /    36 tokens\n",
      " 75%|โโโโโโโโ  | 2616/3487 [7:33:45<1:53:15,  7.80s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2058.32 ms /     7 tokens (  294.05 ms per token,     3.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2982.09 ms /     3 runs   (  994.03 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    5043.23 ms /    10 tokens\n",
      " 75%|โโโโโโโโ  | 2617/3487 [7:33:50<1:41:10,  6.98s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5341.17 ms /    24 tokens (  222.55 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.17 ms /     3 runs   (  887.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8005.73 ms /    27 tokens\n",
      " 75%|โโโโโโโโ  | 2618/3487 [7:33:58<1:45:33,  7.29s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5080.17 ms /    25 tokens (  203.21 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.06 ms /     3 runs   (  880.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7722.78 ms /    28 tokens\n",
      " 75%|โโโโโโโโ  | 2619/3487 [7:34:06<1:47:21,  7.42s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10001.52 ms /    52 tokens (  192.34 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.25 ms /     3 runs   (  877.75 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12637.58 ms /    55 tokens\n",
      " 75%|โโโโโโโโ  | 2620/3487 [7:34:19<2:09:52,  8.99s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4007.95 ms /    19 tokens (  210.94 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.50 ms /     3 runs   (  890.50 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6682.24 ms /    22 tokens\n",
      " 75%|โโโโโโโโ  | 2621/3487 [7:34:25<1:59:46,  8.30s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7574.29 ms /    36 tokens (  210.40 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.21 ms /     3 runs   (  881.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10220.79 ms /    39 tokens\n",
      " 75%|โโโโโโโโ  | 2622/3487 [7:34:36<2:07:59,  8.88s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10205.12 ms /    52 tokens (  196.25 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.27 ms /     3 runs   (  879.76 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12847.08 ms /    55 tokens\n",
      " 75%|โโโโโโโโ  | 2623/3487 [7:34:49<2:25:01, 10.07s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7474.56 ms /    38 tokens (  196.70 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.05 ms /     3 runs   (  878.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10113.43 ms /    41 tokens\n",
      " 75%|โโโโโโโโ  | 2624/3487 [7:34:59<2:25:04, 10.09s/it]Llama.generate: 307 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13890.30 ms /    71 tokens (  195.64 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.86 ms /     3 runs   (  878.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16528.95 ms /    74 tokens\n",
      " 75%|โโโโโโโโ  | 2625/3487 [7:35:15<2:52:42, 12.02s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4835.30 ms /    24 tokens (  201.47 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.87 ms /     3 runs   (  905.96 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7555.23 ms /    27 tokens\n",
      " 75%|โโโโโโโโ  | 2626/3487 [7:35:23<2:33:19, 10.68s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1497.48 ms /     5 tokens (  299.50 ms per token,     3.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2782.28 ms /     3 runs   (  927.43 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    4282.53 ms /     8 tokens\n",
      " 75%|โโโโโโโโ  | 2627/3487 [7:35:27<2:05:38,  8.77s/it]Llama.generate: 306 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13563.97 ms /    72 tokens (  188.39 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.19 ms /     3 runs   (  882.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16212.48 ms /    75 tokens\n",
      " 75%|โโโโโโโโ  | 2628/3487 [7:35:43<2:37:30, 11.00s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5085.41 ms /    25 tokens (  203.42 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.69 ms /     3 runs   (  883.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7738.69 ms /    28 tokens\n",
      " 75%|โโโโโโโโ  | 2629/3487 [7:35:51<2:23:21, 10.03s/it]Llama.generate: 308 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2621.67 ms /    11 tokens (  238.33 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.69 ms /     3 runs   (  888.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5289.84 ms /    14 tokens\n",
      " 75%|โโโโโโโโ  | 2630/3487 [7:35:56<2:02:56,  8.61s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8350.88 ms /    41 tokens (  203.68 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.06 ms /     3 runs   (  879.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10991.49 ms /    44 tokens\n",
      " 75%|โโโโโโโโ  | 2631/3487 [7:36:07<2:13:02,  9.33s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1725.47 ms /     6 tokens (  287.58 ms per token,     3.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.74 ms /     3 runs   (  880.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4368.77 ms /     9 tokens\n",
      " 75%|โโโโโโโโ  | 2632/3487 [7:36:12<1:51:44,  7.84s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4664.40 ms /    23 tokens (  202.80 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.11 ms /     3 runs   (  888.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7333.57 ms /    26 tokens\n",
      " 76%|โโโโโโโโ  | 2633/3487 [7:36:19<1:49:27,  7.69s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5307.60 ms /    27 tokens (  196.58 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.61 ms /     3 runs   (  885.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7968.37 ms /    30 tokens\n",
      " 76%|โโโโโโโโ  | 2634/3487 [7:36:27<1:50:33,  7.78s/it]Llama.generate: 315 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1362.03 ms /     4 tokens (  340.51 ms per token,     2.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2912.96 ms /     3 runs   (  970.99 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    4277.73 ms /     7 tokens\n",
      " 76%|โโโโโโโโ  | 2635/3487 [7:36:31<1:35:33,  6.73s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6612.87 ms /    32 tokens (  206.65 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.29 ms /     3 runs   (  909.76 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    9345.13 ms /    35 tokens\n",
      " 76%|โโโโโโโโ  | 2636/3487 [7:36:41<1:46:37,  7.52s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2781.32 ms /    12 tokens (  231.78 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.13 ms /     3 runs   (  903.04 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5493.27 ms /    15 tokens\n",
      " 76%|โโโโโโโโ  | 2637/3487 [7:36:46<1:37:55,  6.91s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2256.10 ms /     9 tokens (  250.68 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.18 ms /     3 runs   (  883.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4907.67 ms /    12 tokens\n",
      " 76%|โโโโโโโโ  | 2638/3487 [7:36:51<1:29:19,  6.31s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2782.60 ms /    12 tokens (  231.88 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2820.70 ms /     3 runs   (  940.23 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5606.18 ms /    15 tokens\n",
      " 76%|โโโโโโโโ  | 2639/3487 [7:36:57<1:26:15,  6.10s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3686.44 ms /    13 tokens (  283.57 ms per token,     3.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.98 ms /     3 runs   (  906.66 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6408.61 ms /    16 tokens\n",
      " 76%|โโโโโโโโ  | 2640/3487 [7:37:03<1:27:29,  6.20s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8257.12 ms /    41 tokens (  201.39 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.89 ms /     3 runs   (  877.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10893.54 ms /    44 tokens\n",
      " 76%|โโโโโโโโ  | 2641/3487 [7:37:14<1:47:17,  7.61s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2191.34 ms /     9 tokens (  243.48 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.09 ms /     3 runs   (  886.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4851.30 ms /    12 tokens\n",
      " 76%|โโโโโโโโ  | 2642/3487 [7:37:19<1:35:32,  6.78s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6180.76 ms /    31 tokens (  199.38 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.93 ms /     3 runs   (  884.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8836.78 ms /    34 tokens\n",
      " 76%|โโโโโโโโ  | 2643/3487 [7:37:28<1:44:07,  7.40s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8744.88 ms /    45 tokens (  194.33 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.77 ms /     3 runs   (  880.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11388.00 ms /    48 tokens\n",
      " 76%|โโโโโโโโ  | 2644/3487 [7:37:39<2:00:50,  8.60s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2237.34 ms /     9 tokens (  248.59 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.59 ms /     3 runs   (  892.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4916.99 ms /    12 tokens\n",
      " 76%|โโโโโโโโ  | 2645/3487 [7:37:44<1:45:13,  7.50s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4288.43 ms /    21 tokens (  204.21 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.66 ms /     3 runs   (  886.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6950.15 ms /    24 tokens\n",
      " 76%|โโโโโโโโ  | 2646/3487 [7:37:51<1:42:49,  7.34s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4643.29 ms /    23 tokens (  201.88 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.99 ms /     3 runs   (  891.00 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7318.31 ms /    26 tokens\n",
      " 76%|โโโโโโโโ  | 2647/3487 [7:37:58<1:42:39,  7.33s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4168.48 ms /    19 tokens (  219.39 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2835.74 ms /     3 runs   (  945.25 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7006.42 ms /    22 tokens\n",
      " 76%|โโโโโโโโ  | 2648/3487 [7:38:05<1:41:12,  7.24s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4909.57 ms /    24 tokens (  204.57 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.16 ms /     3 runs   (  886.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7571.81 ms /    27 tokens\n",
      " 76%|โโโโโโโโ  | 2649/3487 [7:38:13<1:42:31,  7.34s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4654.75 ms /    23 tokens (  202.38 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.19 ms /     3 runs   (  885.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7312.23 ms /    26 tokens\n",
      " 76%|โโโโโโโโ  | 2650/3487 [7:38:20<1:42:19,  7.34s/it]Llama.generate: 308 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4656.48 ms /    22 tokens (  211.66 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.39 ms /     3 runs   (  879.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7295.87 ms /    25 tokens\n",
      " 76%|โโโโโโโโ  | 2651/3487 [7:38:28<1:42:04,  7.33s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2642.71 ms /    11 tokens (  240.25 ms per token,     4.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.67 ms /     3 runs   (  889.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5314.94 ms /    14 tokens\n",
      " 76%|โโโโโโโโ  | 2652/3487 [7:38:33<1:33:35,  6.72s/it]Llama.generate: 313 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2618.02 ms /    11 tokens (  238.00 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.68 ms /     3 runs   (  888.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5286.99 ms /    14 tokens\n",
      " 76%|โโโโโโโโ  | 2653/3487 [7:38:38<1:27:30,  6.30s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4660.74 ms /    22 tokens (  211.85 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.06 ms /     3 runs   (  888.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7328.13 ms /    25 tokens\n",
      " 76%|โโโโโโโโ  | 2654/3487 [7:38:46<1:31:45,  6.61s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2704.29 ms /    12 tokens (  225.36 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.03 ms /     3 runs   (  877.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5339.83 ms /    15 tokens\n",
      " 76%|โโโโโโโโ  | 2655/3487 [7:38:51<1:26:23,  6.23s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6503.62 ms /    31 tokens (  209.79 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2737.61 ms /     3 runs   (  912.53 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    9243.85 ms /    34 tokens\n",
      " 76%|โโโโโโโโ  | 2656/3487 [7:39:00<1:38:50,  7.14s/it]Llama.generate: 313 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3187.37 ms /    14 tokens (  227.67 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.89 ms /     3 runs   (  877.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5823.79 ms /    17 tokens\n",
      " 76%|โโโโโโโโ  | 2657/3487 [7:39:06<1:33:18,  6.75s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2010.38 ms /     7 tokens (  287.20 ms per token,     3.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.84 ms /     3 runs   (  893.95 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4694.57 ms /    10 tokens\n",
      " 76%|โโโโโโโโ  | 2658/3487 [7:39:11<1:24:44,  6.13s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2542.15 ms /    10 tokens (  254.22 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.34 ms /     3 runs   (  889.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5214.21 ms /    13 tokens\n",
      " 76%|โโโโโโโโ  | 2659/3487 [7:39:16<1:20:52,  5.86s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9472.42 ms /    49 tokens (  193.31 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.34 ms /     3 runs   (  886.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12134.70 ms /    52 tokens\n",
      " 76%|โโโโโโโโ  | 2660/3487 [7:39:28<1:46:44,  7.74s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2227.78 ms /     9 tokens (  247.53 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.98 ms /     3 runs   (  883.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4881.80 ms /    12 tokens\n",
      " 76%|โโโโโโโโ  | 2661/3487 [7:39:33<1:34:49,  6.89s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2719.79 ms /    11 tokens (  247.25 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.51 ms /     3 runs   (  885.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5379.48 ms /    14 tokens\n",
      " 76%|โโโโโโโโ  | 2662/3487 [7:39:38<1:28:30,  6.44s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1756.11 ms /     6 tokens (  292.69 ms per token,     3.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.79 ms /     3 runs   (  889.93 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4428.83 ms /     9 tokens\n",
      " 76%|โโโโโโโโ  | 2663/3487 [7:39:43<1:20:10,  5.84s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4918.29 ms /    24 tokens (  204.93 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2820.33 ms /     3 runs   (  940.11 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7741.65 ms /    27 tokens\n",
      " 76%|โโโโโโโโ  | 2664/3487 [7:39:50<1:27:56,  6.41s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5152.09 ms /    25 tokens (  206.08 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.11 ms /     3 runs   (  888.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7820.97 ms /    28 tokens\n",
      " 76%|โโโโโโโโ  | 2665/3487 [7:39:58<1:33:39,  6.84s/it]Llama.generate: 311 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4995.16 ms /    24 tokens (  208.13 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.90 ms /     3 runs   (  887.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7659.32 ms /    27 tokens\n",
      " 76%|โโโโโโโโ  | 2666/3487 [7:40:06<1:36:57,  7.09s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2636.83 ms /    11 tokens (  239.71 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2896.37 ms /     3 runs   (  965.46 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    5534.72 ms /    14 tokens\n",
      " 76%|โโโโโโโโ  | 2667/3487 [7:40:12<1:30:30,  6.62s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2244.00 ms /     9 tokens (  249.33 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.37 ms /     3 runs   (  889.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4916.16 ms /    12 tokens\n",
      " 77%|โโโโโโโโ  | 2668/3487 [7:40:16<1:23:26,  6.11s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3345.23 ms /    15 tokens (  223.02 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.60 ms /     3 runs   (  887.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6009.63 ms /    18 tokens\n",
      " 77%|โโโโโโโโ  | 2669/3487 [7:40:22<1:22:57,  6.08s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7674.82 ms /    37 tokens (  207.43 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.70 ms /     3 runs   (  881.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10323.21 ms /    40 tokens\n",
      " 77%|โโโโโโโโ  | 2670/3487 [7:40:33<1:40:12,  7.36s/it]Llama.generate: 342 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3997.11 ms /     4 runs   (  999.28 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    3999.85 ms /     5 tokens\n",
      " 77%|โโโโโโโโ  | 2671/3487 [7:40:37<1:26:24,  6.35s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4228.20 ms /    20 tokens (  211.41 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.13 ms /     3 runs   (  877.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6863.12 ms /    23 tokens\n",
      " 77%|โโโโโโโโ  | 2672/3487 [7:40:44<1:28:24,  6.51s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3020.10 ms /    13 tokens (  232.32 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.30 ms /     3 runs   (  895.10 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5708.20 ms /    16 tokens\n",
      " 77%|โโโโโโโโ  | 2673/3487 [7:40:49<1:25:04,  6.27s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2339.33 ms /     9 tokens (  259.93 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.78 ms /     3 runs   (  891.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5016.81 ms /    12 tokens\n",
      " 77%|โโโโโโโโ  | 2674/3487 [7:40:54<1:19:54,  5.90s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10524.12 ms /    54 tokens (  194.89 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.23 ms /     3 runs   (  886.08 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13185.56 ms /    57 tokens\n",
      " 77%|โโโโโโโโ  | 2675/3487 [7:41:08<1:49:26,  8.09s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2707.28 ms /    12 tokens (  225.61 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.27 ms /     3 runs   (  880.76 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5352.29 ms /    15 tokens\n",
      " 77%|โโโโโโโโ  | 2676/3487 [7:41:13<1:38:14,  7.27s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15525.08 ms /    37 tokens (  419.60 ms per token,     2.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7462.94 ms /     3 runs   ( 2487.64 ms per token,     0.40 tokens per second)\n",
      "llama_perf_context_print:       total time =   22993.00 ms /    40 tokens\n",
      " 77%|โโโโโโโโ  | 2677/3487 [7:41:36<2:41:55, 11.99s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3409.13 ms /    11 tokens (  309.92 ms per token,     3.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3474.57 ms /     3 runs   ( 1158.19 ms per token,     0.86 tokens per second)\n",
      "llama_perf_context_print:       total time =    6889.03 ms /    14 tokens\n",
      " 77%|โโโโโโโโ  | 2678/3487 [7:41:43<2:21:11, 10.47s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9627.25 ms /    37 tokens (  260.20 ms per token,     3.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2940.07 ms /     3 runs   (  980.02 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =   12570.08 ms /    40 tokens\n",
      " 77%|โโโโโโโโ  | 2679/3487 [7:41:55<2:29:32, 11.10s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4465.89 ms /    21 tokens (  212.66 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2788.06 ms /     3 runs   (  929.35 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7257.01 ms /    24 tokens\n",
      " 77%|โโโโโโโโ  | 2680/3487 [7:42:03<2:13:52,  9.95s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11878.42 ms /    62 tokens (  191.59 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.65 ms /     3 runs   (  880.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14521.60 ms /    65 tokens\n",
      " 77%|โโโโโโโโ  | 2681/3487 [7:42:17<2:32:08, 11.33s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7887.90 ms /    40 tokens (  197.20 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3522.11 ms /     4 runs   (  880.53 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11413.45 ms /    44 tokens\n",
      " 77%|โโโโโโโโ  | 2682/3487 [7:42:29<2:32:20, 11.35s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7378.57 ms /    37 tokens (  199.42 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.61 ms /     3 runs   (  882.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10029.63 ms /    40 tokens\n",
      " 77%|โโโโโโโโ  | 2683/3487 [7:42:39<2:26:51, 10.96s/it]Llama.generate: 314 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4556.01 ms /    22 tokens (  207.09 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.71 ms /     3 runs   (  882.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7205.17 ms /    25 tokens\n",
      " 77%|โโโโโโโโ  | 2684/3487 [7:42:46<2:11:37,  9.84s/it]Llama.generate: 306 prefix-match hit, remaining 109 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20163.18 ms /   109 tokens (  184.98 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.28 ms /     3 runs   (  881.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   22810.13 ms /   112 tokens\n",
      " 77%|โโโโโโโโ  | 2685/3487 [7:43:09<3:03:31, 13.73s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7921.42 ms /    41 tokens (  193.21 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.72 ms /     3 runs   (  880.57 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10566.70 ms /    44 tokens\n",
      " 77%|โโโโโโโโ  | 2686/3487 [7:43:19<2:50:39, 12.78s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7937.53 ms /    38 tokens (  208.88 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.43 ms /     3 runs   (  888.81 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10606.59 ms /    41 tokens\n",
      " 77%|โโโโโโโโ  | 2687/3487 [7:43:30<2:41:46, 12.13s/it]Llama.generate: 306 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18634.57 ms /    98 tokens (  190.15 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.02 ms /     3 runs   (  876.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21266.55 ms /   101 tokens\n",
      " 77%|โโโโโโโโ  | 2688/3487 [7:43:51<3:18:12, 14.88s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7481.38 ms /    38 tokens (  196.88 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.08 ms /     3 runs   (  897.03 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10175.47 ms /    41 tokens\n",
      " 77%|โโโโโโโโ  | 2689/3487 [7:44:01<2:59:12, 13.47s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5049.17 ms /    25 tokens (  201.97 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.45 ms /     3 runs   (  891.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7725.41 ms /    28 tokens\n",
      " 77%|โโโโโโโโ  | 2690/3487 [7:44:09<2:36:06, 11.75s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2269.42 ms /     9 tokens (  252.16 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.62 ms /     3 runs   (  891.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4947.29 ms /    12 tokens\n",
      " 77%|โโโโโโโโ  | 2691/3487 [7:44:14<2:08:51,  9.71s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2094.93 ms /     8 tokens (  261.87 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.75 ms /     3 runs   (  885.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4752.99 ms /    11 tokens\n",
      " 77%|โโโโโโโโ  | 2692/3487 [7:44:19<1:49:01,  8.23s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5743.82 ms /    29 tokens (  198.06 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.90 ms /     3 runs   (  881.97 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8392.07 ms /    32 tokens\n",
      " 77%|โโโโโโโโ  | 2693/3487 [7:44:27<1:49:34,  8.28s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3712.42 ms /    15 tokens (  247.49 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2867.10 ms /     3 runs   (  955.70 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    6582.23 ms /    18 tokens\n",
      " 77%|โโโโโโโโ  | 2694/3487 [7:44:34<1:42:43,  7.77s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6429.63 ms /    30 tokens (  214.32 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.45 ms /     3 runs   (  897.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9124.18 ms /    33 tokens\n",
      " 77%|โโโโโโโโ  | 2695/3487 [7:44:43<1:47:59,  8.18s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2720.92 ms /    12 tokens (  226.74 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.21 ms /     3 runs   (  889.07 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5391.15 ms /    15 tokens\n",
      " 77%|โโโโโโโโ  | 2696/3487 [7:44:48<1:36:50,  7.35s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11622.45 ms /    60 tokens (  193.71 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.47 ms /     3 runs   (  887.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14286.46 ms /    63 tokens\n",
      " 77%|โโโโโโโโ  | 2697/3487 [7:45:03<2:04:10,  9.43s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1953.78 ms /     7 tokens (  279.11 ms per token,     3.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2793.07 ms /     3 runs   (  931.02 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4749.29 ms /    10 tokens\n",
      " 77%|โโโโโโโโ  | 2698/3487 [7:45:07<1:45:34,  8.03s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5729.58 ms /    26 tokens (  220.37 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2759.31 ms /     3 runs   (  919.77 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8491.07 ms /    29 tokens\n",
      " 77%|โโโโโโโโ  | 2699/3487 [7:45:16<1:47:17,  8.17s/it]Llama.generate: 308 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7430.98 ms /    34 tokens (  218.56 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.29 ms /     3 runs   (  907.10 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   10155.06 ms /    37 tokens\n",
      " 77%|โโโโโโโโ  | 2700/3487 [7:45:26<1:55:00,  8.77s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4547.96 ms /    20 tokens (  227.40 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.37 ms /     3 runs   (  894.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7234.90 ms /    23 tokens\n",
      " 77%|โโโโโโโโ  | 2701/3487 [7:45:33<1:48:52,  8.31s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13557.94 ms /    47 tokens (  288.47 ms per token,     3.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3012.56 ms /     3 runs   ( 1004.19 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =   16573.06 ms /    50 tokens\n",
      " 77%|โโโโโโโโ  | 2702/3487 [7:45:50<2:21:12, 10.79s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7872.19 ms /    34 tokens (  231.53 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3062.60 ms /     3 runs   ( 1020.87 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =   10937.35 ms /    37 tokens\n",
      " 78%|โโโโโโโโ  | 2703/3487 [7:46:01<2:21:37, 10.84s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2302.55 ms /     9 tokens (  255.84 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.19 ms /     3 runs   (  905.40 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5021.16 ms /    12 tokens\n",
      " 78%|โโโโโโโโ  | 2704/3487 [7:46:06<1:58:41,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4269.33 ms /    14 tokens (  304.95 ms per token,     3.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4140.44 ms /     3 runs   ( 1380.15 ms per token,     0.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    8411.87 ms /    17 tokens\n",
      " 78%|โโโโโโโโ  | 2705/3487 [7:46:14<1:55:54,  8.89s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5376.92 ms /    18 tokens (  298.72 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3069.63 ms /     3 runs   ( 1023.21 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    8449.73 ms /    21 tokens\n",
      " 78%|โโโโโโโโ  | 2706/3487 [7:46:23<1:54:03,  8.76s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4480.52 ms /    19 tokens (  235.82 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2762.48 ms /     3 runs   (  920.83 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7246.56 ms /    22 tokens\n",
      " 78%|โโโโโโโโ  | 2707/3487 [7:46:30<1:48:02,  8.31s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10029.18 ms /    49 tokens (  204.68 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.58 ms /     3 runs   (  899.86 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   12731.76 ms /    52 tokens\n",
      " 78%|โโโโโโโโ  | 2708/3487 [7:46:43<2:05:09,  9.64s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11965.78 ms /    62 tokens (  193.00 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.02 ms /     3 runs   (  896.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14658.30 ms /    65 tokens\n",
      " 78%|โโโโโโโโ  | 2709/3487 [7:46:57<2:24:32, 11.15s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7923.58 ms /    37 tokens (  214.15 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.01 ms /     3 runs   (  902.67 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10634.00 ms /    40 tokens\n",
      " 78%|โโโโโโโโ  | 2710/3487 [7:47:08<2:22:23, 11.00s/it]Llama.generate: 315 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3286.78 ms /    15 tokens (  219.12 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.24 ms /     3 runs   (  892.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5966.81 ms /    18 tokens\n",
      " 78%|โโโโโโโโ  | 2711/3487 [7:47:14<2:02:44,  9.49s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4645.69 ms /    22 tokens (  211.17 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.90 ms /     3 runs   (  902.30 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7355.15 ms /    25 tokens\n",
      " 78%|โโโโโโโโ  | 2712/3487 [7:47:21<1:54:20,  8.85s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2267.11 ms /     9 tokens (  251.90 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.84 ms /     3 runs   (  899.28 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4968.09 ms /    12 tokens\n",
      " 78%|โโโโโโโโ  | 2713/3487 [7:47:26<1:39:11,  7.69s/it]Llama.generate: 311 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3304.48 ms /    15 tokens (  220.30 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.70 ms /     3 runs   (  886.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5968.26 ms /    18 tokens\n",
      " 78%|โโโโโโโโ  | 2714/3487 [7:47:32<1:32:26,  7.18s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9124.62 ms /    47 tokens (  194.14 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.28 ms /     3 runs   (  886.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11787.14 ms /    50 tokens\n",
      " 78%|โโโโโโโโ  | 2715/3487 [7:47:44<1:50:09,  8.56s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2586.76 ms /    11 tokens (  235.16 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.95 ms /     3 runs   (  903.65 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5300.17 ms /    14 tokens\n",
      " 78%|โโโโโโโโ  | 2716/3487 [7:47:50<1:37:28,  7.59s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2369.51 ms /     9 tokens (  263.28 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.45 ms /     3 runs   (  887.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5035.64 ms /    12 tokens\n",
      " 78%|โโโโโโโโ  | 2717/3487 [7:47:55<1:27:33,  6.82s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3610.29 ms /    14 tokens (  257.88 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2960.12 ms /     3 runs   (  986.71 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    6572.88 ms /    17 tokens\n",
      " 78%|โโโโโโโโ  | 2718/3487 [7:48:01<1:26:31,  6.75s/it]Llama.generate: 311 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2278.07 ms /     9 tokens (  253.12 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.83 ms /     3 runs   (  902.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4988.57 ms /    12 tokens\n",
      " 78%|โโโโโโโโ  | 2719/3487 [7:48:06<1:19:40,  6.22s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1857.59 ms /     6 tokens (  309.60 ms per token,     3.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2763.12 ms /     3 runs   (  921.04 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4623.37 ms /     9 tokens\n",
      " 78%|โโโโโโโโ  | 2720/3487 [7:48:11<1:13:27,  5.75s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3144.30 ms /    13 tokens (  241.87 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.82 ms /     3 runs   (  893.61 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5828.21 ms /    16 tokens\n",
      " 78%|โโโโโโโโ  | 2721/3487 [7:48:17<1:13:42,  5.77s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5392.94 ms /    27 tokens (  199.74 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.85 ms /     3 runs   (  885.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8053.36 ms /    30 tokens\n",
      " 78%|โโโโโโโโ  | 2722/3487 [7:48:25<1:22:21,  6.46s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5245.74 ms /    26 tokens (  201.76 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.24 ms /     3 runs   (  895.08 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7933.47 ms /    29 tokens\n",
      " 78%|โโโโโโโโ  | 2723/3487 [7:48:33<1:27:55,  6.91s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3663.29 ms /    17 tokens (  215.49 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.42 ms /     3 runs   (  893.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6345.89 ms /    20 tokens\n",
      " 78%|โโโโโโโโ  | 2724/3487 [7:48:39<1:25:42,  6.74s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3327.31 ms /    15 tokens (  221.82 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.93 ms /     3 runs   (  889.31 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5997.86 ms /    18 tokens\n",
      " 78%|โโโโโโโโ  | 2725/3487 [7:48:45<1:22:48,  6.52s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8315.31 ms /    39 tokens (  213.21 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.13 ms /     3 runs   (  909.71 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   11047.44 ms /    42 tokens\n",
      " 78%|โโโโโโโโ  | 2726/3487 [7:48:56<1:39:57,  7.88s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3794.12 ms /    17 tokens (  223.18 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.38 ms /     3 runs   (  892.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6474.64 ms /    20 tokens\n",
      " 78%|โโโโโโโโ  | 2727/3487 [7:49:03<1:34:30,  7.46s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2288.66 ms /     9 tokens (  254.30 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.97 ms /     3 runs   (  897.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4984.80 ms /    12 tokens\n",
      " 78%|โโโโโโโโ  | 2728/3487 [7:49:08<1:25:01,  6.72s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3616.65 ms /    16 tokens (  226.04 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.20 ms /     3 runs   (  888.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6283.16 ms /    19 tokens\n",
      " 78%|โโโโโโโโ  | 2729/3487 [7:49:14<1:23:17,  6.59s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2531.36 ms /    10 tokens (  253.14 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.44 ms /     3 runs   (  892.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5212.82 ms /    13 tokens\n",
      " 78%|โโโโโโโโ  | 2730/3487 [7:49:19<1:17:59,  6.18s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4299.99 ms /    21 tokens (  204.76 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.25 ms /     3 runs   (  891.75 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6978.19 ms /    24 tokens\n",
      " 78%|โโโโโโโโ  | 2731/3487 [7:49:26<1:20:55,  6.42s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2624.34 ms /    11 tokens (  238.58 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.06 ms /     3 runs   (  883.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5277.59 ms /    14 tokens\n",
      " 78%|โโโโโโโโ  | 2732/3487 [7:49:31<1:16:31,  6.08s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4688.25 ms /    23 tokens (  203.84 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.98 ms /     3 runs   (  890.33 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7362.50 ms /    26 tokens\n",
      " 78%|โโโโโโโโ  | 2733/3487 [7:49:39<1:21:17,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3731.37 ms /    15 tokens (  248.76 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.86 ms /     3 runs   (  883.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6386.18 ms /    18 tokens\n",
      " 78%|โโโโโโโโ  | 2734/3487 [7:49:45<1:20:54,  6.45s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5839.61 ms /    30 tokens (  194.65 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.32 ms /     3 runs   (  891.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8516.08 ms /    33 tokens\n",
      " 78%|โโโโโโโโ  | 2735/3487 [7:49:54<1:28:36,  7.07s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2090.40 ms /     7 tokens (  298.63 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.87 ms /     3 runs   (  894.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4777.66 ms /    10 tokens\n",
      " 78%|โโโโโโโโ  | 2736/3487 [7:49:58<1:19:55,  6.39s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7622.42 ms /    38 tokens (  200.59 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.20 ms /     3 runs   (  884.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10279.66 ms /    41 tokens\n",
      " 78%|โโโโโโโโ  | 2737/3487 [7:50:09<1:34:26,  7.56s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2784.97 ms /    12 tokens (  232.08 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.57 ms /     3 runs   (  884.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5441.72 ms /    15 tokens\n",
      " 79%|โโโโโโโโ  | 2738/3487 [7:50:14<1:26:25,  6.92s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4190.19 ms /    20 tokens (  209.51 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.83 ms /     3 runs   (  895.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6880.87 ms /    23 tokens\n",
      " 79%|โโโโโโโโ  | 2739/3487 [7:50:21<1:26:10,  6.91s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1715.74 ms /     6 tokens (  285.96 ms per token,     3.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.80 ms /     3 runs   (  891.27 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4391.94 ms /     9 tokens\n",
      " 79%|โโโโโโโโ  | 2740/3487 [7:50:25<1:16:40,  6.16s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7325.77 ms /    36 tokens (  203.49 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.47 ms /     3 runs   (  884.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9982.77 ms /    39 tokens\n",
      " 79%|โโโโโโโโ  | 2741/3487 [7:50:35<1:30:52,  7.31s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8857.24 ms /    40 tokens (  221.43 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2743.97 ms /     3 runs   (  914.66 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   11604.00 ms /    43 tokens\n",
      " 79%|โโโโโโโโ  | 2742/3487 [7:50:47<1:46:46,  8.60s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10340.98 ms /    54 tokens (  191.50 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.97 ms /     3 runs   (  886.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13002.94 ms /    57 tokens\n",
      " 79%|โโโโโโโโ  | 2743/3487 [7:51:00<2:03:02,  9.92s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3220.29 ms /    15 tokens (  214.69 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.63 ms /     3 runs   (  886.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5883.13 ms /    18 tokens\n",
      " 79%|โโโโโโโโ  | 2744/3487 [7:51:06<1:47:54,  8.71s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7334.17 ms /    35 tokens (  209.55 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.92 ms /     3 runs   (  889.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10006.88 ms /    38 tokens\n",
      " 79%|โโโโโโโโ  | 2745/3487 [7:51:16<1:52:35,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1723.26 ms /     6 tokens (  287.21 ms per token,     3.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.74 ms /     3 runs   (  889.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4394.55 ms /     9 tokens\n",
      " 79%|โโโโโโโโ  | 2746/3487 [7:51:20<1:35:01,  7.69s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8819.10 ms /    45 tokens (  195.98 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.13 ms /     3 runs   (  896.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11510.80 ms /    48 tokens\n",
      " 79%|โโโโโโโโ  | 2747/3487 [7:51:32<1:49:02,  8.84s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7870.60 ms /    38 tokens (  207.12 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2892.49 ms /     3 runs   (  964.16 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   10765.25 ms /    41 tokens\n",
      " 79%|โโโโโโโโ  | 2748/3487 [7:51:43<1:56:02,  9.42s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3469.10 ms /    15 tokens (  231.27 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.80 ms /     3 runs   (  889.93 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6141.43 ms /    18 tokens\n",
      " 79%|โโโโโโโโ  | 2749/3487 [7:51:49<1:43:48,  8.44s/it]Llama.generate: 307 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11066.20 ms /    56 tokens (  197.61 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.27 ms /     3 runs   (  893.42 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13748.84 ms /    59 tokens\n",
      " 79%|โโโโโโโโ  | 2750/3487 [7:52:03<2:03:15, 10.03s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1999.97 ms /     7 tokens (  285.71 ms per token,     3.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.77 ms /     3 runs   (  908.59 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4728.44 ms /    10 tokens\n",
      " 79%|โโโโโโโโ  | 2751/3487 [7:52:07<1:43:36,  8.45s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4083.06 ms /    19 tokens (  214.90 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4152.86 ms /     3 runs   ( 1384.29 ms per token,     0.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    8237.82 ms /    22 tokens\n",
      " 79%|โโโโโโโโ  | 2752/3487 [7:52:16<1:42:43,  8.39s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10360.43 ms /    40 tokens (  259.01 ms per token,     3.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3042.99 ms /     3 runs   ( 1014.33 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   13406.39 ms /    43 tokens\n",
      " 79%|โโโโโโโโ  | 2753/3487 [7:52:29<2:01:03,  9.90s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7195.56 ms /    28 tokens (  256.98 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3453.26 ms /     3 runs   ( 1151.09 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =   10651.93 ms /    31 tokens\n",
      " 79%|โโโโโโโโ  | 2754/3487 [7:52:40<2:03:42, 10.13s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6175.77 ms /    16 tokens (  385.99 ms per token,     2.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3164.38 ms /     3 runs   ( 1054.79 ms per token,     0.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    9343.42 ms /    19 tokens\n",
      " 79%|โโโโโโโโ  | 2755/3487 [7:52:49<2:00:43,  9.89s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3329.88 ms /    13 tokens (  256.14 ms per token,     3.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.77 ms /     3 runs   (  915.92 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6080.38 ms /    16 tokens\n",
      " 79%|โโโโโโโโ  | 2756/3487 [7:52:55<1:46:38,  8.75s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2662.38 ms /    11 tokens (  242.03 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.51 ms /     3 runs   (  901.84 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5370.16 ms /    14 tokens\n",
      " 79%|โโโโโโโโ  | 2757/3487 [7:53:00<1:34:11,  7.74s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4649.53 ms /    20 tokens (  232.48 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.67 ms /     3 runs   (  890.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7322.95 ms /    23 tokens\n",
      " 79%|โโโโโโโโ  | 2758/3487 [7:53:08<1:32:33,  7.62s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3056.34 ms /    13 tokens (  235.10 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.86 ms /     3 runs   (  898.62 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5754.19 ms /    16 tokens\n",
      " 79%|โโโโโโโโ  | 2759/3487 [7:53:14<1:25:40,  7.06s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3026.87 ms /    13 tokens (  232.84 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.39 ms /     3 runs   (  892.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5706.86 ms /    16 tokens\n",
      " 79%|โโโโโโโโ  | 2760/3487 [7:53:19<1:20:39,  6.66s/it]Llama.generate: 316 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3023.27 ms /    13 tokens (  232.56 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.23 ms /     3 runs   (  892.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5703.71 ms /    16 tokens\n",
      " 79%|โโโโโโโโ  | 2761/3487 [7:53:25<1:17:07,  6.37s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2636.97 ms /    11 tokens (  239.72 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.08 ms /     3 runs   (  895.69 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5326.06 ms /    14 tokens\n",
      " 79%|โโโโโโโโ  | 2762/3487 [7:53:30<1:13:14,  6.06s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3040.74 ms /    13 tokens (  233.90 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.97 ms /     3 runs   (  886.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5703.24 ms /    16 tokens\n",
      " 79%|โโโโโโโโ  | 2763/3487 [7:53:36<1:11:52,  5.96s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3023.86 ms /    13 tokens (  232.60 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.89 ms /     3 runs   (  888.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5692.16 ms /    16 tokens\n",
      " 79%|โโโโโโโโ  | 2764/3487 [7:53:42<1:10:50,  5.88s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3010.59 ms /    13 tokens (  231.58 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.59 ms /     3 runs   (  889.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5681.39 ms /    16 tokens\n",
      " 79%|โโโโโโโโ  | 2765/3487 [7:53:47<1:10:03,  5.82s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4693.75 ms /    21 tokens (  223.51 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.69 ms /     3 runs   (  889.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7365.17 ms /    24 tokens\n",
      " 79%|โโโโโโโโ  | 2766/3487 [7:53:55<1:15:33,  6.29s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3909.74 ms /    17 tokens (  229.98 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.48 ms /     3 runs   (  894.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6596.57 ms /    20 tokens\n",
      " 79%|โโโโโโโโ  | 2767/3487 [7:54:01<1:16:35,  6.38s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3179.30 ms /    14 tokens (  227.09 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.30 ms /     3 runs   (  885.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5838.85 ms /    17 tokens\n",
      " 79%|โโโโโโโโ  | 2768/3487 [7:54:07<1:14:33,  6.22s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3060.93 ms /    13 tokens (  235.46 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.67 ms /     3 runs   (  891.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5737.40 ms /    16 tokens\n",
      " 79%|โโโโโโโโ  | 2769/3487 [7:54:13<1:12:44,  6.08s/it]Llama.generate: 316 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2628.78 ms /    11 tokens (  238.98 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.73 ms /     3 runs   (  893.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5312.55 ms /    14 tokens\n",
      " 79%|โโโโโโโโ  | 2770/3487 [7:54:18<1:09:55,  5.85s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2035.90 ms /     7 tokens (  290.84 ms per token,     3.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.88 ms /     3 runs   (  897.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4732.21 ms /    10 tokens\n",
      " 79%|โโโโโโโโ  | 2771/3487 [7:54:23<1:05:50,  5.52s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3153.07 ms /    14 tokens (  225.22 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2862.58 ms /     3 runs   (  954.19 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    6018.40 ms /    17 tokens\n",
      " 79%|โโโโโโโโ  | 2772/3487 [7:54:29<1:07:34,  5.67s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6015.49 ms /    29 tokens (  207.43 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.33 ms /     3 runs   (  902.11 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8724.48 ms /    32 tokens\n",
      " 80%|โโโโโโโโ  | 2773/3487 [7:54:38<1:18:24,  6.59s/it]Llama.generate: 316 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2233.44 ms /     4 tokens (  558.36 ms per token,     1.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2758.78 ms /     3 runs   (  919.59 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4994.99 ms /     7 tokens\n",
      " 80%|โโโโโโโโ  | 2774/3487 [7:54:43<1:12:38,  6.11s/it]Llama.generate: 319 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3893.24 ms /     4 runs   (  973.31 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    3895.38 ms /     5 tokens\n",
      " 80%|โโโโโโโโ  | 2775/3487 [7:54:47<1:04:40,  5.45s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3079.46 ms /    13 tokens (  236.88 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.49 ms /     3 runs   (  889.16 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5749.26 ms /    16 tokens\n",
      " 80%|โโโโโโโโ  | 2776/3487 [7:54:52<1:05:40,  5.54s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5740.67 ms /    28 tokens (  205.02 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.76 ms /     3 runs   (  896.25 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8432.36 ms /    31 tokens\n",
      " 80%|โโโโโโโโ  | 2777/3487 [7:55:01<1:15:52,  6.41s/it]Llama.generate: 316 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1453.53 ms /     4 tokens (  363.38 ms per token,     2.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2831.38 ms /     3 runs   (  943.79 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4287.81 ms /     7 tokens\n",
      " 80%|โโโโโโโโ  | 2778/3487 [7:55:05<1:08:15,  5.78s/it]Llama.generate: 319 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3920.12 ms /     4 runs   (  980.03 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    3922.56 ms /     5 tokens\n",
      " 80%|โโโโโโโโ  | 2779/3487 [7:55:09<1:01:38,  5.22s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2705.65 ms /    11 tokens (  245.97 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.34 ms /     3 runs   (  889.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5377.83 ms /    14 tokens\n",
      " 80%|โโโโโโโโ  | 2780/3487 [7:55:14<1:02:07,  5.27s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5049.79 ms /    23 tokens (  219.56 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.57 ms /     3 runs   (  900.86 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7755.52 ms /    26 tokens\n",
      " 80%|โโโโโโโโ  | 2781/3487 [7:55:22<1:10:50,  6.02s/it]Llama.generate: 316 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1368.39 ms /     4 tokens (  342.10 ms per token,     2.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2844.69 ms /     3 runs   (  948.23 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4215.67 ms /     7 tokens\n",
      " 80%|โโโโโโโโ  | 2782/3487 [7:55:26<1:04:24,  5.48s/it]Llama.generate: 316 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4087.34 ms /    19 tokens (  215.12 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.59 ms /     3 runs   (  888.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6754.51 ms /    22 tokens\n",
      " 80%|โโโโโโโโ  | 2783/3487 [7:55:33<1:08:49,  5.87s/it]Llama.generate: 316 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1404.19 ms /     4 tokens (  351.05 ms per token,     2.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2852.28 ms /     3 runs   (  950.76 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4259.14 ms /     7 tokens\n",
      " 80%|โโโโโโโโ  | 2784/3487 [7:55:38<1:03:06,  5.39s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4365.67 ms /    21 tokens (  207.89 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.04 ms /     3 runs   (  887.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7030.31 ms /    24 tokens\n",
      " 80%|โโโโโโโโ  | 2785/3487 [7:55:45<1:08:49,  5.88s/it]Llama.generate: 307 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   29090.48 ms /   103 tokens (  282.43 ms per token,     3.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3829.70 ms /     3 runs   ( 1276.57 ms per token,     0.78 tokens per second)\n",
      "llama_perf_context_print:       total time =   32924.38 ms /   106 tokens\n",
      " 80%|โโโโโโโโ  | 2786/3487 [7:56:17<2:43:35, 14.00s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3975.88 ms /    13 tokens (  305.84 ms per token,     3.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3545.18 ms /     3 runs   ( 1181.73 ms per token,     0.85 tokens per second)\n",
      "llama_perf_context_print:       total time =    7525.77 ms /    16 tokens\n",
      " 80%|โโโโโโโโ  | 2787/3487 [7:56:25<2:20:47, 12.07s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10776.68 ms /    43 tokens (  250.62 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3044.08 ms /     3 runs   ( 1014.69 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   13823.73 ms /    46 tokens\n",
      " 80%|โโโโโโโโ  | 2788/3487 [7:56:39<2:26:46, 12.60s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2728.26 ms /    10 tokens (  272.83 ms per token,     3.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6754.33 ms /     3 runs   ( 2251.44 ms per token,     0.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    9486.92 ms /    13 tokens\n",
      " 80%|โโโโโโโโ  | 2789/3487 [7:56:48<2:15:45, 11.67s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5521.49 ms /     7 tokens (  788.78 ms per token,     1.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3309.86 ms /     3 runs   ( 1103.29 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =    8835.53 ms /    10 tokens\n",
      " 80%|โโโโโโโโ  | 2790/3487 [7:56:57<2:05:44, 10.82s/it]Llama.generate: 306 prefix-match hit, remaining 122 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23932.99 ms /   122 tokens (  196.17 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.33 ms /     3 runs   (  902.78 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   26644.35 ms /   125 tokens\n",
      " 80%|โโโโโโโโ  | 2791/3487 [7:57:24<3:00:38, 15.57s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7386.69 ms /    34 tokens (  217.26 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.85 ms /     3 runs   (  881.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10035.11 ms /    37 tokens\n",
      " 80%|โโโโโโโโ  | 2792/3487 [7:57:34<2:41:10, 13.92s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11001.50 ms /    57 tokens (  193.01 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.60 ms /     3 runs   (  896.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13693.10 ms /    60 tokens\n",
      " 80%|โโโโโโโโ  | 2793/3487 [7:57:48<2:40:12, 13.85s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9852.93 ms /    51 tokens (  193.19 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.82 ms /     3 runs   (  885.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12513.56 ms /    54 tokens\n",
      " 80%|โโโโโโโโ  | 2794/3487 [7:58:00<2:35:22, 13.45s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8848.24 ms /    45 tokens (  196.63 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.69 ms /     3 runs   (  887.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11514.19 ms /    48 tokens\n",
      " 80%|โโโโโโโโ  | 2795/3487 [7:58:12<2:28:28, 12.87s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4792.92 ms /    20 tokens (  239.65 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.45 ms /     3 runs   (  911.82 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7531.02 ms /    23 tokens\n",
      " 80%|โโโโโโโโ  | 2796/3487 [7:58:19<2:09:50, 11.27s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1362.30 ms /     4 tokens (  340.58 ms per token,     2.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2869.06 ms /     3 runs   (  956.35 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4234.00 ms /     7 tokens\n",
      " 80%|โโโโโโโโ  | 2797/3487 [7:58:23<1:45:23,  9.16s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4289.63 ms /    21 tokens (  204.27 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.56 ms /     3 runs   (  883.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6943.88 ms /    24 tokens\n",
      " 80%|โโโโโโโโ  | 2798/3487 [7:58:30<1:37:36,  8.50s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9127.05 ms /    47 tokens (  194.19 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2872.87 ms /     3 runs   (  957.62 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   12002.23 ms /    50 tokens\n",
      " 80%|โโโโโโโโ  | 2799/3487 [7:58:42<1:49:32,  9.55s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5080.90 ms /    25 tokens (  203.24 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.63 ms /     3 runs   (  885.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7739.64 ms /    28 tokens\n",
      " 80%|โโโโโโโโ  | 2800/3487 [7:58:50<1:43:10,  9.01s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7295.46 ms /    33 tokens (  221.07 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.20 ms /     3 runs   (  893.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9977.86 ms /    36 tokens\n",
      " 80%|โโโโโโโโ  | 2801/3487 [7:59:00<1:46:22,  9.30s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3039.09 ms /    13 tokens (  233.78 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.01 ms /     3 runs   (  883.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5691.63 ms /    16 tokens\n",
      " 80%|โโโโโโโโ  | 2802/3487 [7:59:06<1:33:53,  8.22s/it]Llama.generate: 307 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17820.83 ms /    93 tokens (  191.62 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.15 ms /     3 runs   (  887.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20486.81 ms /    96 tokens\n",
      " 80%|โโโโโโโโ  | 2803/3487 [7:59:26<2:15:43, 11.91s/it]Llama.generate: 307 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12939.83 ms /    66 tokens (  196.06 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.46 ms /     3 runs   (  890.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15612.87 ms /    69 tokens\n",
      " 80%|โโโโโโโโ  | 2804/3487 [7:59:42<2:28:12, 13.02s/it]Llama.generate: 307 prefix-match hit, remaining 121 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   22424.89 ms /   121 tokens (  185.33 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.39 ms /     3 runs   (  881.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   25072.52 ms /   124 tokens\n",
      " 80%|โโโโโโโโ  | 2805/3487 [8:00:07<3:09:07, 16.64s/it]Llama.generate: 307 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20073.46 ms /   107 tokens (  187.60 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.18 ms /     3 runs   (  886.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   22734.39 ms /   110 tokens\n",
      " 80%|โโโโโโโโ  | 2806/3487 [8:00:30<3:29:37, 18.47s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4070.92 ms /    19 tokens (  214.26 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.45 ms /     3 runs   (  880.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6714.81 ms /    22 tokens\n",
      " 80%|โโโโโโโโ  | 2807/3487 [8:00:37<2:49:23, 14.95s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11401.24 ms /    59 tokens (  193.24 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2823.35 ms /     3 runs   (  941.12 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   14227.33 ms /    62 tokens\n",
      " 81%|โโโโโโโโ  | 2808/3487 [8:00:51<2:46:43, 14.73s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4847.04 ms /    24 tokens (  201.96 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.54 ms /     3 runs   (  888.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7515.64 ms /    27 tokens\n",
      " 81%|โโโโโโโโ  | 2809/3487 [8:00:58<2:22:02, 12.57s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12374.45 ms /    63 tokens (  196.42 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.39 ms /     3 runs   (  881.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15021.65 ms /    66 tokens\n",
      " 81%|โโโโโโโโ  | 2810/3487 [8:01:13<2:30:09, 13.31s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2696.54 ms /    12 tokens (  224.71 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.40 ms /     3 runs   (  882.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5346.20 ms /    15 tokens\n",
      " 81%|โโโโโโโโ  | 2811/3487 [8:01:19<2:03:02, 10.92s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6156.66 ms /    31 tokens (  198.60 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.56 ms /     3 runs   (  885.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8815.92 ms /    34 tokens\n",
      " 81%|โโโโโโโโ  | 2812/3487 [8:01:27<1:55:47, 10.29s/it]Llama.generate: 308 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2968.23 ms /    13 tokens (  228.33 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.32 ms /     3 runs   (  879.11 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5608.59 ms /    16 tokens\n",
      " 81%|โโโโโโโโ  | 2813/3487 [8:01:33<1:39:51,  8.89s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2716.34 ms /    12 tokens (  226.36 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.53 ms /     3 runs   (  885.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5374.32 ms /    15 tokens\n",
      " 81%|โโโโโโโโ  | 2814/3487 [8:01:38<1:27:54,  7.84s/it]Llama.generate: 310 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9351.33 ms /    47 tokens (  198.96 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.50 ms /     3 runs   (  880.50 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11994.94 ms /    50 tokens\n",
      " 81%|โโโโโโโโ  | 2815/3487 [8:01:50<1:41:46,  9.09s/it]Llama.generate: 310 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2104.35 ms /     8 tokens (  263.04 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.67 ms /     3 runs   (  890.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4779.26 ms /    11 tokens\n",
      " 81%|โโโโโโโโ  | 2816/3487 [8:01:55<1:27:11,  7.80s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9419.11 ms /    46 tokens (  204.76 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2795.46 ms /     3 runs   (  931.82 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12217.58 ms /    49 tokens\n",
      " 81%|โโโโโโโโ  | 2817/3487 [8:02:08<1:41:54,  9.13s/it]Llama.generate: 306 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14146.20 ms /    73 tokens (  193.78 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.95 ms /     3 runs   (  881.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16795.00 ms /    76 tokens\n",
      " 81%|โโโโโโโโ  | 2818/3487 [8:02:24<2:07:25, 11.43s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3796.33 ms /    18 tokens (  210.91 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.80 ms /     3 runs   (  881.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6443.57 ms /    21 tokens\n",
      " 81%|โโโโโโโโ  | 2819/3487 [8:02:31<1:50:37,  9.94s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4812.12 ms /    24 tokens (  200.51 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.55 ms /     3 runs   (  882.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7462.77 ms /    27 tokens\n",
      " 81%|โโโโโโโโ  | 2820/3487 [8:02:38<1:42:13,  9.20s/it]Llama.generate: 307 prefix-match hit, remaining 97 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19248.16 ms /    97 tokens (  198.43 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.94 ms /     3 runs   (  892.65 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   21928.77 ms /   100 tokens\n",
      " 81%|โโโโโโโโ  | 2821/3487 [8:03:00<2:24:30, 13.02s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13765.10 ms /    72 tokens (  191.18 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.48 ms /     3 runs   (  878.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16402.97 ms /    75 tokens\n",
      " 81%|โโโโโโโโ  | 2822/3487 [8:03:17<2:35:34, 14.04s/it]Llama.generate: 307 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15714.41 ms /    83 tokens (  189.33 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.43 ms /     3 runs   (  905.14 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   18432.43 ms /    86 tokens\n",
      " 81%|โโโโโโโโ  | 2823/3487 [8:03:35<2:49:57, 15.36s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5496.40 ms /    27 tokens (  203.57 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.51 ms /     3 runs   (  894.50 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8182.11 ms /    30 tokens\n",
      " 81%|โโโโโโโโ  | 2824/3487 [8:03:43<2:25:56, 13.21s/it]Llama.generate: 306 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13780.32 ms /    73 tokens (  188.77 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.94 ms /     3 runs   (  881.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16426.67 ms /    76 tokens\n",
      " 81%|โโโโโโโโ  | 2825/3487 [8:04:00<2:36:24, 14.18s/it]Llama.generate: 306 prefix-match hit, remaining 116 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21970.40 ms /   116 tokens (  189.40 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.95 ms /     3 runs   (  885.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   24630.66 ms /   119 tokens\n",
      " 81%|โโโโโโโโ  | 2826/3487 [8:04:24<3:10:44, 17.31s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5478.97 ms /    27 tokens (  202.92 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.36 ms /     3 runs   (  879.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8119.79 ms /    30 tokens\n",
      " 81%|โโโโโโโโ  | 2827/3487 [8:04:32<2:40:08, 14.56s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3528.67 ms /    16 tokens (  220.54 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.52 ms /     3 runs   (  885.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6188.18 ms /    19 tokens\n",
      " 81%|โโโโโโโโ  | 2828/3487 [8:04:39<2:12:21, 12.05s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6278.94 ms /    31 tokens (  202.55 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.49 ms /     3 runs   (  890.50 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8953.07 ms /    34 tokens\n",
      " 81%|โโโโโโโโ  | 2829/3487 [8:04:48<2:01:59, 11.12s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10387.61 ms /    54 tokens (  192.36 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2768.48 ms /     3 runs   (  922.83 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   13159.50 ms /    57 tokens\n",
      " 81%|โโโโโโโโ  | 2830/3487 [8:05:01<2:08:30, 11.74s/it]Llama.generate: 306 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15964.23 ms /    84 tokens (  190.05 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.96 ms /     3 runs   (  879.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18606.51 ms /    87 tokens\n",
      " 81%|โโโโโโโโ  | 2831/3487 [8:05:19<2:30:52, 13.80s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7865.03 ms /    39 tokens (  201.67 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.45 ms /     3 runs   (  879.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10507.46 ms /    42 tokens\n",
      " 81%|โโโโโโโโ  | 2832/3487 [8:05:30<2:19:53, 12.81s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5389.93 ms /    27 tokens (  199.63 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.86 ms /     3 runs   (  883.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8043.10 ms /    30 tokens\n",
      " 81%|โโโโโโโโ  | 2833/3487 [8:05:38<2:04:05, 11.38s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5205.42 ms /    24 tokens (  216.89 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.41 ms /     3 runs   (  874.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7831.39 ms /    27 tokens\n",
      " 81%|โโโโโโโโโ | 2834/3487 [8:05:46<1:52:19, 10.32s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7807.19 ms /    37 tokens (  211.01 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2847.47 ms /     3 runs   (  949.16 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   10657.22 ms /    40 tokens\n",
      " 81%|โโโโโโโโโ | 2835/3487 [8:05:56<1:53:16, 10.42s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8214.08 ms /    41 tokens (  200.34 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.49 ms /     3 runs   (  879.16 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10854.53 ms /    44 tokens\n",
      " 81%|โโโโโโโโโ | 2836/3487 [8:06:07<1:54:32, 10.56s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5291.46 ms /    26 tokens (  203.52 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.61 ms /     3 runs   (  881.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7939.01 ms /    29 tokens\n",
      " 81%|โโโโโโโโโ | 2837/3487 [8:06:15<1:45:52,  9.77s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5338.05 ms /    27 tokens (  197.71 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.06 ms /     3 runs   (  882.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7987.93 ms /    30 tokens\n",
      " 81%|โโโโโโโโโ | 2838/3487 [8:06:23<1:39:57,  9.24s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4359.94 ms /    21 tokens (  207.62 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.95 ms /     3 runs   (  880.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7003.69 ms /    24 tokens\n",
      " 81%|โโโโโโโโโ | 2839/3487 [8:06:30<1:32:34,  8.57s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3040.37 ms /    13 tokens (  233.87 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.61 ms /     3 runs   (  881.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5687.15 ms /    16 tokens\n",
      " 81%|โโโโโโโโโ | 2840/3487 [8:06:36<1:23:07,  7.71s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2248.62 ms /     9 tokens (  249.85 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.18 ms /     3 runs   (  885.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4908.52 ms /    12 tokens\n",
      " 81%|โโโโโโโโโ | 2841/3487 [8:06:41<1:13:59,  6.87s/it]Llama.generate: 307 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12412.19 ms /    61 tokens (  203.48 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2779.86 ms /     3 runs   (  926.62 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   15194.93 ms /    64 tokens\n",
      " 82%|โโโโโโโโโ | 2842/3487 [8:06:56<1:40:44,  9.37s/it]Llama.generate: 312 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3306.57 ms /    14 tokens (  236.18 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.44 ms /     3 runs   (  902.81 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6018.03 ms /    17 tokens\n",
      " 82%|โโโโโโโโโ | 2843/3487 [8:07:02<1:29:49,  8.37s/it]Llama.generate: 315 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1837.04 ms /     4 tokens (  459.26 ms per token,     2.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.16 ms /     3 runs   (  907.05 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4560.50 ms /     7 tokens\n",
      " 82%|โโโโโโโโโ | 2844/3487 [8:07:07<1:17:27,  7.23s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4826.93 ms /    22 tokens (  219.41 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.26 ms /     3 runs   (  882.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7475.92 ms /    25 tokens\n",
      " 82%|โโโโโโโโโ | 2845/3487 [8:07:14<1:18:10,  7.31s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8584.58 ms /    44 tokens (  195.10 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.78 ms /     3 runs   (  883.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11237.77 ms /    47 tokens\n",
      " 82%|โโโโโโโโโ | 2846/3487 [8:07:25<1:30:40,  8.49s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7851.65 ms /    39 tokens (  201.32 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.93 ms /     3 runs   (  883.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10505.68 ms /    42 tokens\n",
      " 82%|โโโโโโโโโ | 2847/3487 [8:07:36<1:37:01,  9.10s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7226.49 ms /    34 tokens (  212.54 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.36 ms /     3 runs   (  876.79 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9859.09 ms /    37 tokens\n",
      " 82%|โโโโโโโโโ | 2848/3487 [8:07:46<1:39:20,  9.33s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10051.47 ms /    52 tokens (  193.30 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.09 ms /     3 runs   (  880.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12696.36 ms /    55 tokens\n",
      " 82%|โโโโโโโโโ | 2849/3487 [8:07:58<1:49:57, 10.34s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9883.55 ms /    49 tokens (  201.71 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.11 ms /     3 runs   (  885.37 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12541.61 ms /    52 tokens\n",
      " 82%|โโโโโโโโโ | 2850/3487 [8:08:11<1:56:48, 11.00s/it]Llama.generate: 306 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13814.99 ms /    73 tokens (  189.25 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.99 ms /     3 runs   (  881.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16462.36 ms /    76 tokens\n",
      " 82%|โโโโโโโโโ | 2851/3487 [8:08:27<2:14:01, 12.64s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1982.04 ms /     7 tokens (  283.15 ms per token,     3.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.15 ms /     3 runs   (  884.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4637.40 ms /    10 tokens\n",
      " 82%|โโโโโโโโโ | 2852/3487 [8:08:32<1:48:25, 10.24s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3801.35 ms /    18 tokens (  211.19 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.92 ms /     3 runs   (  889.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6473.80 ms /    21 tokens\n",
      " 82%|โโโโโโโโโ | 2853/3487 [8:08:39<1:36:19,  9.12s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5340.01 ms /    26 tokens (  205.39 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.07 ms /     3 runs   (  891.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8016.17 ms /    29 tokens\n",
      " 82%|โโโโโโโโโ | 2854/3487 [8:08:47<1:32:43,  8.79s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5286.76 ms /    26 tokens (  203.34 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.52 ms /     3 runs   (  878.84 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7926.37 ms /    29 tokens\n",
      " 82%|โโโโโโโโโ | 2855/3487 [8:08:55<1:29:52,  8.53s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2141.29 ms /     8 tokens (  267.66 ms per token,     3.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.41 ms /     3 runs   (  908.14 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4869.20 ms /    11 tokens\n",
      " 82%|โโโโโโโโโ | 2856/3487 [8:08:59<1:18:12,  7.44s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7277.34 ms /    34 tokens (  214.04 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.66 ms /     3 runs   (  883.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9930.54 ms /    37 tokens\n",
      " 82%|โโโโโโโโโ | 2857/3487 [8:09:09<1:25:57,  8.19s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4979.53 ms /    22 tokens (  226.34 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.98 ms /     3 runs   (  901.66 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7687.38 ms /    25 tokens\n",
      " 82%|โโโโโโโโโ | 2858/3487 [8:09:17<1:24:17,  8.04s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4312.18 ms /    21 tokens (  205.34 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.50 ms /     3 runs   (  898.83 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7011.05 ms /    24 tokens\n",
      " 82%|โโโโโโโโโ | 2859/3487 [8:09:24<1:20:56,  7.73s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4393.22 ms /    21 tokens (  209.20 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.58 ms /     3 runs   (  896.19 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7084.18 ms /    24 tokens\n",
      " 82%|โโโโโโโโโ | 2860/3487 [8:09:31<1:18:48,  7.54s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3298.80 ms /    15 tokens (  219.92 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.42 ms /     3 runs   (  891.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5974.25 ms /    18 tokens\n",
      " 82%|โโโโโโโโโ | 2861/3487 [8:09:37<1:13:47,  7.07s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5157.77 ms /    25 tokens (  206.31 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.67 ms /     3 runs   (  890.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7830.76 ms /    28 tokens\n",
      " 82%|โโโโโโโโโ | 2862/3487 [8:09:45<1:16:04,  7.30s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1992.30 ms /     7 tokens (  284.61 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.23 ms /     3 runs   (  890.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4667.26 ms /    10 tokens\n",
      " 82%|โโโโโโโโโ | 2863/3487 [8:09:50<1:07:44,  6.51s/it]Llama.generate: 306 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14407.90 ms /    72 tokens (  200.11 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.61 ms /     3 runs   (  887.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17073.36 ms /    75 tokens\n",
      " 82%|โโโโโโโโโ | 2864/3487 [8:10:07<1:40:33,  9.68s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7798.47 ms /    36 tokens (  216.62 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.37 ms /     3 runs   (  888.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10465.44 ms /    39 tokens\n",
      " 82%|โโโโโโโโโ | 2865/3487 [8:10:17<1:42:51,  9.92s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4271.90 ms /    19 tokens (  224.84 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.52 ms /     3 runs   (  891.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6950.08 ms /    22 tokens\n",
      " 82%|โโโโโโโโโ | 2866/3487 [8:10:24<1:33:29,  9.03s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8203.68 ms /    41 tokens (  200.09 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.45 ms /     3 runs   (  890.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10877.19 ms /    44 tokens\n",
      " 82%|โโโโโโโโโ | 2867/3487 [8:10:35<1:39:04,  9.59s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3593.08 ms /    16 tokens (  224.57 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.69 ms /     3 runs   (  899.90 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6295.94 ms /    19 tokens\n",
      " 82%|โโโโโโโโโ | 2868/3487 [8:10:41<1:28:45,  8.60s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5798.51 ms /    28 tokens (  207.09 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.54 ms /     3 runs   (  889.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8471.02 ms /    31 tokens\n",
      " 82%|โโโโโโโโโ | 2869/3487 [8:10:50<1:28:13,  8.57s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2533.68 ms /    10 tokens (  253.37 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2944.33 ms /     3 runs   (  981.44 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    5480.97 ms /    13 tokens\n",
      " 82%|โโโโโโโโโ | 2870/3487 [8:10:55<1:18:35,  7.64s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1386.03 ms /     4 tokens (  346.51 ms per token,     2.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2864.86 ms /     3 runs   (  954.95 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4253.63 ms /     7 tokens\n",
      " 82%|โโโโโโโโโ | 2871/3487 [8:11:00<1:08:03,  6.63s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5348.71 ms /    24 tokens (  222.86 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.88 ms /     3 runs   (  892.63 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8028.93 ms /    27 tokens\n",
      " 82%|โโโโโโโโโ | 2872/3487 [8:11:08<1:12:16,  7.05s/it]Llama.generate: 307 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14349.71 ms /    75 tokens (  191.33 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.36 ms /     3 runs   (  887.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17014.33 ms /    78 tokens\n",
      " 82%|โโโโโโโโโ | 2873/3487 [8:11:25<1:42:46, 10.04s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2164.97 ms /     8 tokens (  270.62 ms per token,     3.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.94 ms /     3 runs   (  889.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4837.04 ms /    11 tokens\n",
      " 82%|โโโโโโโโโ | 2874/3487 [8:11:30<1:26:40,  8.48s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9416.40 ms /    47 tokens (  200.35 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2769.39 ms /     3 runs   (  923.13 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   12188.29 ms /    50 tokens\n",
      " 82%|โโโโโโโโโ | 2875/3487 [8:11:42<1:37:53,  9.60s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9590.53 ms /    49 tokens (  195.73 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.89 ms /     3 runs   (  882.96 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12242.36 ms /    52 tokens\n",
      " 82%|โโโโโโโโโ | 2876/3487 [8:11:54<1:45:50, 10.39s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2159.53 ms /     8 tokens (  269.94 ms per token,     3.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.96 ms /     3 runs   (  899.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4862.20 ms /    11 tokens\n",
      " 83%|โโโโโโโโโ | 2877/3487 [8:11:59<1:28:49,  8.74s/it]Llama.generate: 307 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15217.91 ms /    78 tokens (  195.10 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.06 ms /     3 runs   (  905.02 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   17935.58 ms /    81 tokens\n",
      " 83%|โโโโโโโโโ | 2878/3487 [8:12:17<1:56:43, 11.50s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8348.42 ms /    39 tokens (  214.06 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.92 ms /     3 runs   (  886.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11012.21 ms /    42 tokens\n",
      " 83%|โโโโโโโโโ | 2879/3487 [8:12:28<1:55:04, 11.36s/it]Llama.generate: 307 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13670.14 ms /    71 tokens (  192.54 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.28 ms /     3 runs   (  904.09 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   16385.18 ms /    74 tokens\n",
      " 83%|โโโโโโโโโ | 2880/3487 [8:12:44<2:10:10, 12.87s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8242.47 ms /    40 tokens (  206.06 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3459.31 ms /     3 runs   ( 1153.10 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =   11704.87 ms /    43 tokens\n",
      " 83%|โโโโโโโโโ | 2881/3487 [8:12:56<2:06:28, 12.52s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10786.59 ms /    50 tokens (  215.73 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2881.74 ms /     3 runs   (  960.58 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   13671.15 ms /    53 tokens\n",
      " 83%|โโโโโโโโโ | 2882/3487 [8:13:10<2:09:46, 12.87s/it]Llama.generate: 307 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12126.78 ms /    55 tokens (  220.49 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.98 ms /     3 runs   (  908.33 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   14854.49 ms /    58 tokens\n",
      " 83%|โโโโโโโโโ | 2883/3487 [8:13:24<2:15:34, 13.47s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2253.44 ms /     9 tokens (  250.38 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.88 ms /     3 runs   (  895.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4942.90 ms /    12 tokens\n",
      " 83%|โโโโโโโโโ | 2884/3487 [8:13:29<1:49:40, 10.91s/it]Llama.generate: 307 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13058.85 ms /    66 tokens (  197.86 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.83 ms /     3 runs   (  883.28 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15711.08 ms /    69 tokens\n",
      " 83%|โโโโโโโโโ | 2885/3487 [8:13:45<2:03:57, 12.36s/it]Llama.generate: 306 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13511.65 ms /    68 tokens (  198.70 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2718.42 ms /     3 runs   (  906.14 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   16231.98 ms /    71 tokens\n",
      " 83%|โโโโโโโโโ | 2886/3487 [8:14:01<2:15:26, 13.52s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12031.50 ms /    62 tokens (  194.06 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.49 ms /     3 runs   (  893.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14715.11 ms /    65 tokens\n",
      " 83%|โโโโโโโโโ | 2887/3487 [8:14:16<2:18:49, 13.88s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8474.57 ms /    43 tokens (  197.08 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.64 ms /     3 runs   (  886.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11136.91 ms /    46 tokens\n",
      " 83%|โโโโโโโโโ | 2888/3487 [8:14:27<2:10:23, 13.06s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2204.21 ms /     9 tokens (  244.91 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.55 ms /     3 runs   (  897.18 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4898.17 ms /    12 tokens\n",
      " 83%|โโโโโโโโโ | 2889/3487 [8:14:32<1:45:47, 10.61s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3815.77 ms /    18 tokens (  211.99 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.63 ms /     3 runs   (  886.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6479.72 ms /    21 tokens\n",
      " 83%|โโโโโโโโโ | 2890/3487 [8:14:39<1:33:17,  9.38s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7897.71 ms /    37 tokens (  213.45 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.36 ms /     3 runs   (  885.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10555.47 ms /    40 tokens\n",
      " 83%|โโโโโโโโโ | 2891/3487 [8:14:49<1:36:41,  9.73s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3835.13 ms /    18 tokens (  213.06 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.06 ms /     3 runs   (  890.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6507.51 ms /    21 tokens\n",
      " 83%|โโโโโโโโโ | 2892/3487 [8:14:56<1:26:57,  8.77s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3736.22 ms /    15 tokens (  249.08 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.02 ms /     3 runs   (  900.34 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6439.86 ms /    18 tokens\n",
      " 83%|โโโโโโโโโ | 2893/3487 [8:15:02<1:19:55,  8.07s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3779.25 ms /    18 tokens (  209.96 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.22 ms /     3 runs   (  901.41 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6486.00 ms /    21 tokens\n",
      " 83%|โโโโโโโโโ | 2894/3487 [8:15:09<1:15:06,  7.60s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5666.10 ms /    28 tokens (  202.36 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.57 ms /     3 runs   (  894.19 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8351.08 ms /    31 tokens\n",
      " 83%|โโโโโโโโโ | 2895/3487 [8:15:17<1:17:13,  7.83s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4127.09 ms /    19 tokens (  217.22 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2876.61 ms /     3 runs   (  958.87 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    7006.36 ms /    22 tokens\n",
      " 83%|โโโโโโโโโ | 2896/3487 [8:15:24<1:14:41,  7.58s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5454.10 ms /    26 tokens (  209.77 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.28 ms /     3 runs   (  889.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8124.32 ms /    29 tokens\n",
      " 83%|โโโโโโโโโ | 2897/3487 [8:15:32<1:16:11,  7.75s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13183.29 ms /    65 tokens (  202.82 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.69 ms /     3 runs   (  886.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15845.92 ms /    68 tokens\n",
      " 83%|โโโโโโโโโ | 2898/3487 [8:15:48<1:39:55, 10.18s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2631.04 ms /    11 tokens (  239.19 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.86 ms /     3 runs   (  894.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5317.63 ms /    14 tokens\n",
      " 83%|โโโโโโโโโ | 2899/3487 [8:15:53<1:25:29,  8.72s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8555.54 ms /    39 tokens (  219.37 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.49 ms /     3 runs   (  885.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11213.27 ms /    42 tokens\n",
      " 83%|โโโโโโโโโ | 2900/3487 [8:16:05<1:32:40,  9.47s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11242.72 ms /    59 tokens (  190.55 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.35 ms /     3 runs   (  891.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13919.12 ms /    62 tokens\n",
      " 83%|โโโโโโโโโ | 2901/3487 [8:16:19<1:45:33, 10.81s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2754.22 ms /    12 tokens (  229.52 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.03 ms /     3 runs   (  896.34 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5445.45 ms /    15 tokens\n",
      " 83%|โโโโโโโโโ | 2902/3487 [8:16:24<1:29:43,  9.20s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3134.35 ms /    14 tokens (  223.88 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.45 ms /     3 runs   (  888.49 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5802.02 ms /    17 tokens\n",
      " 83%|โโโโโโโโโ | 2903/3487 [8:16:30<1:19:40,  8.19s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3021.70 ms /    13 tokens (  232.44 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.18 ms /     3 runs   (  899.06 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5720.99 ms /    16 tokens\n",
      " 83%|โโโโโโโโโ | 2904/3487 [8:16:36<1:12:22,  7.45s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7212.35 ms /    33 tokens (  218.56 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.72 ms /     3 runs   (  881.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9859.78 ms /    36 tokens\n",
      " 83%|โโโโโโโโโ | 2905/3487 [8:16:45<1:19:17,  8.17s/it]Llama.generate: 308 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10895.13 ms /    57 tokens (  191.14 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.78 ms /     3 runs   (  891.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13572.68 ms /    60 tokens\n",
      " 83%|โโโโโโโโโ | 2906/3487 [8:16:59<1:34:51,  9.80s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3059.93 ms /    13 tokens (  235.38 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.82 ms /     3 runs   (  897.27 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5754.17 ms /    16 tokens\n",
      " 83%|โโโโโโโโโ | 2907/3487 [8:17:05<1:22:59,  8.59s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4668.16 ms /    20 tokens (  233.41 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.37 ms /     3 runs   (  884.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7325.04 ms /    23 tokens\n",
      " 83%|โโโโโโโโโ | 2908/3487 [8:17:12<1:19:13,  8.21s/it]Llama.generate: 306 prefix-match hit, remaining 99 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19610.42 ms /    99 tokens (  198.09 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.97 ms /     3 runs   (  908.32 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   22340.39 ms /   102 tokens\n",
      " 83%|โโโโโโโโโ | 2909/3487 [8:17:34<1:59:57, 12.45s/it]Llama.generate: 309 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8154.84 ms /    39 tokens (  209.10 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.62 ms /     3 runs   (  886.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10817.09 ms /    42 tokens\n",
      " 83%|โโโโโโโโโ | 2910/3487 [8:17:45<1:55:03, 11.96s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8993.71 ms /    45 tokens (  199.86 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.03 ms /     3 runs   (  885.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11652.34 ms /    48 tokens\n",
      " 83%|โโโโโโโโโ | 2911/3487 [8:17:57<1:53:59, 11.87s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5691.69 ms /    28 tokens (  203.27 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.39 ms /     3 runs   (  896.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8383.67 ms /    31 tokens\n",
      " 84%|โโโโโโโโโ | 2912/3487 [8:18:05<1:43:47, 10.83s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7202.41 ms /    33 tokens (  218.25 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.50 ms /     3 runs   (  884.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9859.95 ms /    36 tokens\n",
      " 84%|โโโโโโโโโ | 2913/3487 [8:18:15<1:40:50, 10.54s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3538.59 ms /    16 tokens (  221.16 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.98 ms /     3 runs   (  884.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6195.57 ms /    19 tokens\n",
      " 84%|โโโโโโโโโ | 2914/3487 [8:18:21<1:28:14,  9.24s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5043.41 ms /    23 tokens (  219.28 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.10 ms /     3 runs   (  890.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7717.29 ms /    26 tokens\n",
      " 84%|โโโโโโโโโ | 2915/3487 [8:18:29<1:23:45,  8.79s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2321.99 ms /     9 tokens (  258.00 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.88 ms /     3 runs   (  895.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5010.65 ms /    12 tokens\n",
      " 84%|โโโโโโโโโ | 2916/3487 [8:18:34<1:12:51,  7.66s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3247.47 ms /    15 tokens (  216.50 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.34 ms /     3 runs   (  895.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5937.30 ms /    18 tokens\n",
      " 84%|โโโโโโโโโ | 2917/3487 [8:18:40<1:07:51,  7.14s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4680.17 ms /    22 tokens (  212.74 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.78 ms /     3 runs   (  885.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7339.53 ms /    25 tokens\n",
      " 84%|โโโโโโโโโ | 2918/3487 [8:18:47<1:08:19,  7.20s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2444.43 ms /    10 tokens (  244.44 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.24 ms /     3 runs   (  885.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5103.96 ms /    13 tokens\n",
      " 84%|โโโโโโโโโ | 2919/3487 [8:18:53<1:02:15,  6.58s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4259.74 ms /    20 tokens (  212.99 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2783.10 ms /     3 runs   (  927.70 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7045.62 ms /    23 tokens\n",
      " 84%|โโโโโโโโโ | 2920/3487 [8:19:00<1:03:30,  6.72s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4378.61 ms /    20 tokens (  218.93 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.86 ms /     3 runs   (  894.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7064.23 ms /    23 tokens\n",
      " 84%|โโโโโโโโโ | 2921/3487 [8:19:07<1:04:23,  6.83s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5045.31 ms /    24 tokens (  210.22 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2751.32 ms /     3 runs   (  917.11 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7800.07 ms /    27 tokens\n",
      " 84%|โโโโโโโโโ | 2922/3487 [8:19:14<1:07:03,  7.12s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2983.90 ms /    10 tokens (  298.39 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.27 ms /     3 runs   (  887.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5648.50 ms /    13 tokens\n",
      " 84%|โโโโโโโโโ | 2923/3487 [8:19:20<1:02:48,  6.68s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3851.90 ms /    17 tokens (  226.58 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.43 ms /     3 runs   (  898.14 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6548.96 ms /    20 tokens\n",
      " 84%|โโโโโโโโโ | 2924/3487 [8:19:27<1:02:20,  6.64s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2103.75 ms /     7 tokens (  300.54 ms per token,     3.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.88 ms /     3 runs   (  894.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4790.94 ms /    10 tokens\n",
      " 84%|โโโโโโโโโ | 2925/3487 [8:19:31<57:03,  6.09s/it]  Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3621.79 ms /    16 tokens (  226.36 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.14 ms /     3 runs   (  890.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6295.48 ms /    19 tokens\n",
      " 84%|โโโโโโโโโ | 2926/3487 [8:19:38<57:32,  6.15s/it]Llama.generate: 312 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2027.64 ms /     7 tokens (  289.66 ms per token,     3.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.44 ms /     3 runs   (  900.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4730.53 ms /    10 tokens\n",
      " 84%|โโโโโโโโโ | 2927/3487 [8:19:43<53:28,  5.73s/it]Llama.generate: 312 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2525.41 ms /    10 tokens (  252.54 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.63 ms /     3 runs   (  885.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5185.46 ms /    13 tokens\n",
      " 84%|โโโโโโโโโ | 2928/3487 [8:19:48<51:53,  5.57s/it]Llama.generate: 312 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4360.26 ms /    20 tokens (  218.01 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.53 ms /     3 runs   (  891.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7037.17 ms /    23 tokens\n",
      " 84%|โโโโโโโโโ | 2929/3487 [8:19:55<55:54,  6.01s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13152.01 ms /    65 tokens (  202.34 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.73 ms /     3 runs   (  883.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15804.97 ms /    68 tokens\n",
      " 84%|โโโโโโโโโ | 2930/3487 [8:20:11<1:23:06,  8.95s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8294.40 ms /    39 tokens (  212.68 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.00 ms /     3 runs   (  887.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10958.08 ms /    42 tokens\n",
      " 84%|โโโโโโโโโ | 2931/3487 [8:20:22<1:28:33,  9.56s/it]Llama.generate: 306 prefix-match hit, remaining 88 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16457.35 ms /    88 tokens (  187.02 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2758.56 ms /     3 runs   (  919.52 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   19218.23 ms /    91 tokens\n",
      " 84%|โโโโโโโโโ | 2932/3487 [8:20:41<1:55:14, 12.46s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7342.37 ms /    34 tokens (  215.95 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2855.26 ms /     3 runs   (  951.75 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   10200.27 ms /    37 tokens\n",
      " 84%|โโโโโโโโโ | 2933/3487 [8:20:51<1:48:47, 11.78s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7659.77 ms /    38 tokens (  201.57 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2965.51 ms /     3 runs   (  988.50 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   10628.14 ms /    41 tokens\n",
      " 84%|โโโโโโโโโ | 2934/3487 [8:21:02<1:45:25, 11.44s/it]Llama.generate: 306 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13738.26 ms /    72 tokens (  190.81 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.05 ms /     3 runs   (  894.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16422.46 ms /    75 tokens\n",
      " 84%|โโโโโโโโโ | 2935/3487 [8:21:18<1:59:00, 12.94s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3633.48 ms /    16 tokens (  227.09 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.17 ms /     3 runs   (  886.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6296.11 ms /    19 tokens\n",
      " 84%|โโโโโโโโโ | 2936/3487 [8:21:24<1:40:31, 10.95s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5676.64 ms /    28 tokens (  202.74 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.51 ms /     3 runs   (  885.17 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8334.73 ms /    31 tokens\n",
      " 84%|โโโโโโโโโ | 2937/3487 [8:21:33<1:33:11, 10.17s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2774.29 ms /    12 tokens (  231.19 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.05 ms /     3 runs   (  895.68 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5464.42 ms /    15 tokens\n",
      " 84%|โโโโโโโโโ | 2938/3487 [8:21:38<1:20:07,  8.76s/it]Llama.generate: 312 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3832.04 ms /    15 tokens (  255.47 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.05 ms /     3 runs   (  880.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6475.08 ms /    18 tokens\n",
      " 84%|โโโโโโโโโ | 2939/3487 [8:21:45<1:13:45,  8.08s/it]Llama.generate: 311 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2146.38 ms /     8 tokens (  268.30 ms per token,     3.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.56 ms /     3 runs   (  887.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4811.61 ms /    11 tokens\n",
      " 84%|โโโโโโโโโ | 2940/3487 [8:21:49<1:04:43,  7.10s/it]Llama.generate: 311 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2736.70 ms /    11 tokens (  248.79 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2833.02 ms /     3 runs   (  944.34 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5572.25 ms /    14 tokens\n",
      " 84%|โโโโโโโโโ | 2941/3487 [8:21:55<1:00:27,  6.64s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4769.59 ms /    22 tokens (  216.80 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.57 ms /     3 runs   (  902.52 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7479.45 ms /    25 tokens\n",
      " 84%|โโโโโโโโโ | 2942/3487 [8:22:03<1:02:38,  6.90s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8174.02 ms /    41 tokens (  199.37 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.12 ms /     3 runs   (  883.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10827.59 ms /    44 tokens\n",
      " 84%|โโโโโโโโโ | 2943/3487 [8:22:13<1:13:14,  8.08s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2531.17 ms /    10 tokens (  253.12 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2797.13 ms /     3 runs   (  932.38 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5330.96 ms /    13 tokens\n",
      " 84%|โโโโโโโโโ | 2944/3487 [8:22:19<1:05:40,  7.26s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2993.13 ms /    12 tokens (  249.43 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.69 ms /     3 runs   (  886.23 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5654.77 ms /    15 tokens\n",
      " 84%|โโโโโโโโโ | 2945/3487 [8:22:24<1:01:14,  6.78s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2602.04 ms /    10 tokens (  260.20 ms per token,     3.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.02 ms /     3 runs   (  887.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5266.72 ms /    13 tokens\n",
      " 84%|โโโโโโโโโ | 2946/3487 [8:22:30<57:03,  6.33s/it]  Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3583.04 ms /    13 tokens (  275.62 ms per token,     3.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.16 ms /     3 runs   (  883.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6236.09 ms /    16 tokens\n",
      " 85%|โโโโโโโโโ | 2947/3487 [8:22:36<56:43,  6.30s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2262.16 ms /     9 tokens (  251.35 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.04 ms /     3 runs   (  888.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4929.78 ms /    12 tokens\n",
      " 85%|โโโโโโโโโ | 2948/3487 [8:22:41<52:56,  5.89s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5628.92 ms /    27 tokens (  208.48 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.60 ms /     3 runs   (  883.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8281.21 ms /    30 tokens\n",
      " 85%|โโโโโโโโโ | 2949/3487 [8:22:49<59:17,  6.61s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2566.83 ms /    10 tokens (  256.68 ms per token,     3.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.75 ms /     3 runs   (  895.92 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5257.43 ms /    13 tokens\n",
      " 85%|โโโโโโโโโ | 2950/3487 [8:22:54<55:34,  6.21s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9531.93 ms /    48 tokens (  198.58 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.32 ms /     3 runs   (  879.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12173.59 ms /    51 tokens\n",
      " 85%|โโโโโโโโโ | 2951/3487 [8:23:07<1:11:28,  8.00s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9101.25 ms /    46 tokens (  197.85 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.08 ms /     3 runs   (  878.36 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11739.97 ms /    49 tokens\n",
      " 85%|โโโโโโโโโ | 2952/3487 [8:23:18<1:21:21,  9.12s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3574.38 ms /    16 tokens (  223.40 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.98 ms /     3 runs   (  885.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6234.42 ms /    19 tokens\n",
      " 85%|โโโโโโโโโ | 2953/3487 [8:23:25<1:13:31,  8.26s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4306.50 ms /    21 tokens (  205.07 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.60 ms /     3 runs   (  883.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6958.34 ms /    24 tokens\n",
      " 85%|โโโโโโโโโ | 2954/3487 [8:23:32<1:09:55,  7.87s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7593.25 ms /    33 tokens (  230.10 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.62 ms /     3 runs   (  888.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10260.59 ms /    36 tokens\n",
      " 85%|โโโโโโโโโ | 2955/3487 [8:23:42<1:16:10,  8.59s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2246.81 ms /     9 tokens (  249.65 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.05 ms /     3 runs   (  882.68 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4897.70 ms /    12 tokens\n",
      " 85%|โโโโโโโโโ | 2956/3487 [8:23:47<1:06:14,  7.49s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4627.43 ms /    22 tokens (  210.34 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.13 ms /     3 runs   (  880.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7271.37 ms /    25 tokens\n",
      " 85%|โโโโโโโโโ | 2957/3487 [8:23:54<1:05:34,  7.42s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4166.80 ms /    19 tokens (  219.31 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.89 ms /     3 runs   (  898.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6866.07 ms /    22 tokens\n",
      " 85%|โโโโโโโโโ | 2958/3487 [8:24:01<1:03:59,  7.26s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4460.39 ms /    21 tokens (  212.40 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2751.18 ms /     3 runs   (  917.06 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7214.08 ms /    24 tokens\n",
      " 85%|โโโโโโโโโ | 2959/3487 [8:24:08<1:03:46,  7.25s/it]Llama.generate: 306 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19514.29 ms /   103 tokens (  189.46 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.45 ms /     3 runs   (  896.82 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   22207.08 ms /   106 tokens\n",
      " 85%|โโโโโโโโโ | 2960/3487 [8:24:30<1:43:06, 11.74s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7329.07 ms /    35 tokens (  209.40 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2873.03 ms /     3 runs   (  957.68 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   10204.95 ms /    38 tokens\n",
      " 85%|โโโโโโโโโ | 2961/3487 [8:24:40<1:38:53, 11.28s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3389.31 ms /    13 tokens (  260.72 ms per token,     3.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.24 ms /     3 runs   (  895.75 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6079.64 ms /    16 tokens\n",
      " 85%|โโโโโโโโโ | 2962/3487 [8:24:47<1:25:05,  9.72s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4932.06 ms /    22 tokens (  224.18 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.18 ms /     3 runs   (  887.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7596.02 ms /    25 tokens\n",
      " 85%|โโโโโโโโโ | 2963/3487 [8:24:54<1:19:22,  9.09s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10940.84 ms /    56 tokens (  195.37 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.75 ms /     3 runs   (  881.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13587.34 ms /    59 tokens\n",
      " 85%|โโโโโโโโโ | 2964/3487 [8:25:08<1:31:00, 10.44s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10767.08 ms /    56 tokens (  192.27 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.84 ms /     3 runs   (  881.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13417.07 ms /    59 tokens\n",
      " 85%|โโโโโโโโโ | 2965/3487 [8:25:21<1:38:38, 11.34s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4321.95 ms /    21 tokens (  205.81 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.10 ms /     3 runs   (  894.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7008.66 ms /    24 tokens\n",
      " 85%|โโโโโโโโโ | 2966/3487 [8:25:28<1:27:11, 10.04s/it]Llama.generate: 314 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1392.93 ms /     4 tokens (  348.23 ms per token,     2.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2859.75 ms /     3 runs   (  953.25 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4255.38 ms /     7 tokens\n",
      " 85%|โโโโโโโโโ | 2967/3487 [8:25:32<1:11:59,  8.31s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8831.61 ms /    43 tokens (  205.39 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2810.12 ms /     3 runs   (  936.71 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   11644.37 ms /    46 tokens\n",
      " 85%|โโโโโโโโโ | 2968/3487 [8:25:44<1:20:33,  9.31s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3394.70 ms /    15 tokens (  226.31 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.70 ms /     3 runs   (  903.23 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6106.79 ms /    18 tokens\n",
      " 85%|โโโโโโโโโ | 2969/3487 [8:25:50<1:12:06,  8.35s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4986.10 ms /    24 tokens (  207.75 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.37 ms /     3 runs   (  894.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7671.32 ms /    27 tokens\n",
      " 85%|โโโโโโโโโ | 2970/3487 [8:25:58<1:10:14,  8.15s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2719.23 ms /    11 tokens (  247.20 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.13 ms /     3 runs   (  900.71 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5423.91 ms /    14 tokens\n",
      " 85%|โโโโโโโโโ | 2971/3487 [8:26:03<1:03:05,  7.34s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4957.35 ms /    24 tokens (  206.56 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2748.14 ms /     3 runs   (  916.05 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7707.48 ms /    27 tokens\n",
      " 85%|โโโโโโโโโ | 2972/3487 [8:26:11<1:03:57,  7.45s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2842.84 ms /    11 tokens (  258.44 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.22 ms /     3 runs   (  880.41 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5488.32 ms /    14 tokens\n",
      " 85%|โโโโโโโโโ | 2973/3487 [8:26:17<58:48,  6.87s/it]  Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7567.94 ms /    36 tokens (  210.22 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2759.82 ms /     3 runs   (  919.94 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10330.15 ms /    39 tokens\n",
      " 85%|โโโโโโโโโ | 2974/3487 [8:26:27<1:07:36,  7.91s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4562.10 ms /    20 tokens (  228.10 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.66 ms /     3 runs   (  890.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7235.39 ms /    23 tokens\n",
      " 85%|โโโโโโโโโ | 2975/3487 [8:26:34<1:05:46,  7.71s/it]Llama.generate: 313 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3278.06 ms /    14 tokens (  234.15 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.69 ms /     3 runs   (  897.56 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5973.91 ms /    17 tokens\n",
      " 85%|โโโโโโโโโ | 2976/3487 [8:26:40<1:01:14,  7.19s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8190.44 ms /    41 tokens (  199.77 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.41 ms /     3 runs   (  880.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10834.04 ms /    44 tokens\n",
      " 85%|โโโโโโโโโ | 2977/3487 [8:26:51<1:10:26,  8.29s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2657.93 ms /    11 tokens (  241.63 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.98 ms /     3 runs   (  892.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5339.70 ms /    14 tokens\n",
      " 85%|โโโโโโโโโ | 2978/3487 [8:26:56<1:02:49,  7.41s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2849.83 ms /    12 tokens (  237.49 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.88 ms /     3 runs   (  898.29 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5546.94 ms /    15 tokens\n",
      " 85%|โโโโโโโโโ | 2979/3487 [8:27:02<57:59,  6.85s/it]  Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2817.56 ms /    12 tokens (  234.80 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.76 ms /     3 runs   (  899.25 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5518.39 ms /    15 tokens\n",
      " 85%|โโโโโโโโโ | 2980/3487 [8:27:07<54:32,  6.45s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4146.14 ms /    19 tokens (  218.22 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.53 ms /     3 runs   (  887.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6812.24 ms /    22 tokens\n",
      " 85%|โโโโโโโโโ | 2981/3487 [8:27:14<55:21,  6.56s/it]Llama.generate: 307 prefix-match hit, remaining 226 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   42699.75 ms /   226 tokens (  188.94 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.47 ms /     3 runs   (  886.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   45363.03 ms /   229 tokens\n",
      " 86%|โโโโโโโโโ | 2982/3487 [8:28:00<2:33:13, 18.21s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5236.43 ms /    24 tokens (  218.18 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.24 ms /     3 runs   (  888.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7904.23 ms /    27 tokens\n",
      " 86%|โโโโโโโโโ | 2983/3487 [8:28:08<2:06:59, 15.12s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2186.51 ms /     8 tokens (  273.31 ms per token,     3.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.27 ms /     3 runs   (  890.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4859.13 ms /    11 tokens\n",
      " 86%|โโโโโโโโโ | 2984/3487 [8:28:12<1:40:57, 12.04s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8401.81 ms /    43 tokens (  195.39 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2818.68 ms /     3 runs   (  939.56 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   11223.05 ms /    46 tokens\n",
      " 86%|โโโโโโโโโ | 2985/3487 [8:28:24<1:38:43, 11.80s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2273.02 ms /     9 tokens (  252.56 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.60 ms /     3 runs   (  898.20 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4970.32 ms /    12 tokens\n",
      " 86%|โโโโโโโโโ | 2986/3487 [8:28:29<1:21:26,  9.75s/it]Llama.generate: 312 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2716.22 ms /    11 tokens (  246.93 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.71 ms /     3 runs   (  885.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5373.97 ms /    14 tokens\n",
      " 86%|โโโโโโโโโ | 2987/3487 [8:28:34<1:10:20,  8.44s/it]Llama.generate: 307 prefix-match hit, remaining 153 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28399.33 ms /   153 tokens (  185.62 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.65 ms /     3 runs   (  881.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   31048.30 ms /   156 tokens\n",
      " 86%|โโโโโโโโโ | 2988/3487 [8:29:05<2:06:37, 15.23s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11156.76 ms /    59 tokens (  189.10 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.47 ms /     3 runs   (  885.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13814.46 ms /    62 tokens\n",
      " 86%|โโโโโโโโโ | 2989/3487 [8:29:19<2:02:52, 14.80s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6173.63 ms /    31 tokens (  199.15 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.70 ms /     3 runs   (  888.23 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8840.88 ms /    34 tokens\n",
      " 86%|โโโโโโโโโ | 2990/3487 [8:29:28<1:47:50, 13.02s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4661.24 ms /    20 tokens (  233.06 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.20 ms /     3 runs   (  890.73 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7335.96 ms /    23 tokens\n",
      " 86%|โโโโโโโโโ | 2991/3487 [8:29:35<1:33:32, 11.32s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5285.13 ms /    26 tokens (  203.27 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.04 ms /     3 runs   (  888.01 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7951.42 ms /    29 tokens\n",
      " 86%|โโโโโโโโโ | 2992/3487 [8:29:43<1:25:02, 10.31s/it]Llama.generate: 306 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11607.07 ms /    61 tokens (  190.28 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.97 ms /     3 runs   (  881.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14256.34 ms /    64 tokens\n",
      " 86%|โโโโโโโโโ | 2993/3487 [8:29:57<1:34:38, 11.50s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9969.77 ms /    52 tokens (  191.73 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.61 ms /     3 runs   (  888.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12638.48 ms /    55 tokens\n",
      " 86%|โโโโโโโโโ | 2994/3487 [8:30:10<1:37:17, 11.84s/it]Llama.generate: 317 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13218.00 ms /    69 tokens (  191.57 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.05 ms /     3 runs   (  877.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15852.82 ms /    72 tokens\n",
      " 86%|โโโโโโโโโ | 2995/3487 [8:30:26<1:46:59, 13.05s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4297.49 ms /    21 tokens (  204.64 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.07 ms /     3 runs   (  880.69 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6942.83 ms /    24 tokens\n",
      " 86%|โโโโโโโโโ | 2996/3487 [8:30:33<1:31:48, 11.22s/it]Llama.generate: 312 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1389.69 ms /     4 tokens (  347.42 ms per token,     2.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2808.30 ms /     3 runs   (  936.10 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4200.19 ms /     7 tokens\n",
      " 86%|โโโโโโโโโ | 2997/3487 [8:30:37<1:14:26,  9.12s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4563.11 ms /    19 tokens (  240.16 ms per token,     4.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.05 ms /     3 runs   (  891.35 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7239.62 ms /    22 tokens\n",
      " 86%|โโโโโโโโโ | 2998/3487 [8:30:44<1:09:43,  8.55s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4280.58 ms /    20 tokens (  214.03 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.52 ms /     3 runs   (  899.51 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6981.87 ms /    23 tokens\n",
      " 86%|โโโโโโโโโ | 2999/3487 [8:30:51<1:05:45,  8.09s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2272.84 ms /     9 tokens (  252.54 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.48 ms /     3 runs   (  892.49 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4953.10 ms /    12 tokens\n",
      " 86%|โโโโโโโโโ | 3000/3487 [8:30:56<58:01,  7.15s/it]  Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7332.21 ms /    33 tokens (  222.19 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.53 ms /     3 runs   (  886.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9994.02 ms /    36 tokens\n",
      " 86%|โโโโโโโโโ | 3001/3487 [8:31:06<1:04:50,  8.00s/it]Llama.generate: 313 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3580.18 ms /    16 tokens (  223.76 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.62 ms /     3 runs   (  890.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6255.57 ms /    19 tokens\n",
      " 86%|โโโโโโโโโ | 3002/3487 [8:31:12<1:00:28,  7.48s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2498.59 ms /     9 tokens (  277.62 ms per token,     3.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3625.16 ms /     4 runs   (  906.29 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6157.39 ms /    13 tokens\n",
      " 86%|โโโโโโโโโ | 3003/3487 [8:31:19<57:10,  7.09s/it]  Llama.generate: 312 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2849.66 ms /    12 tokens (  237.47 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.95 ms /     3 runs   (  889.32 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5520.22 ms /    15 tokens\n",
      " 86%|โโโโโโโโโ | 3004/3487 [8:31:24<53:17,  6.62s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5535.53 ms /    25 tokens (  221.42 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.93 ms /     3 runs   (  885.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8196.40 ms /    28 tokens\n",
      " 86%|โโโโโโโโโ | 3005/3487 [8:31:32<57:00,  7.10s/it]Llama.generate: 306 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16809.99 ms /    90 tokens (  186.78 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.64 ms /     3 runs   (  879.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19450.18 ms /    93 tokens\n",
      " 86%|โโโโโโโโโ | 3006/3487 [8:31:52<1:26:37, 10.80s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4353.97 ms /    20 tokens (  217.70 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.90 ms /     3 runs   (  880.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6999.20 ms /    23 tokens\n",
      " 86%|โโโโโโโโโ | 3007/3487 [8:31:59<1:17:19,  9.67s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12530.47 ms /    37 tokens (  338.66 ms per token,     2.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3041.17 ms /     3 runs   ( 1013.72 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   15574.57 ms /    40 tokens\n",
      " 86%|โโโโโโโโโ | 3008/3487 [8:32:14<1:31:20, 11.44s/it]Llama.generate: 306 prefix-match hit, remaining 136 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26606.59 ms /   136 tokens (  195.64 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.17 ms /     3 runs   (  881.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   29254.32 ms /   139 tokens\n",
      " 86%|โโโโโโโโโ | 3009/3487 [8:32:44<2:13:44, 16.79s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3313.22 ms /    15 tokens (  220.88 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2748.10 ms /     3 runs   (  916.03 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6063.96 ms /    18 tokens\n",
      " 86%|โโโโโโโโโ | 3010/3487 [8:32:50<1:47:54, 13.57s/it]Llama.generate: 307 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14846.35 ms /    74 tokens (  200.63 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.91 ms /     3 runs   (  910.64 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   17581.04 ms /    77 tokens\n",
      " 86%|โโโโโโโโโ | 3011/3487 [8:33:07<1:57:14, 14.78s/it]Llama.generate: 307 prefix-match hit, remaining 92 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21240.00 ms /    92 tokens (  230.87 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2976.94 ms /     3 runs   (  992.31 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   24219.51 ms /    95 tokens\n",
      " 86%|โโโโโโโโโ | 3012/3487 [8:33:32<2:19:26, 17.61s/it]Llama.generate: 306 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10805.06 ms /    55 tokens (  196.46 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.35 ms /     3 runs   (  882.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13456.01 ms /    58 tokens\n",
      " 86%|โโโโโโโโโ | 3013/3487 [8:33:45<2:09:18, 16.37s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5754.17 ms /    29 tokens (  198.42 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.05 ms /     3 runs   (  890.68 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8428.30 ms /    32 tokens\n",
      " 86%|โโโโโโโโโ | 3014/3487 [8:33:53<1:50:16, 13.99s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4539.48 ms /    21 tokens (  216.17 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.83 ms /     3 runs   (  902.28 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7248.63 ms /    24 tokens\n",
      " 86%|โโโโโโโโโ | 3015/3487 [8:34:01<1:34:09, 11.97s/it]Llama.generate: 306 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16725.68 ms /    82 tokens (  203.97 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.21 ms /     3 runs   (  913.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   19468.16 ms /    85 tokens\n",
      " 86%|โโโโโโโโโ | 3016/3487 [8:34:20<1:51:38, 14.22s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7050.40 ms /    32 tokens (  220.33 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.54 ms /     3 runs   (  905.85 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    9770.65 ms /    35 tokens\n",
      " 87%|โโโโโโโโโ | 3017/3487 [8:34:30<1:40:57, 12.89s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8351.55 ms /    39 tokens (  214.14 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.31 ms /     3 runs   (  900.77 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11056.99 ms /    42 tokens\n",
      " 87%|โโโโโโโโโ | 3018/3487 [8:34:41<1:36:28, 12.34s/it]Llama.generate: 310 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7383.64 ms /    34 tokens (  217.17 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.42 ms /     3 runs   (  889.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10053.79 ms /    37 tokens\n",
      " 87%|โโโโโโโโโ | 3019/3487 [8:34:51<1:30:55, 11.66s/it]Llama.generate: 310 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7880.17 ms /    36 tokens (  218.89 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.15 ms /     3 runs   (  889.72 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10551.62 ms /    39 tokens\n",
      " 87%|โโโโโโโโโ | 3020/3487 [8:35:02<1:28:10, 11.33s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2104.01 ms /     7 tokens (  300.57 ms per token,     3.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.07 ms /     3 runs   (  884.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4758.94 ms /    10 tokens\n",
      " 87%|โโโโโโโโโ | 3021/3487 [8:35:06<1:12:41,  9.36s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3692.28 ms /    16 tokens (  230.77 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.64 ms /     3 runs   (  894.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6378.41 ms /    19 tokens\n",
      " 87%|โโโโโโโโโ | 3022/3487 [8:35:13<1:05:37,  8.47s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3177.70 ms /    14 tokens (  226.98 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2742.44 ms /     3 runs   (  914.15 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5922.85 ms /    17 tokens\n",
      " 87%|โโโโโโโโโ | 3023/3487 [8:35:19<59:36,  7.71s/it]  Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11548.22 ms /    57 tokens (  202.60 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2875.04 ms /     3 runs   (  958.35 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   14425.77 ms /    60 tokens\n",
      " 87%|โโโโโโโโโ | 3024/3487 [8:35:33<1:15:03,  9.73s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14226.65 ms /    72 tokens (  197.59 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.60 ms /     3 runs   (  884.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16881.79 ms /    75 tokens\n",
      " 87%|โโโโโโโโโ | 3025/3487 [8:35:50<1:31:26, 11.88s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7702.35 ms /    36 tokens (  213.95 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.34 ms /     3 runs   (  885.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10360.80 ms /    39 tokens\n",
      " 87%|โโโโโโโโโ | 3026/3487 [8:36:00<1:27:46, 11.42s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6223.82 ms /    29 tokens (  214.61 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.18 ms /     3 runs   (  887.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8889.08 ms /    32 tokens\n",
      " 87%|โโโโโโโโโ | 3027/3487 [8:36:09<1:21:46, 10.67s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2271.13 ms /     9 tokens (  252.35 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.71 ms /     3 runs   (  900.57 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4975.78 ms /    12 tokens\n",
      " 87%|โโโโโโโโโ | 3028/3487 [8:36:14<1:08:32,  8.96s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3679.46 ms /    15 tokens (  245.30 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.89 ms /     3 runs   (  880.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6324.68 ms /    18 tokens\n",
      " 87%|โโโโโโโโโ | 3029/3487 [8:36:21<1:02:22,  8.17s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2680.72 ms /    11 tokens (  243.70 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.66 ms /     3 runs   (  886.89 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5343.70 ms /    14 tokens\n",
      " 87%|โโโโโโโโโ | 3030/3487 [8:36:26<55:48,  7.33s/it]  Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2295.30 ms /     9 tokens (  255.03 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2887.44 ms /     3 runs   (  962.48 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    5185.42 ms /    12 tokens\n",
      " 87%|โโโโโโโโโ | 3031/3487 [8:36:31<50:48,  6.69s/it]Llama.generate: 311 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2656.92 ms /    10 tokens (  265.69 ms per token,     3.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3133.26 ms /     3 runs   ( 1044.42 ms per token,     0.96 tokens per second)\n",
      "llama_perf_context_print:       total time =    5793.04 ms /    13 tokens\n",
      " 87%|โโโโโโโโโ | 3032/3487 [8:36:37<48:41,  6.42s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3276.04 ms /    13 tokens (  252.00 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.08 ms /     3 runs   (  878.36 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5913.70 ms /    16 tokens\n",
      " 87%|โโโโโโโโโ | 3033/3487 [8:36:43<47:27,  6.27s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3214.65 ms /    15 tokens (  214.31 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2789.43 ms /     3 runs   (  929.81 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6006.65 ms /    18 tokens\n",
      " 87%|โโโโโโโโโ | 3034/3487 [8:36:49<46:45,  6.19s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2648.58 ms /     7 tokens (  378.37 ms per token,     2.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.45 ms /     3 runs   (  890.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5321.74 ms /    10 tokens\n",
      " 87%|โโโโโโโโโ | 3035/3487 [8:36:54<44:42,  5.93s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2972.44 ms /    11 tokens (  270.22 ms per token,     3.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3081.95 ms /     3 runs   ( 1027.32 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    6057.49 ms /    14 tokens\n",
      " 87%|โโโโโโโโโ | 3036/3487 [8:37:00<44:54,  5.97s/it]Llama.generate: 316 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3993.08 ms /     4 runs   (  998.27 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    3995.35 ms /     5 tokens\n",
      " 87%|โโโโโโโโโ | 3037/3487 [8:37:04<40:22,  5.38s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3256.28 ms /    13 tokens (  250.48 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.64 ms /     3 runs   (  883.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5910.68 ms /    16 tokens\n",
      " 87%|โโโโโโโโโ | 3038/3487 [8:37:10<41:29,  5.54s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2250.84 ms /     9 tokens (  250.09 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.61 ms /     3 runs   (  886.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4913.97 ms /    12 tokens\n",
      " 87%|โโโโโโโโโ | 3039/3487 [8:37:15<40:00,  5.36s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2772.26 ms /    11 tokens (  252.02 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.35 ms /     3 runs   (  884.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5428.79 ms /    14 tokens\n",
      " 87%|โโโโโโโโโ | 3040/3487 [8:37:21<40:05,  5.38s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7338.94 ms /    35 tokens (  209.68 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.37 ms /     3 runs   (  887.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10003.14 ms /    38 tokens\n",
      " 87%|โโโโโโโโโ | 3041/3487 [8:37:31<50:19,  6.77s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7601.82 ms /    33 tokens (  230.36 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.13 ms /     3 runs   (  884.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10256.36 ms /    36 tokens\n",
      " 87%|โโโโโโโโโ | 3042/3487 [8:37:41<57:59,  7.82s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7882.29 ms /    39 tokens (  202.11 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.20 ms /     3 runs   (  877.07 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10516.52 ms /    42 tokens\n",
      " 87%|โโโโโโโโโ | 3043/3487 [8:37:51<1:03:52,  8.63s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6312.24 ms /    32 tokens (  197.26 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.51 ms /     3 runs   (  879.84 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8953.41 ms /    35 tokens\n",
      " 87%|โโโโโโโโโ | 3044/3487 [8:38:00<1:04:27,  8.73s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4870.92 ms /    22 tokens (  221.41 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.58 ms /     3 runs   (  878.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7507.86 ms /    25 tokens\n",
      " 87%|โโโโโโโโโ | 3045/3487 [8:38:08<1:01:37,  8.37s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4037.52 ms /    18 tokens (  224.31 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2733.09 ms /     3 runs   (  911.03 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6772.83 ms /    21 tokens\n",
      " 87%|โโโโโโโโโ | 3046/3487 [8:38:15<57:59,  7.89s/it]  Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10332.37 ms /    47 tokens (  219.84 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.78 ms /     3 runs   (  881.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12980.86 ms /    50 tokens\n",
      " 87%|โโโโโโโโโ | 3047/3487 [8:38:28<1:09:05,  9.42s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2324.91 ms /     9 tokens (  258.32 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.91 ms /     3 runs   (  896.30 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5016.49 ms /    12 tokens\n",
      " 87%|โโโโโโโโโ | 3048/3487 [8:38:33<59:16,  8.10s/it]  Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14719.26 ms /    42 tokens (  350.46 ms per token,     2.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14794.67 ms /     3 runs   ( 4931.56 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =   29521.34 ms /    45 tokens\n",
      " 87%|โโโโโโโโโ | 3049/3487 [8:39:02<1:46:06, 14.54s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10952.35 ms /    44 tokens (  248.92 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3453.36 ms /     3 runs   ( 1151.12 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =   14410.20 ms /    47 tokens\n",
      " 87%|โโโโโโโโโ | 3050/3487 [8:39:17<1:45:39, 14.51s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13420.36 ms /    48 tokens (  279.59 ms per token,     3.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3497.64 ms /     3 runs   ( 1165.88 ms per token,     0.86 tokens per second)\n",
      "llama_perf_context_print:       total time =   16920.96 ms /    51 tokens\n",
      " 87%|โโโโโโโโโ | 3051/3487 [8:39:34<1:50:42, 15.24s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3511.76 ms /    13 tokens (  270.14 ms per token,     3.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2974.16 ms /     3 runs   (  991.39 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    6489.47 ms /    16 tokens\n",
      " 88%|โโโโโโโโโ | 3052/3487 [8:39:40<1:31:27, 12.61s/it]Llama.generate: 307 prefix-match hit, remaining 95 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17958.62 ms /    95 tokens (  189.04 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.44 ms /     3 runs   (  881.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20605.38 ms /    98 tokens\n",
      " 88%|โโโโโโโโโ | 3053/3487 [8:40:01<1:48:36, 15.02s/it]Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11498.21 ms /    57 tokens (  201.72 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.58 ms /     3 runs   (  895.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14187.19 ms /    60 tokens\n",
      " 88%|โโโโโโโโโ | 3054/3487 [8:40:15<1:46:35, 14.77s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13530.22 ms /    64 tokens (  211.41 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2823.62 ms /     3 runs   (  941.21 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   16356.60 ms /    67 tokens\n",
      " 88%|โโโโโโโโโ | 3055/3487 [8:40:31<1:49:47, 15.25s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4958.80 ms /    23 tokens (  215.60 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2753.53 ms /     3 runs   (  917.84 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7715.19 ms /    26 tokens\n",
      " 88%|โโโโโโโโโ | 3056/3487 [8:40:39<1:33:19, 12.99s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3996.92 ms /    17 tokens (  235.11 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.91 ms /     3 runs   (  896.97 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6690.33 ms /    20 tokens\n",
      " 88%|โโโโโโโโโ | 3057/3487 [8:40:46<1:19:34, 11.10s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13560.91 ms /    65 tokens (  208.63 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.01 ms /     3 runs   (  886.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16220.93 ms /    68 tokens\n",
      " 88%|โโโโโโโโโ | 3058/3487 [8:41:02<1:30:23, 12.64s/it]Llama.generate: 312 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2270.40 ms /     9 tokens (  252.27 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.22 ms /     3 runs   (  907.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4994.34 ms /    12 tokens\n",
      " 88%|โโโโโโโโโ | 3059/3487 [8:41:07<1:13:49, 10.35s/it]Llama.generate: 317 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4868.87 ms /    22 tokens (  221.31 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.02 ms /     3 runs   (  881.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7515.50 ms /    25 tokens\n",
      " 88%|โโโโโโโโโ | 3060/3487 [8:41:14<1:07:37,  9.50s/it]Llama.generate: 312 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2313.36 ms /     9 tokens (  257.04 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.89 ms /     3 runs   (  908.63 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5041.58 ms /    12 tokens\n",
      " 88%|โโโโโโโโโ | 3061/3487 [8:41:20<57:59,  8.17s/it]  Llama.generate: 320 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4554.77 ms /     4 runs   ( 1138.69 ms per token,     0.88 tokens per second)\n",
      "llama_perf_context_print:       total time =    4557.40 ms /     5 tokens\n",
      " 88%|โโโโโโโโโ | 3062/3487 [8:41:24<50:11,  7.09s/it]Llama.generate: 307 prefix-match hit, remaining 85 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16049.40 ms /    85 tokens (  188.82 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.85 ms /     3 runs   (  885.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18710.01 ms /    88 tokens\n",
      " 88%|โโโโโโโโโ | 3063/3487 [8:41:43<1:14:44, 10.58s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2638.60 ms /    11 tokens (  239.87 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.80 ms /     3 runs   (  892.60 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5319.32 ms /    14 tokens\n",
      " 88%|โโโโโโโโโ | 3064/3487 [8:41:48<1:03:27,  9.00s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3646.38 ms /    16 tokens (  227.90 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.00 ms /     3 runs   (  888.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6313.00 ms /    19 tokens\n",
      " 88%|โโโโโโโโโ | 3065/3487 [8:41:54<57:39,  8.20s/it]  Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4130.56 ms /    18 tokens (  229.48 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.28 ms /     3 runs   (  894.43 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6817.23 ms /    21 tokens\n",
      " 88%|โโโโโโโโโ | 3066/3487 [8:42:01<54:37,  7.79s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5736.03 ms /    28 tokens (  204.86 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.58 ms /     3 runs   (  878.53 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8373.68 ms /    31 tokens\n",
      " 88%|โโโโโโโโโ | 3067/3487 [8:42:10<55:45,  7.96s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9424.94 ms /    48 tokens (  196.35 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.89 ms /     3 runs   (  882.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12073.89 ms /    51 tokens\n",
      " 88%|โโโโโโโโโ | 3068/3487 [8:42:22<1:04:14,  9.20s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2566.44 ms /     8 tokens (  320.80 ms per token,     3.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.59 ms /     3 runs   (  881.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5213.88 ms /    11 tokens\n",
      " 88%|โโโโโโโโโ | 3069/3487 [8:42:27<55:46,  8.01s/it]  Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10026.39 ms /    52 tokens (  192.82 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.08 ms /     3 runs   (  884.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12683.01 ms /    55 tokens\n",
      " 88%|โโโโโโโโโ | 3070/3487 [8:42:40<1:05:24,  9.41s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4850.06 ms /    23 tokens (  210.87 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.58 ms /     3 runs   (  904.19 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7564.65 ms /    26 tokens\n",
      " 88%|โโโโโโโโโ | 3071/3487 [8:42:47<1:01:26,  8.86s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3251.06 ms /    14 tokens (  232.22 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.11 ms /     3 runs   (  897.70 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5946.68 ms /    17 tokens\n",
      " 88%|โโโโโโโโโ | 3072/3487 [8:42:53<55:15,  7.99s/it]  Llama.generate: 307 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17338.28 ms /    90 tokens (  192.65 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.95 ms /     3 runs   (  892.65 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   20018.83 ms /    93 tokens\n",
      " 88%|โโโโโโโโโ | 3073/3487 [8:43:13<1:20:02, 11.60s/it]Llama.generate: 307 prefix-match hit, remaining 155 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28813.28 ms /   155 tokens (  185.89 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.47 ms /     3 runs   (  884.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   31468.17 ms /   158 tokens\n",
      " 88%|โโโโโโโโโ | 3074/3487 [8:43:45<2:00:53, 17.56s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2216.59 ms /     8 tokens (  277.07 ms per token,     3.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.81 ms /     3 runs   (  886.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4878.07 ms /    11 tokens\n",
      " 88%|โโโโโโโโโ | 3075/3487 [8:43:50<1:34:29, 13.76s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2217.74 ms /     6 tokens (  369.62 ms per token,     2.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.00 ms /     3 runs   (  883.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4871.89 ms /     9 tokens\n",
      " 88%|โโโโโโโโโ | 3076/3487 [8:43:54<1:16:00, 11.10s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13433.66 ms /    69 tokens (  194.69 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.88 ms /     3 runs   (  886.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16096.34 ms /    72 tokens\n",
      " 88%|โโโโโโโโโ | 3077/3487 [8:44:11<1:26:05, 12.60s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7535.79 ms /    36 tokens (  209.33 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.77 ms /     3 runs   (  884.92 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10193.53 ms /    39 tokens\n",
      " 88%|โโโโโโโโโ | 3078/3487 [8:44:21<1:20:58, 11.88s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7909.64 ms /    34 tokens (  232.64 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2955.01 ms /     3 runs   (  985.00 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =   10867.58 ms /    37 tokens\n",
      " 88%|โโโโโโโโโ | 3079/3487 [8:44:32<1:18:44, 11.58s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7940.84 ms /    34 tokens (  233.55 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.59 ms /     3 runs   (  900.53 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10645.57 ms /    37 tokens\n",
      " 88%|โโโโโโโโโ | 3080/3487 [8:44:42<1:16:39, 11.30s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3173.14 ms /    13 tokens (  244.09 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.38 ms /     3 runs   (  891.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5851.94 ms /    16 tokens\n",
      " 88%|โโโโโโโโโ | 3081/3487 [8:44:48<1:05:25,  9.67s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8329.88 ms /    39 tokens (  213.59 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.98 ms /     3 runs   (  890.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11005.99 ms /    42 tokens\n",
      " 88%|โโโโโโโโโ | 3082/3487 [8:44:59<1:07:59, 10.07s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2178.79 ms /     8 tokens (  272.35 ms per token,     3.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.76 ms /     3 runs   (  899.92 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4880.91 ms /    11 tokens\n",
      " 88%|โโโโโโโโโ | 3083/3487 [8:45:04<57:21,  8.52s/it]  Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2725.76 ms /    10 tokens (  272.58 ms per token,     3.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.26 ms /     3 runs   (  902.75 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5437.08 ms /    13 tokens\n",
      " 88%|โโโโโโโโโ | 3084/3487 [8:45:09<51:01,  7.60s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2815.68 ms /    12 tokens (  234.64 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.33 ms /     3 runs   (  897.44 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5510.05 ms /    15 tokens\n",
      " 88%|โโโโโโโโโ | 3085/3487 [8:45:15<46:42,  6.97s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2350.37 ms /     8 tokens (  293.80 ms per token,     3.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.66 ms /     3 runs   (  891.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5027.49 ms /    11 tokens\n",
      " 89%|โโโโโโโโโ | 3086/3487 [8:45:20<42:42,  6.39s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7451.63 ms /    34 tokens (  219.17 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2752.11 ms /     3 runs   (  917.37 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10206.86 ms /    37 tokens\n",
      " 89%|โโโโโโโโโ | 3087/3487 [8:45:30<50:15,  7.54s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2941.25 ms /    12 tokens (  245.10 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.60 ms /     3 runs   (  894.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5626.41 ms /    15 tokens\n",
      " 89%|โโโโโโโโโ | 3088/3487 [8:45:36<46:19,  6.97s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2701.93 ms /     9 tokens (  300.21 ms per token,     3.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.15 ms /     3 runs   (  894.72 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5388.80 ms /    12 tokens\n",
      " 89%|โโโโโโโโโ | 3089/3487 [8:45:41<43:05,  6.50s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2701.77 ms /    11 tokens (  245.62 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.43 ms /     3 runs   (  887.81 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5367.87 ms /    14 tokens\n",
      " 89%|โโโโโโโโโ | 3090/3487 [8:45:47<40:45,  6.16s/it]Llama.generate: 306 prefix-match hit, remaining 85 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16516.01 ms /    85 tokens (  194.31 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.39 ms /     3 runs   (  898.46 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   19213.75 ms /    88 tokens\n",
      " 89%|โโโโโโโโโ | 3091/3487 [8:46:06<1:06:31, 10.08s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3068.81 ms /    13 tokens (  236.06 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.40 ms /     3 runs   (  886.80 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5731.83 ms /    16 tokens\n",
      " 89%|โโโโโโโโโ | 3092/3487 [8:46:12<57:47,  8.78s/it]  Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5422.15 ms /    27 tokens (  200.82 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.94 ms /     3 runs   (  883.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8075.71 ms /    30 tokens\n",
      " 89%|โโโโโโโโโ | 3093/3487 [8:46:20<56:16,  8.57s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6324.85 ms /    30 tokens (  210.83 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.02 ms /     3 runs   (  887.01 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8988.38 ms /    33 tokens\n",
      " 89%|โโโโโโโโโ | 3094/3487 [8:46:29<56:58,  8.70s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3789.49 ms /    17 tokens (  222.91 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.60 ms /     3 runs   (  889.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6460.44 ms /    20 tokens\n",
      " 89%|โโโโโโโโโ | 3095/3487 [8:46:35<52:27,  8.03s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10109.84 ms /    49 tokens (  206.32 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2795.20 ms /     3 runs   (  931.73 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12907.94 ms /    52 tokens\n",
      " 89%|โโโโโโโโโ | 3096/3487 [8:46:48<1:01:52,  9.50s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10132.67 ms /    51 tokens (  198.68 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.77 ms /     3 runs   (  891.26 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12808.56 ms /    54 tokens\n",
      " 89%|โโโโโโโโโ | 3097/3487 [8:47:01<1:08:12, 10.49s/it]Llama.generate: 307 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1657.31 ms /     5 tokens (  331.46 ms per token,     3.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2824.59 ms /     3 runs   (  941.53 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4485.46 ms /     8 tokens\n",
      " 89%|โโโโโโโโโ | 3098/3487 [8:47:05<56:21,  8.69s/it]  Llama.generate: 308 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1711.94 ms /     5 tokens (  342.39 ms per token,     2.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.15 ms /     3 runs   (  884.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4369.14 ms /     8 tokens\n",
      " 89%|โโโโโโโโโ | 3099/3487 [8:47:10<47:50,  7.40s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1485.77 ms /     5 tokens (  297.15 ms per token,     3.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2827.37 ms /     3 runs   (  942.46 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4315.58 ms /     8 tokens\n",
      " 89%|โโโโโโโโโ | 3100/3487 [8:47:14<41:46,  6.48s/it]Llama.generate: 306 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16414.68 ms /    87 tokens (  188.67 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.14 ms /     3 runs   (  884.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19069.14 ms /    90 tokens\n",
      " 89%|โโโโโโโโโ | 3101/3487 [8:47:33<1:05:58, 10.26s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3686.23 ms /    16 tokens (  230.39 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.38 ms /     3 runs   (  897.79 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6382.21 ms /    19 tokens\n",
      " 89%|โโโโโโโโโ | 3102/3487 [8:47:40<58:22,  9.10s/it]  Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5599.22 ms /    25 tokens (  223.97 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.57 ms /     3 runs   (  886.19 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8260.25 ms /    28 tokens\n",
      " 89%|โโโโโโโโโ | 3103/3487 [8:47:48<56:37,  8.85s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4900.84 ms /    24 tokens (  204.20 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.42 ms /     3 runs   (  887.81 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7566.70 ms /    27 tokens\n",
      " 89%|โโโโโโโโโ | 3104/3487 [8:47:55<54:02,  8.47s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5329.47 ms /    26 tokens (  204.98 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.37 ms /     3 runs   (  889.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8000.38 ms /    29 tokens\n",
      " 89%|โโโโโโโโโ | 3105/3487 [8:48:03<53:01,  8.33s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7418.93 ms /    35 tokens (  211.97 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.78 ms /     3 runs   (  895.26 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10106.66 ms /    38 tokens\n",
      " 89%|โโโโโโโโโ | 3106/3487 [8:48:14<56:17,  8.86s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4909.06 ms /    24 tokens (  204.54 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.36 ms /     3 runs   (  895.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7596.52 ms /    27 tokens\n",
      " 89%|โโโโโโโโโ | 3107/3487 [8:48:21<53:44,  8.49s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3619.89 ms /    16 tokens (  226.24 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.64 ms /     3 runs   (  892.21 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6299.10 ms /    19 tokens\n",
      " 89%|โโโโโโโโโ | 3108/3487 [8:48:27<49:28,  7.83s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10019.01 ms /    51 tokens (  196.45 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.72 ms /     3 runs   (  895.57 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12707.82 ms /    54 tokens\n",
      " 89%|โโโโโโโโโ | 3109/3487 [8:48:40<58:34,  9.30s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3159.98 ms /    12 tokens (  263.33 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.69 ms /     3 runs   (  888.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5828.18 ms /    15 tokens\n",
      " 89%|โโโโโโโโโ | 3110/3487 [8:48:46<51:53,  8.26s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2875.44 ms /    12 tokens (  239.62 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.28 ms /     3 runs   (  895.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5564.19 ms /    15 tokens\n",
      " 89%|โโโโโโโโโ | 3111/3487 [8:48:52<46:42,  7.45s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3457.84 ms /    15 tokens (  230.52 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2727.31 ms /     3 runs   (  909.10 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6187.22 ms /    18 tokens\n",
      " 89%|โโโโโโโโโ | 3112/3487 [8:48:58<44:13,  7.08s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13346.69 ms /    66 tokens (  202.22 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.18 ms /     3 runs   (  889.39 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16017.38 ms /    69 tokens\n",
      " 89%|โโโโโโโโโ | 3113/3487 [8:49:14<1:00:50,  9.76s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3725.51 ms /    17 tokens (  219.15 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.99 ms /     3 runs   (  898.66 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6424.14 ms /    20 tokens\n",
      " 89%|โโโโโโโโโ | 3114/3487 [8:49:20<54:28,  8.76s/it]  Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4356.78 ms /    20 tokens (  217.84 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.73 ms /     3 runs   (  889.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7026.79 ms /    23 tokens\n",
      " 89%|โโโโโโโโโ | 3115/3487 [8:49:27<51:06,  8.24s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3080.09 ms /    13 tokens (  236.93 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.45 ms /     3 runs   (  898.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5777.25 ms /    16 tokens\n",
      " 89%|โโโโโโโโโ | 3116/3487 [8:49:33<46:24,  7.51s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7983.87 ms /    33 tokens (  241.94 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.36 ms /     3 runs   (  882.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10632.72 ms /    36 tokens\n",
      " 89%|โโโโโโโโโ | 3117/3487 [8:49:44<52:05,  8.45s/it]Llama.generate: 307 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14654.35 ms /    74 tokens (  198.03 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.43 ms /     3 runs   (  894.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   17339.33 ms /    77 tokens\n",
      " 89%|โโโโโโโโโ | 3118/3487 [8:50:01<1:08:21, 11.12s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3768.77 ms /    17 tokens (  221.69 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.59 ms /     3 runs   (  891.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6445.00 ms /    20 tokens\n",
      " 89%|โโโโโโโโโ | 3119/3487 [8:50:08<59:35,  9.72s/it]  Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3147.79 ms /    13 tokens (  242.14 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.78 ms /     3 runs   (  891.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5825.57 ms /    16 tokens\n",
      " 89%|โโโโโโโโโ | 3120/3487 [8:50:13<52:18,  8.55s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3224.35 ms /    14 tokens (  230.31 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.07 ms /     3 runs   (  891.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5901.11 ms /    17 tokens\n",
      " 90%|โโโโโโโโโ | 3121/3487 [8:50:19<47:20,  7.76s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6444.98 ms /    31 tokens (  207.90 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.70 ms /     3 runs   (  893.23 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9127.74 ms /    34 tokens\n",
      " 90%|โโโโโโโโโ | 3122/3487 [8:50:28<49:43,  8.17s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3846.76 ms /    18 tokens (  213.71 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.66 ms /     3 runs   (  882.89 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6498.71 ms /    21 tokens\n",
      " 90%|โโโโโโโโโ | 3123/3487 [8:50:35<46:33,  7.67s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9221.30 ms /    43 tokens (  214.45 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.13 ms /     3 runs   (  887.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11887.03 ms /    46 tokens\n",
      " 90%|โโโโโโโโโ | 3124/3487 [8:50:47<54:05,  8.94s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2175.56 ms /     8 tokens (  271.94 ms per token,     3.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.03 ms /     3 runs   (  893.68 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4858.69 ms /    11 tokens\n",
      " 90%|โโโโโโโโโ | 3125/3487 [8:50:52<46:33,  7.72s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2343.83 ms /     9 tokens (  260.43 ms per token,     3.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.17 ms /     3 runs   (  883.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4997.17 ms /    12 tokens\n",
      " 90%|โโโโโโโโโ | 3126/3487 [8:50:57<41:32,  6.90s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5785.88 ms /    28 tokens (  206.64 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.41 ms /     3 runs   (  887.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8449.61 ms /    31 tokens\n",
      " 90%|โโโโโโโโโ | 3127/3487 [8:51:05<44:13,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4282.57 ms /    19 tokens (  225.40 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.08 ms /     3 runs   (  884.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6938.99 ms /    22 tokens\n",
      " 90%|โโโโโโโโโ | 3128/3487 [8:51:12<43:20,  7.24s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5519.78 ms /    27 tokens (  204.44 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.54 ms /     3 runs   (  902.85 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8231.33 ms /    30 tokens\n",
      " 90%|โโโโโโโโโ | 3129/3487 [8:51:20<45:00,  7.54s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2273.83 ms /     9 tokens (  252.65 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2923.91 ms /     3 runs   (  974.64 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    5200.40 ms /    12 tokens\n",
      " 90%|โโโโโโโโโ | 3130/3487 [8:51:26<40:42,  6.84s/it]Llama.generate: 308 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3997.32 ms /    16 tokens (  249.83 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.28 ms /     3 runs   (  889.76 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6669.78 ms /    19 tokens\n",
      " 90%|โโโโโโโโโ | 3131/3487 [8:51:32<40:18,  6.79s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2759.39 ms /    11 tokens (  250.85 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.70 ms /     3 runs   (  888.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5427.50 ms /    14 tokens\n",
      " 90%|โโโโโโโโโ | 3132/3487 [8:51:38<37:47,  6.39s/it]Llama.generate: 313 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10304.70 ms /    53 tokens (  194.43 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.93 ms /     3 runs   (  882.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12954.34 ms /    56 tokens\n",
      " 90%|โโโโโโโโโ | 3133/3487 [8:51:51<49:19,  8.36s/it]Llama.generate: 313 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1406.29 ms /     4 tokens (  351.57 ms per token,     2.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2874.24 ms /     3 runs   (  958.08 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4283.34 ms /     7 tokens\n",
      " 90%|โโโโโโโโโ | 3134/3487 [8:51:55<42:00,  7.14s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6012.60 ms /    28 tokens (  214.74 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.86 ms /     3 runs   (  905.95 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8733.22 ms /    31 tokens\n",
      " 90%|โโโโโโโโโ | 3135/3487 [8:52:04<44:42,  7.62s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5398.32 ms /    25 tokens (  215.93 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2736.81 ms /     3 runs   (  912.27 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8137.59 ms /    28 tokens\n",
      " 90%|โโโโโโโโโ | 3136/3487 [8:52:12<45:30,  7.78s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7584.91 ms /    36 tokens (  210.69 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.89 ms /     3 runs   (  886.96 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10248.41 ms /    39 tokens\n",
      " 90%|โโโโโโโโโ | 3137/3487 [8:52:22<49:42,  8.52s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16819.21 ms /    86 tokens (  195.57 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2784.59 ms /     3 runs   (  928.20 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   19606.45 ms /    89 tokens\n",
      " 90%|โโโโโโโโโ | 3138/3487 [8:52:42<1:08:55, 11.85s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3948.49 ms /    16 tokens (  246.78 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2748.46 ms /     3 runs   (  916.15 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6699.31 ms /    19 tokens\n",
      " 90%|โโโโโโโโโ | 3139/3487 [8:52:48<59:50, 10.32s/it]  Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2780.39 ms /    11 tokens (  252.76 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.32 ms /     3 runs   (  896.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5472.59 ms /    14 tokens\n",
      " 90%|โโโโโโโโโ | 3140/3487 [8:52:54<51:16,  8.87s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3678.99 ms /    16 tokens (  229.94 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.61 ms /     3 runs   (  901.54 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6386.35 ms /    19 tokens\n",
      " 90%|โโโโโโโโโ | 3141/3487 [8:53:00<46:51,  8.12s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4805.32 ms /    22 tokens (  218.42 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.07 ms /     3 runs   (  899.02 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7535.96 ms /    25 tokens\n",
      " 90%|โโโโโโโโโ | 3142/3487 [8:53:08<45:42,  7.95s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7700.86 ms /    35 tokens (  220.02 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.24 ms /     3 runs   (  890.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10374.60 ms /    38 tokens\n",
      " 90%|โโโโโโโโโ | 3143/3487 [8:53:18<49:46,  8.68s/it]Llama.generate: 315 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1368.54 ms /     4 tokens (  342.13 ms per token,     2.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2819.87 ms /     3 runs   (  939.96 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4191.42 ms /     7 tokens\n",
      " 90%|โโโโโโโโโ | 3144/3487 [8:53:22<41:56,  7.34s/it]Llama.generate: 315 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4984.02 ms /    22 tokens (  226.55 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.10 ms /     3 runs   (  883.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7637.48 ms /    25 tokens\n",
      " 90%|โโโโโโโโโ | 3145/3487 [8:53:30<42:20,  7.43s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3081.14 ms /    13 tokens (  237.01 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.09 ms /     3 runs   (  887.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5745.49 ms /    16 tokens\n",
      " 90%|โโโโโโโโโ | 3146/3487 [8:53:36<39:21,  6.93s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5233.63 ms /    25 tokens (  209.35 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.66 ms /     3 runs   (  897.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7929.86 ms /    28 tokens\n",
      " 90%|โโโโโโโโโ | 3147/3487 [8:53:44<40:58,  7.23s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2247.26 ms /     9 tokens (  249.70 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.07 ms /     3 runs   (  890.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4919.79 ms /    12 tokens\n",
      " 90%|โโโโโโโโโ | 3148/3487 [8:53:49<37:00,  6.55s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3145.16 ms /    13 tokens (  241.94 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.87 ms /     3 runs   (  896.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5837.05 ms /    16 tokens\n",
      " 90%|โโโโโโโโโ | 3149/3487 [8:53:55<35:42,  6.34s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2284.06 ms /     9 tokens (  253.78 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.17 ms /     3 runs   (  907.39 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5008.82 ms /    12 tokens\n",
      " 90%|โโโโโโโโโ | 3150/3487 [8:54:00<33:22,  5.94s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3022.24 ms /    13 tokens (  232.48 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2854.47 ms /     3 runs   (  951.49 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    5879.54 ms /    16 tokens\n",
      " 90%|โโโโโโโโโ | 3151/3487 [8:54:05<33:10,  5.92s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3093.08 ms /    11 tokens (  281.19 ms per token,     3.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.53 ms /     3 runs   (  890.18 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5766.05 ms /    14 tokens\n",
      " 90%|โโโโโโโโโ | 3152/3487 [8:54:11<32:49,  5.88s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5368.04 ms /    25 tokens (  214.72 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.82 ms /     3 runs   (  884.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8025.05 ms /    28 tokens\n",
      " 90%|โโโโโโโโโ | 3153/3487 [8:54:19<36:19,  6.53s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2289.93 ms /     9 tokens (  254.44 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.68 ms /     3 runs   (  892.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4969.91 ms /    12 tokens\n",
      " 90%|โโโโโโโโโ | 3154/3487 [8:54:24<33:38,  6.06s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2653.51 ms /    10 tokens (  265.35 ms per token,     3.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.57 ms /     3 runs   (  889.52 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5325.07 ms /    13 tokens\n",
      " 90%|โโโโโโโโโ | 3155/3487 [8:54:30<32:19,  5.84s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11347.53 ms /    57 tokens (  199.08 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2877.37 ms /     3 runs   (  959.12 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   14229.68 ms /    60 tokens\n",
      " 91%|โโโโโโโโโ | 3156/3487 [8:54:44<46:07,  8.36s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1900.13 ms /     6 tokens (  316.69 ms per token,     3.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.99 ms /     3 runs   (  897.00 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4593.87 ms /     9 tokens\n",
      " 91%|โโโโโโโโโ | 3157/3487 [8:54:48<39:47,  7.23s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3684.67 ms /    16 tokens (  230.29 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.57 ms /     3 runs   (  891.19 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6360.79 ms /    19 tokens\n",
      " 91%|โโโโโโโโโ | 3158/3487 [8:54:55<38:14,  6.97s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12259.93 ms /    60 tokens (  204.33 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.70 ms /     3 runs   (  888.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14929.37 ms /    63 tokens\n",
      " 91%|โโโโโโโโโ | 3159/3487 [8:55:10<51:11,  9.36s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6421.35 ms /    31 tokens (  207.14 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.63 ms /     3 runs   (  883.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9075.16 ms /    34 tokens\n",
      " 91%|โโโโโโโโโ | 3160/3487 [8:55:19<50:34,  9.28s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2805.36 ms /    12 tokens (  233.78 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.54 ms /     3 runs   (  883.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5458.71 ms /    15 tokens\n",
      " 91%|โโโโโโโโโ | 3161/3487 [8:55:24<44:12,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7947.26 ms /    40 tokens (  198.68 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.34 ms /     3 runs   (  894.45 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10633.11 ms /    43 tokens\n",
      " 91%|โโโโโโโโโ | 3162/3487 [8:55:35<48:08,  8.89s/it]Llama.generate: 316 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1402.47 ms /     4 tokens (  350.62 ms per token,     2.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2876.61 ms /     3 runs   (  958.87 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4281.45 ms /     7 tokens\n",
      " 91%|โโโโโโโโโ | 3163/3487 [8:55:39<40:32,  7.51s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12464.23 ms /    64 tokens (  194.75 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.54 ms /     3 runs   (  889.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15136.56 ms /    67 tokens\n",
      " 91%|โโโโโโโโโ | 3164/3487 [8:55:54<52:45,  9.80s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3863.77 ms /    15 tokens (  257.58 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.09 ms /     3 runs   (  885.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6522.26 ms /    18 tokens\n",
      " 91%|โโโโโโโโโ | 3165/3487 [8:56:01<47:19,  8.82s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4346.30 ms /    21 tokens (  206.97 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.47 ms /     3 runs   (  888.49 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7014.84 ms /    24 tokens\n",
      " 91%|โโโโโโโโโ | 3166/3487 [8:56:08<44:17,  8.28s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3063.87 ms /    13 tokens (  235.68 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.02 ms /     3 runs   (  887.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5728.24 ms /    16 tokens\n",
      " 91%|โโโโโโโโโ | 3167/3487 [8:56:14<40:05,  7.52s/it]Llama.generate: 310 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2633.51 ms /    11 tokens (  239.41 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.41 ms /     3 runs   (  882.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5282.55 ms /    14 tokens\n",
      " 91%|โโโโโโโโโ | 3168/3487 [8:56:19<36:24,  6.85s/it]Llama.generate: 310 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2695.36 ms /    10 tokens (  269.54 ms per token,     3.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.62 ms /     3 runs   (  881.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5342.90 ms /    13 tokens\n",
      " 91%|โโโโโโโโโ | 3169/3487 [8:56:24<33:55,  6.40s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8152.16 ms /    40 tokens (  203.80 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2867.72 ms /     3 runs   (  955.91 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   11021.91 ms /    43 tokens\n",
      " 91%|โโโโโโโโโ | 3170/3487 [8:56:35<41:09,  7.79s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3186.82 ms /    14 tokens (  227.63 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.07 ms /     3 runs   (  901.69 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5894.15 ms /    17 tokens\n",
      " 91%|โโโโโโโโโ | 3171/3487 [8:56:41<38:02,  7.22s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4718.84 ms /    20 tokens (  235.94 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.41 ms /     3 runs   (  879.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7358.74 ms /    23 tokens\n",
      " 91%|โโโโโโโโโ | 3172/3487 [8:56:49<38:08,  7.27s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11813.20 ms /    60 tokens (  196.89 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.60 ms /     3 runs   (  895.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14503.13 ms /    63 tokens\n",
      " 91%|โโโโโโโโโ | 3173/3487 [8:57:03<49:24,  9.44s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7601.10 ms /    36 tokens (  211.14 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.30 ms /     3 runs   (  884.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10257.46 ms /    39 tokens\n",
      " 91%|โโโโโโโโโ | 3174/3487 [8:57:13<50:32,  9.69s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7790.80 ms /    38 tokens (  205.02 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2822.05 ms /     3 runs   (  940.68 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   10615.85 ms /    41 tokens\n",
      " 91%|โโโโโโโโโ | 3175/3487 [8:57:24<51:50,  9.97s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2913.86 ms /    12 tokens (  242.82 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.52 ms /     3 runs   (  889.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5585.57 ms /    15 tokens\n",
      " 91%|โโโโโโโโโ | 3176/3487 [8:57:30<44:52,  8.66s/it]Llama.generate: 314 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2207.55 ms /     8 tokens (  275.94 ms per token,     3.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.66 ms /     3 runs   (  890.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4881.51 ms /    11 tokens\n",
      " 91%|โโโโโโโโโ | 3177/3487 [8:57:34<38:53,  7.53s/it]Llama.generate: 314 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7674.59 ms /    36 tokens (  213.18 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.33 ms /     3 runs   (  878.44 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10313.18 ms /    39 tokens\n",
      " 91%|โโโโโโโโโ | 3178/3487 [8:57:45<43:04,  8.37s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2175.83 ms /     5 tokens (  435.17 ms per token,     2.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.28 ms /     3 runs   (  877.09 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4809.53 ms /     8 tokens\n",
      " 91%|โโโโโโโโโ | 3179/3487 [8:57:50<37:28,  7.30s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4840.13 ms /    22 tokens (  220.01 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.84 ms /     3 runs   (  884.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7496.05 ms /    25 tokens\n",
      " 91%|โโโโโโโโโ | 3180/3487 [8:57:57<37:40,  7.36s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3907.14 ms /    18 tokens (  217.06 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.72 ms /     3 runs   (  881.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6554.10 ms /    21 tokens\n",
      " 91%|โโโโโโโโโ | 3181/3487 [8:58:04<36:19,  7.12s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5277.75 ms /    26 tokens (  202.99 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.23 ms /     3 runs   (  876.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7910.38 ms /    29 tokens\n",
      " 91%|โโโโโโโโโโ| 3182/3487 [8:58:12<37:25,  7.36s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6709.14 ms /    32 tokens (  209.66 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.27 ms /     3 runs   (  882.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9360.54 ms /    35 tokens\n",
      " 91%|โโโโโโโโโโ| 3183/3487 [8:58:21<40:21,  7.96s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3900.61 ms /    18 tokens (  216.70 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2945.94 ms /     3 runs   (  981.98 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    6849.21 ms /    21 tokens\n",
      " 91%|โโโโโโโโโโ| 3184/3487 [8:58:28<38:32,  7.63s/it]Llama.generate: 323 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4822.32 ms /     4 runs   ( 1205.58 ms per token,     0.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    4825.56 ms /     5 tokens\n",
      " 91%|โโโโโโโโโโ| 3185/3487 [8:58:33<34:11,  6.79s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6862.77 ms /    30 tokens (  228.76 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.65 ms /     3 runs   (  904.22 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9577.90 ms /    33 tokens\n",
      " 91%|โโโโโโโโโโ| 3186/3487 [8:58:42<38:16,  7.63s/it]Llama.generate: 306 prefix-match hit, remaining 161 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   31224.90 ms /   161 tokens (  193.94 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.63 ms /     3 runs   (  885.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   33885.49 ms /   164 tokens\n",
      " 91%|โโโโโโโโโโ| 3187/3487 [8:59:16<1:17:33, 15.51s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3196.09 ms /    14 tokens (  228.29 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.78 ms /     3 runs   (  898.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5895.78 ms /    17 tokens\n",
      " 91%|โโโโโโโโโโ| 3188/3487 [8:59:22<1:02:55, 12.63s/it]Llama.generate: 309 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7452.13 ms /    35 tokens (  212.92 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.13 ms /     3 runs   (  895.71 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10141.80 ms /    38 tokens\n",
      " 91%|โโโโโโโโโโ| 3189/3487 [8:59:32<59:04, 11.89s/it]  Llama.generate: 309 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2806.83 ms /    11 tokens (  255.17 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2738.65 ms /     3 runs   (  912.88 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5548.01 ms /    14 tokens\n",
      " 91%|โโโโโโโโโโ| 3190/3487 [8:59:38<49:27,  9.99s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2207.31 ms /     8 tokens (  275.91 ms per token,     3.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.75 ms /     3 runs   (  890.25 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4880.74 ms /    11 tokens\n",
      " 92%|โโโโโโโโโโ| 3191/3487 [8:59:43<41:44,  8.46s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2844.99 ms /    12 tokens (  237.08 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.24 ms /     3 runs   (  905.08 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5562.90 ms /    15 tokens\n",
      " 92%|โโโโโโโโโโ| 3192/3487 [8:59:48<37:20,  7.59s/it]Llama.generate: 315 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2156.75 ms /     5 tokens (  431.35 ms per token,     2.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2816.65 ms /     3 runs   (  938.88 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4976.38 ms /     8 tokens\n",
      " 92%|โโโโโโโโโโ| 3193/3487 [8:59:53<33:22,  6.81s/it]Llama.generate: 307 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27499.74 ms /   105 tokens (  261.90 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2968.04 ms /     3 runs   (  989.35 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   30470.38 ms /   108 tokens\n",
      " 92%|โโโโโโโโโโ| 3194/3487 [9:00:24<1:07:56, 13.91s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2685.82 ms /    10 tokens (  268.58 ms per token,     3.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2756.34 ms /     3 runs   (  918.78 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5444.89 ms /    13 tokens\n",
      " 92%|โโโโโโโโโโ| 3195/3487 [9:00:29<55:21, 11.37s/it]  Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2781.97 ms /    11 tokens (  252.91 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.73 ms /     3 runs   (  911.91 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5520.91 ms /    14 tokens\n",
      " 92%|โโโโโโโโโโ| 3196/3487 [9:00:35<46:39,  9.62s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2767.36 ms /    10 tokens (  276.74 ms per token,     3.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.26 ms /     3 runs   (  884.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5423.29 ms /    13 tokens\n",
      " 92%|โโโโโโโโโโ| 3197/3487 [9:00:40<40:25,  8.36s/it]Llama.generate: 306 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17456.68 ms /    90 tokens (  193.96 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.03 ms /     3 runs   (  901.34 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   20163.36 ms /    93 tokens\n",
      " 92%|โโโโโโโโโโ| 3198/3487 [9:01:00<57:20, 11.91s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8802.34 ms /    43 tokens (  204.71 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.22 ms /     3 runs   (  889.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11473.99 ms /    46 tokens\n",
      " 92%|โโโโโโโโโโ| 3199/3487 [9:01:12<56:32, 11.78s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5745.21 ms /    26 tokens (  220.97 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.71 ms /     3 runs   (  885.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8403.75 ms /    29 tokens\n",
      " 92%|โโโโโโโโโโ| 3200/3487 [9:01:20<51:30, 10.77s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6288.66 ms /    31 tokens (  202.86 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.14 ms /     3 runs   (  888.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8955.02 ms /    34 tokens\n",
      " 92%|โโโโโโโโโโ| 3201/3487 [9:01:29<48:44, 10.23s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5079.64 ms /    23 tokens (  220.85 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.60 ms /     3 runs   (  899.20 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7779.74 ms /    26 tokens\n",
      " 92%|โโโโโโโโโโ| 3202/3487 [9:01:37<45:06,  9.50s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2444.35 ms /     8 tokens (  305.54 ms per token,     3.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2965.54 ms /     3 runs   (  988.51 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    5412.50 ms /    11 tokens\n",
      " 92%|โโโโโโโโโโ| 3203/3487 [9:01:42<39:09,  8.27s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11498.45 ms /    56 tokens (  205.33 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2728.59 ms /     3 runs   (  909.53 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   14230.27 ms /    59 tokens\n",
      " 92%|โโโโโโโโโโ| 3204/3487 [9:01:57<47:28, 10.06s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9213.10 ms /    42 tokens (  219.36 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2809.11 ms /     3 runs   (  936.37 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12024.56 ms /    45 tokens\n",
      " 92%|โโโโโโโโโโ| 3205/3487 [9:02:09<50:04, 10.65s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8912.26 ms /    45 tokens (  198.05 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2769.78 ms /     3 runs   (  923.26 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   11684.51 ms /    48 tokens\n",
      " 92%|โโโโโโโโโโ| 3206/3487 [9:02:20<51:21, 10.97s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2715.92 ms /     8 tokens (  339.49 ms per token,     2.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.45 ms /     3 runs   (  880.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5360.24 ms /    11 tokens\n",
      " 92%|โโโโโโโโโโ| 3207/3487 [9:02:26<43:20,  9.29s/it]Llama.generate: 307 prefix-match hit, remaining 81 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15817.20 ms /    81 tokens (  195.27 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.57 ms /     3 runs   (  886.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18480.27 ms /    84 tokens\n",
      " 92%|โโโโโโโโโโ| 3208/3487 [9:02:44<56:01, 12.05s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5927.54 ms /    28 tokens (  211.70 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2750.76 ms /     3 runs   (  916.92 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8680.82 ms /    31 tokens\n",
      " 92%|โโโโโโโโโโ| 3209/3487 [9:02:53<51:09, 11.04s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4209.69 ms /    18 tokens (  233.87 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.71 ms /     3 runs   (  894.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6895.48 ms /    21 tokens\n",
      " 92%|โโโโโโโโโโ| 3210/3487 [9:03:00<45:16,  9.81s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3320.47 ms /    13 tokens (  255.42 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.60 ms /     3 runs   (  889.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5993.89 ms /    16 tokens\n",
      " 92%|โโโโโโโโโโ| 3211/3487 [9:03:06<39:52,  8.67s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2295.27 ms /     9 tokens (  255.03 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.35 ms /     3 runs   (  898.45 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4993.38 ms /    12 tokens\n",
      " 92%|โโโโโโโโโโ| 3212/3487 [9:03:11<34:41,  7.57s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7510.49 ms /    34 tokens (  220.90 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.53 ms /     3 runs   (  882.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10161.44 ms /    37 tokens\n",
      " 92%|โโโโโโโโโโ| 3213/3487 [9:03:21<38:07,  8.35s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8102.64 ms /    36 tokens (  225.07 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.18 ms /     3 runs   (  880.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10745.86 ms /    39 tokens\n",
      " 92%|โโโโโโโโโโ| 3214/3487 [9:03:32<41:16,  9.07s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2828.55 ms /    11 tokens (  257.14 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.90 ms /     3 runs   (  885.97 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5488.58 ms /    14 tokens\n",
      " 92%|โโโโโโโโโโ| 3215/3487 [9:03:37<36:15,  8.00s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3175.44 ms /    13 tokens (  244.26 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.08 ms /     3 runs   (  884.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5830.21 ms /    16 tokens\n",
      " 92%|โโโโโโโโโโ| 3216/3487 [9:03:43<33:11,  7.35s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5901.85 ms /    28 tokens (  210.78 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.21 ms /     3 runs   (  900.74 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8606.37 ms /    31 tokens\n",
      " 92%|โโโโโโโโโโ| 3217/3487 [9:03:52<34:46,  7.73s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8656.12 ms /    44 tokens (  196.73 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.22 ms /     3 runs   (  881.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11303.80 ms /    47 tokens\n",
      " 92%|โโโโโโโโโโ| 3218/3487 [9:04:03<39:28,  8.80s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2674.71 ms /    11 tokens (  243.16 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.79 ms /     3 runs   (  889.60 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5345.84 ms /    14 tokens\n",
      " 92%|โโโโโโโโโโ| 3219/3487 [9:04:08<34:41,  7.77s/it]Llama.generate: 313 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3227.26 ms /    13 tokens (  248.25 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.21 ms /     3 runs   (  913.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5969.32 ms /    16 tokens\n",
      " 92%|โโโโโโโโโโ| 3220/3487 [9:04:14<32:10,  7.23s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3828.58 ms /    15 tokens (  255.24 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.03 ms /     3 runs   (  879.34 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6469.43 ms /    18 tokens\n",
      " 92%|โโโโโโโโโโ| 3221/3487 [9:04:21<31:03,  7.01s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2564.61 ms /    10 tokens (  256.46 ms per token,     3.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.49 ms /     3 runs   (  891.50 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5241.56 ms /    13 tokens\n",
      " 92%|โโโโโโโโโโ| 3222/3487 [9:04:26<28:36,  6.48s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3243.84 ms /    14 tokens (  231.70 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.49 ms /     3 runs   (  879.50 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5884.38 ms /    17 tokens\n",
      " 92%|โโโโโโโโโโ| 3223/3487 [9:04:32<27:43,  6.30s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2292.22 ms /     9 tokens (  254.69 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.24 ms /     3 runs   (  891.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4968.68 ms /    12 tokens\n",
      " 92%|โโโโโโโโโโ| 3224/3487 [9:04:37<25:52,  5.90s/it]Llama.generate: 314 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4098.90 ms /     4 runs   ( 1024.73 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    4101.68 ms /     5 tokens\n",
      " 92%|โโโโโโโโโโ| 3225/3487 [9:04:41<23:25,  5.37s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3087.40 ms /    13 tokens (  237.49 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.14 ms /     3 runs   (  893.71 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5771.34 ms /    16 tokens\n",
      " 93%|โโโโโโโโโโ| 3226/3487 [9:04:47<23:53,  5.49s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3907.15 ms /    18 tokens (  217.06 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.05 ms /     3 runs   (  899.68 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6609.17 ms /    21 tokens\n",
      " 93%|โโโโโโโโโโ| 3227/3487 [9:04:53<25:15,  5.83s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5307.85 ms /    24 tokens (  221.16 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.05 ms /     3 runs   (  893.35 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7990.34 ms /    27 tokens\n",
      " 93%|โโโโโโโโโโ| 3228/3487 [9:05:01<27:58,  6.48s/it]Llama.generate: 315 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1407.91 ms /     4 tokens (  351.98 ms per token,     2.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2856.61 ms /     3 runs   (  952.20 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4267.02 ms /     7 tokens\n",
      " 93%|โโโโโโโโโโ| 3229/3487 [9:05:06<25:01,  5.82s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4540.27 ms /    21 tokens (  216.20 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.23 ms /     3 runs   (  881.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7188.21 ms /    24 tokens\n",
      " 93%|โโโโโโโโโโ| 3230/3487 [9:05:13<26:41,  6.23s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2881.31 ms /    11 tokens (  261.94 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2761.09 ms /     3 runs   (  920.36 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5644.63 ms /    14 tokens\n",
      " 93%|โโโโโโโโโโ| 3231/3487 [9:05:19<25:50,  6.06s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4926.16 ms /    24 tokens (  205.26 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.88 ms /     3 runs   (  889.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7598.39 ms /    27 tokens\n",
      " 93%|โโโโโโโโโโ| 3232/3487 [9:05:26<27:43,  6.52s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2907.86 ms /    11 tokens (  264.35 ms per token,     3.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.37 ms /     3 runs   (  892.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5587.67 ms /    14 tokens\n",
      " 93%|โโโโโโโโโโ| 3233/3487 [9:05:32<26:26,  6.24s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4644.80 ms /    22 tokens (  211.13 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.47 ms /     3 runs   (  884.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7302.29 ms /    25 tokens\n",
      " 93%|โโโโโโโโโโ| 3234/3487 [9:05:39<27:40,  6.56s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2750.47 ms /     9 tokens (  305.61 ms per token,     3.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.81 ms /     3 runs   (  886.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5412.89 ms /    12 tokens\n",
      " 93%|โโโโโโโโโโ| 3235/3487 [9:05:44<26:07,  6.22s/it]Llama.generate: 311 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3556.99 ms /    15 tokens (  237.13 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.78 ms /     3 runs   (  889.26 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6227.10 ms /    18 tokens\n",
      " 93%|โโโโโโโโโโ| 3236/3487 [9:05:51<26:02,  6.23s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3170.37 ms /    12 tokens (  264.20 ms per token,     3.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.39 ms /     3 runs   (  895.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5859.89 ms /    15 tokens\n",
      " 93%|โโโโโโโโโโ| 3237/3487 [9:05:57<25:29,  6.12s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6306.94 ms /    30 tokens (  210.23 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2814.13 ms /     3 runs   (  938.04 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    9123.62 ms /    33 tokens\n",
      " 93%|โโโโโโโโโโ| 3238/3487 [9:06:06<29:10,  7.03s/it]Llama.generate: 313 prefix-match hit, remaining 185 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   34718.56 ms /   185 tokens (  187.67 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.39 ms /     3 runs   (  896.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   37411.18 ms /   188 tokens\n",
      " 93%|โโโโโโโโโโ| 3239/3487 [9:06:43<1:06:44, 16.15s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3292.12 ms /    13 tokens (  253.24 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.54 ms /     3 runs   (  907.18 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6015.73 ms /    16 tokens\n",
      " 93%|โโโโโโโโโโ| 3240/3487 [9:06:49<53:58, 13.11s/it]  Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6214.75 ms /    30 tokens (  207.16 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.57 ms /     3 runs   (  886.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8877.44 ms /    33 tokens\n",
      " 93%|โโโโโโโโโโ| 3241/3487 [9:06:58<48:33, 11.84s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3623.70 ms /    13 tokens (  278.75 ms per token,     3.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2878.14 ms /     3 runs   (  959.38 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    6504.59 ms /    16 tokens\n",
      " 93%|โโโโโโโโโโ| 3242/3487 [9:07:05<41:50, 10.24s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6484.93 ms /    31 tokens (  209.19 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.63 ms /     3 runs   (  884.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9141.68 ms /    34 tokens\n",
      " 93%|โโโโโโโโโโ| 3243/3487 [9:07:14<40:19,  9.92s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5052.43 ms /    24 tokens (  210.52 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.66 ms /     3 runs   (  900.55 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7756.05 ms /    27 tokens\n",
      " 93%|โโโโโโโโโโ| 3244/3487 [9:07:21<37:32,  9.27s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3023.88 ms /    13 tokens (  232.61 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.61 ms /     3 runs   (  895.54 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5713.18 ms /    16 tokens\n",
      " 93%|โโโโโโโโโโ| 3245/3487 [9:07:27<33:05,  8.21s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2667.83 ms /    11 tokens (  242.53 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.86 ms /     3 runs   (  886.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5330.18 ms /    14 tokens\n",
      " 93%|โโโโโโโโโโ| 3246/3487 [9:07:33<29:30,  7.35s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2142.24 ms /     8 tokens (  267.78 ms per token,     3.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.35 ms /     3 runs   (  894.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4827.04 ms /    11 tokens\n",
      " 93%|โโโโโโโโโโ| 3247/3487 [9:07:37<26:22,  6.59s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8237.49 ms /    41 tokens (  200.91 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.23 ms /     3 runs   (  881.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10886.38 ms /    44 tokens\n",
      " 93%|โโโโโโโโโโ| 3248/3487 [9:07:48<31:24,  7.88s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8885.28 ms /    42 tokens (  211.55 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.83 ms /     3 runs   (  883.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11538.41 ms /    45 tokens\n",
      " 93%|โโโโโโโโโโ| 3249/3487 [9:08:00<35:37,  8.98s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3165.63 ms /    14 tokens (  226.12 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.83 ms /     3 runs   (  878.28 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5802.08 ms /    17 tokens\n",
      " 93%|โโโโโโโโโโ| 3250/3487 [9:08:06<31:43,  8.03s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3661.91 ms /    16 tokens (  228.87 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.28 ms /     3 runs   (  893.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6343.50 ms /    19 tokens\n",
      " 93%|โโโโโโโโโโ| 3251/3487 [9:08:12<29:36,  7.53s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1994.96 ms /     7 tokens (  284.99 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.05 ms /     3 runs   (  880.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4639.65 ms /    10 tokens\n",
      " 93%|โโโโโโโโโโ| 3252/3487 [9:08:17<26:05,  6.66s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9053.64 ms /    46 tokens (  196.82 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2799.58 ms /     3 runs   (  933.19 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   11855.91 ms /    49 tokens\n",
      " 93%|โโโโโโโโโโ| 3253/3487 [9:08:29<32:04,  8.22s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8059.36 ms /    39 tokens (  206.65 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.52 ms /     3 runs   (  885.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10718.70 ms /    42 tokens\n",
      " 93%|โโโโโโโโโโ| 3254/3487 [9:08:39<34:51,  8.97s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5597.16 ms /    27 tokens (  207.30 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.22 ms /     3 runs   (  907.74 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8323.12 ms /    30 tokens\n",
      " 93%|โโโโโโโโโโ| 3255/3487 [9:08:48<33:57,  8.78s/it]Llama.generate: 307 prefix-match hit, remaining 567 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =  105784.71 ms /   567 tokens (  186.57 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.80 ms /     3 runs   (  899.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =  108488.08 ms /   570 tokens\n",
      " 93%|โโโโโโโโโโ| 3256/3487 [9:10:36<2:28:59, 38.70s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2287.81 ms /     8 tokens (  285.98 ms per token,     3.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2749.06 ms /     3 runs   (  916.35 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5039.24 ms /    11 tokens\n",
      " 93%|โโโโโโโโโโ| 3257/3487 [9:10:41<1:49:38, 28.60s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3772.66 ms /    17 tokens (  221.92 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.89 ms /     3 runs   (  890.63 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6447.06 ms /    20 tokens\n",
      " 93%|โโโโโโโโโโ| 3258/3487 [9:10:48<1:23:48, 21.96s/it]Llama.generate: 312 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2952.50 ms /    12 tokens (  246.04 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.31 ms /     3 runs   (  891.10 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5628.05 ms /    15 tokens\n",
      " 93%|โโโโโโโโโโ| 3259/3487 [9:10:53<1:04:50, 17.06s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6459.65 ms /    31 tokens (  208.38 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.09 ms /     3 runs   (  906.70 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    9182.67 ms /    34 tokens\n",
      " 93%|โโโโโโโโโโ| 3260/3487 [9:11:02<55:37, 14.70s/it]  Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5491.61 ms /    26 tokens (  211.22 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.57 ms /     3 runs   (  894.52 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8177.14 ms /    29 tokens\n",
      " 94%|โโโโโโโโโโ| 3261/3487 [9:11:11<48:00, 12.75s/it]Llama.generate: 308 prefix-match hit, remaining 92 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17920.70 ms /    92 tokens (  194.79 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.24 ms /     3 runs   (  881.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20567.61 ms /    95 tokens\n",
      " 94%|โโโโโโโโโโ| 3262/3487 [9:11:31<56:36, 15.10s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4797.98 ms /    22 tokens (  218.09 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.76 ms /     3 runs   (  894.92 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7485.50 ms /    25 tokens\n",
      " 94%|โโโโโโโโโโ| 3263/3487 [9:11:39<47:50, 12.81s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5121.78 ms /    24 tokens (  213.41 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.10 ms /     3 runs   (  886.37 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7784.07 ms /    27 tokens\n",
      " 94%|โโโโโโโโโโ| 3264/3487 [9:11:46<42:01, 11.31s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2877.42 ms /    11 tokens (  261.58 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.51 ms /     3 runs   (  893.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5561.79 ms /    14 tokens\n",
      " 94%|โโโโโโโโโโ| 3265/3487 [9:11:52<35:28,  9.59s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3549.38 ms /    14 tokens (  253.53 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.16 ms /     3 runs   (  884.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6205.34 ms /    17 tokens\n",
      " 94%|โโโโโโโโโโ| 3266/3487 [9:11:58<31:35,  8.57s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7518.64 ms /    33 tokens (  227.84 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.74 ms /     3 runs   (  891.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10196.66 ms /    36 tokens\n",
      " 94%|โโโโโโโโโโ| 3267/3487 [9:12:08<33:14,  9.06s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9469.62 ms /    46 tokens (  205.86 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2741.35 ms /     3 runs   (  913.78 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   12213.77 ms /    49 tokens\n",
      " 94%|โโโโโโโโโโ| 3268/3487 [9:12:21<36:32, 10.01s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8281.97 ms /    40 tokens (  207.05 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.76 ms /     3 runs   (  889.25 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10952.59 ms /    43 tokens\n",
      " 94%|โโโโโโโโโโ| 3269/3487 [9:12:32<37:24, 10.30s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10571.77 ms /    54 tokens (  195.77 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.33 ms /     3 runs   (  882.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13221.96 ms /    57 tokens\n",
      " 94%|โโโโโโโโโโ| 3270/3487 [9:12:45<40:25, 11.18s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9666.02 ms /    50 tokens (  193.32 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.30 ms /     3 runs   (  892.43 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12345.73 ms /    53 tokens\n",
      " 94%|โโโโโโโโโโ| 3271/3487 [9:12:57<41:30, 11.53s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2550.99 ms /    10 tokens (  255.10 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.31 ms /     3 runs   (  891.77 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5228.91 ms /    13 tokens\n",
      " 94%|โโโโโโโโโโ| 3272/3487 [9:13:02<34:33,  9.64s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2939.31 ms /    12 tokens (  244.94 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.49 ms /     3 runs   (  890.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5614.64 ms /    15 tokens\n",
      " 94%|โโโโโโโโโโ| 3273/3487 [9:13:08<30:05,  8.44s/it]Llama.generate: 315 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8209.52 ms /    38 tokens (  216.04 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.14 ms /     3 runs   (  883.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10862.92 ms /    41 tokens\n",
      " 94%|โโโโโโโโโโ| 3274/3487 [9:13:19<32:32,  9.17s/it]Llama.generate: 328 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11329.69 ms /    56 tokens (  202.32 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.30 ms /     3 runs   (  884.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13986.36 ms /    59 tokens\n",
      " 94%|โโโโโโโโโโ| 3275/3487 [9:13:33<37:30, 10.62s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4333.24 ms /    20 tokens (  216.66 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.40 ms /     3 runs   (  902.13 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7041.70 ms /    23 tokens\n",
      " 94%|โโโโโโโโโโ| 3276/3487 [9:13:40<33:34,  9.55s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1435.82 ms /     4 tokens (  358.95 ms per token,     2.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2829.88 ms /     3 runs   (  943.29 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4268.52 ms /     7 tokens\n",
      " 94%|โโโโโโโโโโ| 3277/3487 [9:13:44<27:52,  7.96s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2833.43 ms /    11 tokens (  257.58 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.59 ms /     3 runs   (  883.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5485.60 ms /    14 tokens\n",
      " 94%|โโโโโโโโโโ| 3278/3487 [9:13:50<25:09,  7.22s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5172.40 ms /    25 tokens (  206.90 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.28 ms /     3 runs   (  907.76 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7897.81 ms /    28 tokens\n",
      " 94%|โโโโโโโโโโ| 3279/3487 [9:13:58<25:45,  7.43s/it]Llama.generate: 312 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3221.88 ms /    14 tokens (  230.13 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.66 ms /     3 runs   (  893.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5905.55 ms /    17 tokens\n",
      " 94%|โโโโโโโโโโ| 3280/3487 [9:14:04<24:03,  6.97s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2034.17 ms /     4 tokens (  508.54 ms per token,     1.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2801.54 ms /     3 runs   (  933.85 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4838.14 ms /     7 tokens\n",
      " 94%|โโโโโโโโโโ| 3281/3487 [9:14:08<21:45,  6.34s/it]Llama.generate: 311 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3391.72 ms /    14 tokens (  242.27 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.08 ms /     3 runs   (  890.03 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6064.29 ms /    17 tokens\n",
      " 94%|โโโโโโโโโโ| 3282/3487 [9:14:14<21:22,  6.26s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3295.02 ms /    13 tokens (  253.46 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.17 ms /     3 runs   (  902.06 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6003.59 ms /    16 tokens\n",
      " 94%|โโโโโโโโโโ| 3283/3487 [9:14:20<21:01,  6.18s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2310.06 ms /     9 tokens (  256.67 ms per token,     3.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.85 ms /     3 runs   (  900.95 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5015.58 ms /    12 tokens\n",
      " 94%|โโโโโโโโโโ| 3284/3487 [9:14:26<19:44,  5.84s/it]Llama.generate: 314 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3899.89 ms /     4 runs   (  974.97 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    3902.50 ms /     5 tokens\n",
      " 94%|โโโโโโโโโโ| 3285/3487 [9:14:29<17:42,  5.26s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7878.74 ms /    37 tokens (  212.94 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.78 ms /     3 runs   (  901.59 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10586.13 ms /    40 tokens\n",
      " 94%|โโโโโโโโโโ| 3286/3487 [9:14:40<22:58,  6.86s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3496.43 ms /    15 tokens (  233.10 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.81 ms /     3 runs   (  907.94 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6223.39 ms /    18 tokens\n",
      " 94%|โโโโโโโโโโ| 3287/3487 [9:14:46<22:14,  6.67s/it]Llama.generate: 314 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3320.61 ms /    12 tokens (  276.72 ms per token,     3.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.59 ms /     3 runs   (  887.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5984.12 ms /    15 tokens\n",
      " 94%|โโโโโโโโโโ| 3288/3487 [9:14:52<21:27,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3261.58 ms /    13 tokens (  250.89 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.35 ms /     3 runs   (  888.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5929.87 ms /    16 tokens\n",
      " 94%|โโโโโโโโโโ| 3289/3487 [9:14:58<20:49,  6.31s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2765.83 ms /    11 tokens (  251.44 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2775.08 ms /     3 runs   (  925.03 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5543.53 ms /    14 tokens\n",
      " 94%|โโโโโโโโโโ| 3290/3487 [9:15:04<19:57,  6.08s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3466.29 ms /    15 tokens (  231.09 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2736.10 ms /     3 runs   (  912.03 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6205.18 ms /    18 tokens\n",
      " 94%|โโโโโโโโโโ| 3291/3487 [9:15:10<19:59,  6.12s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1460.70 ms /     4 tokens (  365.18 ms per token,     2.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2844.63 ms /     3 runs   (  948.21 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4308.00 ms /     7 tokens\n",
      " 94%|โโโโโโโโโโ| 3292/3487 [9:15:14<18:08,  5.58s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2698.85 ms /    11 tokens (  245.35 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3233.84 ms /     3 runs   ( 1077.95 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    5934.50 ms /    14 tokens\n",
      " 94%|โโโโโโโโโโ| 3293/3487 [9:15:20<18:23,  5.69s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4276.03 ms /     9 tokens (  475.11 ms per token,     2.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4456.84 ms /     3 runs   ( 1485.61 ms per token,     0.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    8736.06 ms /    12 tokens\n",
      " 94%|โโโโโโโโโโ| 3294/3487 [9:15:29<21:14,  6.61s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9061.12 ms /    38 tokens (  238.45 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2895.03 ms /     3 runs   (  965.01 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   11959.33 ms /    41 tokens\n",
      " 94%|โโโโโโโโโโ| 3295/3487 [9:15:41<26:17,  8.21s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2712.52 ms /    10 tokens (  271.25 ms per token,     3.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2792.74 ms /     3 runs   (  930.91 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5507.98 ms /    13 tokens\n",
      " 95%|โโโโโโโโโโ| 3296/3487 [9:15:46<23:34,  7.40s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4014.23 ms /    17 tokens (  236.13 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.63 ms /     3 runs   (  889.21 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6684.09 ms /    20 tokens\n",
      " 95%|โโโโโโโโโโ| 3297/3487 [9:15:53<22:46,  7.19s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2299.10 ms /     9 tokens (  255.46 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2740.17 ms /     3 runs   (  913.39 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5042.16 ms /    12 tokens\n",
      " 95%|โโโโโโโโโโ| 3298/3487 [9:15:58<20:37,  6.55s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10111.59 ms /    49 tokens (  206.36 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.20 ms /     3 runs   (  887.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12777.49 ms /    52 tokens\n",
      " 95%|โโโโโโโโโโ| 3299/3487 [9:16:11<26:23,  8.42s/it]Llama.generate: 307 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13501.62 ms /    68 tokens (  198.55 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.66 ms /     3 runs   (  890.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16177.24 ms /    71 tokens\n",
      " 95%|โโโโโโโโโโ| 3300/3487 [9:16:27<33:30, 10.75s/it]Llama.generate: 308 prefix-match hit, remaining 89 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17285.87 ms /    89 tokens (  194.22 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.42 ms /     3 runs   (  887.81 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19952.24 ms /    92 tokens\n",
      " 95%|โโโโโโโโโโ| 3301/3487 [9:16:47<41:53, 13.51s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4770.61 ms /    23 tokens (  207.42 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.47 ms /     3 runs   (  905.49 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7489.58 ms /    26 tokens\n",
      " 95%|โโโโโโโโโโ| 3302/3487 [9:16:55<36:06, 11.71s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4937.15 ms /    24 tokens (  205.71 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2916.14 ms /     3 runs   (  972.05 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    7855.79 ms /    27 tokens\n",
      " 95%|โโโโโโโโโโ| 3303/3487 [9:17:02<32:22, 10.55s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3256.05 ms /    14 tokens (  232.57 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.84 ms /     3 runs   (  902.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5966.47 ms /    17 tokens\n",
      " 95%|โโโโโโโโโโ| 3304/3487 [9:17:08<28:00,  9.18s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5245.18 ms /    22 tokens (  238.42 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.20 ms /     3 runs   (  900.73 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7950.16 ms /    25 tokens\n",
      " 95%|โโโโโโโโโโ| 3305/3487 [9:17:16<26:44,  8.81s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2832.63 ms /    11 tokens (  257.51 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2764.49 ms /     3 runs   (  921.50 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5599.69 ms /    14 tokens\n",
      " 95%|โโโโโโโโโโ| 3306/3487 [9:17:22<23:41,  7.85s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1954.49 ms /     5 tokens (  390.90 ms per token,     2.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.32 ms /     3 runs   (  892.11 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4633.99 ms /     8 tokens\n",
      " 95%|โโโโโโโโโโ| 3307/3487 [9:17:27<20:40,  6.89s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2147.49 ms /     5 tokens (  429.50 ms per token,     2.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3083.55 ms /     3 runs   ( 1027.85 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    5233.47 ms /     8 tokens\n",
      " 95%|โโโโโโโโโโ| 3308/3487 [9:17:32<19:04,  6.40s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2740.63 ms /     5 tokens (  548.13 ms per token,     1.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2829.94 ms /     3 runs   (  943.31 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5574.11 ms /     8 tokens\n",
      " 95%|โโโโโโโโโโ| 3309/3487 [9:17:37<18:15,  6.15s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2633.26 ms /     8 tokens (  329.16 ms per token,     3.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2893.91 ms /     3 runs   (  964.64 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    5529.83 ms /    11 tokens\n",
      " 95%|โโโโโโโโโโ| 3310/3487 [9:17:43<17:36,  5.97s/it]Llama.generate: 308 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4966.59 ms /    19 tokens (  261.40 ms per token,     3.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2801.42 ms /     3 runs   (  933.81 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7770.51 ms /    22 tokens\n",
      " 95%|โโโโโโโโโโ| 3311/3487 [9:17:51<19:06,  6.51s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8660.70 ms /    34 tokens (  254.73 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.04 ms /     3 runs   (  908.35 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   11388.67 ms /    37 tokens\n",
      " 95%|โโโโโโโโโโ| 3312/3487 [9:18:02<23:16,  7.98s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5317.16 ms /    24 tokens (  221.55 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2756.83 ms /     3 runs   (  918.94 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8076.20 ms /    27 tokens\n",
      " 95%|โโโโโโโโโโ| 3313/3487 [9:18:10<23:13,  8.01s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4152.75 ms /    18 tokens (  230.71 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.24 ms /     3 runs   (  892.75 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6833.37 ms /    21 tokens\n",
      " 95%|โโโโโโโโโโ| 3314/3487 [9:18:17<22:05,  7.66s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2440.15 ms /     6 tokens (  406.69 ms per token,     2.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.04 ms /     3 runs   (  888.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5107.48 ms /     9 tokens\n",
      " 95%|โโโโโโโโโโ| 3315/3487 [9:18:22<19:46,  6.90s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3807.23 ms /    17 tokens (  223.95 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.87 ms /     3 runs   (  895.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6496.07 ms /    20 tokens\n",
      " 95%|โโโโโโโโโโ| 3316/3487 [9:18:29<19:19,  6.78s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9790.10 ms /    49 tokens (  199.80 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.52 ms /     3 runs   (  889.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12462.02 ms /    52 tokens\n",
      " 95%|โโโโโโโโโโ| 3317/3487 [9:18:41<24:02,  8.49s/it]Llama.generate: 306 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14676.77 ms /    76 tokens (  193.12 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.22 ms /     3 runs   (  884.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17333.06 ms /    79 tokens\n",
      " 95%|โโโโโโโโโโ| 3318/3487 [9:18:59<31:22, 11.14s/it]Llama.generate: 307 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12423.53 ms /    64 tokens (  194.12 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.92 ms /     3 runs   (  897.31 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   15117.41 ms /    67 tokens\n",
      " 95%|โโโโโโโโโโ| 3319/3487 [9:19:14<34:32, 12.34s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3224.21 ms /    13 tokens (  248.02 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.88 ms /     3 runs   (  898.63 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5922.43 ms /    16 tokens\n",
      " 95%|โโโโโโโโโโ| 3320/3487 [9:19:20<28:59, 10.41s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16372.59 ms /    86 tokens (  190.38 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.52 ms /     3 runs   (  888.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19040.61 ms /    89 tokens\n",
      " 95%|โโโโโโโโโโ| 3321/3487 [9:19:39<35:58, 13.00s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6339.90 ms /    29 tokens (  218.62 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.28 ms /     3 runs   (  886.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9000.38 ms /    32 tokens\n",
      " 95%|โโโโโโโโโโ| 3322/3487 [9:19:48<32:27, 11.81s/it]Llama.generate: 335 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4067.67 ms /     4 runs   ( 1016.92 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    4070.55 ms /     5 tokens\n",
      " 95%|โโโโโโโโโโ| 3323/3487 [9:19:52<25:56,  9.49s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4875.77 ms /    23 tokens (  211.99 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.73 ms /     3 runs   (  893.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7557.95 ms /    26 tokens\n",
      " 95%|โโโโโโโโโโ| 3324/3487 [9:19:59<24:12,  8.91s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3237.71 ms /    13 tokens (  249.05 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.97 ms /     3 runs   (  894.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5925.23 ms /    16 tokens\n",
      " 95%|โโโโโโโโโโ| 3325/3487 [9:20:05<21:38,  8.02s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2310.18 ms /     8 tokens (  288.77 ms per token,     3.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.82 ms /     3 runs   (  901.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5017.29 ms /    11 tokens\n",
      " 95%|โโโโโโโโโโ| 3326/3487 [9:20:10<19:06,  7.12s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7779.79 ms /    36 tokens (  216.11 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.73 ms /     3 runs   (  883.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10433.94 ms /    39 tokens\n",
      " 95%|โโโโโโโโโโ| 3327/3487 [9:20:21<21:38,  8.12s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2688.69 ms /    10 tokens (  268.87 ms per token,     3.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.95 ms /     3 runs   (  898.32 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5386.43 ms /    13 tokens\n",
      " 95%|โโโโโโโโโโ| 3328/3487 [9:20:26<19:20,  7.30s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5259.51 ms /    22 tokens (  239.07 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.23 ms /     3 runs   (  885.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7918.77 ms /    25 tokens\n",
      " 95%|โโโโโโโโโโ| 3329/3487 [9:20:34<19:43,  7.49s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3771.35 ms /    14 tokens (  269.38 ms per token,     3.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3234.22 ms /     3 runs   ( 1078.08 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    7008.75 ms /    17 tokens\n",
      " 95%|โโโโโโโโโโ| 3330/3487 [9:20:41<19:13,  7.35s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3374.17 ms /    10 tokens (  337.42 ms per token,     2.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3213.14 ms /     3 runs   ( 1071.05 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    6590.68 ms /    13 tokens\n",
      " 96%|โโโโโโโโโโ| 3331/3487 [9:20:48<18:31,  7.12s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6360.59 ms /    30 tokens (  212.02 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.24 ms /     3 runs   (  888.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9029.55 ms /    33 tokens\n",
      " 96%|โโโโโโโโโโ| 3332/3487 [9:20:57<19:53,  7.70s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2647.98 ms /    10 tokens (  264.80 ms per token,     3.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.98 ms /     3 runs   (  891.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5326.58 ms /    13 tokens\n",
      " 96%|โโโโโโโโโโ| 3333/3487 [9:21:02<17:56,  6.99s/it]Llama.generate: 306 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13620.44 ms /    67 tokens (  203.29 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.23 ms /     3 runs   (  893.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16303.39 ms /    70 tokens\n",
      " 96%|โโโโโโโโโโ| 3334/3487 [9:21:18<24:57,  9.79s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2659.64 ms /    10 tokens (  265.96 ms per token,     3.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.83 ms /     3 runs   (  892.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5340.77 ms /    13 tokens\n",
      " 96%|โโโโโโโโโโ| 3335/3487 [9:21:24<21:25,  8.46s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3415.56 ms /    12 tokens (  284.63 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.68 ms /     3 runs   (  880.56 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6059.68 ms /    15 tokens\n",
      " 96%|โโโโโโโโโโ| 3336/3487 [9:21:30<19:28,  7.74s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2830.26 ms /    11 tokens (  257.30 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.11 ms /     3 runs   (  891.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5507.48 ms /    14 tokens\n",
      " 96%|โโโโโโโโโโ| 3337/3487 [9:21:35<17:40,  7.07s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4863.12 ms /    24 tokens (  202.63 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.74 ms /     3 runs   (  886.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7524.25 ms /    27 tokens\n",
      " 96%|โโโโโโโโโโ| 3338/3487 [9:21:43<17:54,  7.21s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2903.75 ms /    12 tokens (  241.98 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.63 ms /     3 runs   (  888.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5571.38 ms /    15 tokens\n",
      " 96%|โโโโโโโโโโ| 3339/3487 [9:21:48<16:34,  6.72s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4601.17 ms /    21 tokens (  219.10 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.57 ms /     3 runs   (  883.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7254.27 ms /    24 tokens\n",
      " 96%|โโโโโโโโโโ| 3340/3487 [9:21:56<16:51,  6.88s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3778.60 ms /    17 tokens (  222.27 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.56 ms /     3 runs   (  895.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6468.66 ms /    20 tokens\n",
      " 96%|โโโโโโโโโโ| 3341/3487 [9:22:02<16:27,  6.76s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2970.65 ms /    10 tokens (  297.06 ms per token,     3.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.97 ms /     3 runs   (  894.32 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5656.03 ms /    13 tokens\n",
      " 96%|โโโโโโโโโโ| 3342/3487 [9:22:08<15:32,  6.43s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11439.39 ms /    57 tokens (  200.69 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.74 ms /     3 runs   (  895.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14129.96 ms /    60 tokens\n",
      " 96%|โโโโโโโโโโ| 3343/3487 [9:22:22<20:59,  8.74s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2897.34 ms /    12 tokens (  241.44 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2732.28 ms /     3 runs   (  910.76 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5633.21 ms /    15 tokens\n",
      " 96%|โโโโโโโโโโ| 3344/3487 [9:22:28<18:37,  7.81s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2207.12 ms /     8 tokens (  275.89 ms per token,     3.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.69 ms /     3 runs   (  881.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4854.37 ms /    11 tokens\n",
      " 96%|โโโโโโโโโโ| 3345/3487 [9:22:32<16:23,  6.93s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1796.42 ms /     6 tokens (  299.40 ms per token,     3.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.93 ms /     3 runs   (  894.31 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4482.39 ms /     9 tokens\n",
      " 96%|โโโโโโโโโโ| 3346/3487 [9:22:37<14:33,  6.20s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3614.57 ms /    16 tokens (  225.91 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.44 ms /     3 runs   (  901.81 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6323.04 ms /    19 tokens\n",
      " 96%|โโโโโโโโโโ| 3347/3487 [9:22:43<14:33,  6.24s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2658.84 ms /    10 tokens (  265.88 ms per token,     3.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.88 ms /     3 runs   (  913.29 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5401.55 ms /    13 tokens\n",
      " 96%|โโโโโโโโโโ| 3348/3487 [9:22:49<13:52,  5.99s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4320.91 ms /    19 tokens (  227.42 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.06 ms /     3 runs   (  882.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6971.75 ms /    22 tokens\n",
      " 96%|โโโโโโโโโโ| 3349/3487 [9:22:56<14:27,  6.29s/it]Llama.generate: 313 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5582.30 ms /    25 tokens (  223.29 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.93 ms /     3 runs   (  887.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8247.60 ms /    28 tokens\n",
      " 96%|โโโโโโโโโโ| 3350/3487 [9:23:04<15:42,  6.88s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5458.88 ms /    27 tokens (  202.18 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.75 ms /     3 runs   (  899.58 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8160.19 ms /    30 tokens\n",
      " 96%|โโโโโโโโโโ| 3351/3487 [9:23:12<16:28,  7.27s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2315.04 ms /     8 tokens (  289.38 ms per token,     3.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.22 ms /     3 runs   (  890.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4989.79 ms /    11 tokens\n",
      " 96%|โโโโโโโโโโ| 3352/3487 [9:23:17<14:49,  6.59s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4919.20 ms /    23 tokens (  213.88 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.50 ms /     3 runs   (  879.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7560.80 ms /    26 tokens\n",
      " 96%|โโโโโโโโโโ| 3353/3487 [9:23:25<15:21,  6.88s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5118.72 ms /    24 tokens (  213.28 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.68 ms /     3 runs   (  898.56 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7816.81 ms /    27 tokens\n",
      " 96%|โโโโโโโโโโ| 3354/3487 [9:23:32<15:52,  7.16s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3268.15 ms /    13 tokens (  251.40 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.19 ms /     3 runs   (  893.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5950.94 ms /    16 tokens\n",
      " 96%|โโโโโโโโโโ| 3355/3487 [9:23:38<14:57,  6.80s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4793.23 ms /    23 tokens (  208.40 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.51 ms /     3 runs   (  893.17 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7475.91 ms /    26 tokens\n",
      " 96%|โโโโโโโโโโ| 3356/3487 [9:23:46<15:17,  7.01s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3120.73 ms /    10 tokens (  312.07 ms per token,     3.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.27 ms /     3 runs   (  876.76 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5753.75 ms /    13 tokens\n",
      " 96%|โโโโโโโโโโ| 3357/3487 [9:23:52<14:22,  6.63s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3797.21 ms /    17 tokens (  223.37 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.55 ms /     3 runs   (  894.18 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6481.99 ms /    20 tokens\n",
      " 96%|โโโโโโโโโโ| 3358/3487 [9:23:58<14:10,  6.59s/it]Llama.generate: 322 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4068.96 ms /     4 runs   ( 1017.24 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    4071.73 ms /     5 tokens\n",
      " 96%|โโโโโโโโโโ| 3359/3487 [9:24:02<12:27,  5.84s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9129.94 ms /    45 tokens (  202.89 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.97 ms /     3 runs   (  884.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11786.90 ms /    48 tokens\n",
      " 96%|โโโโโโโโโโ| 3360/3487 [9:24:14<16:08,  7.62s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3729.64 ms /    16 tokens (  233.10 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.63 ms /     3 runs   (  906.88 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6453.26 ms /    19 tokens\n",
      " 96%|โโโโโโโโโโ| 3361/3487 [9:24:21<15:16,  7.28s/it]Llama.generate: 322 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4053.40 ms /     4 runs   ( 1013.35 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    4055.91 ms /     5 tokens\n",
      " 96%|โโโโโโโโโโ| 3362/3487 [9:24:25<13:09,  6.31s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6169.03 ms /    29 tokens (  212.73 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2977.20 ms /     3 runs   (  992.40 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    9149.62 ms /    32 tokens\n",
      " 96%|โโโโโโโโโโ| 3363/3487 [9:24:34<14:48,  7.17s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4266.76 ms /    19 tokens (  224.57 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2797.52 ms /     3 runs   (  932.51 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7066.86 ms /    22 tokens\n",
      " 96%|โโโโโโโโโโ| 3364/3487 [9:24:41<14:38,  7.14s/it]Llama.generate: 318 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1549.11 ms /     5 tokens (  309.82 ms per token,     3.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2831.25 ms /     3 runs   (  943.75 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4383.16 ms /     8 tokens\n",
      " 97%|โโโโโโโโโโ| 3365/3487 [9:24:45<12:50,  6.32s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3979.53 ms /    18 tokens (  221.09 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.66 ms /     3 runs   (  889.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6650.45 ms /    21 tokens\n",
      " 97%|โโโโโโโโโโ| 3366/3487 [9:24:52<12:56,  6.42s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3904.30 ms /    16 tokens (  244.02 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2718.25 ms /     3 runs   (  906.08 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6625.10 ms /    19 tokens\n",
      " 97%|โโโโโโโโโโ| 3367/3487 [9:24:58<12:57,  6.48s/it]Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9115.03 ms /    44 tokens (  207.16 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2834.02 ms /     3 runs   (  944.67 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   11951.77 ms /    47 tokens\n",
      " 97%|โโโโโโโโโโ| 3368/3487 [9:25:10<16:07,  8.13s/it]Llama.generate: 318 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3351.05 ms /    12 tokens (  279.25 ms per token,     3.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.87 ms /     3 runs   (  903.62 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6064.39 ms /    15 tokens\n",
      " 97%|โโโโโโโโโโ| 3369/3487 [9:25:17<14:46,  7.51s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4387.18 ms /    19 tokens (  230.90 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.41 ms /     3 runs   (  891.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7064.62 ms /    22 tokens\n",
      " 97%|โโโโโโโโโโ| 3370/3487 [9:25:24<14:23,  7.38s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5389.14 ms /    26 tokens (  207.27 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.20 ms /     3 runs   (  889.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8059.27 ms /    29 tokens\n",
      " 97%|โโโโโโโโโโ| 3371/3487 [9:25:32<14:39,  7.59s/it]Llama.generate: 317 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1561.62 ms /     4 tokens (  390.41 ms per token,     2.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2895.74 ms /     3 runs   (  965.25 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4459.62 ms /     7 tokens\n",
      " 97%|โโโโโโโโโโ| 3372/3487 [9:25:36<12:44,  6.65s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3000.17 ms /    12 tokens (  250.01 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.55 ms /     3 runs   (  888.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5667.31 ms /    15 tokens\n",
      " 97%|โโโโโโโโโโ| 3373/3487 [9:25:42<12:04,  6.36s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3403.29 ms /    14 tokens (  243.09 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.72 ms /     3 runs   (  907.57 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6128.55 ms /    17 tokens\n",
      " 97%|โโโโโโโโโโ| 3374/3487 [9:25:48<11:51,  6.29s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4117.93 ms /    17 tokens (  242.23 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.25 ms /     3 runs   (  885.08 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6775.78 ms /    20 tokens\n",
      " 97%|โโโโโโโโโโ| 3375/3487 [9:25:55<12:01,  6.44s/it]Llama.generate: 314 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1397.78 ms /     4 tokens (  349.45 ms per token,     2.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2904.43 ms /     3 runs   (  968.14 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    4304.70 ms /     7 tokens\n",
      " 97%|โโโโโโโโโโ| 3376/3487 [9:25:59<10:44,  5.80s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5481.65 ms /    26 tokens (  210.83 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2977.76 ms /     3 runs   (  992.59 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    8463.32 ms /    29 tokens\n",
      " 97%|โโโโโโโโโโ| 3377/3487 [9:26:08<12:06,  6.60s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4409.14 ms /    20 tokens (  220.46 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.33 ms /     3 runs   (  888.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7075.86 ms /    23 tokens\n",
      " 97%|โโโโโโโโโโ| 3378/3487 [9:26:15<12:15,  6.75s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1573.22 ms /     5 tokens (  314.64 ms per token,     3.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2872.03 ms /     3 runs   (  957.34 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4448.10 ms /     8 tokens\n",
      " 97%|โโโโโโโโโโ| 3379/3487 [9:26:19<10:54,  6.06s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7496.81 ms /    36 tokens (  208.24 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.80 ms /     3 runs   (  893.93 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10181.32 ms /    39 tokens\n",
      " 97%|โโโโโโโโโโ| 3380/3487 [9:26:29<13:00,  7.30s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5053.07 ms /    22 tokens (  229.69 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.17 ms /     3 runs   (  894.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7737.77 ms /    25 tokens\n",
      " 97%|โโโโโโโโโโ| 3381/3487 [9:26:37<13:07,  7.43s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3635.36 ms /    16 tokens (  227.21 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.36 ms /     3 runs   (  892.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6316.65 ms /    19 tokens\n",
      " 97%|โโโโโโโโโโ| 3382/3487 [9:26:43<12:25,  7.10s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7772.24 ms /    38 tokens (  204.53 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.96 ms /     3 runs   (  883.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10426.09 ms /    41 tokens\n",
      " 97%|โโโโโโโโโโ| 3383/3487 [9:26:54<14:02,  8.10s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7684.85 ms /    38 tokens (  202.23 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2871.60 ms /     3 runs   (  957.20 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   10559.31 ms /    41 tokens\n",
      " 97%|โโโโโโโโโโ| 3384/3487 [9:27:04<15:10,  8.84s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4623.94 ms /    20 tokens (  231.20 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3136.70 ms /     3 runs   ( 1045.57 ms per token,     0.96 tokens per second)\n",
      "llama_perf_context_print:       total time =    7763.00 ms /    23 tokens\n",
      " 97%|โโโโโโโโโโ| 3385/3487 [9:27:12<14:28,  8.52s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5473.69 ms /    24 tokens (  228.07 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.75 ms /     3 runs   (  897.92 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8169.90 ms /    27 tokens\n",
      " 97%|โโโโโโโโโโ| 3386/3487 [9:27:20<14:10,  8.42s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3513.74 ms /    15 tokens (  234.25 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.50 ms /     3 runs   (  897.83 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6209.80 ms /    18 tokens\n",
      " 97%|โโโโโโโโโโ| 3387/3487 [9:27:26<12:55,  7.76s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6243.85 ms /    28 tokens (  222.99 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.29 ms /     3 runs   (  883.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8896.54 ms /    31 tokens\n",
      " 97%|โโโโโโโโโโ| 3388/3487 [9:27:35<13:22,  8.10s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3449.12 ms /    15 tokens (  229.94 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.14 ms /     3 runs   (  896.71 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6141.37 ms /    18 tokens\n",
      " 97%|โโโโโโโโโโ| 3389/3487 [9:27:42<12:16,  7.52s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3094.01 ms /    13 tokens (  238.00 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.79 ms /     3 runs   (  903.26 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5806.74 ms /    16 tokens\n",
      " 97%|โโโโโโโโโโ| 3390/3487 [9:27:47<11:19,  7.01s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5348.88 ms /    25 tokens (  213.96 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.14 ms /     3 runs   (  879.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7989.47 ms /    28 tokens\n",
      " 97%|โโโโโโโโโโ| 3391/3487 [9:27:55<11:41,  7.30s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3139.30 ms /    13 tokens (  241.48 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2824.31 ms /     3 runs   (  941.44 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5966.21 ms /    16 tokens\n",
      " 97%|โโโโโโโโโโ| 3392/3487 [9:28:01<10:55,  6.90s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3870.05 ms /    16 tokens (  241.88 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.49 ms /     3 runs   (  889.16 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6541.74 ms /    19 tokens\n",
      " 97%|โโโโโโโโโโ| 3393/3487 [9:28:08<10:39,  6.80s/it]Llama.generate: 314 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1492.13 ms /     4 tokens (  373.03 ms per token,     2.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2861.17 ms /     3 runs   (  953.72 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4355.62 ms /     7 tokens\n",
      " 97%|โโโโโโโโโโ| 3394/3487 [9:28:12<09:24,  6.07s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7948.41 ms /    36 tokens (  220.79 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.77 ms /     3 runs   (  884.26 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10603.65 ms /    39 tokens\n",
      " 97%|โโโโโโโโโโ| 3395/3487 [9:28:23<11:23,  7.43s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2684.54 ms /    11 tokens (  244.05 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.29 ms /     3 runs   (  902.10 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5393.47 ms /    14 tokens\n",
      " 97%|โโโโโโโโโโ| 3396/3487 [9:28:28<10:20,  6.82s/it]Llama.generate: 317 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3852.85 ms /     4 runs   (  963.21 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    3855.41 ms /     5 tokens\n",
      " 97%|โโโโโโโโโโ| 3397/3487 [9:28:32<08:54,  5.94s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4832.09 ms /    22 tokens (  219.64 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.21 ms /     3 runs   (  884.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7488.10 ms /    25 tokens\n",
      " 97%|โโโโโโโโโโ| 3398/3487 [9:28:40<09:29,  6.40s/it]Llama.generate: 317 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1440.80 ms /     4 tokens (  360.20 ms per token,     2.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2803.76 ms /     3 runs   (  934.59 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4246.78 ms /     7 tokens\n",
      " 97%|โโโโโโโโโโ| 3399/3487 [9:28:44<08:26,  5.76s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4513.83 ms /    21 tokens (  214.94 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.26 ms /     3 runs   (  881.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7159.76 ms /    24 tokens\n",
      " 98%|โโโโโโโโโโ| 3400/3487 [9:28:51<08:57,  6.18s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6442.47 ms /    32 tokens (  201.33 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2777.14 ms /     3 runs   (  925.71 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    9221.89 ms /    35 tokens\n",
      " 98%|โโโโโโโโโโ| 3401/3487 [9:29:00<10:10,  7.10s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4709.51 ms /    19 tokens (  247.87 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.79 ms /     3 runs   (  875.60 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7339.04 ms /    22 tokens\n",
      " 98%|โโโโโโโโโโ| 3402/3487 [9:29:08<10:09,  7.17s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5062.36 ms /    24 tokens (  210.93 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.13 ms /     3 runs   (  897.04 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7756.23 ms /    27 tokens\n",
      " 98%|โโโโโโโโโโ| 3403/3487 [9:29:15<10:17,  7.35s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1740.27 ms /     6 tokens (  290.05 ms per token,     3.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2830.24 ms /     3 runs   (  943.41 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4572.95 ms /     9 tokens\n",
      " 98%|โโโโโโโโโโ| 3404/3487 [9:29:20<09:01,  6.52s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12491.92 ms /    42 tokens (  297.43 ms per token,     3.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3976.23 ms /     4 runs   (  994.06 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   16502.94 ms /    46 tokens\n",
      " 98%|โโโโโโโโโโ| 3405/3487 [9:29:36<13:00,  9.52s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2600.55 ms /     8 tokens (  325.07 ms per token,     3.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2843.05 ms /     3 runs   (  947.68 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5446.57 ms /    11 tokens\n",
      " 98%|โโโโโโโโโโ| 3406/3487 [9:29:42<11:12,  8.30s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2804.87 ms /    10 tokens (  280.49 ms per token,     3.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3153.84 ms /     3 runs   ( 1051.28 ms per token,     0.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    5961.45 ms /    13 tokens\n",
      " 98%|โโโโโโโโโโ| 3407/3487 [9:29:48<10:07,  7.60s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9054.64 ms /    31 tokens (  292.08 ms per token,     3.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3155.33 ms /     3 runs   ( 1051.78 ms per token,     0.95 tokens per second)\n",
      "llama_perf_context_print:       total time =   12212.74 ms /    34 tokens\n",
      " 98%|โโโโโโโโโโ| 3408/3487 [9:30:00<11:49,  8.99s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4033.55 ms /     9 tokens (  448.17 ms per token,     2.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3391.59 ms /     3 runs   ( 1130.53 ms per token,     0.88 tokens per second)\n",
      "llama_perf_context_print:       total time =    7428.59 ms /    12 tokens\n",
      " 98%|โโโโโโโโโโ| 3409/3487 [9:30:08<11:04,  8.52s/it]Llama.generate: 310 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1985.72 ms /     4 tokens (  496.43 ms per token,     2.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2844.23 ms /     3 runs   (  948.08 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4833.11 ms /     7 tokens\n",
      " 98%|โโโโโโโโโโ| 3410/3487 [9:30:12<09:31,  7.42s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6355.55 ms /    29 tokens (  219.16 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.68 ms /     3 runs   (  908.23 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    9082.35 ms /    32 tokens\n",
      " 98%|โโโโโโโโโโ| 3411/3487 [9:30:21<10:01,  7.92s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5864.60 ms /    27 tokens (  217.21 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.42 ms /     3 runs   (  893.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8547.57 ms /    30 tokens\n",
      " 98%|โโโโโโโโโโ| 3412/3487 [9:30:30<10:08,  8.11s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3479.54 ms /    14 tokens (  248.54 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.87 ms /     3 runs   (  892.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6159.73 ms /    17 tokens\n",
      " 98%|โโโโโโโโโโ| 3413/3487 [9:30:36<09:17,  7.53s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1919.58 ms /     6 tokens (  319.93 ms per token,     3.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.25 ms /     3 runs   (  898.42 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4617.32 ms /     9 tokens\n",
      " 98%|โโโโโโโโโโ| 3414/3487 [9:30:41<08:05,  6.66s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3829.18 ms /    15 tokens (  255.28 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.47 ms /     3 runs   (  902.82 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6540.08 ms /    18 tokens\n",
      " 98%|โโโโโโโโโโ| 3415/3487 [9:30:47<07:56,  6.62s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7519.42 ms /    35 tokens (  214.84 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.14 ms /     3 runs   (  886.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10180.75 ms /    38 tokens\n",
      " 98%|โโโโโโโโโโ| 3416/3487 [9:30:58<09:06,  7.69s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4464.81 ms /    21 tokens (  212.61 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4207.88 ms /     3 runs   ( 1402.62 ms per token,     0.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    8675.52 ms /    24 tokens\n",
      " 98%|โโโโโโโโโโ| 3417/3487 [9:31:06<09:19,  7.99s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3771.25 ms /    10 tokens (  377.13 ms per token,     2.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3257.55 ms /     3 runs   ( 1085.85 ms per token,     0.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    7031.39 ms /    13 tokens\n",
      " 98%|โโโโโโโโโโ| 3418/3487 [9:31:13<08:51,  7.71s/it]Llama.generate: 306 prefix-match hit, remaining 235 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   44857.47 ms /   235 tokens (  190.88 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.42 ms /     3 runs   (  885.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   47516.25 ms /   238 tokens\n",
      " 98%|โโโโโโโโโโ| 3419/3487 [9:32:01<22:16, 19.65s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14490.16 ms /    74 tokens (  195.81 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2904.74 ms /     3 runs   (  968.25 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   17397.59 ms /    77 tokens\n",
      " 98%|โโโโโโโโโโ| 3420/3487 [9:32:18<21:11, 18.98s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1528.87 ms /     5 tokens (  305.77 ms per token,     3.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2865.14 ms /     3 runs   (  955.05 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4396.02 ms /     8 tokens\n",
      " 98%|โโโโโโโโโโ| 3421/3487 [9:32:23<16:04, 14.61s/it]Llama.generate: 306 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16365.31 ms /    83 tokens (  197.17 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.49 ms /     3 runs   (  880.50 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19009.55 ms /    86 tokens\n",
      " 98%|โโโโโโโโโโ| 3422/3487 [9:32:42<17:15, 15.93s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5377.23 ms /    26 tokens (  206.82 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.57 ms /     3 runs   (  908.52 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8105.53 ms /    29 tokens\n",
      " 98%|โโโโโโโโโโ| 3423/3487 [9:32:50<14:29, 13.58s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9578.26 ms /    48 tokens (  199.55 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.06 ms /     3 runs   (  878.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12214.18 ms /    51 tokens\n",
      " 98%|โโโโโโโโโโ| 3424/3487 [9:33:02<13:50, 13.18s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4640.25 ms /    22 tokens (  210.92 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.10 ms /     3 runs   (  891.03 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7315.95 ms /    25 tokens\n",
      " 98%|โโโโโโโโโโ| 3425/3487 [9:33:09<11:48, 11.42s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7475.89 ms /    34 tokens (  219.88 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.60 ms /     3 runs   (  890.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10149.93 ms /    37 tokens\n",
      " 98%|โโโโโโโโโโ| 3426/3487 [9:33:19<11:13, 11.04s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3170.30 ms /    13 tokens (  243.87 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.66 ms /     3 runs   (  910.55 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5904.42 ms /    16 tokens\n",
      " 98%|โโโโโโโโโโ| 3427/3487 [9:33:25<09:30,  9.50s/it]Llama.generate: 308 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3484.25 ms /    15 tokens (  232.28 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.63 ms /     3 runs   (  881.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6130.37 ms /    18 tokens\n",
      " 98%|โโโโโโโโโโ| 3428/3487 [9:33:32<08:21,  8.49s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3708.05 ms /    13 tokens (  285.23 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.95 ms /     3 runs   (  884.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6364.95 ms /    16 tokens\n",
      " 98%|โโโโโโโโโโ| 3429/3487 [9:33:38<07:35,  7.86s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3082.16 ms /    13 tokens (  237.09 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.27 ms /     3 runs   (  883.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5734.91 ms /    16 tokens\n",
      " 98%|โโโโโโโโโโ| 3430/3487 [9:33:44<06:51,  7.22s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9787.04 ms /    49 tokens (  199.74 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.91 ms /     3 runs   (  881.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12434.59 ms /    52 tokens\n",
      " 98%|โโโโโโโโโโ| 3431/3487 [9:33:56<08:12,  8.79s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3268.10 ms /    13 tokens (  251.39 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.11 ms /     3 runs   (  904.04 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5982.34 ms /    16 tokens\n",
      " 98%|โโโโโโโโโโ| 3432/3487 [9:34:02<07:17,  7.95s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4163.97 ms /    19 tokens (  219.16 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.03 ms /     3 runs   (  889.34 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6834.46 ms /    22 tokens\n",
      " 98%|โโโโโโโโโโ| 3433/3487 [9:34:09<06:51,  7.62s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2735.01 ms /    10 tokens (  273.50 ms per token,     3.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.42 ms /     3 runs   (  896.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5425.95 ms /    13 tokens\n",
      " 98%|โโโโโโโโโโ| 3434/3487 [9:34:14<06:09,  6.96s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5068.61 ms /    24 tokens (  211.19 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.76 ms /     3 runs   (  880.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7714.00 ms /    27 tokens\n",
      " 99%|โโโโโโโโโโ| 3435/3487 [9:34:22<06:13,  7.19s/it]Llama.generate: 309 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3135.34 ms /    11 tokens (  285.03 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.00 ms /     3 runs   (  882.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5783.44 ms /    14 tokens\n",
      " 99%|โโโโโโโโโโ| 3436/3487 [9:34:28<05:45,  6.77s/it]Llama.generate: 319 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3903.02 ms /     4 runs   (  975.76 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    3906.27 ms /     5 tokens\n",
      " 99%|โโโโโโโโโโ| 3437/3487 [9:34:32<04:55,  5.91s/it]Llama.generate: 319 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3868.79 ms /     4 runs   (  967.20 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    3871.30 ms /     5 tokens\n",
      " 99%|โโโโโโโโโโ| 3438/3487 [9:34:36<04:19,  5.30s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3199.32 ms /    13 tokens (  246.10 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2755.19 ms /     3 runs   (  918.40 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5957.41 ms /    16 tokens\n",
      " 99%|โโโโโโโโโโ| 3439/3487 [9:34:42<04:24,  5.50s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3253.09 ms /    13 tokens (  250.24 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.15 ms /     3 runs   (  884.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5909.11 ms /    16 tokens\n",
      " 99%|โโโโโโโโโโ| 3440/3487 [9:34:48<04:24,  5.63s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3173.94 ms /    13 tokens (  244.15 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.42 ms /     3 runs   (  904.47 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5889.62 ms /    16 tokens\n",
      " 99%|โโโโโโโโโโ| 3441/3487 [9:34:53<04:22,  5.71s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3095.18 ms /    13 tokens (  238.09 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.87 ms /     3 runs   (  898.29 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5793.13 ms /    16 tokens\n",
      " 99%|โโโโโโโโโโ| 3442/3487 [9:34:59<04:18,  5.74s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3484.69 ms /    13 tokens (  268.05 ms per token,     3.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.74 ms /     3 runs   (  879.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6127.23 ms /    16 tokens\n",
      " 99%|โโโโโโโโโโ| 3443/3487 [9:35:05<04:17,  5.86s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11485.15 ms /    59 tokens (  194.66 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.92 ms /     3 runs   (  879.64 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14126.98 ms /    62 tokens\n",
      " 99%|โโโโโโโโโโ| 3444/3487 [9:35:20<05:58,  8.34s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5564.89 ms /    27 tokens (  206.11 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.87 ms /     3 runs   (  892.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8244.92 ms /    30 tokens\n",
      " 99%|โโโโโโโโโโ| 3445/3487 [9:35:28<05:49,  8.31s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3146.76 ms /    13 tokens (  242.06 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.84 ms /     3 runs   (  892.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5825.82 ms /    16 tokens\n",
      " 99%|โโโโโโโโโโ| 3446/3487 [9:35:34<05:10,  7.57s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3208.81 ms /    13 tokens (  246.83 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.18 ms /     3 runs   (  878.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5846.54 ms /    16 tokens\n",
      " 99%|โโโโโโโโโโ| 3447/3487 [9:35:39<04:42,  7.06s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3303.12 ms /    14 tokens (  235.94 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.69 ms /     3 runs   (  886.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5966.68 ms /    17 tokens\n",
      " 99%|โโโโโโโโโโ| 3448/3487 [9:35:45<04:22,  6.73s/it]Llama.generate: 313 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4814.69 ms /    23 tokens (  209.33 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.89 ms /     3 runs   (  890.63 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7489.31 ms /    26 tokens\n",
      " 99%|โโโโโโโโโโ| 3449/3487 [9:35:53<04:24,  6.96s/it]Llama.generate: 316 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2138.46 ms /     4 tokens (  534.61 ms per token,     1.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.18 ms /     3 runs   (  879.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4780.82 ms /     7 tokens\n",
      " 99%|โโโโโโโโโโ| 3450/3487 [9:35:58<03:53,  6.31s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3171.64 ms /    13 tokens (  243.97 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.86 ms /     3 runs   (  887.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5837.71 ms /    16 tokens\n",
      " 99%|โโโโโโโโโโ| 3451/3487 [9:36:04<03:42,  6.17s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4858.20 ms /    22 tokens (  220.83 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2836.71 ms /     3 runs   (  945.57 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7698.18 ms /    25 tokens\n",
      " 99%|โโโโโโโโโโ| 3452/3487 [9:36:11<03:52,  6.63s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2388.98 ms /     8 tokens (  298.62 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2737.62 ms /     3 runs   (  912.54 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5129.43 ms /    11 tokens\n",
      " 99%|โโโโโโโโโโ| 3453/3487 [9:36:16<03:30,  6.18s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6577.81 ms /    32 tokens (  205.56 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.13 ms /     3 runs   (  888.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9245.75 ms /    35 tokens\n",
      " 99%|โโโโโโโโโโ| 3454/3487 [9:36:26<03:54,  7.10s/it]Llama.generate: 307 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11102.02 ms /    56 tokens (  198.25 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.99 ms /     3 runs   (  881.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13750.07 ms /    59 tokens\n",
      " 99%|โโโโโโโโโโ| 3455/3487 [9:36:39<04:51,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2835.35 ms /    12 tokens (  236.28 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.26 ms /     3 runs   (  887.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5500.69 ms /    15 tokens\n",
      " 99%|โโโโโโโโโโ| 3456/3487 [9:36:45<04:08,  8.02s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7928.40 ms /    35 tokens (  226.53 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.82 ms /     3 runs   (  883.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10582.42 ms /    38 tokens\n",
      " 99%|โโโโโโโโโโ| 3457/3487 [9:36:56<04:23,  8.79s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3358.55 ms /    15 tokens (  223.90 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.81 ms /     3 runs   (  889.60 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6029.70 ms /    18 tokens\n",
      " 99%|โโโโโโโโโโ| 3458/3487 [9:37:02<03:51,  7.97s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11369.90 ms /    59 tokens (  192.71 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.41 ms /     3 runs   (  881.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14017.25 ms /    62 tokens\n",
      " 99%|โโโโโโโโโโ| 3459/3487 [9:37:16<04:33,  9.78s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3248.55 ms /    11 tokens (  295.32 ms per token,     3.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.99 ms /     3 runs   (  889.66 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5920.44 ms /    14 tokens\n",
      " 99%|โโโโโโโโโโ| 3460/3487 [9:37:22<03:52,  8.63s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2959.93 ms /    12 tokens (  246.66 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.07 ms /     3 runs   (  887.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5624.45 ms /    15 tokens\n",
      " 99%|โโโโโโโโโโ| 3461/3487 [9:37:27<03:20,  7.73s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2800.38 ms /    12 tokens (  233.36 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.28 ms /     3 runs   (  891.43 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5477.16 ms /    15 tokens\n",
      " 99%|โโโโโโโโโโ| 3462/3487 [9:37:33<02:56,  7.06s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2784.36 ms /    12 tokens (  232.03 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.65 ms /     3 runs   (  890.88 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5459.83 ms /    15 tokens\n",
      " 99%|โโโโโโโโโโ| 3463/3487 [9:37:38<02:37,  6.58s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4987.39 ms /    21 tokens (  237.49 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.23 ms /     3 runs   (  878.41 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7624.43 ms /    24 tokens\n",
      " 99%|โโโโโโโโโโ| 3464/3487 [9:37:46<02:38,  6.89s/it]Llama.generate: 307 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14471.20 ms /    74 tokens (  195.56 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.27 ms /     3 runs   (  902.42 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   17180.50 ms /    77 tokens\n",
      " 99%|โโโโโโโโโโ| 3465/3487 [9:38:03<03:39,  9.98s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2824.60 ms /    12 tokens (  235.38 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2703.78 ms /     3 runs   (  901.26 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5530.86 ms /    15 tokens\n",
      " 99%|โโโโโโโโโโ| 3466/3487 [9:38:08<03:01,  8.65s/it]Llama.generate: 310 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3478.61 ms /    15 tokens (  231.91 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.34 ms /     3 runs   (  893.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6162.25 ms /    18 tokens\n",
      " 99%|โโโโโโโโโโ| 3467/3487 [9:38:15<02:38,  7.91s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4036.51 ms /    18 tokens (  224.25 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.39 ms /     3 runs   (  896.13 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6727.38 ms /    21 tokens\n",
      " 99%|โโโโโโโโโโ| 3468/3487 [9:38:21<02:23,  7.56s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2880.17 ms /    12 tokens (  240.01 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.14 ms /     3 runs   (  883.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5531.66 ms /    15 tokens\n",
      " 99%|โโโโโโโโโโ| 3469/3487 [9:38:27<02:05,  6.95s/it]Llama.generate: 317 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3819.83 ms /     4 runs   (  954.96 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    3822.95 ms /     5 tokens\n",
      "100%|โโโโโโโโโโ| 3470/3487 [9:38:31<01:42,  6.01s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8485.08 ms /    40 tokens (  212.13 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.32 ms /     3 runs   (  889.77 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11157.09 ms /    43 tokens\n",
      "100%|โโโโโโโโโโ| 3471/3487 [9:38:42<02:00,  7.56s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4986.08 ms /    23 tokens (  216.79 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.67 ms /     3 runs   (  883.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7638.35 ms /    26 tokens\n",
      "100%|โโโโโโโโโโ| 3472/3487 [9:38:50<01:53,  7.59s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4314.70 ms /    19 tokens (  227.09 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.73 ms /     3 runs   (  885.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6973.45 ms /    22 tokens\n",
      "100%|โโโโโโโโโโ| 3473/3487 [9:38:57<01:43,  7.40s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4531.25 ms /    20 tokens (  226.56 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.75 ms /     3 runs   (  887.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7195.91 ms /    23 tokens\n",
      "100%|โโโโโโโโโโ| 3474/3487 [9:39:04<01:35,  7.34s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4406.44 ms /    20 tokens (  220.32 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.31 ms /     3 runs   (  888.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7073.31 ms /    23 tokens\n",
      "100%|โโโโโโโโโโ| 3475/3487 [9:39:11<01:27,  7.27s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5584.77 ms /    27 tokens (  206.84 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.42 ms /     3 runs   (  885.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8243.54 ms /    30 tokens\n",
      "100%|โโโโโโโโโโ| 3476/3487 [9:39:19<01:23,  7.56s/it]Llama.generate: 306 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10816.08 ms /    55 tokens (  196.66 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2857.08 ms /     3 runs   (  952.36 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   13675.09 ms /    58 tokens\n",
      "100%|โโโโโโโโโโ| 3477/3487 [9:39:33<01:33,  9.40s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3174.78 ms /    13 tokens (  244.21 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.68 ms /     3 runs   (  911.89 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5912.98 ms /    16 tokens\n",
      "100%|โโโโโโโโโโ| 3478/3487 [9:39:39<01:15,  8.35s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5419.21 ms /    25 tokens (  216.77 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.71 ms /     3 runs   (  877.57 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8054.49 ms /    28 tokens\n",
      "100%|โโโโโโโโโโ| 3479/3487 [9:39:47<01:06,  8.27s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3969.93 ms /    18 tokens (  220.55 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.94 ms /     3 runs   (  887.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6635.47 ms /    21 tokens\n",
      "100%|โโโโโโโโโโ| 3480/3487 [9:39:53<00:54,  7.78s/it]Llama.generate: 324 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4044.65 ms /     4 runs   ( 1011.16 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    4046.98 ms /     5 tokens\n",
      "100%|โโโโโโโโโโ| 3481/3487 [9:39:57<00:39,  6.66s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3305.81 ms /    14 tokens (  236.13 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2755.36 ms /     3 runs   (  918.45 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6063.72 ms /    17 tokens\n",
      "100%|โโโโโโโโโโ| 3482/3487 [9:40:03<00:32,  6.49s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12628.89 ms /    59 tokens (  214.05 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.80 ms /     3 runs   (  906.93 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   15352.51 ms /    62 tokens\n",
      "100%|โโโโโโโโโโ| 3483/3487 [9:40:19<00:36,  9.15s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3512.88 ms /    14 tokens (  250.92 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2773.64 ms /     3 runs   (  924.55 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6289.26 ms /    17 tokens\n",
      "100%|โโโโโโโโโโ| 3484/3487 [9:40:25<00:24,  8.29s/it]Llama.generate: 320 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3995.72 ms /     4 runs   (  998.93 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    3997.91 ms /     5 tokens\n",
      "100%|โโโโโโโโโโ| 3485/3487 [9:40:29<00:14,  7.01s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7769.66 ms /    37 tokens (  209.99 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4197.83 ms /     3 runs   ( 1399.28 ms per token,     0.71 tokens per second)\n",
      "llama_perf_context_print:       total time =   11970.23 ms /    40 tokens\n",
      "100%|โโโโโโโโโโ| 3486/3487 [9:40:41<00:08,  8.50s/it]Llama.generate: 306 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15315.52 ms /    65 tokens (  235.62 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.22 ms /     3 runs   (  897.41 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   18010.56 ms /    68 tokens\n",
      "100%|โโโโโโโโโโ| 3487/3487 [9:40:59<00:00, 11.36s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2363.00 ms /     8 tokens (  295.37 ms per token,     3.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.40 ms /     3 runs   (  907.13 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5086.45 ms /    11 tokens\n",
      "100%|โโโโโโโโโโ| 3487/3487 [9:41:04<00:00, 10.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# ๐ Apply Sentiment Classification with Progress Bar\n",
    "tqdm.pandas()\n",
    "comments_df[\"Sentiment_Predicted\"] = comments_df[\"Comments\"].progress_apply(classify_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "โ Sentiment annotation completed! Results saved to Results/Comments_Annotated_Mistral-7B.csv\n"
     ]
    }
   ],
   "source": [
    "# ๐ Save the Annotated Data\n",
    "output_path = \"Results/Comments_Annotated_Mistral-7B.csv\"\n",
    "comments_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"โ Sentiment annotation completed! Results saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
