{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: emoji in c:\\users\\kikoo\\appdata\\roaming\\python\\python312\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kikoo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install emoji pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID Post",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comments",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Sentiments",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "418e823b-b853-454a-a1c7-0eeec1ecb903",
       "rows": [
        [
         "0",
         "1",
         "Samir Bekhouche",
         null,
         "Neutre"
        ],
        [
         "1",
         "1",
         "Yanise Yanise",
         "سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و بدأت تنقص شوي شويا من 100 دج إلى 75دج و بعدها إلى 50 دج و بعدها إلى 25 دج !!!!!!!!!!! اين ذهبت لزونيتي تاعي ؟؟؟؟!!!!!!\n لن أتكلم بها و لم اتصل بها و ليس لي خاصية رنتي اذن اين ذهب مالي؟!؟!؟!؟\n و صار نفس الشيء مع أخي!!!!!!!!!!!!\n ماهذا لابد من استرجاعه",
         "Negatif"
        ],
        [
         "2",
         "1",
         "Jj Kie",
         "كل عام و انتم بخير",
         "Positif"
        ],
        [
         "3",
         "1",
         "Sakou Younes",
         "كل عام وأنتم بخير",
         "Positif"
        ],
        [
         "4",
         "1",
         "راني نعاني",
         "كل عام وحنا بخير",
         "Positif"
        ],
        [
         "5",
         "1",
         "Wahab Ziadi",
         "كل عام وحنا بخير",
         "Positif"
        ],
        [
         "6",
         "1",
         "أحمد فيراس",
         "🥰",
         "Positif"
        ],
        [
         "7",
         "1",
         "مروان سيدهم سيدهم مروان",
         "كل عام وأنتم بخير وأتمنا رد علا أسإلتي علا لحاص وكل عام وأنتم بخير",
         "Positif"
        ],
        [
         "8",
         "1",
         "Mostefa Merabti",
         "Happy New year",
         "Positif"
        ],
        [
         "9",
         "1",
         "وليد برك",
         "كاش عروض مدم رن في 2024",
         "Neutre"
        ],
        [
         "10",
         "1",
         "Aymen Aymen",
         "تحيا جيزي",
         "Positif"
        ],
        [
         "11",
         "1",
         "Maram Akram",
         "Bonne année à tous",
         "Positif"
        ],
        [
         "12",
         "1",
         "Plako Platr Ba 13",
         "🙏",
         "Neutre"
        ],
        [
         "13",
         "1",
         "Lina Sami",
         "كيفه نحول عروض جيزي سبيسيال باه نرجعها هايلة بزاف",
         "Neutre"
        ],
        [
         "14",
         "1",
         "Yakoub Boussebsi",
         "سنة سعيدة ورجعونا 6h",
         "Positif"
        ],
        [
         "15",
         "1",
         "Hamza Othmani",
         "بداية سنة سيئة جدا، لقد ثم قطع خطي ضلم، و مصلحة الزبائن لا ترد، عيب",
         "Negatif"
        ],
        [
         "16",
         "1",
         "RED ROSE",
         "🌹🌹🌹🌹",
         "Positif"
        ],
        [
         "17",
         "1",
         "Mohamed Mellak",
         "عام سعيد 2024",
         "Positif"
        ],
        [
         "18",
         "1",
         "Naseraddein Hamada",
         null,
         "Neutre"
        ],
        [
         "19",
         "1",
         "Saber Zem",
         "أنا مشترك دفع بعدي تم تزويدي بخدمة chirpix دون علمي في 2 ديسمبر 2023، وعند الاطلاع على فاتورة شهر جانفي وجدت مبلغ 740.00 دج زائد عن الفاتورة وعند الاستفسار عند خدمة الزبائن كان بسبب chirpix، علما أنني لم أطلب هذه الخدمة أبدا ؟؟؟؟؟؟؟",
         "Neutre"
        ],
        [
         "20",
         "1",
         "جمعية الحي أبناء الغد لعياضات -قصر الأبطال-",
         "نحيطكم علما انا قريتنا ( قرية لعياضات ) التابعة لبلدية قصر الأبطال دائرة عين ولمان ولاية سطيف ان شبكة الانترنت جيزي تنعدم تماما في قريتنا.نرجو منكم ايجاد حل لهذه المشكلة",
         "Negatif"
        ],
        [
         "21",
         "1",
         "Sàm Fàràh Mehimdà",
         "كل مرة تسرقوا 50دج ؟؟؟؟ علاش هاك تخلونا نبدلوا الخط 🥴🥴🥴",
         "Negatif"
        ],
        [
         "22",
         "1",
         "Şàłàh Şğhïr",
         "كل عام وانتم بالف خير ❣️❣️",
         "Positif"
        ],
        [
         "23",
         "1",
         "Sofiane Sofiane",
         "علاه ديتولي 50 دج كل مرة راكم ديروهالي",
         "Negatif"
        ],
        [
         "24",
         "1",
         "Lamine Jseb",
         "واش بيه الريزو اليوم؟؟ ماكاش انترنت منذ 3 ساعات",
         "Negatif"
        ],
        [
         "25",
         "1",
         "マウンテ ンライト",
         "بهد مناسبة تبرعو علينا ب انترنت😁",
         "Neutre"
        ],
        [
         "26",
         "1",
         "Bnamer Boutayeb",
         "ريقلو ابليكاسيو نتاعكم",
         "Negatif"
        ],
        [
         "27",
         "1",
         "ゞゞじ づ づ",
         "ديرولنا كش حاجة نتع كونيكسيون",
         "Neutre"
        ],
        [
         "28",
         "1",
         "كنوش سمير",
         "مكانش كونيكسو 🙄😒",
         "Negatif"
        ],
        [
         "29",
         "1",
         "Fati Fati",
         "من 2006 راني مشتاركه معاكم كاش نهار فرحونا بهديه 😉",
         "Neutre"
        ],
        [
         "30",
         "1",
         "Sofiane Renault Medea",
         "بطيءة",
         "Negatif"
        ],
        [
         "31",
         "1",
         "Sifadine Mehdi",
         "ريزو وشبيه يروح و يجي ؟",
         "Negatif"
        ],
        [
         "32",
         "1",
         "Añdřeä Añdřeä",
         "وقتاه تردولنا ريزو🤧",
         "Negatif"
        ],
        [
         "33",
         "1",
         "Nabil Issam",
         "ريڨلونا رب ريزو",
         "Negatif"
        ],
        [
         "34",
         "1",
         "Abdo Gros",
         "Malheureusement le réseau était coupé men 17h ! Hata dok bach wala en plus c'est en niveau d'Alger yahsra les autres wilaya !! Ni excuses ni rien! Mais bon en souhaitant une amélioration cette année nchlh",
         "Negatif"
        ],
        [
         "35",
         "2",
         "Djezzy",
         "مرحباً\n يرجى التواصل معنا في الخاص حتى نتمكن من مساعدتكم\n شكراً ( سميرة .ق ) من جازي",
         "Neutre"
        ],
        [
         "36",
         "2",
         "Abdelghani Tahtah",
         "ماهو هو الكود نتاع سلفلي ... ؟؟",
         "Neutre"
        ],
        [
         "37",
         "2",
         "أحمد فيراس",
         "مليح",
         "Positif"
        ],
        [
         "38",
         "2",
         "Œœ Œœ",
         "كيفاه نسلف عشرالاف",
         "Neutre"
        ],
        [
         "39",
         "2",
         "Houhou Ben Medani",
         null,
         "Neutre"
        ],
        [
         "40",
         "2",
         "Riad BM",
         "شكون يبعثلي 2 جيغا 😂😂",
         "Neutre"
        ],
        [
         "41",
         "2",
         "Amine Boudiaf",
         "رجعونا عروض امتياز لي نحيتوها لنا",
         "Negatif"
        ],
        [
         "42",
         "2",
         "زين الدين ابن البوادي",
         "أود معرفة كيفية سرقة رصيدي ؟\n الرجاء التوضيح \n لي رقمين من جيزي دائما لا اجد الرصيد Djezzy",
         "Negatif"
        ],
        [
         "43",
         "2",
         "Amani Amina",
         "كيف رقم خدمة سلفي",
         "Neutre"
        ],
        [
         "44",
         "2",
         "العربي نواوي",
         "ممكن نعرف علاش تنقصو من الرصيد \n والله العظيم عيب عيب عيب \n تفليكسي 50 الف غدوة تلقى 20 الف عيب\n حسبنا الله ونعم الوكيل.",
         "Negatif"
        ],
        [
         "45",
         "2",
         "Yassine Madrid",
         "من فضلكم شريت شريحة جيزي جديدة كيفاه نأكتيفيها مع العلم فيها 60g انترنت و 7000 مكالمات",
         "Neutre"
        ],
        [
         "46",
         "2",
         "Aoudjia Aimen",
         "وشبيه تطبيق حابس اي ريقلوه وريقليو الريزو رانا نعانيو 2024 وريزو ميت في حالا والله ما فهمنا ومفهمتش علاه رانا فالعالم الثالث (السبب الوحيد لا غيره لي مخلينا فالعالم الثالث انو مكاش عالم رابع او خامس)",
         "Negatif"
        ],
        [
         "47",
         "2",
         "صاحبة السعادة",
         "علابيها وليتو كنفليكسيو تدوهم",
         "Negatif"
        ],
        [
         "48",
         "2",
         "عائشة صديقة",
         "Djezzy من فضلكم أريد تقطيع الشريحة لتناسب الهاتف..لكن هذا غير ممكن مع شريحتي الحالية هل يمكن استبدالها مع أخرى قابلة لتقطيع مع شرط الاحتفاظ برقمي الحالي..",
         "Neutre"
        ],
        [
         "49",
         "2",
         "Youcef Mellah",
         "رانا نسلكو 150 لشهر و كونيكسيون ربي يجيب ممكن توضيح",
         "Negatif"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4129
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Post</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Samir Bekhouche</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yanise Yanise</td>\n",
       "      <td>سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jj Kie</td>\n",
       "      <td>كل عام و انتم بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sakou Younes</td>\n",
       "      <td>كل عام وأنتم بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>راني نعاني</td>\n",
       "      <td>كل عام وحنا بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>183</td>\n",
       "      <td>Ĺã Rõsë Ýb</td>\n",
       "      <td>❤️❤️</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>183</td>\n",
       "      <td>نسمات هادئة</td>\n",
       "      <td>💕💕💕💕</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>183</td>\n",
       "      <td>ملك ملهاش غيرك</td>\n",
       "      <td>❤❤❤❤❤❤🌹</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>183</td>\n",
       "      <td>سعيدي رضا</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>183</td>\n",
       "      <td>جيبلي فيت فيت</td>\n",
       "      <td>❤️❤️❤️❤️</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4129 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Post        User Name  \\\n",
       "0           1  Samir Bekhouche   \n",
       "1           1    Yanise Yanise   \n",
       "2           1           Jj Kie   \n",
       "3           1     Sakou Younes   \n",
       "4           1       راني نعاني   \n",
       "...       ...              ...   \n",
       "4124      183       Ĺã Rõsë Ýb   \n",
       "4125      183      نسمات هادئة   \n",
       "4126      183   ملك ملهاش غيرك   \n",
       "4127      183        سعيدي رضا   \n",
       "4128      183    جيبلي فيت فيت   \n",
       "\n",
       "                                               Comments Sentiments  \n",
       "0                                                   NaN     Neutre  \n",
       "1     سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و...    Negatif  \n",
       "2                                    كل عام و انتم بخير    Positif  \n",
       "3                                     كل عام وأنتم بخير    Positif  \n",
       "4                                      كل عام وحنا بخير    Positif  \n",
       "...                                                 ...        ...  \n",
       "4124                                               ❤️❤️    Positif  \n",
       "4125                                               💕💕💕💕    Positif  \n",
       "4126                                            ❤❤❤❤❤❤🌹    Positif  \n",
       "4127                                                NaN     Neutre  \n",
       "4128                                           ❤️❤️❤️❤️    Positif  \n",
       "\n",
       "[4129 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger les fichiers Excel\n",
    "comments_df = pd.read_excel('Data/Comments.xlsx')\n",
    "\n",
    "# Afficher DataFrame \"Comments\"\n",
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Contents",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Lien Post",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Nb Like",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Love",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Care",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Wow",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Sad",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Angry",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Haha",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "82502164-6493-4eeb-9ba1-d2fb1699420c",
       "rows": [
        [
         "0",
         "1",
         "جازي تتمنّى لكم سنة سعيدة🥰\n#DJEZZY #HAPPY_NEW_YEAR_2024",
         "https://www.facebook.com/djezzy/posts/788227516669599?ref=embed_post",
         "272",
         "45",
         "0",
         "1",
         "1",
         "76",
         "14",
         "Djezzy",
         "2024-01-01 00:00:00"
        ],
        [
         "1",
         "2",
         "راك en panne و خصك رصيد ؟\nمع خدمة Tranquilo تاع Djezzy كلش ساهل👌\n#جازي #Astuces_ساهلة",
         "https://www.facebook.com/watch/?v=1068829281022985&ref=sharing",
         "255",
         "28",
         "0",
         "1",
         "0",
         "12",
         "31",
         "Djezzy",
         "2024-01-04 00:00:00"
        ],
        [
         "2",
         "3",
         "It's Time To be a legend",
         "https://www.facebook.com/djezzy/posts/392564993435969:392564993435969?ref=embed_post",
         "257",
         "51",
         "2",
         "0",
         "0",
         "2",
         "8",
         "Djezzy",
         "2024-01-10 00:00:00"
        ],
        [
         "3",
         "4",
         "Djezzy vous souhaite Yennayer amervuh!  ⴰⵙⵙⴻⴳⴰⵙ ⴰⵎⴻⴳⴰⵣ 2974\n ! جازي تقدم لكم أحرّ التهاني بمناسبة السنة الأمازيغية الجديدة\n#DJEZZY #Yennayer_2974",
         "https://www.facebook.com/share/p/19UDNBoQ1k/",
         "621",
         "231",
         "10",
         "3",
         "0",
         "1",
         "300",
         "Djezzy",
         "2024-01-11 00:00:00"
        ],
        [
         "4",
         "5",
         "قريباً ...",
         "https://www.facebook.com/share/v/12B9LZySBRe/",
         "288",
         "49",
         "4",
         "0",
         "0",
         "3",
         "24",
         "Djezzy",
         "2024-01-12 00:00:00"
        ],
        [
         "5",
         "6",
         "و مكالمات غير محدودة نحو جميع شبكات النقال و الثابت.\nبـ 2500دج فقط !\n#نتا_هو_الأسطورة",
         "https://www.facebook.com/share/v/15R9u8sYHg/",
         "564",
         "157",
         "24",
         "0",
         "0",
         "7",
         "73",
         "Djezzy",
         "2024-01-13 00:00:00"
        ],
        [
         "6",
         "7",
         "مع جازي LEGEND\nإستفد من مكالمات مجانية نحو كل شبكات النقال و الثابت !\nوحجم انترنت يصل إلى غاية 100 جيغا !\nإكتشفوا مزايا العرض الجديد DJEZZY LEGEND على 👈 https://ms.spr.ly/6188iUry6\n#نتا_هو_الأسطورة",
         "https://www.facebook.com/djezzy/posts/797321975760153?ref=embed_post",
         "438",
         "31",
         "5",
         "0",
         "0",
         "26",
         "52",
         "Djezzy",
         "2024-01-14 00:00:00"
        ],
        [
         "7",
         "8",
         "تمتع بالمكالمات المجانية نحو جميع شبكات الجوال📱 والثابت  ☎️ واستفد من 70جيغا ب2000 دج فقط !\nاستكشف كل المميزات على 👈https://ms.spr.ly/6187iUx8v \n#نتا_هو_الأسطورة",
         "https://www.facebook.com/djezzy/posts/797937005698650?ref=embed_post",
         "428",
         "23",
         "4",
         "1",
         "1",
         "5",
         "52",
         "Djezzy",
         "2024-01-15 00:00:00"
        ],
        [
         "8",
         "9",
         "مع DJEZZY LEGEND انت هو الـ LEGEND \nبـ 2000دج !\nتحصلوا على 70Go انترنت، مكالمات غير محدودة نحو جميع شبكات الثابت و النقال ! \nإكتشفوا مزايا DJEZZY LEGEND على 👈 https://ms.spr.ly/6183isCkU \n#نتا_هو_الأسطورة",
         "https://www.facebook.com/share/v/12BG5K7FV8K/",
         "323",
         "37",
         "5",
         "0",
         "1",
         "2",
         "9",
         "Djezzy",
         "2024-01-20 00:00:00"
        ],
        [
         "9",
         "10",
         "GOAL Algeria VS Burkina Faso Football ",
         "https://www.facebook.com/watch/?v=1346282365905418&ref=sharing",
         "170",
         "26",
         "1",
         "1",
         "0",
         "4",
         "2",
         "Djezzy",
         "2024-01-20 00:00:00"
        ],
        [
         "10",
         "11",
         "مع  PACK 3AYLA متراطي حتى Match ⚽  \nاستفاد من Modem 4G و 150GO انترنت لمدة 6 أشهر ب9990دج 🤩\nمع PACK 3AYLA SUPPORTY \n فريقك مع عايلتك💪\nلمزيد من المعلومات زوروا موقعنا 👇🏻\n https://bit.ly/Djezzy-Pack3ayla\n#Djezzy #Match #3ayla",
         "https://www.facebook.com/watch/?v=1387729078503230&ref=sharing",
         "130",
         "8",
         "1",
         "1",
         "1",
         "2",
         "31",
         "Djezzy",
         "2024-01-23 00:00:00"
        ],
        [
         "11",
         "12",
         "مع ZUNI SPORT  على DJEZZY APP 📲 تابع مواعيد و نتائج المباريات لحظة بلحظة ⚽ 👌 \nحمّل التطبيق الآن 👈 https://ms.spr.ly/6181gi6y3\n#Djezzy_App #ZUNI_SPORT #Max_Foot",
         "https://www.facebook.com/share/p/13tcBA3rkg/",
         "189",
         "16",
         "3",
         "0",
         "0",
         "3",
         "11",
         "Djezzy",
         "2024-01-27 00:00:00"
        ],
        [
         "12",
         "13",
         "اليوم هو اليوم العالمي لحماية البيانات. تذكير أساسي بأهمية الحفاظ على خصوصيتك على الإنترنت. \nحماية البيانات تهم كل واحد منا 💻🔐 \nAujourd'hui, c'est la Journée Mondiale de la Protection des Données. Un rappel essentiel de l'importance de préserver votre vie privée en ligne. La protection des données concerne chacun d'entre \nnous💻🔐 \n#ProtectionDesDonnées #ViePrivéeEnLigne #Djezzy",
         "https://www.facebook.com/share/p/15aRgkr5JS/",
         "161",
         "13",
         "2",
         "1",
         "0",
         "1",
         "11",
         "Djezzy",
         "2024-01-28 00:00:00"
        ],
        [
         "13",
         "14",
         "اختبر معلوماتك في كرة القدم ⚽️ \n وحاول تفوز بقسيمة شراء بقيمة 100 مليون سنتيم أسبوعيا 🤑 \nما عليك غير تحمّل DJEZZY APP 📲 على الرابط  👈 https://ms.spr.ly/6181gi6y3\n#DJEZZY_APP #DJEZZY_WIN",
         "https://www.facebook.com/share/p/1AzBbfwqh1/",
         "229",
         "22",
         "5",
         "0",
         "0",
         "2",
         "9",
         "Djezzy",
         "2024-01-30 00:00:00"
        ],
        [
         "14",
         "15",
         "أخبار محلية ، ثقافية ، رياضية ⚽\nمع  DJEZZY SCOOP 📣 ميفوتك حتى خبر ! \n للاشتراك إتصل على 404 أو أرسل SMS الى نفس الرقم\n#Djezzy_Scoop #Max_News",
         "https://www.facebook.com/share/p/13yNkR5JW2/",
         "150",
         "7",
         "0",
         "0",
         "0",
         "1",
         "11",
         "Djezzy",
         "2024-01-31 00:00:00"
        ],
        [
         "15",
         "16",
         "شكون فيكم يعرف Le code باش يكتيفي Double Appel ؟\n#جازي #Astuces_ساهلة",
         "https://www.facebook.com/watch/?v=1497445130819223&ref=sharing",
         "325",
         "33",
         "4",
         "0",
         "0",
         "5",
         "6",
         "Djezzy",
         "2024-02-01 00:00:00"
        ],
        [
         "16",
         "17",
         "كيفاش تتفادى توقف الخط ديالك 🤔 ؟\nتابع الحل في الفيديو 👇 \n#جازي #Astuces_ساهلة",
         "https://www.facebook.com/watch/?v=408877615031858&rdid=nscweaDh1ie6K7G0",
         "161",
         "18",
         "2",
         "0",
         "0",
         "3",
         "10",
         "Djezzy",
         "2024-02-15 00:00:00"
        ],
        [
         "17",
         "18",
         "في رايكم , هاذ المرة علاش جينا 😉",
         "https://www.facebook.com/share/v/1CVK8AkWr6/",
         "202",
         "24",
         "2",
         "1",
         "0",
         "5",
         "18",
         "Djezzy",
         "2024-02-18 00:00:00"
        ],
        [
         "18",
         "19",
         "انضموا إلينا  🚶‍ في مبادرة البسمة WALK for ؛ لنرسم البسمة مع بعض في كل خطوة.\nحملوا  DJEZZY APP 📱 و حولوا خطواتكم إلى تبرعات لقفة رمضان  🌙 \nرابط التحميل 👈 https://ms.spr.ly/6181gi6y3\n#جازي #قفة_رمضان #البسمةWalk4",
         "https://www.facebook.com/share/p/14kGTVBiaXU/",
         "177",
         "19",
         "3",
         "0",
         "0",
         "13",
         "3",
         "Djezzy",
         "2024-02-19 00:00:00"
        ],
        [
         "19",
         "20",
         "باش نفرحو الناس في هذا رمضان 🌙 و نرسموا البسمة على وجوه الصايمين 😀 \nيلا نمشوا مع بعض و نتبرعوا بخطواتنا على DJEZZY APP 👣 📲 \nرابط التحميل  👈 https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/19nVrLQmjV/",
         "173",
         "17",
         "5",
         "0",
         "0",
         "0",
         "2",
         "Djezzy",
         "2024-02-20 00:00:00"
        ],
        [
         "20",
         "21",
         "شارك في تحدي المشي 🚶‍♂️ مع صحابك و سجل خطواتك في فيديو و أنشرها على صفحتك ، طاڨي DJEEZY مع هاشتاغ\n #جازي #قفة_رمضان #البسمةWalk4\nأحسن فيديو  راح نبرطاجيوها عبر صفحتنا 💪 \nرابط التطبيق👈 https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/p/1ESi1iAD8L/",
         "299",
         "34",
         "3",
         "2",
         "1",
         "6",
         "52",
         "Djezzy",
         "2024-02-21 00:00:00"
        ],
        [
         "21",
         "22",
         "خطوة ساهلة بمناسبة شهر رمضان الكريم 🌙 \n#جازي #Astuces_ساهلة #قفة_رمضان #البسمةWalk4",
         "https://www.facebook.com/share/v/19dwGJKfjm/",
         "181",
         "23",
         "3",
         "0",
         "0",
         "4",
         "1",
         "Djezzy",
         "2024-02-22 00:00:00"
        ],
        [
         "22",
         "23",
         "طاڨي صاحبك  يمشي بالزربة 🚶‍♂️ 🏃‍♂️\n#جازي  #قفة_رمضان #البسمةWalk4",
         "https://www.facebook.com/share/p/14KAHkwsXF/",
         "201",
         "23",
         "3",
         "0",
         "2",
         "4",
         "58",
         "Djezzy",
         "2024-02-23 00:00:00"
        ],
        [
         "23",
         "24",
         "كل واحد يكتبلنا في التعليقات شحال من خطوة مشاها على Djezzy App 👣 🚶‍♂️ 📱 \nيدرى شكون راح يكون 🏆 Le champion  ؟\n #جازي #قفة_رمضان #البسمةWalk4",
         "https://www.facebook.com/share/p/18BbsUNDKa/",
         "204",
         "18",
         "3",
         "0",
         "0",
         "3",
         "26",
         "Djezzy",
         "2024-02-24 00:00:00"
        ],
        [
         "24",
         "25",
         "البسمة WALK FOR 🚶‍♂️ مازالها متواصلة 👣\n طاڨي صاحبك لي مازال ماشاركش معانا \n#جازي #قفة_رمضان #البسمةWalk4",
         "https://www.facebook.com/share/v/17cPeTM5qo/",
         "111",
         "20",
         "0",
         "0",
         "0",
         "5",
         "9",
         "Djezzy",
         "2024-02-26 00:00:00"
        ],
        [
         "25",
         "26",
         "نشاركوا معاكم  TOP 10 تع البسمة Walk for\nإنضموا إلينا، مازلنا متواصلين من أجل رسم البسمة مع بعض.\n#جازي #قفة_رمضان #البسمةWalk4",
         "https://www.facebook.com/share/p/1BYQb7q2cL/",
         "185",
         "17",
         "1",
         "0",
         "0",
         "4",
         "10",
         "Djezzy",
         "2024-02-27 00:00:00"
        ],
        [
         "26",
         "27",
         "🚶‍ مبادرة البسمة  WALK for مازالها متواصلة  ؛ خطواتنا راح تفرّح بزاف ناس \nحملوا  DJEZZY APP 📱 و حولوا خطواتكم إلى تبرعات لقفة رمضان  🌙 \nرابط التحميل 👈 https://ms.spr.ly/6181gi6y3\n#جازي #قفة_رمضان #البسمةWalk4",
         "https://www.facebook.com/share/p/18KCQQmfLL/",
         "228",
         "30",
         "2",
         "0",
         "1",
         "3",
         "6",
         "Djezzy",
         "2024-02-29 00:00:00"
        ],
        [
         "27",
         "28",
         "و للأسبوع الثاني ✌️ البسمة WALK FOR مازالها متواصلة بنجاح بفضل خطواتكم 👣\n#جازي #قفة_رمضان #البسمةwalk4",
         "https://www.facebook.com/share/v/12AywsCXXA3/",
         "128",
         "20",
         "0",
         "0",
         "0",
         "2",
         "4",
         "Djezzy",
         "2024-03-04 00:00:00"
        ],
        [
         "28",
         "29",
         "نشاركوا معاكم   🚶‍♂️ 👣 The best walkers  للأسبوع الثاني ✌️ \nإنضموا إلينا من أجل رسم البسمة مع بعض في هذا رمضان \n#جازي #قفة_رمضان #البسمةWalk4",
         "https://www.facebook.com/share/p/1Azzo8rf7E/",
         "167",
         "19",
         "0",
         "0",
         "0",
         "1",
         "2",
         "Djezzy",
         "2024-03-06 00:00:00"
        ],
        [
         "29",
         "30",
         "نختتم مبادرة البسمة WALK FOR بأكثر من 821 مليون خطوة 💪 👣\nشكراً على مشاركتكم و دعمكم القيّم 🙏 مع بعض صنعنا البسمة 😀\n#جازي #قفة_رمضان #البسمةWalk4",
         "https://www.facebook.com/watch/?v=3419181848374064&rdid=OpVtNNOSdxW0g2eO",
         "110",
         "23",
         "1",
         "0",
         "0",
         "1",
         "1",
         "Djezzy",
         "2024-03-10 00:00:00"
        ],
        [
         "30",
         "31",
         "باش تولي مشهور لازملك بزّاف انترنت 🤩\nو باش تولي أسطورة لازملك DJEZZY LEGEND 😉\nاكتشفوا تفاصيل العرض على 👈 https://bit.ly/3uW7xsl",
         "https://www.facebook.com/share/v/15kQvgwaYH/",
         "89",
         "15",
         "2",
         "0",
         "0",
         "1",
         "13",
         "Djezzy",
         "2024-03-11 00:00:00"
        ],
        [
         "31",
         "32",
         "حمّل DJEZZY APP و شارك في مسابقة عمرة RANATI لشخصين 🕋\nرابط التطبيق👈 https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/18BXF4DAnq/",
         "131",
         "37",
         "0",
         "0",
         "0",
         "0",
         "1",
         "Djezzy",
         "2024-03-11 00:00:00"
        ],
        [
         "32",
         "33",
         "هذا رمضان الفرحة دوبل 😄X2 على DJEZZY APP 📱  \nرابط التطبيق👈 https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/1FyzpbnWBQ/",
         "106",
         "30",
         "1",
         "1",
         "0",
         "2",
         "0",
         "Djezzy",
         "2024-03-12 00:00:00"
        ],
        [
         "33",
         "34",
         "مع DJEZZY APP دوبلي فرحتك 🤩 و الانترنت ديالك ✌️ \nرابط التطبيق👈 https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/17z9TWBMWj/",
         "132",
         "20",
         "2",
         "0",
         "0",
         "2",
         "2",
         "Djezzy",
         "2024-03-13 00:00:00"
        ],
        [
         "34",
         "35",
         "باش دير محتوى أسطوري لازملك عرض أسطوري 😎 \nاكتشفوا التفاصيل   👈 https://ms.spr.ly/6187cis3P\nمع DJEZZY LEGEND انت هو الأسطورة  👊",
         "https://www.facebook.com/share/p/1NTLjuLH4q/",
         "179",
         "22",
         "0",
         "1",
         "0",
         "3",
         "31",
         "Djezzy",
         "2024-03-14 00:00:00"
        ],
        [
         "35",
         "36",
         "كامل يوصلنا  SMS 📲 بلي ربحنا في مسابقات و حنا ماشاركناش فيها !\nكيفاش نتفادوها  ؟\n#جازي #Astuces_ساهلة #رمضان2024",
         "https://www.facebook.com/share/v/1Ax3tK3yQf/",
         "71",
         "13",
         "1",
         "0",
         "0",
         "2",
         "0",
         "Djezzy",
         "2024-03-14 00:00:00"
        ],
        [
         "36",
         "37",
         "انترنت ❌ 2  لمدة أسبوع !\nحمّل Djezzy App و استمتع ب10 جيغا لكل عرض تاع 300 دج \nرابط التطبيق👈 https://ms.spr.ly/6181gi6y3\n#جازي #دوبل_أنترنت #رمضان2024_جازي_APP",
         "https://www.facebook.com/share/v/1QvSNe3qr6/",
         "86",
         "16",
         "2",
         "0",
         "0",
         "8",
         "3",
         "Djezzy",
         "2024-03-17 00:00:00"
        ],
        [
         "37",
         "38",
         "كونكتي Double❌ 2 و أفرح Double❌ 2 مع انترنت  Double ❌ 2\nحمّل التطبيق👈 https://ms.spr.ly/6181gi6y3\n#جازي #دوبل_أنترنت #رمضان2024_جازي_APP",
         "https://www.facebook.com/share/p/19cMcLv6sd/",
         "139",
         "18",
         "0",
         "0",
         "0",
         "4",
         "2",
         "Djezzy",
         "2024-03-17 00:00:00"
        ],
        [
         "38",
         "39",
         "مع عرض جازي LEGEND MAX الجديد، استفد من مكالمات غير محدودة نحو جميع الشبكات الوطنية وحدّ أقصى من الانترنت !\nللمزيد من التفاصيل : https://ms.spr.ly/6186cUdNk\n#جازي #نتاـهوـالأسطورة",
         "https://www.facebook.com/share/p/1Gxhnote12/",
         "163",
         "31",
         "1",
         "0",
         "0",
         "2",
         "1",
         "Djezzy",
         "2024-03-22 00:00:00"
        ],
        [
         "39",
         "40",
         "مع DJEZZY APP أبقى دايماً Connecté بDouble \n  استمتع ب10 جيغا لمدة أسبوع  ب300 دج فقط ! \nرابط التطبيق👈 https://ms.spr.ly/6181gi6y3\n#جازي #دوبل_أنترنت #رمضان2024_جازي_APP",
         "https://www.facebook.com/share/v/19THVFCcWA/",
         "64",
         "18",
         "0",
         "0",
         "0",
         "2",
         "2",
         "Djezzy",
         "2024-03-23 00:00:00"
        ],
        [
         "40",
         "41",
         "\nعندك LEGEND MAX؟\nBIEN SÛR QUE انت اسطورة 😎",
         "https://www.facebook.com/share/v/1EZyVsxH3S/",
         "91",
         "20",
         "0",
         "1",
         "0",
         "0",
         "6",
         "Djezzy",
         "2024-03-25 00:00:00"
        ],
        [
         "41",
         "42",
         "بالشراكة مع الكشافة الإسلامية الجزائرية، جازي تشارككم الأجواء التضامنية من مطعم فوج امال قاوش ببلدية الشراقة.\nتتميز هذه المبادرة بمساهمة الكشافين من مختلف الأعمار  في ادخال الفرحة ورسم البسمة على وجوه القاصدين و العابرين من كل مكان.\nفي هذا رمضان نرسمو البسمة  مع بعض 🤝 \nفوج ٱمال قاوش الكشافة الإسلامية الجزائرية \n #جازي #مائدة_البسمة #الكشافة_الإسلامية_الجزائرية",
         "https://www.facebook.com/share/v/1Dcy3GKWLV/",
         "65",
         "28",
         "3",
         "0",
         "0",
         "0",
         "0",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "42",
         "43",
         "تابعوا الاحداث المتنوعة في حلقة اليوم من شبه حصة 2 في هذا رمضان 🌙 \nشاهدوا  الحلقة كاملة على 👈  https://youtu.be/iarIxuw3n40\n#جازي #شبه_حصة2 #رمضان2024",
         "https://www.facebook.com/share/v/196vTS7ztN/",
         "49",
         "17",
         "2",
         "0",
         "0",
         "0",
         "1",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "43",
         "44",
         "مع  LEGEND MAX استفد من مكالمات غير محدودة نحو جميع الشبكات الوطنية و الMax  تاع الانترنت 😎 \nللمزيد من التفاصيل : https://ms.spr.ly/6186cUdNk\n#جازي #نتا_هو_الأسطورة",
         "https://www.facebook.com/share/p/15N1wg8V2N/",
         "133",
         "20",
         "4",
         "2",
         "0",
         "5",
         "4",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "44",
         "45",
         "متفوتش العرض في هذا رمضان 😎 \nحمّل ، اكتيفي ، و دوبلي ✌️ \nهذا كامل على 👈 https://ms.spr.ly/6181gi6y3\n#جازي #دوبل_أنترنت #رمضان2024_جازي_APP",
         "https://www.facebook.com/share/v/19HbnWWpMa/",
         "37",
         "15",
         "1",
         "0",
         "0",
         "4",
         "0",
         "Djezzy",
         "2024-03-28 00:00:00"
        ],
        [
         "45",
         "46",
         "تابعوا حلقة اليوم من شبه حصة مع مراد و أرقام 🎬\nلمشاهدة الحلقة كاملة 👈 https://youtu.be/SqxB8u6ui-4",
         "https://www.facebook.com/share/v/1AewF1ZDSN/",
         "35",
         "16",
         "1",
         "0",
         "0",
         "0",
         "0",
         "Djezzy",
         "2024-03-28 00:00:00"
        ],
        [
         "46",
         "47",
         "ألف شكر Super Fans تاعنا ،شكرا على محبتكم و وفائكم لينا و تفاعلكم الدائم معانا 🥰🙏🏻🙌\nصح سحوركم 🌙",
         "https://www.facebook.com/share/v/15Z5g8V2Cs/",
         "76",
         "33",
         "5",
         "0",
         "0",
         "1",
         "0",
         "Djezzy",
         "2024-03-29 00:00:00"
        ],
        [
         "47",
         "48",
         "تحب دير بزاف LES STORIES ، les REELS ، Les PHOTOS غير DJEZZY LEGEND لي تخرج عليك , 100 GO إنترنت و انت مهني 😎 \nللمزيد من التفاصيل : https://ms.spr.ly/6186cUdNk\n#جازي #نتا_هو_الأسطورة",
         "https://www.facebook.com/share/v/19aWCgdZW3/",
         "133",
         "20",
         "2",
         "0",
         "0",
         "2",
         "7",
         "Djezzy",
         "2024-03-30 00:00:00"
        ],
        [
         "48",
         "49",
         "نتوما عشاق الألعاب الإلكترونية 🎮🕹️ تحبو تقضيو وقت شباب معنا؟🎯 \nخممت فيكم  #MobiliStore  عيشوا متعة الألعاب فيها  🎊🎁🎀\n#موبيليس #معا_نصنع_المستقبل",
         "https://www.facebook.com/share/p/18K8JuwacB/",
         "399",
         "38",
         "8",
         "0",
         "0",
         "1",
         "2",
         "Mobilis",
         "2024-01-04 00:00:00"
        ],
        [
         "49",
         "50",
         "قرعة الدورين الـ32 والـ16 لكأس الجزائر الطبعة 59 🏆⚽🇩🇿\nتتابعونها يوم الأحد 7 جانفي 2024 على الساعة 17:30⏳\n#موبيليس #الراعي_والشريك_الرسمي_لكأس_الجزائر\n#معا_نصنع_المستقبل",
         "https://www.facebook.com/share/p/15Y99MUo3z/",
         "612",
         "61",
         "7",
         "0",
         "0",
         "1",
         "0",
         "Mobilis",
         "2024-01-06 00:00:00"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 183
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Contents</th>\n",
       "      <th>Lien Post</th>\n",
       "      <th>Nb Like</th>\n",
       "      <th>Nb Love</th>\n",
       "      <th>Nb Care</th>\n",
       "      <th>Nb Wow</th>\n",
       "      <th>Nb Sad</th>\n",
       "      <th>Nb Angry</th>\n",
       "      <th>Nb Haha</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>جازي تتمنّى لكم سنة سعيدة🥰\\n#DJEZZY #HAPPY_NEW...</td>\n",
       "      <td>https://www.facebook.com/djezzy/posts/78822751...</td>\n",
       "      <td>272</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>14</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>راك en panne و خصك رصيد ؟\\nمع خدمة Tranquilo ت...</td>\n",
       "      <td>https://www.facebook.com/watch/?v=106882928102...</td>\n",
       "      <td>255</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>It's Time To be a legend</td>\n",
       "      <td>https://www.facebook.com/djezzy/posts/39256499...</td>\n",
       "      <td>257</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Djezzy vous souhaite Yennayer amervuh!  ⴰⵙⵙⴻⴳⴰ...</td>\n",
       "      <td>https://www.facebook.com/share/p/19UDNBoQ1k/</td>\n",
       "      <td>621</td>\n",
       "      <td>231</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>قريباً ...</td>\n",
       "      <td>https://www.facebook.com/share/v/12B9LZySBRe/</td>\n",
       "      <td>288</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>179</td>\n",
       "      <td>إثارة الألعاب تتعاش مع الأحباب، خاصة كي Ooredo...</td>\n",
       "      <td>https://www.facebook.com/share/p/1KGHZQuXex/</td>\n",
       "      <td>208</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>مع Ooredoo ديما رابحين !\\nوجّدنا لكم حاجة جديد...</td>\n",
       "      <td>https://www.facebook.com/share/v/1Bc7FtdDPx/</td>\n",
       "      <td>625</td>\n",
       "      <td>125</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>عشنا مع بعض أجواء رمضانية رائعة من خلال الإفطا...</td>\n",
       "      <td>https://www.facebook.com/reel/954679512980806</td>\n",
       "      <td>280</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>182</td>\n",
       "      <td>ضاعفوا اشتراك الإنترنت الخاص بكم خلال شهر رمضا...</td>\n",
       "      <td>https://www.facebook.com/watch/?v=193245186050...</td>\n",
       "      <td>148</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>183</td>\n",
       "      <td>أنتم من عشاق السينما العربية؟ حمّلوا التطبيق ش...</td>\n",
       "      <td>https://www.facebook.com/OoredooDZ/posts/44139...</td>\n",
       "      <td>215</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                           Contents  \\\n",
       "0      1  جازي تتمنّى لكم سنة سعيدة🥰\\n#DJEZZY #HAPPY_NEW...   \n",
       "1      2  راك en panne و خصك رصيد ؟\\nمع خدمة Tranquilo ت...   \n",
       "2      3                           It's Time To be a legend   \n",
       "3      4  Djezzy vous souhaite Yennayer amervuh!  ⴰⵙⵙⴻⴳⴰ...   \n",
       "4      5                                         قريباً ...   \n",
       "..   ...                                                ...   \n",
       "178  179  إثارة الألعاب تتعاش مع الأحباب، خاصة كي Ooredo...   \n",
       "179  180  مع Ooredoo ديما رابحين !\\nوجّدنا لكم حاجة جديد...   \n",
       "180  181  عشنا مع بعض أجواء رمضانية رائعة من خلال الإفطا...   \n",
       "181  182  ضاعفوا اشتراك الإنترنت الخاص بكم خلال شهر رمضا...   \n",
       "182  183  أنتم من عشاق السينما العربية؟ حمّلوا التطبيق ش...   \n",
       "\n",
       "                                             Lien Post  Nb Like  Nb Love  \\\n",
       "0    https://www.facebook.com/djezzy/posts/78822751...      272       45   \n",
       "1    https://www.facebook.com/watch/?v=106882928102...      255       28   \n",
       "2    https://www.facebook.com/djezzy/posts/39256499...      257       51   \n",
       "3         https://www.facebook.com/share/p/19UDNBoQ1k/      621      231   \n",
       "4        https://www.facebook.com/share/v/12B9LZySBRe/      288       49   \n",
       "..                                                 ...      ...      ...   \n",
       "178       https://www.facebook.com/share/p/1KGHZQuXex/      208       46   \n",
       "179       https://www.facebook.com/share/v/1Bc7FtdDPx/      625      125   \n",
       "180      https://www.facebook.com/reel/954679512980806      280       40   \n",
       "181  https://www.facebook.com/watch/?v=193245186050...      148       35   \n",
       "182  https://www.facebook.com/OoredooDZ/posts/44139...      215       46   \n",
       "\n",
       "     Nb Care  Nb Wow  Nb Sad  Nb Angry  Nb Haha  Company       Date  \n",
       "0          0       1       1        76       14   Djezzy 2024-01-01  \n",
       "1          0       1       0        12       31   Djezzy 2024-01-04  \n",
       "2          2       0       0         2        8   Djezzy 2024-01-10  \n",
       "3         10       3       0         1      300   Djezzy 2024-01-11  \n",
       "4          4       0       0         3       24   Djezzy 2024-01-12  \n",
       "..       ...     ...     ...       ...      ...      ...        ...  \n",
       "178        6       0       0         0        1  Ooredoo 2024-03-26  \n",
       "179       14       0       1         1        1  Ooredoo 2024-03-27  \n",
       "180        7       1       1         0        0  Ooredoo 2024-03-28  \n",
       "181        3       0       0         2        0  Ooredoo 2024-03-28  \n",
       "182        5       0       0         1        0  Ooredoo 2024-03-30  \n",
       "\n",
       "[183 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger les fichiers Excel\n",
    "posts_df = pd.read_excel('Data/Posts.xlsx')\n",
    "\n",
    "# Afficher DataFrame \"Posts\"\n",
    "posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID Post",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comments",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Sentiments",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6771f1ba-c19e-41a2-ab60-942f17344545",
       "rows": [
        [
         "0",
         "1",
         "Samir Bekhouche",
         null,
         "Neutre"
        ],
        [
         "1",
         "1",
         "Yanise Yanise",
         "سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و بدأت تنقص شوي شويا من 100 دج إلى 75دج و بعدها إلى 50 دج و بعدها إلى 25 دج !!!!!!!!!!! اين ذهبت لزونيتي تاعي ؟؟؟؟!!!!!!\n لن أتكلم بها و لم اتصل بها و ليس لي خاصية رنتي اذن اين ذهب مالي؟!؟!؟!؟\n و صار نفس الشيء مع أخي!!!!!!!!!!!!\n ماهذا لابد من استرجاعه",
         "Negatif"
        ],
        [
         "2",
         "1",
         "Jj Kie",
         "كل عام و انتم بخير",
         "Positif"
        ],
        [
         "3",
         "1",
         "Sakou Younes",
         "كل عام وأنتم بخير",
         "Positif"
        ],
        [
         "4",
         "1",
         "راني نعاني",
         "كل عام وحنا بخير",
         "Positif"
        ],
        [
         "5",
         "1",
         "Wahab Ziadi",
         "كل عام وحنا بخير",
         "Positif"
        ],
        [
         "6",
         "1",
         "أحمد فيراس",
         "🥰",
         "Positif"
        ],
        [
         "7",
         "1",
         "مروان سيدهم سيدهم مروان",
         "كل عام وأنتم بخير وأتمنا رد علا أسإلتي علا لحاص وكل عام وأنتم بخير",
         "Positif"
        ],
        [
         "8",
         "1",
         "Mostefa Merabti",
         "Happy New year",
         "Positif"
        ],
        [
         "9",
         "1",
         "وليد برك",
         "كاش عروض مدم رن في 2024",
         "Neutre"
        ],
        [
         "10",
         "1",
         "Aymen Aymen",
         "تحيا جيزي",
         "Positif"
        ],
        [
         "11",
         "1",
         "Maram Akram",
         "Bonne année à tous",
         "Positif"
        ],
        [
         "12",
         "1",
         "Plako Platr Ba 13",
         "🙏",
         "Neutre"
        ],
        [
         "13",
         "1",
         "Lina Sami",
         "كيفه نحول عروض جيزي سبيسيال باه نرجعها هايلة بزاف",
         "Neutre"
        ],
        [
         "14",
         "1",
         "Yakoub Boussebsi",
         "سنة سعيدة ورجعونا 6h",
         "Positif"
        ],
        [
         "15",
         "1",
         "Hamza Othmani",
         "بداية سنة سيئة جدا، لقد ثم قطع خطي ضلم، و مصلحة الزبائن لا ترد، عيب",
         "Negatif"
        ],
        [
         "16",
         "1",
         "RED ROSE",
         "🌹🌹🌹🌹",
         "Positif"
        ],
        [
         "17",
         "1",
         "Mohamed Mellak",
         "عام سعيد 2024",
         "Positif"
        ],
        [
         "18",
         "1",
         "Naseraddein Hamada",
         null,
         "Neutre"
        ],
        [
         "19",
         "1",
         "Saber Zem",
         "أنا مشترك دفع بعدي تم تزويدي بخدمة chirpix دون علمي في 2 ديسمبر 2023، وعند الاطلاع على فاتورة شهر جانفي وجدت مبلغ 740.00 دج زائد عن الفاتورة وعند الاستفسار عند خدمة الزبائن كان بسبب chirpix، علما أنني لم أطلب هذه الخدمة أبدا ؟؟؟؟؟؟؟",
         "Neutre"
        ],
        [
         "20",
         "1",
         "جمعية الحي أبناء الغد لعياضات -قصر الأبطال-",
         "نحيطكم علما انا قريتنا ( قرية لعياضات ) التابعة لبلدية قصر الأبطال دائرة عين ولمان ولاية سطيف ان شبكة الانترنت جيزي تنعدم تماما في قريتنا.نرجو منكم ايجاد حل لهذه المشكلة",
         "Negatif"
        ],
        [
         "21",
         "1",
         "Sàm Fàràh Mehimdà",
         "كل مرة تسرقوا 50دج ؟؟؟؟ علاش هاك تخلونا نبدلوا الخط 🥴🥴🥴",
         "Negatif"
        ],
        [
         "22",
         "1",
         "Şàłàh Şğhïr",
         "كل عام وانتم بالف خير ❣️❣️",
         "Positif"
        ],
        [
         "23",
         "1",
         "Sofiane Sofiane",
         "علاه ديتولي 50 دج كل مرة راكم ديروهالي",
         "Negatif"
        ],
        [
         "24",
         "1",
         "Lamine Jseb",
         "واش بيه الريزو اليوم؟؟ ماكاش انترنت منذ 3 ساعات",
         "Negatif"
        ],
        [
         "25",
         "1",
         "マウンテ ンライト",
         "بهد مناسبة تبرعو علينا ب انترنت😁",
         "Neutre"
        ],
        [
         "26",
         "1",
         "Bnamer Boutayeb",
         "ريقلو ابليكاسيو نتاعكم",
         "Negatif"
        ],
        [
         "27",
         "1",
         "ゞゞじ づ づ",
         "ديرولنا كش حاجة نتع كونيكسيون",
         "Neutre"
        ],
        [
         "28",
         "1",
         "كنوش سمير",
         "مكانش كونيكسو 🙄😒",
         "Negatif"
        ],
        [
         "29",
         "1",
         "Fati Fati",
         "من 2006 راني مشتاركه معاكم كاش نهار فرحونا بهديه 😉",
         "Neutre"
        ],
        [
         "30",
         "1",
         "Sofiane Renault Medea",
         "بطيءة",
         "Negatif"
        ],
        [
         "31",
         "1",
         "Sifadine Mehdi",
         "ريزو وشبيه يروح و يجي ؟",
         "Negatif"
        ],
        [
         "32",
         "1",
         "Añdřeä Añdřeä",
         "وقتاه تردولنا ريزو🤧",
         "Negatif"
        ],
        [
         "33",
         "1",
         "Nabil Issam",
         "ريڨلونا رب ريزو",
         "Negatif"
        ],
        [
         "34",
         "1",
         "Abdo Gros",
         "Malheureusement le réseau était coupé men 17h ! Hata dok bach wala en plus c'est en niveau d'Alger yahsra les autres wilaya !! Ni excuses ni rien! Mais bon en souhaitant une amélioration cette année nchlh",
         "Negatif"
        ],
        [
         "36",
         "2",
         "Abdelghani Tahtah",
         "ماهو هو الكود نتاع سلفلي ... ؟؟",
         "Neutre"
        ],
        [
         "37",
         "2",
         "أحمد فيراس",
         "مليح",
         "Positif"
        ],
        [
         "38",
         "2",
         "Œœ Œœ",
         "كيفاه نسلف عشرالاف",
         "Neutre"
        ],
        [
         "39",
         "2",
         "Houhou Ben Medani",
         null,
         "Neutre"
        ],
        [
         "40",
         "2",
         "Riad BM",
         "شكون يبعثلي 2 جيغا 😂😂",
         "Neutre"
        ],
        [
         "41",
         "2",
         "Amine Boudiaf",
         "رجعونا عروض امتياز لي نحيتوها لنا",
         "Negatif"
        ],
        [
         "42",
         "2",
         "زين الدين ابن البوادي",
         "أود معرفة كيفية سرقة رصيدي ؟\n الرجاء التوضيح \n لي رقمين من جيزي دائما لا اجد الرصيد Djezzy",
         "Negatif"
        ],
        [
         "43",
         "2",
         "Amani Amina",
         "كيف رقم خدمة سلفي",
         "Neutre"
        ],
        [
         "44",
         "2",
         "العربي نواوي",
         "ممكن نعرف علاش تنقصو من الرصيد \n والله العظيم عيب عيب عيب \n تفليكسي 50 الف غدوة تلقى 20 الف عيب\n حسبنا الله ونعم الوكيل.",
         "Negatif"
        ],
        [
         "45",
         "2",
         "Yassine Madrid",
         "من فضلكم شريت شريحة جيزي جديدة كيفاه نأكتيفيها مع العلم فيها 60g انترنت و 7000 مكالمات",
         "Neutre"
        ],
        [
         "46",
         "2",
         "Aoudjia Aimen",
         "وشبيه تطبيق حابس اي ريقلوه وريقليو الريزو رانا نعانيو 2024 وريزو ميت في حالا والله ما فهمنا ومفهمتش علاه رانا فالعالم الثالث (السبب الوحيد لا غيره لي مخلينا فالعالم الثالث انو مكاش عالم رابع او خامس)",
         "Negatif"
        ],
        [
         "47",
         "2",
         "صاحبة السعادة",
         "علابيها وليتو كنفليكسيو تدوهم",
         "Negatif"
        ],
        [
         "48",
         "2",
         "عائشة صديقة",
         "Djezzy من فضلكم أريد تقطيع الشريحة لتناسب الهاتف..لكن هذا غير ممكن مع شريحتي الحالية هل يمكن استبدالها مع أخرى قابلة لتقطيع مع شرط الاحتفاظ برقمي الحالي..",
         "Neutre"
        ],
        [
         "49",
         "2",
         "Youcef Mellah",
         "رانا نسلكو 150 لشهر و كونيكسيون ربي يجيب ممكن توضيح",
         "Negatif"
        ],
        [
         "50",
         "2",
         "Mar Lyn",
         "تخدمو الجمعة ؟",
         "Neutre"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4104
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Post</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Samir Bekhouche</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yanise Yanise</td>\n",
       "      <td>سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jj Kie</td>\n",
       "      <td>كل عام و انتم بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sakou Younes</td>\n",
       "      <td>كل عام وأنتم بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>راني نعاني</td>\n",
       "      <td>كل عام وحنا بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>183</td>\n",
       "      <td>Ĺã Rõsë Ýb</td>\n",
       "      <td>❤️❤️</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>183</td>\n",
       "      <td>نسمات هادئة</td>\n",
       "      <td>💕💕💕💕</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>183</td>\n",
       "      <td>ملك ملهاش غيرك</td>\n",
       "      <td>❤❤❤❤❤❤🌹</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>183</td>\n",
       "      <td>سعيدي رضا</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>183</td>\n",
       "      <td>جيبلي فيت فيت</td>\n",
       "      <td>❤️❤️❤️❤️</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4104 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Post        User Name  \\\n",
       "0           1  Samir Bekhouche   \n",
       "1           1    Yanise Yanise   \n",
       "2           1           Jj Kie   \n",
       "3           1     Sakou Younes   \n",
       "4           1       راني نعاني   \n",
       "...       ...              ...   \n",
       "4124      183       Ĺã Rõsë Ýb   \n",
       "4125      183      نسمات هادئة   \n",
       "4126      183   ملك ملهاش غيرك   \n",
       "4127      183        سعيدي رضا   \n",
       "4128      183    جيبلي فيت فيت   \n",
       "\n",
       "                                               Comments Sentiments  \n",
       "0                                                   NaN     Neutre  \n",
       "1     سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و...    Negatif  \n",
       "2                                    كل عام و انتم بخير    Positif  \n",
       "3                                     كل عام وأنتم بخير    Positif  \n",
       "4                                      كل عام وحنا بخير    Positif  \n",
       "...                                                 ...        ...  \n",
       "4124                                               ❤️❤️    Positif  \n",
       "4125                                               💕💕💕💕    Positif  \n",
       "4126                                            ❤❤❤❤❤❤🌹    Positif  \n",
       "4127                                                NaN     Neutre  \n",
       "4128                                           ❤️❤️❤️❤️    Positif  \n",
       "\n",
       "[4104 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppression des lignes où \"User Name\" est \"Djezzy\", \"Mobilis\" ou \"Ooredoo\"\n",
    "comments_df = comments_df[~comments_df[\"User Name\"].isin([\"Djezzy\", \"Mobilis\", \"Ooredoo Algérie\"])]\n",
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID Post",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comments",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiments",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "36b6352d-9b75-4bf4-a9c5-92ba458e7589",
       "rows": [
        [
         "1",
         "1",
         "Yanise Yanise",
         "سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و بدأت تنقص شوي شويا من 100 دج إلى 75دج و بعدها إلى 50 دج و بعدها إلى 25 دج !!!!!!!!!!! اين ذهبت لزونيتي تاعي ؟؟؟؟!!!!!!\n لن أتكلم بها و لم اتصل بها و ليس لي خاصية رنتي اذن اين ذهب مالي؟!؟!؟!؟\n و صار نفس الشيء مع أخي!!!!!!!!!!!!\n ماهذا لابد من استرجاعه",
         "Negatif"
        ],
        [
         "2",
         "1",
         "Jj Kie",
         "كل عام و انتم بخير",
         "Positif"
        ],
        [
         "3",
         "1",
         "Sakou Younes",
         "كل عام وأنتم بخير",
         "Positif"
        ],
        [
         "4",
         "1",
         "راني نعاني",
         "كل عام وحنا بخير",
         "Positif"
        ],
        [
         "5",
         "1",
         "Wahab Ziadi",
         "كل عام وحنا بخير",
         "Positif"
        ],
        [
         "6",
         "1",
         "أحمد فيراس",
         "🥰",
         "Positif"
        ],
        [
         "7",
         "1",
         "مروان سيدهم سيدهم مروان",
         "كل عام وأنتم بخير وأتمنا رد علا أسإلتي علا لحاص وكل عام وأنتم بخير",
         "Positif"
        ],
        [
         "8",
         "1",
         "Mostefa Merabti",
         "Happy New year",
         "Positif"
        ],
        [
         "9",
         "1",
         "وليد برك",
         "كاش عروض مدم رن في 2024",
         "Neutre"
        ],
        [
         "10",
         "1",
         "Aymen Aymen",
         "تحيا جيزي",
         "Positif"
        ],
        [
         "11",
         "1",
         "Maram Akram",
         "Bonne année à tous",
         "Positif"
        ],
        [
         "12",
         "1",
         "Plako Platr Ba 13",
         "🙏",
         "Neutre"
        ],
        [
         "13",
         "1",
         "Lina Sami",
         "كيفه نحول عروض جيزي سبيسيال باه نرجعها هايلة بزاف",
         "Neutre"
        ],
        [
         "14",
         "1",
         "Yakoub Boussebsi",
         "سنة سعيدة ورجعونا 6h",
         "Positif"
        ],
        [
         "15",
         "1",
         "Hamza Othmani",
         "بداية سنة سيئة جدا، لقد ثم قطع خطي ضلم، و مصلحة الزبائن لا ترد، عيب",
         "Negatif"
        ],
        [
         "16",
         "1",
         "RED ROSE",
         "🌹🌹🌹🌹",
         "Positif"
        ],
        [
         "17",
         "1",
         "Mohamed Mellak",
         "عام سعيد 2024",
         "Positif"
        ],
        [
         "19",
         "1",
         "Saber Zem",
         "أنا مشترك دفع بعدي تم تزويدي بخدمة chirpix دون علمي في 2 ديسمبر 2023، وعند الاطلاع على فاتورة شهر جانفي وجدت مبلغ 740.00 دج زائد عن الفاتورة وعند الاستفسار عند خدمة الزبائن كان بسبب chirpix، علما أنني لم أطلب هذه الخدمة أبدا ؟؟؟؟؟؟؟",
         "Neutre"
        ],
        [
         "20",
         "1",
         "جمعية الحي أبناء الغد لعياضات -قصر الأبطال-",
         "نحيطكم علما انا قريتنا ( قرية لعياضات ) التابعة لبلدية قصر الأبطال دائرة عين ولمان ولاية سطيف ان شبكة الانترنت جيزي تنعدم تماما في قريتنا.نرجو منكم ايجاد حل لهذه المشكلة",
         "Negatif"
        ],
        [
         "21",
         "1",
         "Sàm Fàràh Mehimdà",
         "كل مرة تسرقوا 50دج ؟؟؟؟ علاش هاك تخلونا نبدلوا الخط 🥴🥴🥴",
         "Negatif"
        ],
        [
         "22",
         "1",
         "Şàłàh Şğhïr",
         "كل عام وانتم بالف خير ❣️❣️",
         "Positif"
        ],
        [
         "23",
         "1",
         "Sofiane Sofiane",
         "علاه ديتولي 50 دج كل مرة راكم ديروهالي",
         "Negatif"
        ],
        [
         "24",
         "1",
         "Lamine Jseb",
         "واش بيه الريزو اليوم؟؟ ماكاش انترنت منذ 3 ساعات",
         "Negatif"
        ],
        [
         "25",
         "1",
         "マウンテ ンライト",
         "بهد مناسبة تبرعو علينا ب انترنت😁",
         "Neutre"
        ],
        [
         "26",
         "1",
         "Bnamer Boutayeb",
         "ريقلو ابليكاسيو نتاعكم",
         "Negatif"
        ],
        [
         "27",
         "1",
         "ゞゞじ づ づ",
         "ديرولنا كش حاجة نتع كونيكسيون",
         "Neutre"
        ],
        [
         "28",
         "1",
         "كنوش سمير",
         "مكانش كونيكسو 🙄😒",
         "Negatif"
        ],
        [
         "29",
         "1",
         "Fati Fati",
         "من 2006 راني مشتاركه معاكم كاش نهار فرحونا بهديه 😉",
         "Neutre"
        ],
        [
         "30",
         "1",
         "Sofiane Renault Medea",
         "بطيءة",
         "Negatif"
        ],
        [
         "31",
         "1",
         "Sifadine Mehdi",
         "ريزو وشبيه يروح و يجي ؟",
         "Negatif"
        ],
        [
         "32",
         "1",
         "Añdřeä Añdřeä",
         "وقتاه تردولنا ريزو🤧",
         "Negatif"
        ],
        [
         "33",
         "1",
         "Nabil Issam",
         "ريڨلونا رب ريزو",
         "Negatif"
        ],
        [
         "34",
         "1",
         "Abdo Gros",
         "Malheureusement le réseau était coupé men 17h ! Hata dok bach wala en plus c'est en niveau d'Alger yahsra les autres wilaya !! Ni excuses ni rien! Mais bon en souhaitant une amélioration cette année nchlh",
         "Negatif"
        ],
        [
         "36",
         "2",
         "Abdelghani Tahtah",
         "ماهو هو الكود نتاع سلفلي ... ؟؟",
         "Neutre"
        ],
        [
         "37",
         "2",
         "أحمد فيراس",
         "مليح",
         "Positif"
        ],
        [
         "38",
         "2",
         "Œœ Œœ",
         "كيفاه نسلف عشرالاف",
         "Neutre"
        ],
        [
         "40",
         "2",
         "Riad BM",
         "شكون يبعثلي 2 جيغا 😂😂",
         "Neutre"
        ],
        [
         "41",
         "2",
         "Amine Boudiaf",
         "رجعونا عروض امتياز لي نحيتوها لنا",
         "Negatif"
        ],
        [
         "42",
         "2",
         "زين الدين ابن البوادي",
         "أود معرفة كيفية سرقة رصيدي ؟\n الرجاء التوضيح \n لي رقمين من جيزي دائما لا اجد الرصيد Djezzy",
         "Negatif"
        ],
        [
         "43",
         "2",
         "Amani Amina",
         "كيف رقم خدمة سلفي",
         "Neutre"
        ],
        [
         "44",
         "2",
         "العربي نواوي",
         "ممكن نعرف علاش تنقصو من الرصيد \n والله العظيم عيب عيب عيب \n تفليكسي 50 الف غدوة تلقى 20 الف عيب\n حسبنا الله ونعم الوكيل.",
         "Negatif"
        ],
        [
         "45",
         "2",
         "Yassine Madrid",
         "من فضلكم شريت شريحة جيزي جديدة كيفاه نأكتيفيها مع العلم فيها 60g انترنت و 7000 مكالمات",
         "Neutre"
        ],
        [
         "46",
         "2",
         "Aoudjia Aimen",
         "وشبيه تطبيق حابس اي ريقلوه وريقليو الريزو رانا نعانيو 2024 وريزو ميت في حالا والله ما فهمنا ومفهمتش علاه رانا فالعالم الثالث (السبب الوحيد لا غيره لي مخلينا فالعالم الثالث انو مكاش عالم رابع او خامس)",
         "Negatif"
        ],
        [
         "47",
         "2",
         "صاحبة السعادة",
         "علابيها وليتو كنفليكسيو تدوهم",
         "Negatif"
        ],
        [
         "48",
         "2",
         "عائشة صديقة",
         "Djezzy من فضلكم أريد تقطيع الشريحة لتناسب الهاتف..لكن هذا غير ممكن مع شريحتي الحالية هل يمكن استبدالها مع أخرى قابلة لتقطيع مع شرط الاحتفاظ برقمي الحالي..",
         "Neutre"
        ],
        [
         "49",
         "2",
         "Youcef Mellah",
         "رانا نسلكو 150 لشهر و كونيكسيون ربي يجيب ممكن توضيح",
         "Negatif"
        ],
        [
         "50",
         "2",
         "Mar Lyn",
         "تخدمو الجمعة ؟",
         "Neutre"
        ],
        [
         "51",
         "2",
         "Oussama Chabane",
         "الحل",
         "Neutre"
        ],
        [
         "52",
         "2",
         "Sifoune Soufyane",
         "هل الرقم 455 خاص بكم ولماذا يتصل بي",
         "Neutre"
        ],
        [
         "53",
         "2",
         "Mohamed Rakmouche",
         "طريقة فلكسي من جيزي الى جيزي",
         "Neutre"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3924
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Post</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yanise Yanise</td>\n",
       "      <td>سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jj Kie</td>\n",
       "      <td>كل عام و انتم بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sakou Younes</td>\n",
       "      <td>كل عام وأنتم بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>راني نعاني</td>\n",
       "      <td>كل عام وحنا بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Wahab Ziadi</td>\n",
       "      <td>كل عام وحنا بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>183</td>\n",
       "      <td>مر سلين 'ے</td>\n",
       "      <td>🩷🩷🩷🩷🩷🩷</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>183</td>\n",
       "      <td>Ĺã Rõsë Ýb</td>\n",
       "      <td>❤️❤️</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>183</td>\n",
       "      <td>نسمات هادئة</td>\n",
       "      <td>💕💕💕💕</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>183</td>\n",
       "      <td>ملك ملهاش غيرك</td>\n",
       "      <td>❤❤❤❤❤❤🌹</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>183</td>\n",
       "      <td>جيبلي فيت فيت</td>\n",
       "      <td>❤️❤️❤️❤️</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3924 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Post       User Name  \\\n",
       "1           1   Yanise Yanise   \n",
       "2           1          Jj Kie   \n",
       "3           1    Sakou Younes   \n",
       "4           1      راني نعاني   \n",
       "5           1     Wahab Ziadi   \n",
       "...       ...             ...   \n",
       "4123      183      مر سلين 'ے   \n",
       "4124      183      Ĺã Rõsë Ýb   \n",
       "4125      183     نسمات هادئة   \n",
       "4126      183  ملك ملهاش غيرك   \n",
       "4128      183   جيبلي فيت فيت   \n",
       "\n",
       "                                               Comments Sentiments  \n",
       "1     سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و...    Negatif  \n",
       "2                                    كل عام و انتم بخير    Positif  \n",
       "3                                     كل عام وأنتم بخير    Positif  \n",
       "4                                      كل عام وحنا بخير    Positif  \n",
       "5                                      كل عام وحنا بخير    Positif  \n",
       "...                                                 ...        ...  \n",
       "4123                                             🩷🩷🩷🩷🩷🩷    Positif  \n",
       "4124                                               ❤️❤️    Positif  \n",
       "4125                                               💕💕💕💕    Positif  \n",
       "4126                                            ❤❤❤❤❤❤🌹    Positif  \n",
       "4128                                           ❤️❤️❤️❤️    Positif  \n",
       "\n",
       "[3924 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = comments_df.dropna(subset=[\"Comments\"])\n",
    "comments_df = comments_df[comments_df[\"Comments\"].str.strip() != \"\"]\n",
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID Post",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comments",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiments",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1d8b1ba0-3669-40f2-8fb2-38ef9a5a96d5",
       "rows": [
        [
         "1",
         "1",
         "Yanise Yanise",
         "سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و بدأت تنقص شوي شويا من 100 دج إلى 75دج و بعدها إلى 50 دج و بعدها إلى 25 دج !!!!!!!!!!! اين ذهبت لزونيتي تاعي ؟؟؟؟!!!!!!\n لن أتكلم بها و لم اتصل بها و ليس لي خاصية رنتي اذن اين ذهب مالي؟!؟!؟!؟\n و صار نفس الشيء مع أخي!!!!!!!!!!!!\n ماهذا لابد من استرجاعه",
         "Negatif"
        ],
        [
         "2",
         "1",
         "Jj Kie",
         "كل عام و انتم بخير",
         "Positif"
        ],
        [
         "3",
         "1",
         "Sakou Younes",
         "كل عام وأنتم بخير",
         "Positif"
        ],
        [
         "4",
         "1",
         "راني نعاني",
         "كل عام وحنا بخير",
         "Positif"
        ],
        [
         "6",
         "1",
         "أحمد فيراس",
         "🥰",
         "Positif"
        ],
        [
         "7",
         "1",
         "مروان سيدهم سيدهم مروان",
         "كل عام وأنتم بخير وأتمنا رد علا أسإلتي علا لحاص وكل عام وأنتم بخير",
         "Positif"
        ],
        [
         "8",
         "1",
         "Mostefa Merabti",
         "Happy New year",
         "Positif"
        ],
        [
         "9",
         "1",
         "وليد برك",
         "كاش عروض مدم رن في 2024",
         "Neutre"
        ],
        [
         "10",
         "1",
         "Aymen Aymen",
         "تحيا جيزي",
         "Positif"
        ],
        [
         "11",
         "1",
         "Maram Akram",
         "Bonne année à tous",
         "Positif"
        ],
        [
         "12",
         "1",
         "Plako Platr Ba 13",
         "🙏",
         "Neutre"
        ],
        [
         "13",
         "1",
         "Lina Sami",
         "كيفه نحول عروض جيزي سبيسيال باه نرجعها هايلة بزاف",
         "Neutre"
        ],
        [
         "14",
         "1",
         "Yakoub Boussebsi",
         "سنة سعيدة ورجعونا 6h",
         "Positif"
        ],
        [
         "15",
         "1",
         "Hamza Othmani",
         "بداية سنة سيئة جدا، لقد ثم قطع خطي ضلم، و مصلحة الزبائن لا ترد، عيب",
         "Negatif"
        ],
        [
         "16",
         "1",
         "RED ROSE",
         "🌹🌹🌹🌹",
         "Positif"
        ],
        [
         "17",
         "1",
         "Mohamed Mellak",
         "عام سعيد 2024",
         "Positif"
        ],
        [
         "19",
         "1",
         "Saber Zem",
         "أنا مشترك دفع بعدي تم تزويدي بخدمة chirpix دون علمي في 2 ديسمبر 2023، وعند الاطلاع على فاتورة شهر جانفي وجدت مبلغ 740.00 دج زائد عن الفاتورة وعند الاستفسار عند خدمة الزبائن كان بسبب chirpix، علما أنني لم أطلب هذه الخدمة أبدا ؟؟؟؟؟؟؟",
         "Neutre"
        ],
        [
         "20",
         "1",
         "جمعية الحي أبناء الغد لعياضات -قصر الأبطال-",
         "نحيطكم علما انا قريتنا ( قرية لعياضات ) التابعة لبلدية قصر الأبطال دائرة عين ولمان ولاية سطيف ان شبكة الانترنت جيزي تنعدم تماما في قريتنا.نرجو منكم ايجاد حل لهذه المشكلة",
         "Negatif"
        ],
        [
         "21",
         "1",
         "Sàm Fàràh Mehimdà",
         "كل مرة تسرقوا 50دج ؟؟؟؟ علاش هاك تخلونا نبدلوا الخط 🥴🥴🥴",
         "Negatif"
        ],
        [
         "22",
         "1",
         "Şàłàh Şğhïr",
         "كل عام وانتم بالف خير ❣️❣️",
         "Positif"
        ],
        [
         "23",
         "1",
         "Sofiane Sofiane",
         "علاه ديتولي 50 دج كل مرة راكم ديروهالي",
         "Negatif"
        ],
        [
         "24",
         "1",
         "Lamine Jseb",
         "واش بيه الريزو اليوم؟؟ ماكاش انترنت منذ 3 ساعات",
         "Negatif"
        ],
        [
         "25",
         "1",
         "マウンテ ンライト",
         "بهد مناسبة تبرعو علينا ب انترنت😁",
         "Neutre"
        ],
        [
         "26",
         "1",
         "Bnamer Boutayeb",
         "ريقلو ابليكاسيو نتاعكم",
         "Negatif"
        ],
        [
         "27",
         "1",
         "ゞゞじ づ づ",
         "ديرولنا كش حاجة نتع كونيكسيون",
         "Neutre"
        ],
        [
         "28",
         "1",
         "كنوش سمير",
         "مكانش كونيكسو 🙄😒",
         "Negatif"
        ],
        [
         "29",
         "1",
         "Fati Fati",
         "من 2006 راني مشتاركه معاكم كاش نهار فرحونا بهديه 😉",
         "Neutre"
        ],
        [
         "30",
         "1",
         "Sofiane Renault Medea",
         "بطيءة",
         "Negatif"
        ],
        [
         "31",
         "1",
         "Sifadine Mehdi",
         "ريزو وشبيه يروح و يجي ؟",
         "Negatif"
        ],
        [
         "32",
         "1",
         "Añdřeä Añdřeä",
         "وقتاه تردولنا ريزو🤧",
         "Negatif"
        ],
        [
         "33",
         "1",
         "Nabil Issam",
         "ريڨلونا رب ريزو",
         "Negatif"
        ],
        [
         "34",
         "1",
         "Abdo Gros",
         "Malheureusement le réseau était coupé men 17h ! Hata dok bach wala en plus c'est en niveau d'Alger yahsra les autres wilaya !! Ni excuses ni rien! Mais bon en souhaitant une amélioration cette année nchlh",
         "Negatif"
        ],
        [
         "36",
         "2",
         "Abdelghani Tahtah",
         "ماهو هو الكود نتاع سلفلي ... ؟؟",
         "Neutre"
        ],
        [
         "37",
         "2",
         "أحمد فيراس",
         "مليح",
         "Positif"
        ],
        [
         "38",
         "2",
         "Œœ Œœ",
         "كيفاه نسلف عشرالاف",
         "Neutre"
        ],
        [
         "40",
         "2",
         "Riad BM",
         "شكون يبعثلي 2 جيغا 😂😂",
         "Neutre"
        ],
        [
         "41",
         "2",
         "Amine Boudiaf",
         "رجعونا عروض امتياز لي نحيتوها لنا",
         "Negatif"
        ],
        [
         "42",
         "2",
         "زين الدين ابن البوادي",
         "أود معرفة كيفية سرقة رصيدي ؟\n الرجاء التوضيح \n لي رقمين من جيزي دائما لا اجد الرصيد Djezzy",
         "Negatif"
        ],
        [
         "43",
         "2",
         "Amani Amina",
         "كيف رقم خدمة سلفي",
         "Neutre"
        ],
        [
         "44",
         "2",
         "العربي نواوي",
         "ممكن نعرف علاش تنقصو من الرصيد \n والله العظيم عيب عيب عيب \n تفليكسي 50 الف غدوة تلقى 20 الف عيب\n حسبنا الله ونعم الوكيل.",
         "Negatif"
        ],
        [
         "45",
         "2",
         "Yassine Madrid",
         "من فضلكم شريت شريحة جيزي جديدة كيفاه نأكتيفيها مع العلم فيها 60g انترنت و 7000 مكالمات",
         "Neutre"
        ],
        [
         "46",
         "2",
         "Aoudjia Aimen",
         "وشبيه تطبيق حابس اي ريقلوه وريقليو الريزو رانا نعانيو 2024 وريزو ميت في حالا والله ما فهمنا ومفهمتش علاه رانا فالعالم الثالث (السبب الوحيد لا غيره لي مخلينا فالعالم الثالث انو مكاش عالم رابع او خامس)",
         "Negatif"
        ],
        [
         "47",
         "2",
         "صاحبة السعادة",
         "علابيها وليتو كنفليكسيو تدوهم",
         "Negatif"
        ],
        [
         "48",
         "2",
         "عائشة صديقة",
         "Djezzy من فضلكم أريد تقطيع الشريحة لتناسب الهاتف..لكن هذا غير ممكن مع شريحتي الحالية هل يمكن استبدالها مع أخرى قابلة لتقطيع مع شرط الاحتفاظ برقمي الحالي..",
         "Neutre"
        ],
        [
         "49",
         "2",
         "Youcef Mellah",
         "رانا نسلكو 150 لشهر و كونيكسيون ربي يجيب ممكن توضيح",
         "Negatif"
        ],
        [
         "50",
         "2",
         "Mar Lyn",
         "تخدمو الجمعة ؟",
         "Neutre"
        ],
        [
         "51",
         "2",
         "Oussama Chabane",
         "الحل",
         "Neutre"
        ],
        [
         "52",
         "2",
         "Sifoune Soufyane",
         "هل الرقم 455 خاص بكم ولماذا يتصل بي",
         "Neutre"
        ],
        [
         "53",
         "2",
         "Mohamed Rakmouche",
         "طريقة فلكسي من جيزي الى جيزي",
         "Neutre"
        ],
        [
         "54",
         "2",
         "Ÿõn És",
         "ريڨلو ريزو رحمة على والديكم",
         "Negatif"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3826
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Post</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yanise Yanise</td>\n",
       "      <td>سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jj Kie</td>\n",
       "      <td>كل عام و انتم بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sakou Younes</td>\n",
       "      <td>كل عام وأنتم بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>راني نعاني</td>\n",
       "      <td>كل عام وحنا بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>أحمد فيراس</td>\n",
       "      <td>🥰</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>183</td>\n",
       "      <td>مر سلين 'ے</td>\n",
       "      <td>🩷🩷🩷🩷🩷🩷</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>183</td>\n",
       "      <td>Ĺã Rõsë Ýb</td>\n",
       "      <td>❤️❤️</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>183</td>\n",
       "      <td>نسمات هادئة</td>\n",
       "      <td>💕💕💕💕</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>183</td>\n",
       "      <td>ملك ملهاش غيرك</td>\n",
       "      <td>❤❤❤❤❤❤🌹</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>183</td>\n",
       "      <td>جيبلي فيت فيت</td>\n",
       "      <td>❤️❤️❤️❤️</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3826 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Post       User Name  \\\n",
       "1           1   Yanise Yanise   \n",
       "2           1          Jj Kie   \n",
       "3           1    Sakou Younes   \n",
       "4           1      راني نعاني   \n",
       "6           1      أحمد فيراس   \n",
       "...       ...             ...   \n",
       "4123      183      مر سلين 'ے   \n",
       "4124      183      Ĺã Rõsë Ýb   \n",
       "4125      183     نسمات هادئة   \n",
       "4126      183  ملك ملهاش غيرك   \n",
       "4128      183   جيبلي فيت فيت   \n",
       "\n",
       "                                               Comments Sentiments  \n",
       "1     سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و...    Negatif  \n",
       "2                                    كل عام و انتم بخير    Positif  \n",
       "3                                     كل عام وأنتم بخير    Positif  \n",
       "4                                      كل عام وحنا بخير    Positif  \n",
       "6                                                     🥰    Positif  \n",
       "...                                                 ...        ...  \n",
       "4123                                             🩷🩷🩷🩷🩷🩷    Positif  \n",
       "4124                                               ❤️❤️    Positif  \n",
       "4125                                               💕💕💕💕    Positif  \n",
       "4126                                            ❤❤❤❤❤❤🌹    Positif  \n",
       "4128                                           ❤️❤️❤️❤️    Positif  \n",
       "\n",
       "[3826 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = comments_df.loc[comments_df[\"Comments\"].shift() != comments_df[\"Comments\"]]\n",
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kikoo\\AppData\\Local\\Temp\\ipykernel_17412\\1392052614.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comments_df[\"Comments\"] = comments_df[\"Comments\"].apply(normalize_arabic)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncomments_df[\"Comments\"] = comments_df[\"Comments\"].apply(replace_emojis)\\nposts_df[\"Contents\"] = posts_df[\"Contents\"].apply(replace_emojis)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_arabic(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "    text = re.sub(\"ڭ\", \"ك\", text)\n",
    "    text = re.sub(\"ڤ\", \"ق\", text)\n",
    "    text = re.sub(\"ڨ\", \"ق\", text)\n",
    "    text = re.sub(\"پ\", \"ب\", text)\n",
    "    text = re.sub(\"é\", \"e\", text)\n",
    "    text = re.sub(\"ê\", \"e\", text)\n",
    "    text = re.sub(\"ë\", \"e\", text)\n",
    "    text = re.sub(\"ç\", \"c\", text)\n",
    "    text = re.sub(\"à\", \"a\", text)\n",
    "    text = re.sub(\"â\", \"a\", text)\n",
    "    text = re.sub(\"ä\", \"a\", text)\n",
    "    text = re.sub(\"î\", \"i\", text)\n",
    "    text = re.sub(\"ï\", \"a\", text)\n",
    "    text = re.sub(\"æ\", \"ae\", text)\n",
    "    text = re.sub(\"œ\", \"oe\", text)\n",
    "    return text\n",
    "\"\"\"\n",
    "def replace_emojis(text):\n",
    "    emojis = {\n",
    "        \"\\U0001F601\": \"فرح\",\n",
    "        \"\\U0001F602\": \"فرح\",\n",
    "        \"\\U0001F603\": \"فرح\",\n",
    "        \"\\U0001F604\": \"فرح\",\n",
    "        \"\\U0001F606\": \"فرح\",\n",
    "        \"\\U0001F607\": \"فرح\",\n",
    "        \"\\U0001F60D\": \"حب\",\n",
    "        \"\\U0001F618\": \"حب\",\n",
    "        \"\\U0001F619\": \"حب\",\n",
    "        \"\\U0001F61A\": \"حب\",\n",
    "        \"\\U0001F61E\": \"حزن\",\n",
    "        \"\\U0001F61F\": \"حزن\",\n",
    "        \"\\U0001F620\": \"غضب\",\n",
    "        \"\\U0001F621\": \"غضب\",\n",
    "        \"\\U0001F92C\": \"غضب\",\n",
    "        \"\\U0001F636\": \"صمت\",\n",
    "        \"\\U0001F637\": \"مرض\",\n",
    "        \"\\U0001F638\": \"فرح\",\n",
    "        \"\\U0001F639\": \"ضحك\",\n",
    "        \"\\U0001F63B\": \"حب\",\n",
    "        \"\\U0001F63C\": \"فرح\",\n",
    "        \"\\U0001F63D\": \"حب\",\n",
    "        \"\\U0001F63E\": \"غضب\",\n",
    "        \"\\U0001F63F\": \"حزن\",\n",
    "        \"\\U0001F640\": \"حزن\",\n",
    "        \"\\U0001F641\": \"حزن\",\n",
    "        \"\\U0001F64B\": \"تحية\",\n",
    "        \"\\U0001F64E\": \"حزن\",\n",
    "        \"\\U0001FA79\": \"حب\",\n",
    "        \"\\U0001F970\": \"إعجاب\",\n",
    "        \"\\U00002764\": \"حب\",\n",
    "        \"\\U0001F495\": \"حب\",\n",
    "        \"\\U0001F339\": \"حب\",\n",
    "    }\n",
    "    for emoji, arabic_equivalent in emojis.items():\n",
    "        # Ajouter un espace après chaque remplacement\n",
    "        text = re.sub(emoji, f\" {arabic_equivalent} \", text)\n",
    "    return text.strip()\n",
    "\"\"\"\n",
    "\n",
    "# Appliquer la normalisation\n",
    "comments_df[\"Comments\"] = comments_df[\"Comments\"].apply(normalize_arabic)\n",
    "posts_df[\"Contents\"] = posts_df[\"Contents\"].apply(normalize_arabic)\n",
    "\n",
    "\"\"\"\n",
    "comments_df[\"Comments\"] = comments_df[\"Comments\"].apply(replace_emojis)\n",
    "posts_df[\"Contents\"] = posts_df[\"Contents\"].apply(replace_emojis)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID Post",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comments",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiments",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4c7e3ca2-5058-4189-9d1d-8487c0f0afc3",
       "rows": [
        [
         "1",
         "1",
         "Yanise Yanise",
         "سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و بدأت تنقص شوي شويا من 100 دج إلى 75دج و بعدها إلى 50 دج و بعدها إلى 25 دج !!!!!!!!!!! اين ذهبت لزونيتي تاعي ؟؟؟؟!!!!!!\n لن أتكلم بها و لم اتصل بها و ليس لي خاصية رنتي اذن اين ذهب مالي؟!؟!؟!؟\n و صار نفس الشيء مع أخي!!!!!!!!!!!!\n ماهذا لابد من استرجاعه",
         "Negatif"
        ],
        [
         "2",
         "1",
         "Jj Kie",
         "كل عام و انتم بخير",
         "Positif"
        ],
        [
         "3",
         "1",
         "Sakou Younes",
         "كل عام وأنتم بخير",
         "Positif"
        ],
        [
         "4",
         "1",
         "راني نعاني",
         "كل عام وحنا بخير",
         "Positif"
        ],
        [
         "6",
         "1",
         "أحمد فيراس",
         "🥰",
         "Positif"
        ],
        [
         "7",
         "1",
         "مروان سيدهم سيدهم مروان",
         "كل عام وأنتم بخير وأتمنا رد علا أسإلتي علا لحاص وكل عام وأنتم بخير",
         "Positif"
        ],
        [
         "8",
         "1",
         "Mostefa Merabti",
         "happy new year",
         "Positif"
        ],
        [
         "9",
         "1",
         "وليد برك",
         "كاش عروض مدم رن في 2024",
         "Neutre"
        ],
        [
         "10",
         "1",
         "Aymen Aymen",
         "تحيا جيزي",
         "Positif"
        ],
        [
         "11",
         "1",
         "Maram Akram",
         "bonne annee a tous",
         "Positif"
        ],
        [
         "12",
         "1",
         "Plako Platr Ba 13",
         "🙏",
         "Neutre"
        ],
        [
         "13",
         "1",
         "Lina Sami",
         "كيفه نحول عروض جيزي سبيسيال باه نرجعها هايلة بزاف",
         "Neutre"
        ],
        [
         "14",
         "1",
         "Yakoub Boussebsi",
         "سنة سعيدة ورجعونا 6h",
         "Positif"
        ],
        [
         "15",
         "1",
         "Hamza Othmani",
         "بداية سنة سيئة جدا، لقد ثم قطع خطي ضلم، و مصلحة الزبائن لا ترد، عيب",
         "Negatif"
        ],
        [
         "16",
         "1",
         "RED ROSE",
         "🌹🌹🌹🌹",
         "Positif"
        ],
        [
         "17",
         "1",
         "Mohamed Mellak",
         "عام سعيد 2024",
         "Positif"
        ],
        [
         "19",
         "1",
         "Saber Zem",
         "أنا مشترك دفع بعدي تم تزويدي بخدمة chirpix دون علمي في 2 ديسمبر 2023، وعند الاطلاع على فاتورة شهر جانفي وجدت مبلغ 740.00 دج زائد عن الفاتورة وعند الاستفسار عند خدمة الزبائن كان بسبب chirpix، علما أنني لم أطلب هذه الخدمة أبدا ؟؟؟؟؟؟؟",
         "Neutre"
        ],
        [
         "20",
         "1",
         "جمعية الحي أبناء الغد لعياضات -قصر الأبطال-",
         "نحيطكم علما انا قريتنا ( قرية لعياضات ) التابعة لبلدية قصر الأبطال دائرة عين ولمان ولاية سطيف ان شبكة الانترنت جيزي تنعدم تماما في قريتنا.نرجو منكم ايجاد حل لهذه المشكلة",
         "Negatif"
        ],
        [
         "21",
         "1",
         "Sàm Fàràh Mehimdà",
         "كل مرة تسرقوا 50دج ؟؟؟؟ علاش هاك تخلونا نبدلوا الخط 🥴🥴🥴",
         "Negatif"
        ],
        [
         "22",
         "1",
         "Şàłàh Şğhïr",
         "كل عام وانتم بالف خير ❣️❣️",
         "Positif"
        ],
        [
         "23",
         "1",
         "Sofiane Sofiane",
         "علاه ديتولي 50 دج كل مرة راكم ديروهالي",
         "Negatif"
        ],
        [
         "24",
         "1",
         "Lamine Jseb",
         "واش بيه الريزو اليوم؟؟ ماكاش انترنت منذ 3 ساعات",
         "Negatif"
        ],
        [
         "25",
         "1",
         "マウンテ ンライト",
         "بهد مناسبة تبرعو علينا ب انترنت😁",
         "Neutre"
        ],
        [
         "26",
         "1",
         "Bnamer Boutayeb",
         "ريقلو ابليكاسيو نتاعكم",
         "Negatif"
        ],
        [
         "27",
         "1",
         "ゞゞじ づ づ",
         "ديرولنا كش حاجة نتع كونيكسيون",
         "Neutre"
        ],
        [
         "28",
         "1",
         "كنوش سمير",
         "مكانش كونيكسو 🙄😒",
         "Negatif"
        ],
        [
         "29",
         "1",
         "Fati Fati",
         "من 2006 راني مشتاركه معاكم كاش نهار فرحونا بهديه 😉",
         "Neutre"
        ],
        [
         "30",
         "1",
         "Sofiane Renault Medea",
         "بطيءة",
         "Negatif"
        ],
        [
         "31",
         "1",
         "Sifadine Mehdi",
         "ريزو وشبيه يروح و يجي ؟",
         "Negatif"
        ],
        [
         "32",
         "1",
         "Añdřeä Añdřeä",
         "وقتاه تردولنا ريزو🤧",
         "Negatif"
        ],
        [
         "33",
         "1",
         "Nabil Issam",
         "ريقلونا رب ريزو",
         "Negatif"
        ],
        [
         "34",
         "1",
         "Abdo Gros",
         "malheureusement le reseau etait coupe men 17h ! hata dok bach wala en plus c'est en niveau d'alger yahsra les autres wilaya !! ni excuses ni rien! mais bon en souhaitant une amelioration cette annee nchlh",
         "Negatif"
        ],
        [
         "36",
         "2",
         "Abdelghani Tahtah",
         "ماهو هو الكود نتاع سلفلي ... ؟؟",
         "Neutre"
        ],
        [
         "37",
         "2",
         "أحمد فيراس",
         "مليح",
         "Positif"
        ],
        [
         "38",
         "2",
         "Œœ Œœ",
         "كيفاه نسلف عشرالاف",
         "Neutre"
        ],
        [
         "40",
         "2",
         "Riad BM",
         "شكون يبعثلي 2 جيغا 😂😂",
         "Neutre"
        ],
        [
         "41",
         "2",
         "Amine Boudiaf",
         "رجعونا عروض امتياز لي نحيتوها لنا",
         "Negatif"
        ],
        [
         "42",
         "2",
         "زين الدين ابن البوادي",
         "أود معرفة كيفية سرقة رصيدي ؟\n الرجاء التوضيح \n لي رقمين من جيزي دائما لا اجد الرصيد djezzy",
         "Negatif"
        ],
        [
         "43",
         "2",
         "Amani Amina",
         "كيف رقم خدمة سلفي",
         "Neutre"
        ],
        [
         "44",
         "2",
         "العربي نواوي",
         "ممكن نعرف علاش تنقصو من الرصيد \n والله العظيم عيب عيب عيب \n تفليكسي 50 الف غدوة تلقى 20 الف عيب\n حسبنا الله ونعم الوكيل.",
         "Negatif"
        ],
        [
         "45",
         "2",
         "Yassine Madrid",
         "من فضلكم شريت شريحة جيزي جديدة كيفاه نأكتيفيها مع العلم فيها 60g انترنت و 7000 مكالمات",
         "Neutre"
        ],
        [
         "46",
         "2",
         "Aoudjia Aimen",
         "وشبيه تطبيق حابس اي ريقلوه وريقليو الريزو رانا نعانيو 2024 وريزو ميت في حالا والله ما فهمنا ومفهمتش علاه رانا فالعالم الثالث (السبب الوحيد لا غيره لي مخلينا فالعالم الثالث انو مكاش عالم رابع او خامس)",
         "Negatif"
        ],
        [
         "47",
         "2",
         "صاحبة السعادة",
         "علابيها وليتو كنفليكسيو تدوهم",
         "Negatif"
        ],
        [
         "48",
         "2",
         "عائشة صديقة",
         "djezzy من فضلكم أريد تقطيع الشريحة لتناسب الهاتف..لكن هذا غير ممكن مع شريحتي الحالية هل يمكن استبدالها مع أخرى قابلة لتقطيع مع شرط الاحتفاظ برقمي الحالي..",
         "Neutre"
        ],
        [
         "49",
         "2",
         "Youcef Mellah",
         "رانا نسلكو 150 لشهر و كونيكسيون ربي يجيب ممكن توضيح",
         "Negatif"
        ],
        [
         "50",
         "2",
         "Mar Lyn",
         "تخدمو الجمعة ؟",
         "Neutre"
        ],
        [
         "51",
         "2",
         "Oussama Chabane",
         "الحل",
         "Neutre"
        ],
        [
         "52",
         "2",
         "Sifoune Soufyane",
         "هل الرقم 455 خاص بكم ولماذا يتصل بي",
         "Neutre"
        ],
        [
         "53",
         "2",
         "Mohamed Rakmouche",
         "طريقة فلكسي من جيزي الى جيزي",
         "Neutre"
        ],
        [
         "54",
         "2",
         "Ÿõn És",
         "ريقلو ريزو رحمة على والديكم",
         "Negatif"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3826
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Post</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yanise Yanise</td>\n",
       "      <td>سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jj Kie</td>\n",
       "      <td>كل عام و انتم بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sakou Younes</td>\n",
       "      <td>كل عام وأنتم بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>راني نعاني</td>\n",
       "      <td>كل عام وحنا بخير</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>أحمد فيراس</td>\n",
       "      <td>🥰</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>183</td>\n",
       "      <td>مر سلين 'ے</td>\n",
       "      <td>🩷🩷🩷🩷🩷🩷</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>183</td>\n",
       "      <td>Ĺã Rõsë Ýb</td>\n",
       "      <td>❤️❤️</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>183</td>\n",
       "      <td>نسمات هادئة</td>\n",
       "      <td>💕💕💕💕</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>183</td>\n",
       "      <td>ملك ملهاش غيرك</td>\n",
       "      <td>❤❤❤❤❤❤🌹</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>183</td>\n",
       "      <td>جيبلي فيت فيت</td>\n",
       "      <td>❤️❤️❤️❤️</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3826 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Post       User Name  \\\n",
       "1           1   Yanise Yanise   \n",
       "2           1          Jj Kie   \n",
       "3           1    Sakou Younes   \n",
       "4           1      راني نعاني   \n",
       "6           1      أحمد فيراس   \n",
       "...       ...             ...   \n",
       "4123      183      مر سلين 'ے   \n",
       "4124      183      Ĺã Rõsë Ýb   \n",
       "4125      183     نسمات هادئة   \n",
       "4126      183  ملك ملهاش غيرك   \n",
       "4128      183   جيبلي فيت فيت   \n",
       "\n",
       "                                               Comments Sentiments  \n",
       "1     سلام عليكم ورحمة لديا مشكلة ! فليكسيت 100 دج و...    Negatif  \n",
       "2                                    كل عام و انتم بخير    Positif  \n",
       "3                                     كل عام وأنتم بخير    Positif  \n",
       "4                                      كل عام وحنا بخير    Positif  \n",
       "6                                                     🥰    Positif  \n",
       "...                                                 ...        ...  \n",
       "4123                                             🩷🩷🩷🩷🩷🩷    Positif  \n",
       "4124                                               ❤️❤️    Positif  \n",
       "4125                                               💕💕💕💕    Positif  \n",
       "4126                                            ❤❤❤❤❤❤🌹    Positif  \n",
       "4128                                           ❤️❤️❤️❤️    Positif  \n",
       "\n",
       "[3826 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Contents",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Lien Post",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Nb Like",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Love",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Care",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Wow",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Sad",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Angry",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Haha",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cfbcef3b-130c-4ea0-8867-59969cd73b7a",
       "rows": [
        [
         "0",
         "1",
         "جازي تتمنّى لكم سنة سعيدة🥰\n#djezzy #happy_new_year_2024",
         "https://www.facebook.com/djezzy/posts/788227516669599?ref=embed_post",
         "272",
         "45",
         "0",
         "1",
         "1",
         "76",
         "14",
         "Djezzy",
         "2024-01-01 00:00:00"
        ],
        [
         "1",
         "2",
         "راك en panne و خصك رصيد ؟\nمع خدمة tranquilo تاع djezzy كلش ساهل👌\n#جازي #astuces_ساهلة",
         "https://www.facebook.com/watch/?v=1068829281022985&ref=sharing",
         "255",
         "28",
         "0",
         "1",
         "0",
         "12",
         "31",
         "Djezzy",
         "2024-01-04 00:00:00"
        ],
        [
         "2",
         "3",
         "it's time to be a legend",
         "https://www.facebook.com/djezzy/posts/392564993435969:392564993435969?ref=embed_post",
         "257",
         "51",
         "2",
         "0",
         "0",
         "2",
         "8",
         "Djezzy",
         "2024-01-10 00:00:00"
        ],
        [
         "3",
         "4",
         "djezzy vous souhaite yennayer amervuh!  ⴰⵙⵙⴻⴳⴰⵙ ⴰⵎⴻⴳⴰⵣ 2974\n ! جازي تقدم لكم أحرّ التهاني بمناسبة السنة الأمازيغية الجديدة\n#djezzy #yennayer_2974",
         "https://www.facebook.com/share/p/19UDNBoQ1k/",
         "621",
         "231",
         "10",
         "3",
         "0",
         "1",
         "300",
         "Djezzy",
         "2024-01-11 00:00:00"
        ],
        [
         "4",
         "5",
         "قريباً ...",
         "https://www.facebook.com/share/v/12B9LZySBRe/",
         "288",
         "49",
         "4",
         "0",
         "0",
         "3",
         "24",
         "Djezzy",
         "2024-01-12 00:00:00"
        ],
        [
         "5",
         "6",
         "و مكالمات غير محدودة نحو جميع شبكات النقال و الثابت.\nبـ 2500دج فقط !\n#نتا_هو_الأسطورة",
         "https://www.facebook.com/share/v/15R9u8sYHg/",
         "564",
         "157",
         "24",
         "0",
         "0",
         "7",
         "73",
         "Djezzy",
         "2024-01-13 00:00:00"
        ],
        [
         "6",
         "7",
         "مع جازي legend\nإستفد من مكالمات مجانية نحو كل شبكات النقال و الثابت !\nوحجم انترنت يصل إلى غاية 100 جيغا !\nإكتشفوا مزايا العرض الجديد djezzy legend على 👈 https://ms.spr.ly/6188iury6\n#نتا_هو_الأسطورة",
         "https://www.facebook.com/djezzy/posts/797321975760153?ref=embed_post",
         "438",
         "31",
         "5",
         "0",
         "0",
         "26",
         "52",
         "Djezzy",
         "2024-01-14 00:00:00"
        ],
        [
         "7",
         "8",
         "تمتع بالمكالمات المجانية نحو جميع شبكات الجوال📱 والثابت  ☎️ واستفد من 70جيغا ب2000 دج فقط !\nاستكشف كل المميزات على 👈https://ms.spr.ly/6187iux8v \n#نتا_هو_الأسطورة",
         "https://www.facebook.com/djezzy/posts/797937005698650?ref=embed_post",
         "428",
         "23",
         "4",
         "1",
         "1",
         "5",
         "52",
         "Djezzy",
         "2024-01-15 00:00:00"
        ],
        [
         "8",
         "9",
         "مع djezzy legend انت هو الـ legend \nبـ 2000دج !\nتحصلوا على 70go انترنت، مكالمات غير محدودة نحو جميع شبكات الثابت و النقال ! \nإكتشفوا مزايا djezzy legend على 👈 https://ms.spr.ly/6183iscku \n#نتا_هو_الأسطورة",
         "https://www.facebook.com/share/v/12BG5K7FV8K/",
         "323",
         "37",
         "5",
         "0",
         "1",
         "2",
         "9",
         "Djezzy",
         "2024-01-20 00:00:00"
        ],
        [
         "9",
         "10",
         "goal algeria vs burkina faso football ",
         "https://www.facebook.com/watch/?v=1346282365905418&ref=sharing",
         "170",
         "26",
         "1",
         "1",
         "0",
         "4",
         "2",
         "Djezzy",
         "2024-01-20 00:00:00"
        ],
        [
         "10",
         "11",
         "مع  pack 3ayla متراطي حتى match ⚽  \nاستفاد من modem 4g و 150go انترنت لمدة 6 أشهر ب9990دج 🤩\nمع pack 3ayla supporty \n فريقك مع عايلتك💪\nلمزيد من المعلومات زوروا موقعنا 👇🏻\n https://bit.ly/djezzy-pack3ayla\n#djezzy #match #3ayla",
         "https://www.facebook.com/watch/?v=1387729078503230&ref=sharing",
         "130",
         "8",
         "1",
         "1",
         "1",
         "2",
         "31",
         "Djezzy",
         "2024-01-23 00:00:00"
        ],
        [
         "11",
         "12",
         "مع zuni sport  على djezzy app 📲 تابع مواعيد و نتائج المباريات لحظة بلحظة ⚽ 👌 \nحمّل التطبيق الآن 👈 https://ms.spr.ly/6181gi6y3\n#djezzy_app #zuni_sport #max_foot",
         "https://www.facebook.com/share/p/13tcBA3rkg/",
         "189",
         "16",
         "3",
         "0",
         "0",
         "3",
         "11",
         "Djezzy",
         "2024-01-27 00:00:00"
        ],
        [
         "12",
         "13",
         "اليوم هو اليوم العالمي لحماية البيانات. تذكير أساسي بأهمية الحفاظ على خصوصيتك على الإنترنت. \nحماية البيانات تهم كل واحد منا 💻🔐 \naujourd'hui, c'est la journee mondiale de la protection des donnees. un rappel essentiel de l'importance de preserver votre vie privee en ligne. la protection des donnees concerne chacun d'entre \nnous💻🔐 \n#protectiondesdonnees #viepriveeenligne #djezzy",
         "https://www.facebook.com/share/p/15aRgkr5JS/",
         "161",
         "13",
         "2",
         "1",
         "0",
         "1",
         "11",
         "Djezzy",
         "2024-01-28 00:00:00"
        ],
        [
         "13",
         "14",
         "اختبر معلوماتك في كرة القدم ⚽️ \n وحاول تفوز بقسيمة شراء بقيمة 100 مليون سنتيم أسبوعيا 🤑 \nما عليك غير تحمّل djezzy app 📲 على الرابط  👈 https://ms.spr.ly/6181gi6y3\n#djezzy_app #djezzy_win",
         "https://www.facebook.com/share/p/1AzBbfwqh1/",
         "229",
         "22",
         "5",
         "0",
         "0",
         "2",
         "9",
         "Djezzy",
         "2024-01-30 00:00:00"
        ],
        [
         "14",
         "15",
         "أخبار محلية ، ثقافية ، رياضية ⚽\nمع  djezzy scoop 📣 ميفوتك حتى خبر ! \n للاشتراك إتصل على 404 أو أرسل sms الى نفس الرقم\n#djezzy_scoop #max_news",
         "https://www.facebook.com/share/p/13yNkR5JW2/",
         "150",
         "7",
         "0",
         "0",
         "0",
         "1",
         "11",
         "Djezzy",
         "2024-01-31 00:00:00"
        ],
        [
         "15",
         "16",
         "شكون فيكم يعرف le code باش يكتيفي double appel ؟\n#جازي #astuces_ساهلة",
         "https://www.facebook.com/watch/?v=1497445130819223&ref=sharing",
         "325",
         "33",
         "4",
         "0",
         "0",
         "5",
         "6",
         "Djezzy",
         "2024-02-01 00:00:00"
        ],
        [
         "16",
         "17",
         "كيفاش تتفادى توقف الخط ديالك 🤔 ؟\nتابع الحل في الفيديو 👇 \n#جازي #astuces_ساهلة",
         "https://www.facebook.com/watch/?v=408877615031858&rdid=nscweaDh1ie6K7G0",
         "161",
         "18",
         "2",
         "0",
         "0",
         "3",
         "10",
         "Djezzy",
         "2024-02-15 00:00:00"
        ],
        [
         "17",
         "18",
         "في رايكم , هاذ المرة علاش جينا 😉",
         "https://www.facebook.com/share/v/1CVK8AkWr6/",
         "202",
         "24",
         "2",
         "1",
         "0",
         "5",
         "18",
         "Djezzy",
         "2024-02-18 00:00:00"
        ],
        [
         "18",
         "19",
         "انضموا إلينا  🚶‍ في مبادرة البسمة walk for ؛ لنرسم البسمة مع بعض في كل خطوة.\nحملوا  djezzy app 📱 و حولوا خطواتكم إلى تبرعات لقفة رمضان  🌙 \nرابط التحميل 👈 https://ms.spr.ly/6181gi6y3\n#جازي #قفة_رمضان #البسمةwalk4",
         "https://www.facebook.com/share/p/14kGTVBiaXU/",
         "177",
         "19",
         "3",
         "0",
         "0",
         "13",
         "3",
         "Djezzy",
         "2024-02-19 00:00:00"
        ],
        [
         "19",
         "20",
         "باش نفرحو الناس في هذا رمضان 🌙 و نرسموا البسمة على وجوه الصايمين 😀 \nيلا نمشوا مع بعض و نتبرعوا بخطواتنا على djezzy app 👣 📲 \nرابط التحميل  👈 https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/19nVrLQmjV/",
         "173",
         "17",
         "5",
         "0",
         "0",
         "0",
         "2",
         "Djezzy",
         "2024-02-20 00:00:00"
        ],
        [
         "20",
         "21",
         "شارك في تحدي المشي 🚶‍♂️ مع صحابك و سجل خطواتك في فيديو و أنشرها على صفحتك ، طاقي djeezy مع هاشتاغ\n #جازي #قفة_رمضان #البسمةwalk4\nأحسن فيديو  راح نبرطاجيوها عبر صفحتنا 💪 \nرابط التطبيق👈 https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/p/1ESi1iAD8L/",
         "299",
         "34",
         "3",
         "2",
         "1",
         "6",
         "52",
         "Djezzy",
         "2024-02-21 00:00:00"
        ],
        [
         "21",
         "22",
         "خطوة ساهلة بمناسبة شهر رمضان الكريم 🌙 \n#جازي #astuces_ساهلة #قفة_رمضان #البسمةwalk4",
         "https://www.facebook.com/share/v/19dwGJKfjm/",
         "181",
         "23",
         "3",
         "0",
         "0",
         "4",
         "1",
         "Djezzy",
         "2024-02-22 00:00:00"
        ],
        [
         "22",
         "23",
         "طاقي صاحبك  يمشي بالزربة 🚶‍♂️ 🏃‍♂️\n#جازي  #قفة_رمضان #البسمةwalk4",
         "https://www.facebook.com/share/p/14KAHkwsXF/",
         "201",
         "23",
         "3",
         "0",
         "2",
         "4",
         "58",
         "Djezzy",
         "2024-02-23 00:00:00"
        ],
        [
         "23",
         "24",
         "كل واحد يكتبلنا في التعليقات شحال من خطوة مشاها على djezzy app 👣 🚶‍♂️ 📱 \nيدرى شكون راح يكون 🏆 le champion  ؟\n #جازي #قفة_رمضان #البسمةwalk4",
         "https://www.facebook.com/share/p/18BbsUNDKa/",
         "204",
         "18",
         "3",
         "0",
         "0",
         "3",
         "26",
         "Djezzy",
         "2024-02-24 00:00:00"
        ],
        [
         "24",
         "25",
         "البسمة walk for 🚶‍♂️ مازالها متواصلة 👣\n طاقي صاحبك لي مازال ماشاركش معانا \n#جازي #قفة_رمضان #البسمةwalk4",
         "https://www.facebook.com/share/v/17cPeTM5qo/",
         "111",
         "20",
         "0",
         "0",
         "0",
         "5",
         "9",
         "Djezzy",
         "2024-02-26 00:00:00"
        ],
        [
         "25",
         "26",
         "نشاركوا معاكم  top 10 تع البسمة walk for\nإنضموا إلينا، مازلنا متواصلين من أجل رسم البسمة مع بعض.\n#جازي #قفة_رمضان #البسمةwalk4",
         "https://www.facebook.com/share/p/1BYQb7q2cL/",
         "185",
         "17",
         "1",
         "0",
         "0",
         "4",
         "10",
         "Djezzy",
         "2024-02-27 00:00:00"
        ],
        [
         "26",
         "27",
         "🚶‍ مبادرة البسمة  walk for مازالها متواصلة  ؛ خطواتنا راح تفرّح بزاف ناس \nحملوا  djezzy app 📱 و حولوا خطواتكم إلى تبرعات لقفة رمضان  🌙 \nرابط التحميل 👈 https://ms.spr.ly/6181gi6y3\n#جازي #قفة_رمضان #البسمةwalk4",
         "https://www.facebook.com/share/p/18KCQQmfLL/",
         "228",
         "30",
         "2",
         "0",
         "1",
         "3",
         "6",
         "Djezzy",
         "2024-02-29 00:00:00"
        ],
        [
         "27",
         "28",
         "و للأسبوع الثاني ✌️ البسمة walk for مازالها متواصلة بنجاح بفضل خطواتكم 👣\n#جازي #قفة_رمضان #البسمةwalk4",
         "https://www.facebook.com/share/v/12AywsCXXA3/",
         "128",
         "20",
         "0",
         "0",
         "0",
         "2",
         "4",
         "Djezzy",
         "2024-03-04 00:00:00"
        ],
        [
         "28",
         "29",
         "نشاركوا معاكم   🚶‍♂️ 👣 the best walkers  للأسبوع الثاني ✌️ \nإنضموا إلينا من أجل رسم البسمة مع بعض في هذا رمضان \n#جازي #قفة_رمضان #البسمةwalk4",
         "https://www.facebook.com/share/p/1Azzo8rf7E/",
         "167",
         "19",
         "0",
         "0",
         "0",
         "1",
         "2",
         "Djezzy",
         "2024-03-06 00:00:00"
        ],
        [
         "29",
         "30",
         "نختتم مبادرة البسمة walk for بأكثر من 821 مليون خطوة 💪 👣\nشكراً على مشاركتكم و دعمكم القيّم 🙏 مع بعض صنعنا البسمة 😀\n#جازي #قفة_رمضان #البسمةwalk4",
         "https://www.facebook.com/watch/?v=3419181848374064&rdid=OpVtNNOSdxW0g2eO",
         "110",
         "23",
         "1",
         "0",
         "0",
         "1",
         "1",
         "Djezzy",
         "2024-03-10 00:00:00"
        ],
        [
         "30",
         "31",
         "باش تولي مشهور لازملك بزّاف انترنت 🤩\nو باش تولي أسطورة لازملك djezzy legend 😉\nاكتشفوا تفاصيل العرض على 👈 https://bit.ly/3uw7xsl",
         "https://www.facebook.com/share/v/15kQvgwaYH/",
         "89",
         "15",
         "2",
         "0",
         "0",
         "1",
         "13",
         "Djezzy",
         "2024-03-11 00:00:00"
        ],
        [
         "31",
         "32",
         "حمّل djezzy app و شارك في مسابقة عمرة ranati لشخصين 🕋\nرابط التطبيق👈 https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/18BXF4DAnq/",
         "131",
         "37",
         "0",
         "0",
         "0",
         "0",
         "1",
         "Djezzy",
         "2024-03-11 00:00:00"
        ],
        [
         "32",
         "33",
         "هذا رمضان الفرحة دوبل 😄x2 على djezzy app 📱  \nرابط التطبيق👈 https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/1FyzpbnWBQ/",
         "106",
         "30",
         "1",
         "1",
         "0",
         "2",
         "0",
         "Djezzy",
         "2024-03-12 00:00:00"
        ],
        [
         "33",
         "34",
         "مع djezzy app دوبلي فرحتك 🤩 و الانترنت ديالك ✌️ \nرابط التطبيق👈 https://ms.spr.ly/6181gi6y3",
         "https://www.facebook.com/share/v/17z9TWBMWj/",
         "132",
         "20",
         "2",
         "0",
         "0",
         "2",
         "2",
         "Djezzy",
         "2024-03-13 00:00:00"
        ],
        [
         "34",
         "35",
         "باش دير محتوى أسطوري لازملك عرض أسطوري 😎 \nاكتشفوا التفاصيل   👈 https://ms.spr.ly/6187cis3p\nمع djezzy legend انت هو الأسطورة  👊",
         "https://www.facebook.com/share/p/1NTLjuLH4q/",
         "179",
         "22",
         "0",
         "1",
         "0",
         "3",
         "31",
         "Djezzy",
         "2024-03-14 00:00:00"
        ],
        [
         "35",
         "36",
         "كامل يوصلنا  sms 📲 بلي ربحنا في مسابقات و حنا ماشاركناش فيها !\nكيفاش نتفادوها  ؟\n#جازي #astuces_ساهلة #رمضان2024",
         "https://www.facebook.com/share/v/1Ax3tK3yQf/",
         "71",
         "13",
         "1",
         "0",
         "0",
         "2",
         "0",
         "Djezzy",
         "2024-03-14 00:00:00"
        ],
        [
         "36",
         "37",
         "انترنت ❌ 2  لمدة أسبوع !\nحمّل djezzy app و استمتع ب10 جيغا لكل عرض تاع 300 دج \nرابط التطبيق👈 https://ms.spr.ly/6181gi6y3\n#جازي #دوبل_أنترنت #رمضان2024_جازي_app",
         "https://www.facebook.com/share/v/1QvSNe3qr6/",
         "86",
         "16",
         "2",
         "0",
         "0",
         "8",
         "3",
         "Djezzy",
         "2024-03-17 00:00:00"
        ],
        [
         "37",
         "38",
         "كونكتي double❌ 2 و أفرح double❌ 2 مع انترنت  double ❌ 2\nحمّل التطبيق👈 https://ms.spr.ly/6181gi6y3\n#جازي #دوبل_أنترنت #رمضان2024_جازي_app",
         "https://www.facebook.com/share/p/19cMcLv6sd/",
         "139",
         "18",
         "0",
         "0",
         "0",
         "4",
         "2",
         "Djezzy",
         "2024-03-17 00:00:00"
        ],
        [
         "38",
         "39",
         "مع عرض جازي legend max الجديد، استفد من مكالمات غير محدودة نحو جميع الشبكات الوطنية وحدّ أقصى من الانترنت !\nللمزيد من التفاصيل : https://ms.spr.ly/6186cudnk\n#جازي #نتاـهوـالأسطورة",
         "https://www.facebook.com/share/p/1Gxhnote12/",
         "163",
         "31",
         "1",
         "0",
         "0",
         "2",
         "1",
         "Djezzy",
         "2024-03-22 00:00:00"
        ],
        [
         "39",
         "40",
         "مع djezzy app أبقى دايماً connecte بdouble \n  استمتع ب10 جيغا لمدة أسبوع  ب300 دج فقط ! \nرابط التطبيق👈 https://ms.spr.ly/6181gi6y3\n#جازي #دوبل_أنترنت #رمضان2024_جازي_app",
         "https://www.facebook.com/share/v/19THVFCcWA/",
         "64",
         "18",
         "0",
         "0",
         "0",
         "2",
         "2",
         "Djezzy",
         "2024-03-23 00:00:00"
        ],
        [
         "40",
         "41",
         "\nعندك legend max؟\nbien sûr que انت اسطورة 😎",
         "https://www.facebook.com/share/v/1EZyVsxH3S/",
         "91",
         "20",
         "0",
         "1",
         "0",
         "0",
         "6",
         "Djezzy",
         "2024-03-25 00:00:00"
        ],
        [
         "41",
         "42",
         "بالشراكة مع الكشافة الإسلامية الجزائرية، جازي تشارككم الأجواء التضامنية من مطعم فوج امال قاوش ببلدية الشراقة.\nتتميز هذه المبادرة بمساهمة الكشافين من مختلف الأعمار  في ادخال الفرحة ورسم البسمة على وجوه القاصدين و العابرين من كل مكان.\nفي هذا رمضان نرسمو البسمة  مع بعض 🤝 \nفوج ٱمال قاوش الكشافة الإسلامية الجزائرية \n #جازي #مائدة_البسمة #الكشافة_الإسلامية_الجزائرية",
         "https://www.facebook.com/share/v/1Dcy3GKWLV/",
         "65",
         "28",
         "3",
         "0",
         "0",
         "0",
         "0",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "42",
         "43",
         "تابعوا الاحداث المتنوعة في حلقة اليوم من شبه حصة 2 في هذا رمضان 🌙 \nشاهدوا  الحلقة كاملة على 👈  https://youtu.be/iarixuw3n40\n#جازي #شبه_حصة2 #رمضان2024",
         "https://www.facebook.com/share/v/196vTS7ztN/",
         "49",
         "17",
         "2",
         "0",
         "0",
         "0",
         "1",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "43",
         "44",
         "مع  legend max استفد من مكالمات غير محدودة نحو جميع الشبكات الوطنية و الmax  تاع الانترنت 😎 \nللمزيد من التفاصيل : https://ms.spr.ly/6186cudnk\n#جازي #نتا_هو_الأسطورة",
         "https://www.facebook.com/share/p/15N1wg8V2N/",
         "133",
         "20",
         "4",
         "2",
         "0",
         "5",
         "4",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "44",
         "45",
         "متفوتش العرض في هذا رمضان 😎 \nحمّل ، اكتيفي ، و دوبلي ✌️ \nهذا كامل على 👈 https://ms.spr.ly/6181gi6y3\n#جازي #دوبل_أنترنت #رمضان2024_جازي_app",
         "https://www.facebook.com/share/v/19HbnWWpMa/",
         "37",
         "15",
         "1",
         "0",
         "0",
         "4",
         "0",
         "Djezzy",
         "2024-03-28 00:00:00"
        ],
        [
         "45",
         "46",
         "تابعوا حلقة اليوم من شبه حصة مع مراد و أرقام 🎬\nلمشاهدة الحلقة كاملة 👈 https://youtu.be/sqxb8u6ui-4",
         "https://www.facebook.com/share/v/1AewF1ZDSN/",
         "35",
         "16",
         "1",
         "0",
         "0",
         "0",
         "0",
         "Djezzy",
         "2024-03-28 00:00:00"
        ],
        [
         "46",
         "47",
         "ألف شكر super fans تاعنا ،شكرا على محبتكم و وفائكم لينا و تفاعلكم الدائم معانا 🥰🙏🏻🙌\nصح سحوركم 🌙",
         "https://www.facebook.com/share/v/15Z5g8V2Cs/",
         "76",
         "33",
         "5",
         "0",
         "0",
         "1",
         "0",
         "Djezzy",
         "2024-03-29 00:00:00"
        ],
        [
         "47",
         "48",
         "تحب دير بزاف les stories ، les reels ، les photos غير djezzy legend لي تخرج عليك , 100 go إنترنت و انت مهني 😎 \nللمزيد من التفاصيل : https://ms.spr.ly/6186cudnk\n#جازي #نتا_هو_الأسطورة",
         "https://www.facebook.com/share/v/19aWCgdZW3/",
         "133",
         "20",
         "2",
         "0",
         "0",
         "2",
         "7",
         "Djezzy",
         "2024-03-30 00:00:00"
        ],
        [
         "48",
         "49",
         "نتوما عشاق الألعاب الإلكترونية 🎮🕹️ تحبو تقضيو وقت شباب معنا؟🎯 \nخممت فيكم  #mobilistore  عيشوا متعة الألعاب فيها  🎊🎁🎀\n#موبيليس #معا_نصنع_المستقبل",
         "https://www.facebook.com/share/p/18K8JuwacB/",
         "399",
         "38",
         "8",
         "0",
         "0",
         "1",
         "2",
         "Mobilis",
         "2024-01-04 00:00:00"
        ],
        [
         "49",
         "50",
         "قرعة الدورين الـ32 والـ16 لكأس الجزائر الطبعة 59 🏆⚽🇩🇿\nتتابعونها يوم الأحد 7 جانفي 2024 على الساعة 17:30⏳\n#موبيليس #الراعي_والشريك_الرسمي_لكأس_الجزائر\n#معا_نصنع_المستقبل",
         "https://www.facebook.com/share/p/15Y99MUo3z/",
         "612",
         "61",
         "7",
         "0",
         "0",
         "1",
         "0",
         "Mobilis",
         "2024-01-06 00:00:00"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 183
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Contents</th>\n",
       "      <th>Lien Post</th>\n",
       "      <th>Nb Like</th>\n",
       "      <th>Nb Love</th>\n",
       "      <th>Nb Care</th>\n",
       "      <th>Nb Wow</th>\n",
       "      <th>Nb Sad</th>\n",
       "      <th>Nb Angry</th>\n",
       "      <th>Nb Haha</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>جازي تتمنّى لكم سنة سعيدة🥰\\n#djezzy #happy_new...</td>\n",
       "      <td>https://www.facebook.com/djezzy/posts/78822751...</td>\n",
       "      <td>272</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>14</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>راك en panne و خصك رصيد ؟\\nمع خدمة tranquilo ت...</td>\n",
       "      <td>https://www.facebook.com/watch/?v=106882928102...</td>\n",
       "      <td>255</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>it's time to be a legend</td>\n",
       "      <td>https://www.facebook.com/djezzy/posts/39256499...</td>\n",
       "      <td>257</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>djezzy vous souhaite yennayer amervuh!  ⴰⵙⵙⴻⴳⴰ...</td>\n",
       "      <td>https://www.facebook.com/share/p/19UDNBoQ1k/</td>\n",
       "      <td>621</td>\n",
       "      <td>231</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>قريباً ...</td>\n",
       "      <td>https://www.facebook.com/share/v/12B9LZySBRe/</td>\n",
       "      <td>288</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>179</td>\n",
       "      <td>إثارة الألعاب تتعاش مع الأحباب، خاصة كي ooredo...</td>\n",
       "      <td>https://www.facebook.com/share/p/1KGHZQuXex/</td>\n",
       "      <td>208</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>مع ooredoo ديما رابحين !\\nوجّدنا لكم حاجة جديد...</td>\n",
       "      <td>https://www.facebook.com/share/v/1Bc7FtdDPx/</td>\n",
       "      <td>625</td>\n",
       "      <td>125</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>عشنا مع بعض أجواء رمضانية رائعة من خلال الإفطا...</td>\n",
       "      <td>https://www.facebook.com/reel/954679512980806</td>\n",
       "      <td>280</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>182</td>\n",
       "      <td>ضاعفوا اشتراك الإنترنت الخاص بكم خلال شهر رمضا...</td>\n",
       "      <td>https://www.facebook.com/watch/?v=193245186050...</td>\n",
       "      <td>148</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>183</td>\n",
       "      <td>أنتم من عشاق السينما العربية؟ حمّلوا التطبيق ش...</td>\n",
       "      <td>https://www.facebook.com/OoredooDZ/posts/44139...</td>\n",
       "      <td>215</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                           Contents  \\\n",
       "0      1  جازي تتمنّى لكم سنة سعيدة🥰\\n#djezzy #happy_new...   \n",
       "1      2  راك en panne و خصك رصيد ؟\\nمع خدمة tranquilo ت...   \n",
       "2      3                           it's time to be a legend   \n",
       "3      4  djezzy vous souhaite yennayer amervuh!  ⴰⵙⵙⴻⴳⴰ...   \n",
       "4      5                                         قريباً ...   \n",
       "..   ...                                                ...   \n",
       "178  179  إثارة الألعاب تتعاش مع الأحباب، خاصة كي ooredo...   \n",
       "179  180  مع ooredoo ديما رابحين !\\nوجّدنا لكم حاجة جديد...   \n",
       "180  181  عشنا مع بعض أجواء رمضانية رائعة من خلال الإفطا...   \n",
       "181  182  ضاعفوا اشتراك الإنترنت الخاص بكم خلال شهر رمضا...   \n",
       "182  183  أنتم من عشاق السينما العربية؟ حمّلوا التطبيق ش...   \n",
       "\n",
       "                                             Lien Post  Nb Like  Nb Love  \\\n",
       "0    https://www.facebook.com/djezzy/posts/78822751...      272       45   \n",
       "1    https://www.facebook.com/watch/?v=106882928102...      255       28   \n",
       "2    https://www.facebook.com/djezzy/posts/39256499...      257       51   \n",
       "3         https://www.facebook.com/share/p/19UDNBoQ1k/      621      231   \n",
       "4        https://www.facebook.com/share/v/12B9LZySBRe/      288       49   \n",
       "..                                                 ...      ...      ...   \n",
       "178       https://www.facebook.com/share/p/1KGHZQuXex/      208       46   \n",
       "179       https://www.facebook.com/share/v/1Bc7FtdDPx/      625      125   \n",
       "180      https://www.facebook.com/reel/954679512980806      280       40   \n",
       "181  https://www.facebook.com/watch/?v=193245186050...      148       35   \n",
       "182  https://www.facebook.com/OoredooDZ/posts/44139...      215       46   \n",
       "\n",
       "     Nb Care  Nb Wow  Nb Sad  Nb Angry  Nb Haha  Company       Date  \n",
       "0          0       1       1        76       14   Djezzy 2024-01-01  \n",
       "1          0       1       0        12       31   Djezzy 2024-01-04  \n",
       "2          2       0       0         2        8   Djezzy 2024-01-10  \n",
       "3         10       3       0         1      300   Djezzy 2024-01-11  \n",
       "4          4       0       0         3       24   Djezzy 2024-01-12  \n",
       "..       ...     ...     ...       ...      ...      ...        ...  \n",
       "178        6       0       0         0        1  Ooredoo 2024-03-26  \n",
       "179       14       0       1         1        1  Ooredoo 2024-03-27  \n",
       "180        7       1       1         0        0  Ooredoo 2024-03-28  \n",
       "181        3       0       0         2        0  Ooredoo 2024-03-28  \n",
       "182        5       0       0         1        0  Ooredoo 2024-03-30  \n",
       "\n",
       "[183 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = emoji.replace_emoji(text, replace=\" \")  # Supprimer les emojis\n",
    "    text = re.sub(r'http\\S+ | htps\\S+', \" \", str(text))  # Supprimer les hyperliens\n",
    "    text = re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+))', \" \", str(text))  # Supprimer les URL\n",
    "    text = re.sub(r'@\\S+', '', str(text))  # Supprimer les mots commençant par @\n",
    "    text = text.replace(\"_\", \" \").replace(\"#\", \"\")  # Supprimer # et _\n",
    "    text = text.replace(\"'\", \" \")  # Supprimer '\n",
    "    text = re.sub(r'\\. | , | ، | ؛', \" \", text)  # Supprimer les ponctuations\n",
    "    \n",
    "    # Supprimer les mots réservés\n",
    "    text = re.sub(r'\\bRT\\b | \\bRetweeted\\b', \" \", text)\n",
    "\n",
    "    # Supprimer tout caractère spécial sauf l'alphabet arabe et latin\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\u0600-\\u06FF\\s]', \" \", text)\n",
    "        \n",
    "    # Supprimer les voyelles courtes arabes (حركات)\n",
    "    harakat = \"[\\u064B-\\u0652]\"  # Comprend\n",
    "    text = re.sub(harakat, '', text)\n",
    "\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\", text)  # Supprimer les caractères consécutifs en double\n",
    "    text = text.replace('\\n', \" \").replace('/', \" \")  # Supprimer sauts de ligne et /\n",
    "    text = re.sub(r'[^\\w\\s]', \" \", text)  # Supprimer les caractères spéciaux\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "comments_df[\"Comments\"] = comments_df[\"Comments\"].apply(clean_text)\n",
    "posts_df[\"Contents\"] = posts_df[\"Contents\"].apply(clean_text)\n",
    "\n",
    "# Remplacer les valeurs nulles par une chaîne vide\n",
    "comments_df[\"Comments\"] = comments_df[\"Comments\"].fillna('')\n",
    "posts_df[\"Contents\"] = posts_df[\"Contents\"].fillna('')\n",
    "\n",
    "comments_df = comments_df.dropna(subset=[\"Comments\"])\n",
    "comments_df = comments_df[comments_df[\"Comments\"].str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID Post",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comments",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiments",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment_Predicted",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f1be4f68-c8f3-402f-8eb5-71d6e49875ad",
       "rows": [
        [
         "1",
         "1",
         "Yanise Yanise",
         "سلام عليكم ورحمة لديا مشكلة تعبئة 100 دج و بدأت تنقص قليل قليل من 100 دج إلى 75دج و بعدها إلى 50 دج و بعدها إلى 25 دج اين ذهبت رصيد تاعي    لن أتكلم بها و لم اتصل بها و ليس لي خاصية رنتي اذن اين ذهب مالي        و صار نفس الشيء مع أخي  ماهذا لابد من استرجاعه",
         "Negatif",
         "Negatif"
        ],
        [
         "2",
         "1",
         "Jj Kie",
         "كل عام و انتم بخير",
         "Positif",
         "Positif"
        ],
        [
         "3",
         "1",
         "Sakou Younes",
         "كل عام وأنتم بخير",
         "Positif",
         "Neutre"
        ],
        [
         "4",
         "1",
         "راني نعاني",
         "كل عام وحنا بخير",
         "Positif",
         "Positif"
        ],
        [
         "7",
         "1",
         "مروان سيدهم سيدهم مروان",
         "كل عام وأنتم بخير وأتمنا رد لماذا اسئلة لماذا لحاص وكل عام وأنتم بخير",
         "Positif",
         "Neutre"
        ],
        [
         "8",
         "1",
         "Mostefa Merabti",
         "سعيدة جديدة سنة",
         "Positif",
         "Positif"
        ],
        [
         "9",
         "1",
         "وليد برك",
         "أي عروض مدم رن في 2024",
         "Neutre",
         "Neutre"
        ],
        [
         "10",
         "1",
         "Aymen Aymen",
         "تحيا جازي",
         "Positif",
         "Positif"
        ],
        [
         "11",
         "1",
         "Maram Akram",
         "bonne annee a tous",
         "Positif",
         "Positif"
        ],
        [
         "13",
         "1",
         "Lina Sami",
         "كيفه نحول عروض جازي منفرد لكي نرجعها هايلة كثيرا",
         "Neutre",
         "Positif"
        ],
        [
         "14",
         "1",
         "Yakoub Boussebsi",
         "سنة سعيدة ورجعونا 6h",
         "Positif",
         "Positif"
        ],
        [
         "15",
         "1",
         "Hamza Othmani",
         "بداية سنة سيئة جدا  لقد ثم قطع شبكة ضلم  و مصلحة الزبائن لا ترد  عيب",
         "Negatif",
         "Negatif"
        ],
        [
         "17",
         "1",
         "Mohamed Mellak",
         "عام سعيد 2024",
         "Positif",
         "Positif"
        ],
        [
         "19",
         "1",
         "Saber Zem",
         "أنا مشترك دفع بعدي تم تزويدي بخدمة chirpix دون علمي في 2 ديسمبر 2023  وعند الاطلاع على فاتورة شهر جانفي وجدت مبلغ 740 00 دج زائد عن الفاتورة وعند الاستفسار عند خدمة الزبائن كان بسبب chirpix  علما أنني لم أطلب هذه الخدمة أبدا",
         "Neutre",
         "Negatif"
        ],
        [
         "20",
         "1",
         "جمعية الحي أبناء الغد لعياضات -قصر الأبطال-",
         "نحيطكم علما انا قريتنا قرية لعياضات التابعة لبلدية قصر الأبطال دائرة عين ولمان ولاية سطيف ان شبكة انترنت جازي تنعدم تماما في قريتنا نرجو منكم ايجاد حل لهذه المشكلة",
         "Negatif",
         "Negatif"
        ],
        [
         "21",
         "1",
         "Sàm Fàràh Mehimdà",
         "كل مرة تسرقوا 50دج   لماذا هاك تخلونا نبدلوا الخط",
         "Negatif",
         "Negatif"
        ],
        [
         "22",
         "1",
         "Şàłàh Şğhïr",
         "كل عام وانتم بالف خير",
         "Positif",
         "Positif"
        ],
        [
         "23",
         "1",
         "Sofiane Sofiane",
         "لماذا ديتولي 50 دج كل مرة راكم ديروهالي",
         "Negatif",
         "Negatif"
        ],
        [
         "24",
         "1",
         "Lamine Jseb",
         "ماذا بيه شبكة اليوم   لا يوجد انترنت منذ 3 ساعات",
         "Negatif",
         "Negatif"
        ],
        [
         "25",
         "1",
         "マウンテ ンライト",
         "بهد مناسبة تبرع علينا ب انترنت",
         "Neutre",
         "Positif"
        ],
        [
         "26",
         "1",
         "Bnamer Boutayeb",
         "اصلحوا تطبيق نتاعكم",
         "Negatif",
         "Negatif"
        ],
        [
         "27",
         "1",
         "ゞゞじ づ づ",
         "افعلو لنا أي شيء خاص ب انترنت",
         "Neutre",
         "Negatif"
        ],
        [
         "28",
         "1",
         "كنوش سمير",
         "لا يوجد انترنت",
         "Negatif",
         "Negatif"
        ],
        [
         "29",
         "1",
         "Fati Fati",
         "من 2006 راني مشاركة معاكم أي نهار فرحونا بهديه",
         "Neutre",
         "Positif"
        ],
        [
         "30",
         "1",
         "Sofiane Renault Medea",
         "بطيءة",
         "Negatif",
         "Negatif"
        ],
        [
         "31",
         "1",
         "Sifadine Mehdi",
         "شبكة ما به يذهب و يأتي",
         "Negatif",
         "Negatif"
        ],
        [
         "32",
         "1",
         "Añdřeä Añdřeä",
         "متى تردون شبكة",
         "Negatif",
         "Positif"
        ],
        [
         "33",
         "1",
         "Nabil Issam",
         "ريقلونا رب شبكة",
         "Negatif",
         "Negatif"
        ],
        [
         "34",
         "1",
         "Abdo Gros",
         "malheureusement le reseau etait coupe men 17h hata maintenant pour wala في plus c est في niveau d alger yahsra les autres wilaya ni excuses ni rien  mais bon في souhaitant une amelioration cette annee incha allah",
         "Negatif",
         "Negatif"
        ],
        [
         "36",
         "2",
         "Abdelghani Tahtah",
         "ماهو هو الكود خاص ب قرض",
         "Neutre",
         "Neutre"
        ],
        [
         "37",
         "2",
         "أحمد فيراس",
         "جيد",
         "Positif",
         "Positif"
        ],
        [
         "38",
         "2",
         "Œœ Œœ",
         "كيفاه نسلف عشرالاف",
         "Neutre",
         "Negatif"
        ],
        [
         "40",
         "2",
         "Riad BM",
         "من يبعثلي 2 جيغا",
         "Neutre",
         "Negatif"
        ],
        [
         "41",
         "2",
         "Amine Boudiaf",
         "رجعونا عروض امتياز لي نزع لنا",
         "Negatif",
         "Negatif"
        ],
        [
         "42",
         "2",
         "زين الدين ابن البوادي",
         "أود معرفة كيفية سرقة رصيدي   الرجاء التوضيح لي رقمين من جازي دائما لا اجد الرصيد djezzy",
         "Negatif",
         "Negatif"
        ],
        [
         "43",
         "2",
         "Amani Amina",
         "كيف رقم خدمة سلفي",
         "Neutre",
         "Negatif"
        ],
        [
         "44",
         "2",
         "العربي نواوي",
         "ممكن نعرف لماذا تنقصو من الرصيد والله العظيم عيب عيب عيب تعبئة 50 الف غدا تجد 20 الف عيب حسبنا الله ونعم الوكيل",
         "Negatif",
         "Negatif"
        ],
        [
         "45",
         "2",
         "Yassine Madrid",
         "من فضلكم شريت شريحة جازي جديدة كيفاه تفعيل مع العلم فيها 60g انترنت و 70 مكالمات",
         "Neutre",
         "Positif"
        ],
        [
         "46",
         "2",
         "Aoudjia Aimen",
         "ما به تطبيق حابس اي اصلحوا اصلحوا شبكة نحن نعانون 2024 وريزو ميت في حالا والله ما فهمنا ومفهمتش لماذا نحن فالعالم الثالث  السبب الوحيد لا غيره لي مخلينا فالعالم الثالث انه لا يوجد عالم رابع او خامس",
         "Negatif",
         "Negatif"
        ],
        [
         "47",
         "2",
         "صاحبة السعادة",
         "علابيها اصبحتم تعبئة تدوهم",
         "Negatif",
         "Negatif"
        ],
        [
         "48",
         "2",
         "عائشة صديقة",
         "djezzy من فضلكم أريد تقطيع الشريحة لتناسب الهاتف  لكن هذا الا ممكن مع شريحتي الحالية هل يمكن استبدالها مع أخرى قابلة لتقطيع مع شرط الاحتفاظ برقمي الحالي",
         "Neutre",
         "Positif"
        ],
        [
         "49",
         "2",
         "Youcef Mellah",
         "نحن نسلكو 150 لشهر و انترنت ربي يجيب ممكن توضيح",
         "Negatif",
         "Negatif"
        ],
        [
         "50",
         "2",
         "Mar Lyn",
         "تخدمو الجمعة",
         "Neutre",
         "Neutre"
        ],
        [
         "51",
         "2",
         "Oussama Chabane",
         "الحل",
         "Neutre",
         "Positif"
        ],
        [
         "52",
         "2",
         "Sifoune Soufyane",
         "هل الرقم 455 خاص بكم ولماذا يتصل بي",
         "Neutre",
         "Negatif"
        ],
        [
         "53",
         "2",
         "Mohamed Rakmouche",
         "طريقة فلكسي من جازي إلى جازي",
         "Neutre",
         "Positif"
        ],
        [
         "54",
         "2",
         "Ÿõn És",
         "اصلحوا شبكة رحمة على والديكم",
         "Negatif",
         "Negatif"
        ],
        [
         "55",
         "2",
         "Kh Khaled",
         "احتاج إنترنت تمشي عادي",
         "Neutre",
         "Neutre"
        ],
        [
         "56",
         "2",
         "Sid Ali Haciane",
         "شبكة جازي لا يوجد وليدوني لا يوجد",
         "Negatif",
         "Negatif"
        ],
        [
         "57",
         "2",
         "Àyõub Ĥaňni",
         "اريد طرح شكوا",
         "Negatif",
         "Negatif"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3469
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Post</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>Sentiment_Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yanise Yanise</td>\n",
       "      <td>سلام عليكم ورحمة لديا مشكلة تعبئة 100 دج و بدأ...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jj Kie</td>\n",
       "      <td>كل عام و انتم بخير</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sakou Younes</td>\n",
       "      <td>كل عام وأنتم بخير</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Neutre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>راني نعاني</td>\n",
       "      <td>كل عام وحنا بخير</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>مروان سيدهم سيدهم مروان</td>\n",
       "      <td>كل عام وأنتم بخير وأتمنا رد لماذا اسئلة لماذا ...</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Neutre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4102</th>\n",
       "      <td>183</td>\n",
       "      <td>Kà Nø</td>\n",
       "      <td>اصلحوا انترنت الا العاب خسرت كم من بارطيا من أ...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105</th>\n",
       "      <td>183</td>\n",
       "      <td>Noé Noé</td>\n",
       "      <td>رمضان كريم</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>183</td>\n",
       "      <td>Koléa Koléa</td>\n",
       "      <td>رمضان كريم</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>183</td>\n",
       "      <td>Oussama Zhm</td>\n",
       "      <td>walah connexion ta3koum rahi t3ayi lyamat hado...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>183</td>\n",
       "      <td>B-m Lamine</td>\n",
       "      <td>سلام عليكم اوريدو عندي مشكل كل مرة تعبئة نزع خ...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3469 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Post                User Name  \\\n",
       "1           1            Yanise Yanise   \n",
       "2           1                   Jj Kie   \n",
       "3           1             Sakou Younes   \n",
       "4           1               راني نعاني   \n",
       "7           1  مروان سيدهم سيدهم مروان   \n",
       "...       ...                      ...   \n",
       "4102      183                    Kà Nø   \n",
       "4105      183                  Noé Noé   \n",
       "4114      183              Koléa Koléa   \n",
       "4120      183              Oussama Zhm   \n",
       "4122      183               B-m Lamine   \n",
       "\n",
       "                                               Comments Sentiments  \\\n",
       "1     سلام عليكم ورحمة لديا مشكلة تعبئة 100 دج و بدأ...    Negatif   \n",
       "2                                    كل عام و انتم بخير    Positif   \n",
       "3                                     كل عام وأنتم بخير    Positif   \n",
       "4                                      كل عام وحنا بخير    Positif   \n",
       "7     كل عام وأنتم بخير وأتمنا رد لماذا اسئلة لماذا ...    Positif   \n",
       "...                                                 ...        ...   \n",
       "4102  اصلحوا انترنت الا العاب خسرت كم من بارطيا من أ...    Negatif   \n",
       "4105                                         رمضان كريم    Positif   \n",
       "4114                                         رمضان كريم    Positif   \n",
       "4120  walah connexion ta3koum rahi t3ayi lyamat hado...    Negatif   \n",
       "4122  سلام عليكم اوريدو عندي مشكل كل مرة تعبئة نزع خ...    Negatif   \n",
       "\n",
       "     Sentiment_Predicted  \n",
       "1                Negatif  \n",
       "2                Positif  \n",
       "3                 Neutre  \n",
       "4                Positif  \n",
       "7                 Neutre  \n",
       "...                  ...  \n",
       "4102             Negatif  \n",
       "4105             Positif  \n",
       "4114             Positif  \n",
       "4120             Negatif  \n",
       "4122             Negatif  \n",
       "\n",
       "[3469 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Contents",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Lien Post",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Nb Like",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Love",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Care",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Wow",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Sad",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Angry",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nb Haha",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e65b73ac-bdbe-438b-9b61-b54f4ff29fcc",
       "rows": [
        [
         "0",
         "1",
         "جازي تتمنى لكم سنة سعيدة  djezzy happy new year 2024",
         "https://www.facebook.com/djezzy/posts/788227516669599?ref=embed_post",
         "272",
         "45",
         "0",
         "1",
         "1",
         "76",
         "14",
         "Djezzy",
         "2024-01-01 00:00:00"
        ],
        [
         "1",
         "2",
         "راك en panne و خصك رصيد ؟ مع خدمة tranquilo تاع djezzy كلش ساهل  جازي astuces ساهلة",
         "https://www.facebook.com/watch/?v=1068829281022985&ref=sharing",
         "255",
         "28",
         "0",
         "1",
         "0",
         "12",
         "31",
         "Djezzy",
         "2024-01-04 00:00:00"
        ],
        [
         "2",
         "3",
         "it s time to be a legend",
         "https://www.facebook.com/djezzy/posts/392564993435969:392564993435969?ref=embed_post",
         "257",
         "51",
         "2",
         "0",
         "0",
         "2",
         "8",
         "Djezzy",
         "2024-01-10 00:00:00"
        ],
        [
         "3",
         "4",
         "djezzy vous souhaite yennayer amervuh!  ⴰⵙⵙⴻⴳⴰⵙ ⴰⵎⴻⴳⴰⵣ 2974  ! جازي تقدم لكم أحر التهاني بمناسبة السنة الأمازيغية الجديدة djezzy yennayer 2974",
         "https://www.facebook.com/share/p/19UDNBoQ1k/",
         "621",
         "231",
         "10",
         "3",
         "0",
         "1",
         "300",
         "Djezzy",
         "2024-01-11 00:00:00"
        ],
        [
         "4",
         "5",
         "قريبا .",
         "https://www.facebook.com/share/v/12B9LZySBRe/",
         "288",
         "49",
         "4",
         "0",
         "0",
         "3",
         "24",
         "Djezzy",
         "2024-01-12 00:00:00"
        ],
        [
         "5",
         "6",
         "و مكالمات غير محدودة نحو جميع شبكات النقال و الثابت. بـ 2500دج فقط ! نتا هو الأسطورة",
         "https://www.facebook.com/share/v/15R9u8sYHg/",
         "564",
         "157",
         "24",
         "0",
         "0",
         "7",
         "73",
         "Djezzy",
         "2024-01-13 00:00:00"
        ],
        [
         "6",
         "7",
         "مع جازي legend إستفد من مكالمات مجانية نحو كل شبكات النقال و الثابت ! وحجم انترنت يصل إلى غاية 100 جيغا ! إكتشفوا مزايا العرض الجديد djezzy legend على  نتا هو الأسطورة",
         "https://www.facebook.com/djezzy/posts/797321975760153?ref=embed_post",
         "438",
         "31",
         "5",
         "0",
         "0",
         "26",
         "52",
         "Djezzy",
         "2024-01-14 00:00:00"
        ],
        [
         "7",
         "8",
         "تمتع بالمكالمات المجانية نحو جميع شبكات الجوال  والثابت واستفد من 70جيغا ب20 دج فقط ! استكشف كل المميزات على  نتا هو الأسطورة",
         "https://www.facebook.com/djezzy/posts/797937005698650?ref=embed_post",
         "428",
         "23",
         "4",
         "1",
         "1",
         "5",
         "52",
         "Djezzy",
         "2024-01-15 00:00:00"
        ],
        [
         "8",
         "9",
         "مع djezzy legend انت هو الـ legend  بـ 20دج ! تحصلوا على 70go انترنت، مكالمات غير محدودة نحو جميع شبكات الثابت و النقال !  إكتشفوا مزايا djezzy legend على  نتا هو الأسطورة",
         "https://www.facebook.com/share/v/12BG5K7FV8K/",
         "323",
         "37",
         "5",
         "0",
         "1",
         "2",
         "9",
         "Djezzy",
         "2024-01-20 00:00:00"
        ],
        [
         "9",
         "10",
         "goal algeria vs burkina faso football",
         "https://www.facebook.com/watch/?v=1346282365905418&ref=sharing",
         "170",
         "26",
         "1",
         "1",
         "0",
         "4",
         "2",
         "Djezzy",
         "2024-01-20 00:00:00"
        ],
        [
         "10",
         "11",
         "مع  pack 3ayla متراطي حتى match  استفاد من modem 4g و 150go انترنت لمدة 6 أشهر ب90دج   مع pack 3ayla supporty   فريقك مع عايلتك  لمزيد من المعلومات زوروا موقعنا      djezzy match 3ayla",
         "https://www.facebook.com/watch/?v=1387729078503230&ref=sharing",
         "130",
         "8",
         "1",
         "1",
         "1",
         "2",
         "31",
         "Djezzy",
         "2024-01-23 00:00:00"
        ],
        [
         "11",
         "12",
         "مع zuni sport  على djezzy app تابع مواعيد و نتائج المباريات لحظة بلحظة  حمل التطبيق الآن  djezzy app zuni sport max foot",
         "https://www.facebook.com/share/p/13tcBA3rkg/",
         "189",
         "16",
         "3",
         "0",
         "0",
         "3",
         "11",
         "Djezzy",
         "2024-01-27 00:00:00"
        ],
        [
         "12",
         "13",
         "اليوم هو اليوم العالمي لحماية البيانات تذكير أساسي بأهمية الحفاظ على خصوصيتك على الإنترنت  حماية البيانات تهم كل واحد منا  aujourd hui, c est la journee mondiale de la protection des donnees un rappel essentiel de l importance de preserver votre vie privee en ligne la protection des donnees concerne chacun d entre  nous  protectiondesdonnees vieprivenligne djezzy",
         "https://www.facebook.com/share/p/15aRgkr5JS/",
         "161",
         "13",
         "2",
         "1",
         "0",
         "1",
         "11",
         "Djezzy",
         "2024-01-28 00:00:00"
        ],
        [
         "13",
         "14",
         "اختبر معلوماتك في كرة القدم   وحاول تفوز بقسيمة شراء بقيمة 100 مليون سنتيم أسبوعيا  ما عليك غير تحمل djezzy app على الرابط  djezzy app djezzy win",
         "https://www.facebook.com/share/p/1AzBbfwqh1/",
         "229",
         "22",
         "5",
         "0",
         "0",
         "2",
         "9",
         "Djezzy",
         "2024-01-30 00:00:00"
        ],
        [
         "14",
         "15",
         "أخبار محلية ثقافية رياضية   مع  djezzy scoop ميفوتك حتى خبر !   للاشتراك إتصل على 404 أو أرسل sms الى نفس الرقم djezzy scoop max news",
         "https://www.facebook.com/share/p/13yNkR5JW2/",
         "150",
         "7",
         "0",
         "0",
         "0",
         "1",
         "11",
         "Djezzy",
         "2024-01-31 00:00:00"
        ],
        [
         "15",
         "16",
         "شكون فيكم يعرف le code باش يكتيفي double appel ؟ جازي astuces ساهلة",
         "https://www.facebook.com/watch/?v=1497445130819223&ref=sharing",
         "325",
         "33",
         "4",
         "0",
         "0",
         "5",
         "6",
         "Djezzy",
         "2024-02-01 00:00:00"
        ],
        [
         "16",
         "17",
         "كيفاش تتفادى توقف الخط ديالك ؟ تابع الحل في الفيديو  جازي astuces ساهلة",
         "https://www.facebook.com/watch/?v=408877615031858&rdid=nscweaDh1ie6K7G0",
         "161",
         "18",
         "2",
         "0",
         "0",
         "3",
         "10",
         "Djezzy",
         "2024-02-15 00:00:00"
        ],
        [
         "17",
         "18",
         "في رايكم هاذ المرة علاش جينا",
         "https://www.facebook.com/share/v/1CVK8AkWr6/",
         "202",
         "24",
         "2",
         "1",
         "0",
         "5",
         "18",
         "Djezzy",
         "2024-02-18 00:00:00"
        ],
        [
         "18",
         "19",
         "انضموا إلينا ‍ في مبادرة البسمة walk for  لنرسم البسمة مع بعض في كل خطوة. حملوا  djezzy app و حولوا خطواتكم إلى تبرعات لقفة رمضان  رابط التحميل  جازي قفة رمضان البسمةwalk4",
         "https://www.facebook.com/share/p/14kGTVBiaXU/",
         "177",
         "19",
         "3",
         "0",
         "0",
         "13",
         "3",
         "Djezzy",
         "2024-02-19 00:00:00"
        ],
        [
         "19",
         "20",
         "باش نفرحو الناس في هذا رمضان و نرسموا البسمة على وجوه الصايمين  يلا نمشوا مع بعض و نتبرعوا بخطواتنا على djezzy app  رابط التحميل",
         "https://www.facebook.com/share/v/19nVrLQmjV/",
         "173",
         "17",
         "5",
         "0",
         "0",
         "0",
         "2",
         "Djezzy",
         "2024-02-20 00:00:00"
        ],
        [
         "20",
         "21",
         "شارك في تحدي المشي مع صحابك و سجل خطواتك في فيديو و أنشرها على صفحتك طاقي djeezy مع هاشتاغ  جازي قفة رمضان البسمةwalk4 أحسن فيديو  راح نبرطاجيوها عبر صفحتنا  رابط التطبيق",
         "https://www.facebook.com/share/p/1ESi1iAD8L/",
         "299",
         "34",
         "3",
         "2",
         "1",
         "6",
         "52",
         "Djezzy",
         "2024-02-21 00:00:00"
        ],
        [
         "21",
         "22",
         "خطوة ساهلة بمناسبة شهر رمضان الكريم  جازي astuces ساهلة قفة رمضان البسمةwalk4",
         "https://www.facebook.com/share/v/19dwGJKfjm/",
         "181",
         "23",
         "3",
         "0",
         "0",
         "4",
         "1",
         "Djezzy",
         "2024-02-22 00:00:00"
        ],
        [
         "22",
         "23",
         "طاقي صاحبك  يمشي بالزربة  جازي  قفة رمضان البسمةwalk4",
         "https://www.facebook.com/share/p/14KAHkwsXF/",
         "201",
         "23",
         "3",
         "0",
         "2",
         "4",
         "58",
         "Djezzy",
         "2024-02-23 00:00:00"
        ],
        [
         "23",
         "24",
         "كل واحد يكتبلنا في التعليقات شحال من خطوة مشاها على djezzy app  يدرى شكون راح يكون le champion  ؟  جازي قفة رمضان البسمةwalk4",
         "https://www.facebook.com/share/p/18BbsUNDKa/",
         "204",
         "18",
         "3",
         "0",
         "0",
         "3",
         "26",
         "Djezzy",
         "2024-02-24 00:00:00"
        ],
        [
         "24",
         "25",
         "البسمة walk for مازالها متواصلة    طاقي صاحبك لي مازال ماشاركش معانا  جازي قفة رمضان البسمةwalk4",
         "https://www.facebook.com/share/v/17cPeTM5qo/",
         "111",
         "20",
         "0",
         "0",
         "0",
         "5",
         "9",
         "Djezzy",
         "2024-02-26 00:00:00"
        ],
        [
         "25",
         "26",
         "نشاركوا معاكم  top 10 تع البسمة walk for إنضموا إلينا، مازلنا متواصلين من أجل رسم البسمة مع بعض. جازي قفة رمضان البسمةwalk4",
         "https://www.facebook.com/share/p/1BYQb7q2cL/",
         "185",
         "17",
         "1",
         "0",
         "0",
         "4",
         "10",
         "Djezzy",
         "2024-02-27 00:00:00"
        ],
        [
         "26",
         "27",
         "‍ مبادرة البسمة  walk for مازالها متواصلة خطواتنا راح تفرح بزاف ناس  حملوا  djezzy app و حولوا خطواتكم إلى تبرعات لقفة رمضان  رابط التحميل  جازي قفة رمضان البسمةwalk4",
         "https://www.facebook.com/share/p/18KCQQmfLL/",
         "228",
         "30",
         "2",
         "0",
         "1",
         "3",
         "6",
         "Djezzy",
         "2024-02-29 00:00:00"
        ],
        [
         "27",
         "28",
         "و للأسبوع الثاني البسمة walk for مازالها متواصلة بنجاح بفضل خطواتكم   جازي قفة رمضان البسمةwalk4",
         "https://www.facebook.com/share/v/12AywsCXXA3/",
         "128",
         "20",
         "0",
         "0",
         "0",
         "2",
         "4",
         "Djezzy",
         "2024-03-04 00:00:00"
        ],
        [
         "28",
         "29",
         "نشاركوا معاكم the best walkers  للأسبوع الثاني  إنضموا إلينا من أجل رسم البسمة مع بعض في هذا رمضان  جازي قفة رمضان البسمةwalk4",
         "https://www.facebook.com/share/p/1Azzo8rf7E/",
         "167",
         "19",
         "0",
         "0",
         "0",
         "1",
         "2",
         "Djezzy",
         "2024-03-06 00:00:00"
        ],
        [
         "29",
         "30",
         "نختتم مبادرة البسمة walk for بأكثر من 821 مليون خطوة  شكرا على مشاركتكم و دعمكم القيم مع بعض صنعنا البسمة   جازي قفة رمضان البسمةwalk4",
         "https://www.facebook.com/watch/?v=3419181848374064&rdid=OpVtNNOSdxW0g2eO",
         "110",
         "23",
         "1",
         "0",
         "0",
         "1",
         "1",
         "Djezzy",
         "2024-03-10 00:00:00"
        ],
        [
         "30",
         "31",
         "باش تولي مشهور لازملك بزاف انترنت   و باش تولي أسطورة لازملك djezzy legend   اكتشفوا تفاصيل العرض على",
         "https://www.facebook.com/share/v/15kQvgwaYH/",
         "89",
         "15",
         "2",
         "0",
         "0",
         "1",
         "13",
         "Djezzy",
         "2024-03-11 00:00:00"
        ],
        [
         "31",
         "32",
         "حمل djezzy app و شارك في مسابقة عمرة ranati لشخصين   رابط التطبيق",
         "https://www.facebook.com/share/v/18BXF4DAnq/",
         "131",
         "37",
         "0",
         "0",
         "0",
         "0",
         "1",
         "Djezzy",
         "2024-03-11 00:00:00"
        ],
        [
         "32",
         "33",
         "هذا رمضان الفرحة دوبل  x2 على djezzy app  رابط التطبيق",
         "https://www.facebook.com/share/v/1FyzpbnWBQ/",
         "106",
         "30",
         "1",
         "1",
         "0",
         "2",
         "0",
         "Djezzy",
         "2024-03-12 00:00:00"
        ],
        [
         "33",
         "34",
         "مع djezzy app دوبلي فرحتك و الانترنت ديالك  رابط التطبيق",
         "https://www.facebook.com/share/v/17z9TWBMWj/",
         "132",
         "20",
         "2",
         "0",
         "0",
         "2",
         "2",
         "Djezzy",
         "2024-03-13 00:00:00"
        ],
        [
         "34",
         "35",
         "باش دير محتوى أسطوري لازملك عرض أسطوري  اكتشفوا التفاصيل  مع djezzy legend انت هو الأسطورة",
         "https://www.facebook.com/share/p/1NTLjuLH4q/",
         "179",
         "22",
         "0",
         "1",
         "0",
         "3",
         "31",
         "Djezzy",
         "2024-03-14 00:00:00"
        ],
        [
         "35",
         "36",
         "كامل يوصلنا  sms بلي ربحنا في مسابقات و حنا ماشاركناش فيها ! كيفاش نتفادوها  ؟ جازي astuces ساهلة رمضان2024",
         "https://www.facebook.com/share/v/1Ax3tK3yQf/",
         "71",
         "13",
         "1",
         "0",
         "0",
         "2",
         "0",
         "Djezzy",
         "2024-03-14 00:00:00"
        ],
        [
         "36",
         "37",
         "انترنت 2  لمدة أسبوع ! حمل djezzy app و استمتع ب10 جيغا لكل عرض تاع 300 دج  رابط التطبيق  جازي دوبل أنترنت رمضان2024 جازي app",
         "https://www.facebook.com/share/v/1QvSNe3qr6/",
         "86",
         "16",
         "2",
         "0",
         "0",
         "8",
         "3",
         "Djezzy",
         "2024-03-17 00:00:00"
        ],
        [
         "37",
         "38",
         "كونكتي double  2 و أفرح double  2 مع انترنت  double 2 حمل التطبيق  جازي دوبل أنترنت رمضان2024 جازي app",
         "https://www.facebook.com/share/p/19cMcLv6sd/",
         "139",
         "18",
         "0",
         "0",
         "0",
         "4",
         "2",
         "Djezzy",
         "2024-03-17 00:00:00"
        ],
        [
         "38",
         "39",
         "مع عرض جازي legend max الجديد، استفد من مكالمات غير محدودة نحو جميع الشبكات الوطنية وحد أقصى من الانترنت ! للمزيد من التفاصيل :   جازي نتاـهوـالأسطورة",
         "https://www.facebook.com/share/p/1Gxhnote12/",
         "163",
         "31",
         "1",
         "0",
         "0",
         "2",
         "1",
         "Djezzy",
         "2024-03-22 00:00:00"
        ],
        [
         "39",
         "40",
         "مع djezzy app أبقى دايما connecte بdouble    استمتع ب10 جيغا لمدة أسبوع  ب300 دج فقط !  رابط التطبيق  جازي دوبل أنترنت رمضان2024 جازي app",
         "https://www.facebook.com/share/v/19THVFCcWA/",
         "64",
         "18",
         "0",
         "0",
         "0",
         "2",
         "2",
         "Djezzy",
         "2024-03-23 00:00:00"
        ],
        [
         "40",
         "41",
         "عندك legend max؟ bien sûr que انت اسطورة",
         "https://www.facebook.com/share/v/1EZyVsxH3S/",
         "91",
         "20",
         "0",
         "1",
         "0",
         "0",
         "6",
         "Djezzy",
         "2024-03-25 00:00:00"
        ],
        [
         "41",
         "42",
         "بالشراكة مع الكشافة الإسلامية الجزائرية، جازي تشارككم الأجواء التضامنية من مطعم فوج امال قاوش ببلدية الشراقة. تتميز هذه المبادرة بمساهمة الكشافين من مختلف الأعمار  في ادخال الفرحة ورسم البسمة على وجوه القاصدين و العابرين من كل مكان. في هذا رمضان نرسمو البسمة  مع بعض  فوج ٱمال قاوش الكشافة الإسلامية الجزائرية   جازي مائدة البسمة الكشافة الإسلامية الجزائرية",
         "https://www.facebook.com/share/v/1Dcy3GKWLV/",
         "65",
         "28",
         "3",
         "0",
         "0",
         "0",
         "0",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "42",
         "43",
         "تابعوا الاحداث المتنوعة في حلقة اليوم من شبه حصة 2 في هذا رمضان  شاهدوا  الحلقة كاملة على  جازي شبه حصة2 رمضان2024",
         "https://www.facebook.com/share/v/196vTS7ztN/",
         "49",
         "17",
         "2",
         "0",
         "0",
         "0",
         "1",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "43",
         "44",
         "مع  legend max استفد من مكالمات غير محدودة نحو جميع الشبكات الوطنية و الmax  تاع الانترنت  للمزيد من التفاصيل :   جازي نتا هو الأسطورة",
         "https://www.facebook.com/share/p/15N1wg8V2N/",
         "133",
         "20",
         "4",
         "2",
         "0",
         "5",
         "4",
         "Djezzy",
         "2024-03-27 00:00:00"
        ],
        [
         "44",
         "45",
         "متفوتش العرض في هذا رمضان  حمل اكتيفي و دوبلي  هذا كامل على  جازي دوبل أنترنت رمضان2024 جازي app",
         "https://www.facebook.com/share/v/19HbnWWpMa/",
         "37",
         "15",
         "1",
         "0",
         "0",
         "4",
         "0",
         "Djezzy",
         "2024-03-28 00:00:00"
        ],
        [
         "45",
         "46",
         "تابعوا حلقة اليوم من شبه حصة مع مراد و أرقام   لمشاهدة الحلقة كاملة",
         "https://www.facebook.com/share/v/1AewF1ZDSN/",
         "35",
         "16",
         "1",
         "0",
         "0",
         "0",
         "0",
         "Djezzy",
         "2024-03-28 00:00:00"
        ],
        [
         "46",
         "47",
         "ألف شكر super fans تاعنا ،شكرا على محبتكم و وفائكم لينا و تفاعلكم الدائم معانا  صح سحوركم",
         "https://www.facebook.com/share/v/15Z5g8V2Cs/",
         "76",
         "33",
         "5",
         "0",
         "0",
         "1",
         "0",
         "Djezzy",
         "2024-03-29 00:00:00"
        ],
        [
         "47",
         "48",
         "تحب دير بزاف les stories les reels les photos غير djezzy legend لي تخرج عليك 100 go إنترنت و انت مهني  للمزيد من التفاصيل :   جازي نتا هو الأسطورة",
         "https://www.facebook.com/share/v/19aWCgdZW3/",
         "133",
         "20",
         "2",
         "0",
         "0",
         "2",
         "7",
         "Djezzy",
         "2024-03-30 00:00:00"
        ],
        [
         "48",
         "49",
         "نتوما عشاق الألعاب الإلكترونية تحبو تقضيو وقت شباب معنا؟   خممت فيكم  mobilistore  عيشوا متعة الألعاب فيها  موبيليس معا نصنع المستقبل",
         "https://www.facebook.com/share/p/18K8JuwacB/",
         "399",
         "38",
         "8",
         "0",
         "0",
         "1",
         "2",
         "Mobilis",
         "2024-01-04 00:00:00"
        ],
        [
         "49",
         "50",
         "قرعة الدورين الـ32 والـ16 لكأس الجزائر الطبعة 59  تتابعونها يوم الأحد 7 جانفي 2024 على الساعة 17:30  موبيليس الراعي والشريك الرسمي لكأس الجزائر معا نصنع المستقبل",
         "https://www.facebook.com/share/p/15Y99MUo3z/",
         "612",
         "61",
         "7",
         "0",
         "0",
         "1",
         "0",
         "Mobilis",
         "2024-01-06 00:00:00"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 183
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Contents</th>\n",
       "      <th>Lien Post</th>\n",
       "      <th>Nb Like</th>\n",
       "      <th>Nb Love</th>\n",
       "      <th>Nb Care</th>\n",
       "      <th>Nb Wow</th>\n",
       "      <th>Nb Sad</th>\n",
       "      <th>Nb Angry</th>\n",
       "      <th>Nb Haha</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>جازي تتمنى لكم سنة سعيدة  djezzy happy new yea...</td>\n",
       "      <td>https://www.facebook.com/djezzy/posts/78822751...</td>\n",
       "      <td>272</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>14</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>راك en panne و خصك رصيد ؟ مع خدمة tranquilo تا...</td>\n",
       "      <td>https://www.facebook.com/watch/?v=106882928102...</td>\n",
       "      <td>255</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>it s time to be a legend</td>\n",
       "      <td>https://www.facebook.com/djezzy/posts/39256499...</td>\n",
       "      <td>257</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>djezzy vous souhaite yennayer amervuh!  ⴰⵙⵙⴻⴳⴰ...</td>\n",
       "      <td>https://www.facebook.com/share/p/19UDNBoQ1k/</td>\n",
       "      <td>621</td>\n",
       "      <td>231</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>قريبا .</td>\n",
       "      <td>https://www.facebook.com/share/v/12B9LZySBRe/</td>\n",
       "      <td>288</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Djezzy</td>\n",
       "      <td>2024-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>179</td>\n",
       "      <td>إثارة الألعاب تتعاش مع الأحباب، خاصة كي ooredo...</td>\n",
       "      <td>https://www.facebook.com/share/p/1KGHZQuXex/</td>\n",
       "      <td>208</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>مع ooredoo ديما رابحين ! وجدنا لكم حاجة جديدة ...</td>\n",
       "      <td>https://www.facebook.com/share/v/1Bc7FtdDPx/</td>\n",
       "      <td>625</td>\n",
       "      <td>125</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>عشنا مع بعض أجواء رمضانية رائعة من خلال الإفطا...</td>\n",
       "      <td>https://www.facebook.com/reel/954679512980806</td>\n",
       "      <td>280</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>182</td>\n",
       "      <td>ضاعفوا اشتراك الإنترنت الخاص بكم خلال شهر رمضا...</td>\n",
       "      <td>https://www.facebook.com/watch/?v=193245186050...</td>\n",
       "      <td>148</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>183</td>\n",
       "      <td>أنتم من عشاق السينما العربية؟ حملوا التطبيق شا...</td>\n",
       "      <td>https://www.facebook.com/OoredooDZ/posts/44139...</td>\n",
       "      <td>215</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ooredoo</td>\n",
       "      <td>2024-03-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                           Contents  \\\n",
       "0      1  جازي تتمنى لكم سنة سعيدة  djezzy happy new yea...   \n",
       "1      2  راك en panne و خصك رصيد ؟ مع خدمة tranquilo تا...   \n",
       "2      3                           it s time to be a legend   \n",
       "3      4  djezzy vous souhaite yennayer amervuh!  ⴰⵙⵙⴻⴳⴰ...   \n",
       "4      5                                            قريبا .   \n",
       "..   ...                                                ...   \n",
       "178  179  إثارة الألعاب تتعاش مع الأحباب، خاصة كي ooredo...   \n",
       "179  180  مع ooredoo ديما رابحين ! وجدنا لكم حاجة جديدة ...   \n",
       "180  181  عشنا مع بعض أجواء رمضانية رائعة من خلال الإفطا...   \n",
       "181  182  ضاعفوا اشتراك الإنترنت الخاص بكم خلال شهر رمضا...   \n",
       "182  183  أنتم من عشاق السينما العربية؟ حملوا التطبيق شا...   \n",
       "\n",
       "                                             Lien Post  Nb Like  Nb Love  \\\n",
       "0    https://www.facebook.com/djezzy/posts/78822751...      272       45   \n",
       "1    https://www.facebook.com/watch/?v=106882928102...      255       28   \n",
       "2    https://www.facebook.com/djezzy/posts/39256499...      257       51   \n",
       "3         https://www.facebook.com/share/p/19UDNBoQ1k/      621      231   \n",
       "4        https://www.facebook.com/share/v/12B9LZySBRe/      288       49   \n",
       "..                                                 ...      ...      ...   \n",
       "178       https://www.facebook.com/share/p/1KGHZQuXex/      208       46   \n",
       "179       https://www.facebook.com/share/v/1Bc7FtdDPx/      625      125   \n",
       "180      https://www.facebook.com/reel/954679512980806      280       40   \n",
       "181  https://www.facebook.com/watch/?v=193245186050...      148       35   \n",
       "182  https://www.facebook.com/OoredooDZ/posts/44139...      215       46   \n",
       "\n",
       "     Nb Care  Nb Wow  Nb Sad  Nb Angry  Nb Haha  Company       Date  \n",
       "0          0       1       1        76       14   Djezzy 2024-01-01  \n",
       "1          0       1       0        12       31   Djezzy 2024-01-04  \n",
       "2          2       0       0         2        8   Djezzy 2024-01-10  \n",
       "3         10       3       0         1      300   Djezzy 2024-01-11  \n",
       "4          4       0       0         3       24   Djezzy 2024-01-12  \n",
       "..       ...     ...     ...       ...      ...      ...        ...  \n",
       "178        6       0       0         0        1  Ooredoo 2024-03-26  \n",
       "179       14       0       1         1        1  Ooredoo 2024-03-27  \n",
       "180        7       1       1         0        0  Ooredoo 2024-03-28  \n",
       "181        3       0       0         2        0  Ooredoo 2024-03-28  \n",
       "182        5       0       0         1        0  Ooredoo 2024-03-30  \n",
       "\n",
       "[183 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    \"mrc\": \"merci\",\n",
    "    \"num\": \"numéro\",\n",
    "    \"numro\": \"numéro\",\n",
    "    \"nn\": \"non\",\n",
    "    \"bn\": \"bonne\",\n",
    "    \"topp\": \"top\",\n",
    "    \"شوي\": \"قليل\",\n",
    "    \"شويا\": \"قليل\",\n",
    "    \"لزونيتي\": \"رصيد\",\n",
    "    \"حنا\": \"نحن\",\n",
    "    \"أسإلتي\": \"اسئلة\",\n",
    "    \"حاص\": \"خاص\",\n",
    "    \"مدام\": \"بينما\",\n",
    "    \"رانا\": \"نحن\",\n",
    "    \"بون\": \"حسن\",\n",
    "    \"توس\": \"جميع\",\n",
    "    \"سبيسيال\": \"منفرد\",\n",
    "    \"سبيال\": \"منفرد\",\n",
    "    \"باه\": \"لكي\",\n",
    "    \"زاف\": \"كثيرا\",\n",
    "    \"بزاف\": \"كثيرا\",\n",
    "    \"نتمني\": \"نتمنى\",\n",
    "    \"فظلكم\": \"فضلكم\",\n",
    "    \"ضلم\": \"ظلم\",\n",
    "    \"ردى\": \"رد\",\n",
    "    \"علاش\": \"لماذا\",\n",
    "    \"علاه\": \"لماذا\",\n",
    "    \"علا\": \"لماذا\",\n",
    "    \"هذ\": \"هذا\",\n",
    "    \"تبرعو\": \"تبرع\",\n",
    "    \"ابليكاسيو\": \"تطبيق\",\n",
    "    \"أبليكاسيون\": \"تطبيق\",\n",
    "    \"أبليكاسيو\": \"تطبيق\",\n",
    "    \"الخاص بكم\": \"نتاعكم\",\n",
    "    \"ديرولنا\": \"افعلو لنا\",\n",
    "    \"ديرو\": \"افعلو\",\n",
    "    \"نحا\": \"نزع\",\n",
    "    \"دير\": \"افعل\",\n",
    "    \"حاجة\": \"شيء\",\n",
    "    \"نتع\": \"خاص ب\",\n",
    "    \"تاع\": \"خاص ب\",\n",
    "    \"تع\": \"خاص ب\",\n",
    "    \"جاوبوني\": \"رد علي\",\n",
    "    \"مشتاركه\": \"مشاركة\",\n",
    "    \"رحو\": \"اذهبو\",\n",
    "    \"هذي\": \"هذه\",\n",
    "    \"يروح\": \"يذهب\",\n",
    "    \"يجي\": \"يأتي\",\n",
    "    \"وقتاه\": \"متى\",\n",
    "    \"وقتاش\": \"متى\",\n",
    "    \"وقتش\": \"متى\",\n",
    "    \"تردولنا\": \"تردون\",\n",
    "    \"نتاع\": \"خاص ب\",\n",
    "    \"شكون\": \"من\",\n",
    "    \"نحيتوها\": \"نزع\",\n",
    "    \"نحيتو\": \"نزع\",\n",
    "    \"نحيت\": \"نزع\",\n",
    "    \"سلفلي\": \"قرض\",\n",
    "    \"سلفولي\": \"قرض\",\n",
    "    \"غدوة\": \"غدا\",\n",
    "    \"تلقى\": \"تجد\",\n",
    "    \"نلقى\": \"اجد\",\n",
    "    \"نأكتيفيها\": \"تفعيل\",\n",
    "    \"نأكتيفي\": \"تفعيل\",\n",
    "    \"ناكتيفي\": \"تفعيل\",\n",
    "    \"نعانيو\": \"نعانون\",\n",
    "    \"نعانو\": \"نعانون\",\n",
    "    \"ميت حال\": \"رديء\",\n",
    "    \"مفهمتش\": \"لم افهم\",\n",
    "    \"انو\": \"انه\",\n",
    "    \"علابالي\": \"اعلم\",\n",
    "    \"ليتو\": \"اصبحتم\",\n",
    "    \"وليتو\": \"اصبحتم\",\n",
    "    \"تدو\": \"تاخذون\",\n",
    "    \"الى\": \"إلى\",\n",
    "    \"خاستني\": \"احتاج\",\n",
    "    \"خستني\": \"احتاج\",\n",
    "    \"مشى\": \"تعمل\",\n",
    "    \"مشا\": \"تعمل\",\n",
    "    \"شكا\": \"شكوى\",\n",
    "    \"شكيت\": \"شكوى\",\n",
    "    \"زرو\": \"سيء\",\n",
    "    \"زيرو\": \"سيء\",\n",
    "    \"سرفيك\": \"خدمة\",\n",
    "    \"سرفيس\": \"خدمة\",\n",
    "    \"جيزي اب\": \"djezzy app\",\n",
    "    \"nchlh\": \"incha allah\",\n",
    "    \"riglou\": \"regler\",\n",
    "    \"bah\": \"pour\",\n",
    "    \"nwaliw\": \"devenir\",\n",
    "    \"مراحش\": \"لن\",\n",
    "    \"مهمش\": \"ليسو\",\n",
    "    \"تعليع\": \"تعليق\",\n",
    "    \"زااف\": \"كثيرا\",\n",
    "    \"khayan\": \"voleur\",\n",
    "    \"djezzyy\": \"djezzy\",\n",
    "    \"ومرديتش\": \"لم ترد\",\n",
    "    \"واش\": \"ماذا\",\n",
    "    \"منبعد\": \"بعد ذلك\",\n",
    "    \"تفتحش\": \"لا تفتح\",\n",
    "    \"ندير\": \"افعل\",\n",
    "    \"راه\": \"اصبح\",\n",
    "    \"لازم\": \"يجب\",\n",
    "    \"pix\": \"pixx\",\n",
    "    \"Twanty\": \"Twenty\",\n",
    "    \"orod\": \"prod\",\n",
    "    \"imtiyaaz\": \"imtiyaz\",\n",
    "    \"tm\": \"ok\",\n",
    "    \"نم\": \"تم\",\n",
    "    \"جداو\": \"جدا\",\n",
    "    \"زلب\": \"زبل\",\n",
    "    \"كونطرا\": \"عقد\",\n",
    "    \"شري\": \"شراء\",\n",
    "    \"توب\": \"رائع\",\n",
    "    \"جزل\": \"جزيلا\",\n",
    "    \"ياسر\": \"كثيرا\",\n",
    "    \"golde\": \"gold\",\n",
    "    \"mknch\": \"introuvable\",\n",
    "    \"rani\": \"je suis\",\n",
    "    \"شكرالكم\": \"شكرا لكم\",\n",
    "    \"viv\": \"vive\",\n",
    "    \"عتل\": \"ارسل\",\n",
    "    \"بعت\": \"ارسل\",\n",
    "    \"لاجونس\": \"مقر\",\n",
    "    \"rpnd\": \"repond\",\n",
    "    \"prv\": \"prive\",\n",
    "    \"svp\": \"s il vous plais\",\n",
    "    \"yennayer\": \"سنة\",\n",
    "    \"amervuh\": \"سعيدة\",\n",
    "    \"assgas\": \"assegas\",\n",
    "    \"asugas\": \"assegas\",\n",
    "    \"asegas\": \"assegas\",\n",
    "    \"amegaz\": \"amegas\",\n",
    "    \"amgaz\": \"amegas\",\n",
    "    \"amegaz\": \"amegas\",\n",
    "    \"amgaz\": \"amegas\",\n",
    "    \"amegaz\": \"amegas\",\n",
    "    \"خخ\": \"ضحك\",\n",
    "    \"هه\": \"ضحك\",\n",
    "    \"سبي\": \"سبيسيال\",\n",
    "    \"شبكهمشكورين\": \"شبكة مشكورين\",\n",
    "    \"يعطيكمصحه\": \"يعطيكم صحة\",\n",
    "    \"نشله\": \"ان شاء الله\",\n",
    "    \"عندوش\": \"لا يوجد\",\n",
    "    \"خفظو\": \"تخفيض\",\n",
    "    \"مليحة\": \"حسن\",\n",
    "    \"مليحه\": \"حسن\",\n",
    "    \"وله\": \"و الله\",\n",
    "    \"مكمات\": \"مكالمات\",\n",
    "    \"وينتا\": \"متى\",\n",
    "    \"تدوها\": \"تاخذون\",\n",
    "    \"felawen\": \"tous\",\n",
    "    \"ya\": \"il y a\",\n",
    "    \"en\": \"في\",\n",
    "    \"panne\": \"عطل\",\n",
    "    \"happy\": \"سعيدة\",\n",
    "    \"koum\": \"votre\",\n",
    "    \"ayi\": \"faible\",\n",
    "    \"new\": \"جديدة\",\n",
    "    \"year\": \"سنة\",\n",
    "    \"years\": \"سنة\",\n",
    "    \"شنو\": \"ما هو\",\n",
    "    \"هدا\": \"هذا\",\n",
    "    \"شالنج\": \"تحدي\",\n",
    "    \"li\": \"qui\",\n",
    "    \"bghi\": \"aime\",\n",
    "    \"ndirlo\": \"faire\",\n",
    "    \"yji\": \"viens\",\n",
    "    \"lah\": \"pourquoi\",\n",
    "    \"raho\": \"que il\",\n",
    "    \"hbs\": \"arret\",\n",
    "    \"بر\": \"فقط\",\n",
    "    \"برك\": \"فقط\",\n",
    "    \"غي\": \"الا\",\n",
    "    \"غير\": \"الا\",\n",
    "    \"الي\": \"الى\",\n",
    "    \"حسنو\": \"اصلاح\",\n",
    "    \"سقمو\": \"اصلاح\",\n",
    "    \"جوند\": \"legend\",\n",
    "    \"يجاند\": \"legend\",\n",
    "    \"ليجند\": \"legend\",\n",
    "    \"علجال\": \"من أجل\",\n",
    "    \"تثقال\": \"بطء\",\n",
    "    \"كون\": \"ليت\",\n",
    "    \"بغى\": \"اراد\",\n",
    "    \"يبغي\": \"يريد\",\n",
    "    \"نبغي\": \"نريد\",\n",
    "    \"تفرج\": \"مشاهدة\",\n",
    "    \"ماتش\": \"مباراة\",\n",
    "    \"رجا\": \"رجاء\",\n",
    "    \"متمشلكش\": \"لا تعمل\",\n",
    "    \"متمسيلكش\": \"لا تعمل\",\n",
    "    \"لايص\": \"اماكن\",\n",
    "    \"بلايص\": \"اماكن\",\n",
    "    \"بلاصة\": \"اماكن\",\n",
    "    \"نسقسي\": \"اسأل\",\n",
    "    \"اذ\": \"اذا\",\n",
    "    \"يمتي\": \"بلا حدود\",\n",
    "    \"اليميتي\": \"بلا حدود\",\n",
    "    \"خسني\": \"اريد\",\n",
    "    \"باطل\": \"مجانا\",\n",
    "    \"قولد\": \"gold\",\n",
    "    \"تعيف\": \"سيء\",\n",
    "    \"نسييو\": \"محاولة\",\n",
    "    \"نلعبو\": \"لعب\",\n",
    "    \"نكونو\": \"أكون\",\n",
    "    \"عب\": \"لعب\",\n",
    "    \"كف\": \"كيف\",\n",
    "    \"اللهيوفقناجميعاقولويارب\": \"الله يوفقنا جميع اقولو يارب\",\n",
    "    \"congratulations\": \"مبروك\",\n",
    "    \"berkaw\": \"arret\",\n",
    "    \"ser\": \"vole\",\n",
    "    \"تردوش\": \"لا تردون\",\n",
    "    \"هضرت\": \"تكلمت\",\n",
    "    \"باش\": \"لكي\",\n",
    "    \"تحلى\": \"حل\",\n",
    "    \"تحلي\": \"حل\",\n",
    "    \"لينا\": \"لنا\",\n",
    "    \"حض\": \"حظ\",\n",
    "    \"wech\": \"Quoi\",\n",
    "    \"ndirou\": \"faire\",\n",
    "    \"bach\": \"pour\",\n",
    "    \"nrebhou\": \"gagner\",\n",
    "    \"elfe\": \"mille\",\n",
    "    \"mabrok\": \"felicitations\",\n",
    "    \"koules\": \"tous\",\n",
    "    \"moucharikones\": \"participants\",\n",
    "    \"el\": \"les\",\n",
    "    \"mabrouk\": \"مبروك\",\n",
    "    \"اطوههالي\": \"اعطوها لي\",\n",
    "    \"شاب\": \"جميل\",\n",
    "    \"يعطيكمالصحة\": \"يعطيكم الصحة\",\n",
    "    \"illa\": \"lent\",\n",
    "    \"woww\": \"wow\",\n",
    "    \"يارب\": \"يا رب\",\n",
    "    \"كلشي\": \"كل شيء\",\n",
    "    \"كنكتي\": \"تواصل\",\n",
    "    \"مانكونيكتيش\": \"لا أتواصل\",\n",
    "    \"يووز\": \"yooz\",\n",
    "    \"يوز\": \"yooz\",\n",
    "    \"وش\": \"ما هو\",\n",
    "    \"وشمن\": \"اي\",\n",
    "    \"ديما\": \"dima\",\n",
    "    \"راه\": \"انه\",\n",
    "    \"معجبتنيش\": \"سيء\",\n",
    "    \"تحبسلي\": \"توقف\",\n",
    "    \"انتاع\": \"ل\",\n",
    "    \"لوس\": \"plus\",\n",
    "    \"شكراوريدو\": \"شكرا أوريدو\",\n",
    "    \"در\": \"فعل\",\n",
    "    \"رهي\": \"انه\",\n",
    "    \"كاين\": \"يوجد\",\n",
    "    \"مباغش\": \"لا يريد\",\n",
    "    \"يمدلي\": \"يعطيني\",\n",
    "    \"يخرجو\": \"خروج\",\n",
    "    \"اكتر\": \"أكثر\",\n",
    "    \"مايمشيش\": \"لا يعمل\",\n",
    "    \"سوايع\": \"ساعة\",\n",
    "    \"محبتش\": \"لا\",\n",
    "    \"جام\": \"مستحيل\",\n",
    "    \"جامي\": \"مستحيل\",\n",
    "    \"تمشلي\": \"تعمل\",\n",
    "    \"ريفي\": \"خاص\",\n",
    "    \"قاع\": \"كل\",\n",
    "    \"منربحش\": \"لا أربح\",\n",
    "    \"منربحوش\": \"لا أربح\",\n",
    "    \"نقارع\": \"صبر\",\n",
    "    \"مفتحتوهاليش\": \"لا تفتح\",\n",
    "    \"ابونمون\": \"اشتراك\",\n",
    "    \"مساج\": \"رسالة\",\n",
    "    \"رجعو\": \"رد\",\n",
    "    \"صحيتو\": \"شكرا\",\n",
    "    \"لاتوجد\": \"لا توجد\",\n",
    "    \"نلقاش\": \"لا أجد\",\n",
    "    \"ما نلقاش\": \"لا أجد\",\n",
    "    \"كريدي\": \"رصيد\",\n",
    "    \"ريبونديولنا\": \"رد\",\n",
    "    \"جد\": \"جدا\",\n",
    "    \"ينحيولي\": \"نزع\",\n",
    "    \"يحذفولي\": \"نزع\",\n",
    "    \"ماسلفت\": \"لم اقترض\",\n",
    "    \"مدايرا\": \"لم أفعل\",\n",
    "    \"راهي\": \"إنها\",\n",
    "    \"فور\": \"ممتاز\",\n",
    "    \"هايل\": \"ممتاز\",\n",
    "    \"مليح\": \"جيد\",\n",
    "    \"شابة\": \"جميل\",\n",
    "    \"ماصلحتليش\": \"لا تعمل\",\n",
    "    \"إستلاف\": \"قرض\",\n",
    "    \"خص\": \"اريد\",\n",
    "    \"هاذ\": \"هذا\",\n",
    "    \"شحال\": \"كم\",\n",
    "    \"تاكتيفيه\": \"تفعيل\",\n",
    "    \"حتان\": \"كي\",\n",
    "    \"كيفاش\": \"كيف\",\n",
    "    \"غلطة\": \"خطا\",\n",
    "    \"ختاريت\": \"خيار\",\n",
    "    \"ديالي\": \"خاص بي\",\n",
    "    \"حاب\": \"اريد\",\n",
    "    \"ويل\": \"أو\",\n",
    "    \"ابعث\": \"ارسال\",\n",
    "    \"goold\": \"gold\",\n",
    "    \"ماتجاوبوش\": \"عدم رد\",\n",
    "    \"مهدى\": \"هدية\",\n",
    "    \"واشهرالجاي\": \"شهر موالي\",\n",
    "    \"نخلصش\": \"لا أدفع\",\n",
    "    \"ابليس\": \"plus\",\n",
    "    \"تأكتيفها\": \"تفعيل\",\n",
    "    \"هيل\": \"hayla\",\n",
    "    \"هاذي\": \"هذه\",\n",
    "    \"وشمن\": \"ما هي\",\n",
    "    \"جزاير\": \"جزائر\",\n",
    "    \"معن\": \"معنى\",\n",
    "    \"فاه\": \"فيها\",\n",
    "    \"فاش\": \"اي\",\n",
    "    \"مكوبي\": \"مقطوع\",\n",
    "    \"مي\": \"لكن\",\n",
    "    \"مايمشيلك\": \"لا يعمل\",\n",
    "    \"نديرلهم\": \"اعمل لهم\",\n",
    "    \"تتمسخرو\": \"استهزاء\",\n",
    "    \"ريبونديو\": \"رد\",\n",
    "    \"plais\" : \"من فظلكم\",\n",
    "    \"كفاه\": \"كيف\",\n",
    "    \"ندموندي\": \"طلب\",\n",
    "    \"دخلتو\": \"ادخال\",\n",
    "    \"العالميه\": \"عالمية\",\n",
    "    \"قات\": \"بقي\",\n",
    "    \"بقات\": \"بقي\",\n",
    "    \"nechlh\": \"incha allah\",\n",
    "    \"jdida\": \"جديد\",\n",
    "    \"كيفما\": \"كيف\",\n",
    "    \"اندير\": \"افعل\",\n",
    "    \"ذيم\": \"دائما\",\n",
    "    \"وين\": \"أين\",\n",
    "    \"راهي\": \"هي\",\n",
    "    \"ماندمت\": \"ندم\",\n",
    "    \"حشو\": \"خدعة\",\n",
    "    \"حشوة\": \"خدعة\",\n",
    "    \"انشاءاللهتكونمننصيبي\": \"ان شاء الله تكون من نصيبي\",\n",
    "    \"نتمنالهم\": \"اتمنى\",\n",
    "    \"راحوش\": \"لم يذهب\",\n",
    "    \"بادن\": \"باذن\",\n",
    "    \"الي\": \"الذي\",\n",
    "    \"تغلقلو\": \"غلق\",\n",
    "    \"نيمروه\": \"رقم\",\n",
    "    \"يسترجعو\": \"استرجاع\",\n",
    "    \"رانيني\": \"ranini\",\n",
    "    \"عقوبة\": \"عاقبة\",\n",
    "    \"قوب\": \"عاقبة\",\n",
    "    \"حطو\": \"وضع\",\n",
    "    \"لينا\": \"لنا\",\n",
    "    \"ستمرار\": \"مستمر\",\n",
    "    \"لابيلكاسيو\": \"تطبيق\",\n",
    "    \"لبليكاسيو\": \"تطبيق\",\n",
    "    \"متمشيش\": \"لا تعمل\",\n",
    "    \"حبستوها\": \"توقف\",\n",
    "    \"حمال\": \"تحميل\",\n",
    "    \"مزان\": \"ميزان\",\n",
    "    \"جيه\": \"جهة\",\n",
    "    \"فلاترددو\": \"فلا تترددو\",\n",
    "    \"خدمهوعروضاطاقم\": \"خدمة و عروض طاقم\",\n",
    "    \"فلعاصمة\": \"في عاصمة\",\n",
    "    \"nztjwice\": \" \",\n",
    "    \"refvf\": \" \",\n",
    "    \"b\": \" \",\n",
    "    \"br\": \" \",\n",
    "    \"ابار\": \"يبارك\",\n",
    "    \"يحفضكم\": \"يحفظكم\",\n",
    "    \"يلوس\": \"plus\",\n",
    "    \"تاه\": \"متى\",\n",
    "    \"بف\": \" \",\n",
    "    \"sagmou\": \"regler\",\n",
    "    \"شويش\": \"switch\",\n",
    "    \"بغية\": \"اريد\",\n",
    "    \"dialkom\": \"vous\",\n",
    "    \"sahel\": \"facile\",\n",
    "    \"toop\": \"top\",\n",
    "    \"هنيء\": \"مبروك\",\n",
    "    \"puse\": \"sim\",\n",
    "    \"pui\": \"puis\",\n",
    "    \"nerbah\": \"gagne\",\n",
    "    \"ghir\": \"sauf\",\n",
    "    \"بيان\": \"جيدا\",\n",
    "    \"ماتمشيش\": \"لا تعمل\",\n",
    "    \"نحافضو\": \"حفاظ\",\n",
    "    \"تخلاص\": \"انتهاء\",\n",
    "    \"متعرفش\": \"لا تعلم\",\n",
    "    \"خاصتا\": \"خاصة\",\n",
    "    \"وفى\": \"و في\",\n",
    "    \"ظل\": \"دائما\",\n",
    "    \"مدرتو\": \"لم تفعلو\",\n",
    "    \"لموبليس\": \"موبيليس\",\n",
    "    \"را\": \"انه\",\n",
    "    \"صر\": \"حدث\",\n",
    "    \"rah\": \"il est\",\n",
    "    \"gae\": \"tous\",\n",
    "    \"dok\": \"maintenant\",\n",
    "    \"لابليكاسيون\": \"تطبيق\",\n",
    "    \"كلش\": \"كل\",\n",
    "    \"مشاءالله\": \"ما شاء الله\",\n",
    "    \"حبس\": \"توقف\",\n",
    "    \"زيد\": \"ايضا\",\n",
    "    \"تسرقو\": \"سرق\",\n",
    "    \"تاكتيفي\": \"تفعيل\",\n",
    "    \"زوعاماء\": \"زعماء\",\n",
    "    \"ul\": \" \",\n",
    "    \"كدب\": \"كذب\",\n",
    "    \"ميقراسيون\": \"تبديل\",\n",
    "    \"شح\": \"كم\",\n",
    "    \"فيهاش\": \"لا يوجد\",\n",
    "    \"نجاوب\": \"اجيب\",\n",
    "    \"راحت\": \"ذهب\",\n",
    "    \"متسواش\": \"سيء\",\n",
    "    \"تعكم\": \"خاص بكم\",\n",
    "    \"حقاهايلة\": \"ممتاز\",\n",
    "    \"صرقولي\": \"سرق\",\n",
    "    \"صرق\": \"سرق\",\n",
    "    \"ويني\": \"اين\",\n",
    "    \"حمدلله\": \"حمد لله\",\n",
    "    \"رحمن\": \"رحمان\",\n",
    "    \"نشال\": \"شاء الله\",\n",
    "    \"ماشاء\": \"ما شاء\",\n",
    "    \"تنحولي\": \"نزع\",\n",
    "    \"خمسلاف\": \"خمسة ألف\",\n",
    "    \"خمسلاف\": \"خمسة ألف\",\n",
    "    \"مفعلتهاش\": \"لا تفعيل\",\n",
    "    \"سرقتولي\": \"سرق\",\n",
    "    \"لكريدي\": \"رصيد\",\n",
    "    \"انترنتوراها\": \"اين انترنت\",\n",
    "    \"تعييف\": \"سيء\",\n",
    "    \"تعيف\": \"سيء\",\n",
    "    \"ضك\": \"الان\",\n",
    "    \"جزى\": \"جزاك\",\n",
    "    \"نشاء\": \"ان شاء\",\n",
    "    \"إنشاءالله\": \"ان شاء الله\",\n",
    "    \"نشالله\": \"ان شاء الله\",\n",
    "    \"شاءالله\": \"شاء الله\"\n",
    "}\n",
    "\n",
    "def replace_abbreviations(text):\n",
    "    words = text.split()\n",
    "    return ' '.join([abbreviations[word] if word in abbreviations else word for word in words])\n",
    "\n",
    "comments_df['Comments'] = comments_df['Comments'].apply(replace_abbreviations)\n",
    "posts_df['Contents'] = posts_df['Contents'].apply(replace_abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# Dictionnaire de regroupement phonétique\n",
    "phonetic_groups = {\n",
    "    \"تعبئة\": [\"كنفليكسيو\", \"نفليكسي\", \"نفليكسيو\", \"فليكس\", \"تفليكسي\", \"فليكسولنا\", \"نفلبكسى\", \"فليكسيت\", \"كسي\", \"فليكسي\"],\n",
    "    \"connexion\": [\"conx\", \"cnx\", \"ncx\", \"conexion\", \"connection\"],\n",
    "    \"reseau\": [\"wrizo\", \"rizo\", \"riso\", \"rysou\", \"resou\", \"risou\"],\n",
    "    \"اصلحوا\": [\"ريقلوه\", \"ريقلو\", \"صلحو\", \"ريقولو\", \"صلحونا\", \"عدلو\", \"ريغلونا\", \"رقليو\", \"تريغليونا\", \"لوتصلحولينا\", \"تريقلونا\", \"وريقليو\"],\n",
    "    \"شبكة\": [\"ريزو\", \"اريزو\", \"الريزو\", \"ااريزو\", \"خط\", \"خطي\", \"رزو\"],\n",
    "    \"ما به\": [\"واشي\", \"وشبيه\", \"شبيه\"],\n",
    "    \"لا يوجد\": [\"ماكاش\", \"مكانش\", \"مكاش\", \"مكااش\", \"والو\", \"معنديش\", \"الو\"], \n",
    "    \"أي\": [\"كش\", \"كاش\"],\n",
    "    \"انترنت\": [\"كونيكسيون\", \"كونكسيو\", \"كونكزيون\", \"كونيكسيو\", \"ليدوني\", \"انترنات\", \"انترنيت\",\"نترنت\", \"أنترنات\", \"الكنكسيو\", \"الانثرنات\", \"الانترنت\", \"أنترنت\",  \"اترنات\", \"الكونيكسيوو\", \"نت\", \"لكونيكسيو\", \"كنكسيو\", \"كونيكسو\", \"انترن\"],\n",
    "    \"جازي\": [\"جايز\", \"جاز\", \"دجيزي\", \"دجزي\", \"جيزي\", \"جايزي\"],\n",
    "    \"اسقاس\": [\"اسوكاس\", \"اصكاس\", \"اسيقاس\", \"اسكاس\"],\n",
    "    \"امقاز\": [\"أموقاز\", \"امكاز\"],\n",
    "    \"رمز\": [\"كود\", \"رزم\"],\n",
    "    \"بارك\": [\"بارى\", \"بيار\", \"باراك\", \"يبارك\"],\n",
    "    \"شريحة\": [\"لابيس\", \"لبيس\", \"بيس\", \"لابوس\", \"لبييس\", \"ليبيس\", \"بوس\", \"سبيسي\", \"لبووس\", \"pis\"],\n",
    "    \"اوريدو\": [\"اريدوو\", \"لأوريد\", \"ياؤريدوا\", \"اوريدوا\", \"واوريدو\", \"ااوريدو\", \"اريدو\"],\n",
    "    \"ان شاء\": [\"إنشاء\", \"نشالله\", \"انشاء\"],\n",
    "    \"ilimite\": [\"ilm\", \"ilmt\", \"ilimiti\", \"ilim\"],\n",
    "}\n",
    "\n",
    "# Création d’un mapping inverse (pour accélérer la recherche)\n",
    "phonetic_mapping = {}\n",
    "for standard, variations in phonetic_groups.items():\n",
    "    for variant in variations:\n",
    "        phonetic_mapping[variant] = standard\n",
    "\n",
    "# Fonction de remplacement des variantes phonétiques\n",
    "def replace_phonetic_variants(text):\n",
    "    words = text.split()\n",
    "    return ' '.join([phonetic_mapping[word] if word in phonetic_mapping else word for word in words])\n",
    "\n",
    "comments_df['Comments'] = comments_df['Comments'].apply(replace_phonetic_variants)\n",
    "posts_df['Contents'] = posts_df['Contents'].apply(replace_phonetic_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'سلام عليكم ورحمة لديا مشكلة ! تعبئة 100 دج و بدأت تنقص قليل قليل من 100 دج إلى 75دج و بعدها إلى 50 دج و بعدها إلى 25 دج ! اين ذهبت رصيد تاعي ؟! لن أتكلم بها و لم اتصل بها و ليس لي خاصية رنتي اذن اين ذهب مالي؟!؟!؟!؟ و صار نفس الشيء مع أخي! ماهذا لابد من استرجاعه'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df[\"Comments\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'راك في عطل و خصك رصيد ؟ مع خدمة tranquilo خاص ب djezzy كل ساهل جازي astuces ساهلة'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df[\"Contents\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: llama-cpp-python in c:\\users\\kikoo\\appdata\\roaming\\python\\python312\\site-packages (0.3.8)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kikoo\\appdata\\roaming\\python\\python312\\site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from llama-cpp-python) (1.26.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\kikoo\\appdata\\roaming\\python\\python312\\site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from llama-cpp-python) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\kikoo\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installer la bibliothèque pour exécuter GGUF\n",
    "%pip install llama-cpp-python tqdm\n",
    "\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle\n",
    "model_path = \"models/DeepSeek-R1-Distill-Qwen-7B-Q8_0.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 30 key-value pairs and 339 tensors from models/DeepSeek-R1-Distill-Qwen-7B-Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = DeepSeek R1 Distill Qwen 7B\n",
      "llama_model_loader: - kv   3:                           general.basename str              = DeepSeek-R1-Distill-Qwen\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 7B\n",
      "llama_model_loader: - kv   5:                          qwen2.block_count u32              = 28\n",
      "llama_model_loader: - kv   6:                       qwen2.context_length u32              = 131072\n",
      "llama_model_loader: - kv   7:                     qwen2.embedding_length u32              = 3584\n",
      "llama_model_loader: - kv   8:                  qwen2.feed_forward_length u32              = 18944\n",
      "llama_model_loader: - kv   9:                 qwen2.attention.head_count u32              = 28\n",
      "llama_model_loader: - kv  10:              qwen2.attention.head_count_kv u32              = 4\n",
      "llama_model_loader: - kv  11:                       qwen2.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  12:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = deepseek-r1-qwen\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,152064]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,152064]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 151646\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% if not add_generation_prompt is de...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  25:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  26:                      quantize.imatrix.file str              = /models_out/DeepSeek-R1-Distill-Qwen-...\n",
      "llama_model_loader: - kv  27:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  28:             quantize.imatrix.entries_count i32              = 196\n",
      "llama_model_loader: - kv  29:              quantize.imatrix.chunks_count i32              = 128\n",
      "llama_model_loader: - type  f32:  141 tensors\n",
      "llama_model_loader: - type q8_0:  198 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q8_0\n",
      "print_info: file size   = 7.54 GiB (8.50 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 151661 '<|fim_suffix|>' is not marked as EOG\n",
      "load: control token: 151647 '<|EOT|>' is not marked as EOG\n",
      "load: control token: 151654 '<|vision_pad|>' is not marked as EOG\n",
      "load: control token: 151659 '<|fim_prefix|>' is not marked as EOG\n",
      "load: control token: 151646 '<｜begin▁of▁sentence｜>' is not marked as EOG\n",
      "load: control token: 151643 '<｜end▁of▁sentence｜>' is not marked as EOG\n",
      "load: control token: 151644 '<｜User｜>' is not marked as EOG\n",
      "load: control token: 151645 '<｜Assistant｜>' is not marked as EOG\n",
      "load: control token: 151650 '<|quad_start|>' is not marked as EOG\n",
      "load: control token: 151651 '<|quad_end|>' is not marked as EOG\n",
      "load: control token: 151652 '<|vision_start|>' is not marked as EOG\n",
      "load: control token: 151653 '<|vision_end|>' is not marked as EOG\n",
      "load: control token: 151655 '<|image_pad|>' is not marked as EOG\n",
      "load: control token: 151656 '<|video_pad|>' is not marked as EOG\n",
      "load: control token: 151660 '<|fim_middle|>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 22\n",
      "load: token to piece cache size = 0.9310 MB\n",
      "print_info: arch             = qwen2\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3584\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 28\n",
      "print_info: n_head_kv        = 4\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 7\n",
      "print_info: n_embd_k_gqa     = 512\n",
      "print_info: n_embd_v_gqa     = 512\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-06\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 18944\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.62 B\n",
      "print_info: general.name     = DeepSeek R1 Distill Qwen 7B\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 152064\n",
      "print_info: n_merges         = 151387\n",
      "print_info: BOS token        = 151646 '<｜begin▁of▁sentence｜>'\n",
      "print_info: EOS token        = 151643 '<｜end▁of▁sentence｜>'\n",
      "print_info: EOT token        = 151643 '<｜end▁of▁sentence｜>'\n",
      "print_info: PAD token        = 151643 '<｜end▁of▁sentence｜>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: FIM PRE token    = 151659 '<|fim_prefix|>'\n",
      "print_info: FIM SUF token    = 151661 '<|fim_suffix|>'\n",
      "print_info: FIM MID token    = 151660 '<|fim_middle|>'\n",
      "print_info: FIM PAD token    = 151662 '<|fim_pad|>'\n",
      "print_info: FIM REP token    = 151663 '<|repo_name|>'\n",
      "print_info: FIM SEP token    = 151664 '<|file_sep|>'\n",
      "print_info: EOG token        = 151643 '<｜end▁of▁sentence｜>'\n",
      "print_info: EOG token        = 151662 '<|fim_pad|>'\n",
      "print_info: EOG token        = 151663 '<|repo_name|>'\n",
      "print_info: EOG token        = 151664 '<|file_sep|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU\n",
      "load_tensors: layer   1 assigned to device CPU\n",
      "load_tensors: layer   2 assigned to device CPU\n",
      "load_tensors: layer   3 assigned to device CPU\n",
      "load_tensors: layer   4 assigned to device CPU\n",
      "load_tensors: layer   5 assigned to device CPU\n",
      "load_tensors: layer   6 assigned to device CPU\n",
      "load_tensors: layer   7 assigned to device CPU\n",
      "load_tensors: layer   8 assigned to device CPU\n",
      "load_tensors: layer   9 assigned to device CPU\n",
      "load_tensors: layer  10 assigned to device CPU\n",
      "load_tensors: layer  11 assigned to device CPU\n",
      "load_tensors: layer  12 assigned to device CPU\n",
      "load_tensors: layer  13 assigned to device CPU\n",
      "load_tensors: layer  14 assigned to device CPU\n",
      "load_tensors: layer  15 assigned to device CPU\n",
      "load_tensors: layer  16 assigned to device CPU\n",
      "load_tensors: layer  17 assigned to device CPU\n",
      "load_tensors: layer  18 assigned to device CPU\n",
      "load_tensors: layer  19 assigned to device CPU\n",
      "load_tensors: layer  20 assigned to device CPU\n",
      "load_tensors: layer  21 assigned to device CPU\n",
      "load_tensors: layer  22 assigned to device CPU\n",
      "load_tensors: layer  23 assigned to device CPU\n",
      "load_tensors: layer  24 assigned to device CPU\n",
      "load_tensors: layer  25 assigned to device CPU\n",
      "load_tensors: layer  26 assigned to device CPU\n",
      "load_tensors: layer  27 assigned to device CPU\n",
      "load_tensors: layer  28 assigned to device CPU\n",
      "load_tensors: tensor 'token_embd.weight' (q8_0) (and 338 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =  7717.68 MiB\n",
      "........................................................................................\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 2048\n",
      "llama_init_from_model: n_ctx_per_seq = 2048\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 10000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 2048, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init:        CPU KV buffer size =   112.00 MiB\n",
      "llama_init_from_model: KV self size  =  112.00 MiB, K (f16):   56.00 MiB, V (f16):   56.00 MiB\n",
      "llama_init_from_model:        CPU  output buffer size =     0.58 MiB\n",
      "llama_init_from_model:        CPU compute buffer size =   304.00 MiB\n",
      "llama_init_from_model: graph nodes  = 986\n",
      "llama_init_from_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.name': 'DeepSeek R1 Distill Qwen 7B', 'general.architecture': 'qwen2', 'general.type': 'model', 'general.basename': 'DeepSeek-R1-Distill-Qwen', 'qwen2.block_count': '28', 'general.size_label': '7B', 'qwen2.context_length': '131072', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'qwen2.embedding_length': '3584', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '151646', 'qwen2.feed_forward_length': '18944', 'qwen2.attention.head_count': '28', 'qwen2.attention.head_count_kv': '4', 'tokenizer.ggml.padding_token_id': '151643', 'qwen2.rope.freq_base': '10000.000000', 'qwen2.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'deepseek-r1-qwen', 'general.file_type': '7', 'tokenizer.ggml.eos_token_id': '151643', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.chat_template': \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜>'}}{% endif %}\", 'quantize.imatrix.chunks_count': '128', 'quantize.imatrix.file': '/models_out/DeepSeek-R1-Distill-Qwen-7B-GGUF/DeepSeek-R1-Distill-Qwen-7B.imatrix', 'quantize.imatrix.entries_count': '196'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜>'}}{% endif %}\n",
      "Using chat eos_token: <｜end▁of▁sentence｜>\n",
      "Using chat bos_token: <｜begin▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_ctx=2048,\n",
    "    n_threads=4,\n",
    "    n_gpu_layers=1  # Mettez une valeur >0 si vous avez un GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le prompt système\n",
    "system_prompt = \"\"\"\n",
    "### Tâche ###\n",
    "Analyse le sentiment du commentaire et classe-le exclusivement sous l'un de ces trois labels:\n",
    "- **\"Positif\"** : Pour les commentaires contenant des **émotions positives**, des **éloges**, de la **satisfaction**, des **félicitations**, des **encouragements**, des **salutations**, des **remerciements** ...ect.  \n",
    "- **\"Negatif\"** : Pour les commentaires contenant des **émotions négatives**, des **critiques**, des **plaintes**, des **déceptions**, des **insultes**, des **frustrations**, des **menaces** ou des mots négatifs ...ect.  \n",
    "- **\"Neutre\"** : Pour les commentaires **factuels**, **informatifs**, **neutres en tonalité**, **des suggestions**, ou **des demandes d'information** ...ect.\n",
    "\n",
    "### Règles Strictes ###\n",
    "1. Répondre UNIQUEMENT par un des trois mots: Positif, Negatif ou Neutre.\n",
    "2. Pas d'explications, pas de phrases complètes.\n",
    "3. Langues supportées: Arabe, Darija Algérienne, Français, Anglais.\n",
    "4. Attention il faut bien réfléchir.\n",
    "5. Si le commentaire contient des abréviations, remplacez-les par leur forme complète avant d'analyser le sentiment.\n",
    "6. Si le commentaire contient des variantes phonétiques, remplacez-les par leur forme standard avant d'analyser le sentiment.\n",
    "7. Avant finir, assurez-vous que le commentaire est bien nettoyé et compréhensible.\n",
    "8. Avant de répondre, assurez-vous que le commentaire est bien nettoyé et compréhensible.\n",
    "\n",
    "### **EXEMPLES**\n",
    "\n",
    "#### **Arabe et Darija Algérienne**\n",
    "- `\"المنتج رائع!\"` → **Positif**  \n",
    "- `\"الخدمة سيئة جداً\"` → **Negatif**  \n",
    "- `\"التوصيل استغرق يومين\"` → **Neutre**  \n",
    "\n",
    "- `\"الخدمة مليحة\"` → **Positif**\n",
    "- `\"ماكاش ريزو\"` → **Negatif**  \n",
    "- `\"جاتني الفاتورة\"` → **Neutre**  \n",
    "\n",
    "#### **Français**\n",
    "- `\"Super produit !\"` → **Positif**  \n",
    "- `\"Service horrible\"` → **Negatif**  \n",
    "- `\"D'accord\"` → **Neutre**  \n",
    "\n",
    "- `\"Merci pour votre aide !\"` → **Positif**  \n",
    "- `\"Je suis extrêmement déçu du service\"` → **Negatif**  \n",
    "- `\"La livraison était de 3 jours\"` → **Neutre**  \n",
    "\n",
    "#### **Anglais**\n",
    "- `\"Great product!\"` → **Positif**  \n",
    "- `\"Terrible service\"` → **Negatif**  \n",
    "- `\"Received in 2 days\"` → **Neutre**  \n",
    "\n",
    "### **Tests et Validation**\n",
    "Tu peux tester plusieurs exemples pour vérifier si le modèle les prédit correctement.  \n",
    "Ton objectif est d’optimiser l’annotation automatique pour assurer une **précision maximale**. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(comment_text):\n",
    "    prompt = f\"{system_prompt}\\nComment: {comment_text}\\nSentiment:\"\n",
    "    \n",
    "    output = llm(\n",
    "        prompt,\n",
    "        max_tokens=10,\n",
    "        temperature=1,\n",
    "        stop=[\"\\n\"],\n",
    "        echo=False\n",
    "    )\n",
    "    \n",
    "    # Nettoyer la sortie pour ne garder que le label\n",
    "    sentiment = output['choices'][0]['text'].strip()\n",
    "    sentiment = sentiment.split()[0] if sentiment else \"Neutre\"\n",
    "    \n",
    "    # Forcer l'un des trois labels\n",
    "    if sentiment not in [\"Positif\", \"Negatif\", \"Neutre\"]:\n",
    "        sentiment = \"Neutre\"\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendre seulement les 30 premiers commentaires pour le test\n",
    "test_df = comments_df.head(30).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing comments:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Annotation des commentaires\n",
    "tqdm.pandas(desc=\"Analyzing comments\")\n",
    "test_df['Predicted_Sentiment'] = test_df['Comments'].progress_apply(\n",
    "    lambda x: analyze_sentiment(x) if pd.notna(x) else \"Neutre\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les résultats du test\n",
    "test_df.to_csv(\"Data/Test_Comments_Annotated.csv\", index=False)\n",
    "print(\"\\nTest terminé. Résultats sauvegardés dans Test_Comments_Annotated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Annotation des commentaires\n",
    "tqdm.pandas(desc=\"Analyzing comments\")\n",
    "comments_df['Predicted_Sentiment'] = comments_df['Comments'].progress_apply(\n",
    "    lambda x: analyze_sentiment(x) if pd.notna(x) else \"Neutre\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matrice de confusion enregistrée dans : Results/confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "output_dir = \"Results/\"\n",
    "\n",
    "# Évaluation des Résultats\n",
    "y_true = comments_df[\"Sentiments\"]\n",
    "y_pred = comments_df[\"Sentiment_Predicted\"]\n",
    "\n",
    "# Calcul des métriques\n",
    "accuracy = accuracy_score(y_true, y_pred) * 100  # Pourcentage\n",
    "precision = precision_score(y_true, y_pred, average=None) * 100\n",
    "recall = recall_score(y_true, y_pred, average=None) * 100\n",
    "\n",
    "# Générer la matrice de confusion\n",
    "labels = [\"Negatif\", \"Neutre\", \"Positif\"]\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "# Tracer la matrice de confusion\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "# Titres et labels\n",
    "plt.title(\"Matrice de Confusion de Model DeepSeek-R1-Distill-Qwen-7B-Q8_0\", fontsize=12)\n",
    "plt.xlabel(\"Prédit\", fontsize=15)\n",
    "plt.ylabel(\"Réel\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "# Sauvegarde de la Matrice\n",
    "confusion_matrix_path = os.path.join(output_dir, \"confusion_matrix.png\")\n",
    "plt.savefig(confusion_matrix_path)\n",
    "print(f\"✅ Matrice de confusion enregistrée dans : {confusion_matrix_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy du modèle sur l'ensemble de test : 59.93 %\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.63      0.84      0.72       863\n",
      "      Neutre       0.43      0.17      0.25      1139\n",
      "     Positif       0.62      0.79      0.70      1467\n",
      "\n",
      "    accuracy                           0.60      3469\n",
      "   macro avg       0.56      0.60      0.55      3469\n",
      "weighted avg       0.56      0.60      0.55      3469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Affichage des résultats\n",
    "print(f\"\\n✅ Accuracy du modèle sur l'ensemble de test : {round(accuracy, 2)} %\\n\")\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Annotation terminée ! Résultats enregistrés dans : Results/comments_annotated.csv\n",
      "✅ Scores des métriques enregistrés dans : Results/metrics_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Enregistrement des Résultats\n",
    "metrics_path = os.path.join(output_dir, \"metrics_results.txt\")\n",
    "annotated_csv_path = os.path.join(output_dir, \"comments_annotated.csv\")\n",
    "\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    f.write(f\"🔍 Évaluation des Sentiments\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    f.write(f\"\\n✅ Accuracy du modèle sur l'ensemble de test : {round(accuracy, 2)} %\\n\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "# Sauvegarde du DataFrame annoté\n",
    "comments_df.to_csv(annotated_csv_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ Annotation terminée ! Résultats enregistrés dans : {annotated_csv_path}\")\n",
    "print(f\"✅ Scores des métriques enregistrés dans : {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 Load Mistral-7B-Instruct-v0.3 GGUF Model\n",
    "model_path = \"models/Mistral-7B-Instruct-v0.3.fp16.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 25 key-value pairs and 291 tensors from models/Mistral-7B-Instruct-v0.3.fp16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = models--mistralai--Mistral-7B-Instruc...\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 32768\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32768]   = [\"<unk>\", \"<s>\", \"</s>\", \"[INST]\", \"[...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32768]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32768]   = [2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type  f16:  226 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = F16\n",
      "print_info: file size   = 13.50 GiB (16.00 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:     48 '[control_46]' is not marked as EOG\n",
      "load: control token:    624 '[control_622]' is not marked as EOG\n",
      "load: control token:    216 '[control_214]' is not marked as EOG\n",
      "load: control token:     40 '[control_38]' is not marked as EOG\n",
      "load: control token:    322 '[control_320]' is not marked as EOG\n",
      "load: control token:      4 '[/INST]' is not marked as EOG\n",
      "load: control token:    366 '[control_364]' is not marked as EOG\n",
      "load: control token:     32 '[control_30]' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: control token:    425 '[control_423]' is not marked as EOG\n",
      "load: control token:     44 '[control_42]' is not marked as EOG\n",
      "load: control token:      7 '[/AVAILABLE_TOOLS]' is not marked as EOG\n",
      "load: control token:    206 '[control_204]' is not marked as EOG\n",
      "load: control token:     22 '[control_20]' is not marked as EOG\n",
      "load: control token:    241 '[control_239]' is not marked as EOG\n",
      "load: control token:    112 '[control_110]' is not marked as EOG\n",
      "load: control token:    398 '[control_396]' is not marked as EOG\n",
      "load: control token:      5 '[TOOL_CALLS]' is not marked as EOG\n",
      "load: control token:    655 '[control_653]' is not marked as EOG\n",
      "load: control token:    725 '[control_723]' is not marked as EOG\n",
      "load: control token:    340 '[control_338]' is not marked as EOG\n",
      "load: control token:    523 '[control_521]' is not marked as EOG\n",
      "load: control token:    242 '[control_240]' is not marked as EOG\n",
      "load: control token:      3 '[INST]' is not marked as EOG\n",
      "load: control token:    364 '[control_362]' is not marked as EOG\n",
      "load: control token:     38 '[control_36]' is not marked as EOG\n",
      "load: control token:    333 '[control_331]' is not marked as EOG\n",
      "load: control token:    530 '[control_528]' is not marked as EOG\n",
      "load: control token:    251 '[control_249]' is not marked as EOG\n",
      "load: control token:      6 '[AVAILABLE_TOOLS]' is not marked as EOG\n",
      "load: control token:     63 '[control_61]' is not marked as EOG\n",
      "load: control token:    346 '[control_344]' is not marked as EOG\n",
      "load: control token:     12 '[control_10]' is not marked as EOG\n",
      "load: control token:    409 '[control_407]' is not marked as EOG\n",
      "load: control token:      8 '[TOOL_RESULTS]' is not marked as EOG\n",
      "load: control token:    694 '[control_692]' is not marked as EOG\n",
      "load: control token:    153 '[control_151]' is not marked as EOG\n",
      "load: control token:    374 '[control_372]' is not marked as EOG\n",
      "load: control token:      9 '[/TOOL_RESULTS]' is not marked as EOG\n",
      "load: control token:     59 '[control_57]' is not marked as EOG\n",
      "load: control token:    191 '[control_189]' is not marked as EOG\n",
      "load: control token:    284 '[control_282]' is not marked as EOG\n",
      "load: control token:     10 '[control_8]' is not marked as EOG\n",
      "load: control token:     58 '[control_56]' is not marked as EOG\n",
      "load: control token:    190 '[control_188]' is not marked as EOG\n",
      "load: control token:    285 '[control_283]' is not marked as EOG\n",
      "load: control token:     11 '[control_9]' is not marked as EOG\n",
      "load: control token:     62 '[control_60]' is not marked as EOG\n",
      "load: control token:    347 '[control_345]' is not marked as EOG\n",
      "load: control token:     13 '[control_11]' is not marked as EOG\n",
      "load: control token:    348 '[control_346]' is not marked as EOG\n",
      "load: control token:     14 '[control_12]' is not marked as EOG\n",
      "load: control token:    349 '[control_347]' is not marked as EOG\n",
      "load: control token:     15 '[control_13]' is not marked as EOG\n",
      "load: control token:    698 '[control_696]' is not marked as EOG\n",
      "load: control token:    405 '[control_403]' is not marked as EOG\n",
      "load: control token:    157 '[control_155]' is not marked as EOG\n",
      "load: control token:     60 '[control_58]' is not marked as EOG\n",
      "load: control token:    342 '[control_340]' is not marked as EOG\n",
      "load: control token:     16 '[control_14]' is not marked as EOG\n",
      "load: control token:    699 '[control_697]' is not marked as EOG\n",
      "load: control token:    404 '[control_402]' is not marked as EOG\n",
      "load: control token:    156 '[control_154]' is not marked as EOG\n",
      "load: control token:     61 '[control_59]' is not marked as EOG\n",
      "load: control token:    343 '[control_341]' is not marked as EOG\n",
      "load: control token:     17 '[control_15]' is not marked as EOG\n",
      "load: control token:    344 '[control_342]' is not marked as EOG\n",
      "load: control token:     18 '[control_16]' is not marked as EOG\n",
      "load: control token:    345 '[control_343]' is not marked as EOG\n",
      "load: control token:     19 '[control_17]' is not marked as EOG\n",
      "load: control token:    161 '[control_159]' is not marked as EOG\n",
      "load: control token:     56 '[control_54]' is not marked as EOG\n",
      "load: control token:     20 '[control_18]' is not marked as EOG\n",
      "load: control token:     57 '[control_55]' is not marked as EOG\n",
      "load: control token:    160 '[control_158]' is not marked as EOG\n",
      "load: control token:     21 '[control_19]' is not marked as EOG\n",
      "load: control token:    207 '[control_205]' is not marked as EOG\n",
      "load: control token:     23 '[control_21]' is not marked as EOG\n",
      "load: control token:     24 '[control_22]' is not marked as EOG\n",
      "load: control token:    208 '[control_206]' is not marked as EOG\n",
      "load: control token:    209 '[control_207]' is not marked as EOG\n",
      "load: control token:     25 '[control_23]' is not marked as EOG\n",
      "load: control token:    380 '[control_378]' is not marked as EOG\n",
      "load: control token:     26 '[control_24]' is not marked as EOG\n",
      "load: control token:    202 '[control_200]' is not marked as EOG\n",
      "load: control token:    381 '[control_379]' is not marked as EOG\n",
      "load: control token:    203 '[control_201]' is not marked as EOG\n",
      "load: control token:     27 '[control_25]' is not marked as EOG\n",
      "load: control token:     28 '[control_26]' is not marked as EOG\n",
      "load: control token:    204 '[control_202]' is not marked as EOG\n",
      "load: control token:    205 '[control_203]' is not marked as EOG\n",
      "load: control token:     29 '[control_27]' is not marked as EOG\n",
      "load: control token:    376 '[control_374]' is not marked as EOG\n",
      "load: control token:     30 '[control_28]' is not marked as EOG\n",
      "load: control token:    377 '[control_375]' is not marked as EOG\n",
      "load: control token:     31 '[control_29]' is not marked as EOG\n",
      "load: control token:    367 '[control_365]' is not marked as EOG\n",
      "load: control token:     33 '[control_31]' is not marked as EOG\n",
      "load: control token:    368 '[control_366]' is not marked as EOG\n",
      "load: control token:     34 '[control_32]' is not marked as EOG\n",
      "load: control token:    369 '[control_367]' is not marked as EOG\n",
      "load: control token:     35 '[control_33]' is not marked as EOG\n",
      "load: control token:    362 '[control_360]' is not marked as EOG\n",
      "load: control token:    220 '[control_218]' is not marked as EOG\n",
      "load: control token:     36 '[control_34]' is not marked as EOG\n",
      "load: control token:    363 '[control_361]' is not marked as EOG\n",
      "load: control token:    221 '[control_219]' is not marked as EOG\n",
      "load: control token:     37 '[control_35]' is not marked as EOG\n",
      "load: control token:    365 '[control_363]' is not marked as EOG\n",
      "load: control token:     39 '[control_37]' is not marked as EOG\n",
      "load: control token:     41 '[control_39]' is not marked as EOG\n",
      "load: control token:    217 '[control_215]' is not marked as EOG\n",
      "load: control token:     42 '[control_40]' is not marked as EOG\n",
      "load: control token:     43 '[control_41]' is not marked as EOG\n",
      "load: control token:     45 '[control_43]' is not marked as EOG\n",
      "load: control token:    481 '[control_479]' is not marked as EOG\n",
      "load: control token:     46 '[control_44]' is not marked as EOG\n",
      "load: control token:    480 '[control_478]' is not marked as EOG\n",
      "load: control token:     47 '[control_45]' is not marked as EOG\n",
      "load: control token:     49 '[control_47]' is not marked as EOG\n",
      "load: control token:    477 '[control_475]' is not marked as EOG\n",
      "load: control token:     50 '[control_48]' is not marked as EOG\n",
      "load: control token:    476 '[control_474]' is not marked as EOG\n",
      "load: control token:     51 '[control_49]' is not marked as EOG\n",
      "load: control token:     52 '[control_50]' is not marked as EOG\n",
      "load: control token:     53 '[control_51]' is not marked as EOG\n",
      "load: control token:    411 '[control_409]' is not marked as EOG\n",
      "load: control token:     54 '[control_52]' is not marked as EOG\n",
      "load: control token:    410 '[control_408]' is not marked as EOG\n",
      "load: control token:     55 '[control_53]' is not marked as EOG\n",
      "load: control token:     64 '[control_62]' is not marked as EOG\n",
      "load: control token:     65 '[control_63]' is not marked as EOG\n",
      "load: control token:     66 '[control_64]' is not marked as EOG\n",
      "load: control token:     67 '[control_65]' is not marked as EOG\n",
      "load: control token:     68 '[control_66]' is not marked as EOG\n",
      "load: control token:     69 '[control_67]' is not marked as EOG\n",
      "load: control token:     70 '[control_68]' is not marked as EOG\n",
      "load: control token:     71 '[control_69]' is not marked as EOG\n",
      "load: control token:     72 '[control_70]' is not marked as EOG\n",
      "load: control token:     73 '[control_71]' is not marked as EOG\n",
      "load: control token:     74 '[control_72]' is not marked as EOG\n",
      "load: control token:     75 '[control_73]' is not marked as EOG\n",
      "load: control token:     76 '[control_74]' is not marked as EOG\n",
      "load: control token:     77 '[control_75]' is not marked as EOG\n",
      "load: control token:     78 '[control_76]' is not marked as EOG\n",
      "load: control token:     79 '[control_77]' is not marked as EOG\n",
      "load: control token:     80 '[control_78]' is not marked as EOG\n",
      "load: control token:     81 '[control_79]' is not marked as EOG\n",
      "load: control token:     82 '[control_80]' is not marked as EOG\n",
      "load: control token:     83 '[control_81]' is not marked as EOG\n",
      "load: control token:     84 '[control_82]' is not marked as EOG\n",
      "load: control token:     85 '[control_83]' is not marked as EOG\n",
      "load: control token:     86 '[control_84]' is not marked as EOG\n",
      "load: control token:     87 '[control_85]' is not marked as EOG\n",
      "load: control token:     88 '[control_86]' is not marked as EOG\n",
      "load: control token:     89 '[control_87]' is not marked as EOG\n",
      "load: control token:     90 '[control_88]' is not marked as EOG\n",
      "load: control token:     91 '[control_89]' is not marked as EOG\n",
      "load: control token:     92 '[control_90]' is not marked as EOG\n",
      "load: control token:     93 '[control_91]' is not marked as EOG\n",
      "load: control token:     94 '[control_92]' is not marked as EOG\n",
      "load: control token:     95 '[control_93]' is not marked as EOG\n",
      "load: control token:     96 '[control_94]' is not marked as EOG\n",
      "load: control token:     97 '[control_95]' is not marked as EOG\n",
      "load: control token:     98 '[control_96]' is not marked as EOG\n",
      "load: control token:     99 '[control_97]' is not marked as EOG\n",
      "load: control token:    100 '[control_98]' is not marked as EOG\n",
      "load: control token:    101 '[control_99]' is not marked as EOG\n",
      "load: control token:    454 '[control_452]' is not marked as EOG\n",
      "load: control token:    102 '[control_100]' is not marked as EOG\n",
      "load: control token:    455 '[control_453]' is not marked as EOG\n",
      "load: control token:    103 '[control_101]' is not marked as EOG\n",
      "load: control token:    452 '[control_450]' is not marked as EOG\n",
      "load: control token:    104 '[control_102]' is not marked as EOG\n",
      "load: control token:    390 '[control_388]' is not marked as EOG\n",
      "load: control token:    453 '[control_451]' is not marked as EOG\n",
      "load: control token:    105 '[control_103]' is not marked as EOG\n",
      "load: control token:    391 '[control_389]' is not marked as EOG\n",
      "load: control token:    458 '[control_456]' is not marked as EOG\n",
      "load: control token:    106 '[control_104]' is not marked as EOG\n",
      "load: control token:    459 '[control_457]' is not marked as EOG\n",
      "load: control token:    107 '[control_105]' is not marked as EOG\n",
      "load: control token:    456 '[control_454]' is not marked as EOG\n",
      "load: control token:    108 '[control_106]' is not marked as EOG\n",
      "load: control token:    457 '[control_455]' is not marked as EOG\n",
      "load: control token:    109 '[control_107]' is not marked as EOG\n",
      "load: control token:    110 '[control_108]' is not marked as EOG\n",
      "load: control token:    384 '[control_382]' is not marked as EOG\n",
      "load: control token:    111 '[control_109]' is not marked as EOG\n",
      "load: control token:    385 '[control_383]' is not marked as EOG\n",
      "load: control token:    240 '[control_238]' is not marked as EOG\n",
      "load: control token:    113 '[control_111]' is not marked as EOG\n",
      "load: control token:    399 '[control_397]' is not marked as EOG\n",
      "load: control token:    114 '[control_112]' is not marked as EOG\n",
      "load: control token:    396 '[control_394]' is not marked as EOG\n",
      "load: control token:    115 '[control_113]' is not marked as EOG\n",
      "load: control token:    397 '[control_395]' is not marked as EOG\n",
      "load: control token:    116 '[control_114]' is not marked as EOG\n",
      "load: control token:    394 '[control_392]' is not marked as EOG\n",
      "load: control token:    395 '[control_393]' is not marked as EOG\n",
      "load: control token:    117 '[control_115]' is not marked as EOG\n",
      "load: control token:    450 '[control_448]' is not marked as EOG\n",
      "load: control token:    657 '[control_655]' is not marked as EOG\n",
      "load: control token:    118 '[control_116]' is not marked as EOG\n",
      "load: control token:    392 '[control_390]' is not marked as EOG\n",
      "load: control token:    656 '[control_654]' is not marked as EOG\n",
      "load: control token:    451 '[control_449]' is not marked as EOG\n",
      "load: control token:    119 '[control_117]' is not marked as EOG\n",
      "load: control token:    393 '[control_391]' is not marked as EOG\n",
      "load: control token:    448 '[control_446]' is not marked as EOG\n",
      "load: control token:    120 '[control_118]' is not marked as EOG\n",
      "load: control token:    233 '[control_231]' is not marked as EOG\n",
      "load: control token:    449 '[control_447]' is not marked as EOG\n",
      "load: control token:    121 '[control_119]' is not marked as EOG\n",
      "load: control token:    232 '[control_230]' is not marked as EOG\n",
      "load: control token:    122 '[control_120]' is not marked as EOG\n",
      "load: control token:    123 '[control_121]' is not marked as EOG\n",
      "load: control token:    124 '[control_122]' is not marked as EOG\n",
      "load: control token:    125 '[control_123]' is not marked as EOG\n",
      "load: control token:    126 '[control_124]' is not marked as EOG\n",
      "load: control token:    127 '[control_125]' is not marked as EOG\n",
      "load: control token:    510 '[control_508]' is not marked as EOG\n",
      "load: control token:    231 '[control_229]' is not marked as EOG\n",
      "load: control token:    128 '[control_126]' is not marked as EOG\n",
      "load: control token:    129 '[control_127]' is not marked as EOG\n",
      "load: control token:    230 '[control_228]' is not marked as EOG\n",
      "load: control token:    511 '[control_509]' is not marked as EOG\n",
      "load: control token:    130 '[control_128]' is not marked as EOG\n",
      "load: control token:    229 '[control_227]' is not marked as EOG\n",
      "load: control token:    508 '[control_506]' is not marked as EOG\n",
      "load: control token:    131 '[control_129]' is not marked as EOG\n",
      "load: control token:    228 '[control_226]' is not marked as EOG\n",
      "load: control token:    509 '[control_507]' is not marked as EOG\n",
      "load: control token:    132 '[control_130]' is not marked as EOG\n",
      "load: control token:    261 '[control_259]' is not marked as EOG\n",
      "load: control token:    133 '[control_131]' is not marked as EOG\n",
      "load: control token:    260 '[control_258]' is not marked as EOG\n",
      "load: control token:    520 '[control_518]' is not marked as EOG\n",
      "load: control token:    134 '[control_132]' is not marked as EOG\n",
      "load: control token:    135 '[control_133]' is not marked as EOG\n",
      "load: control token:    521 '[control_519]' is not marked as EOG\n",
      "load: control token:    136 '[control_134]' is not marked as EOG\n",
      "load: control token:    137 '[control_135]' is not marked as EOG\n",
      "load: control token:    138 '[control_136]' is not marked as EOG\n",
      "load: control token:    139 '[control_137]' is not marked as EOG\n",
      "load: control token:    514 '[control_512]' is not marked as EOG\n",
      "load: control token:    140 '[control_138]' is not marked as EOG\n",
      "load: control token:    253 '[control_251]' is not marked as EOG\n",
      "load: control token:    515 '[control_513]' is not marked as EOG\n",
      "load: control token:    141 '[control_139]' is not marked as EOG\n",
      "load: control token:    252 '[control_250]' is not marked as EOG\n",
      "load: control token:    414 '[control_412]' is not marked as EOG\n",
      "load: control token:    142 '[control_140]' is not marked as EOG\n",
      "load: control token:    415 '[control_413]' is not marked as EOG\n",
      "load: control token:    143 '[control_141]' is not marked as EOG\n",
      "load: control token:    412 '[control_410]' is not marked as EOG\n",
      "load: control token:    144 '[control_142]' is not marked as EOG\n",
      "load: control token:    413 '[control_411]' is not marked as EOG\n",
      "load: control token:    145 '[control_143]' is not marked as EOG\n",
      "load: control token:    418 '[control_416]' is not marked as EOG\n",
      "load: control token:    146 '[control_144]' is not marked as EOG\n",
      "load: control token:    419 '[control_417]' is not marked as EOG\n",
      "load: control token:    147 '[control_145]' is not marked as EOG\n",
      "load: control token:    416 '[control_414]' is not marked as EOG\n",
      "load: control token:    148 '[control_146]' is not marked as EOG\n",
      "load: control token:    417 '[control_415]' is not marked as EOG\n",
      "load: control token:    149 '[control_147]' is not marked as EOG\n",
      "load: control token:    150 '[control_148]' is not marked as EOG\n",
      "load: control token:    151 '[control_149]' is not marked as EOG\n",
      "load: control token:    695 '[control_693]' is not marked as EOG\n",
      "load: control token:    408 '[control_406]' is not marked as EOG\n",
      "load: control token:    152 '[control_150]' is not marked as EOG\n",
      "load: control token:    406 '[control_404]' is not marked as EOG\n",
      "load: control token:    693 '[control_691]' is not marked as EOG\n",
      "load: control token:    154 '[control_152]' is not marked as EOG\n",
      "load: control token:    692 '[control_690]' is not marked as EOG\n",
      "load: control token:    407 '[control_405]' is not marked as EOG\n",
      "load: control token:    155 '[control_153]' is not marked as EOG\n",
      "load: control token:    697 '[control_695]' is not marked as EOG\n",
      "load: control token:    402 '[control_400]' is not marked as EOG\n",
      "load: control token:    158 '[control_156]' is not marked as EOG\n",
      "load: control token:    696 '[control_694]' is not marked as EOG\n",
      "load: control token:    403 '[control_401]' is not marked as EOG\n",
      "load: control token:    159 '[control_157]' is not marked as EOG\n",
      "load: control token:    162 '[control_160]' is not marked as EOG\n",
      "load: control token:    163 '[control_161]' is not marked as EOG\n",
      "load: control token:    164 '[control_162]' is not marked as EOG\n",
      "load: control token:    165 '[control_163]' is not marked as EOG\n",
      "load: control token:    166 '[control_164]' is not marked as EOG\n",
      "load: control token:    167 '[control_165]' is not marked as EOG\n",
      "load: control token:    761 '[control_759]' is not marked as EOG\n",
      "load: control token:    168 '[control_166]' is not marked as EOG\n",
      "load: control token:    760 '[control_758]' is not marked as EOG\n",
      "load: control token:    169 '[control_167]' is not marked as EOG\n",
      "load: control token:    759 '[control_757]' is not marked as EOG\n",
      "load: control token:    170 '[control_168]' is not marked as EOG\n",
      "load: control token:    758 '[control_756]' is not marked as EOG\n",
      "load: control token:    171 '[control_169]' is not marked as EOG\n",
      "load: control token:    464 '[control_462]' is not marked as EOG\n",
      "load: control token:    172 '[control_170]' is not marked as EOG\n",
      "load: control token:    465 '[control_463]' is not marked as EOG\n",
      "load: control token:    173 '[control_171]' is not marked as EOG\n",
      "load: control token:    462 '[control_460]' is not marked as EOG\n",
      "load: control token:    174 '[control_172]' is not marked as EOG\n",
      "load: control token:    463 '[control_461]' is not marked as EOG\n",
      "load: control token:    175 '[control_173]' is not marked as EOG\n",
      "load: control token:    468 '[control_466]' is not marked as EOG\n",
      "load: control token:    176 '[control_174]' is not marked as EOG\n",
      "load: control token:    469 '[control_467]' is not marked as EOG\n",
      "load: control token:    177 '[control_175]' is not marked as EOG\n",
      "load: control token:    466 '[control_464]' is not marked as EOG\n",
      "load: control token:    178 '[control_176]' is not marked as EOG\n",
      "load: control token:    467 '[control_465]' is not marked as EOG\n",
      "load: control token:    179 '[control_177]' is not marked as EOG\n",
      "load: control token:    180 '[control_178]' is not marked as EOG\n",
      "load: control token:    181 '[control_179]' is not marked as EOG\n",
      "load: control token:    182 '[control_180]' is not marked as EOG\n",
      "load: control token:    183 '[control_181]' is not marked as EOG\n",
      "load: control token:    184 '[control_182]' is not marked as EOG\n",
      "load: control token:    291 '[control_289]' is not marked as EOG\n",
      "load: control token:    185 '[control_183]' is not marked as EOG\n",
      "load: control token:    290 '[control_288]' is not marked as EOG\n",
      "load: control token:    186 '[control_184]' is not marked as EOG\n",
      "load: control token:    187 '[control_185]' is not marked as EOG\n",
      "load: control token:    188 '[control_186]' is not marked as EOG\n",
      "load: control token:    189 '[control_187]' is not marked as EOG\n",
      "load: control token:    192 '[control_190]' is not marked as EOG\n",
      "load: control token:    318 '[control_316]' is not marked as EOG\n",
      "load: control token:    193 '[control_191]' is not marked as EOG\n",
      "load: control token:    319 '[control_317]' is not marked as EOG\n",
      "load: control token:    194 '[control_192]' is not marked as EOG\n",
      "load: control token:    316 '[control_314]' is not marked as EOG\n",
      "load: control token:    195 '[control_193]' is not marked as EOG\n",
      "load: control token:    317 '[control_315]' is not marked as EOG\n",
      "load: control token:    196 '[control_194]' is not marked as EOG\n",
      "load: control token:    314 '[control_312]' is not marked as EOG\n",
      "load: control token:    315 '[control_313]' is not marked as EOG\n",
      "load: control token:    197 '[control_195]' is not marked as EOG\n",
      "load: control token:    198 '[control_196]' is not marked as EOG\n",
      "load: control token:    312 '[control_310]' is not marked as EOG\n",
      "load: control token:    551 '[control_549]' is not marked as EOG\n",
      "load: control token:    270 '[control_268]' is not marked as EOG\n",
      "load: control token:    199 '[control_197]' is not marked as EOG\n",
      "load: control token:    313 '[control_311]' is not marked as EOG\n",
      "load: control token:    550 '[control_548]' is not marked as EOG\n",
      "load: control token:    271 '[control_269]' is not marked as EOG\n",
      "load: control token:    268 '[control_266]' is not marked as EOG\n",
      "load: control token:    549 '[control_547]' is not marked as EOG\n",
      "load: control token:    200 '[control_198]' is not marked as EOG\n",
      "load: control token:    548 '[control_546]' is not marked as EOG\n",
      "load: control token:    269 '[control_267]' is not marked as EOG\n",
      "load: control token:    201 '[control_199]' is not marked as EOG\n",
      "load: control token:    372 '[control_370]' is not marked as EOG\n",
      "load: control token:    210 '[control_208]' is not marked as EOG\n",
      "load: control token:    373 '[control_371]' is not marked as EOG\n",
      "load: control token:    211 '[control_209]' is not marked as EOG\n",
      "load: control token:    370 '[control_368]' is not marked as EOG\n",
      "load: control token:    212 '[control_210]' is not marked as EOG\n",
      "load: control token:    371 '[control_369]' is not marked as EOG\n",
      "load: control token:    213 '[control_211]' is not marked as EOG\n",
      "load: control token:    214 '[control_212]' is not marked as EOG\n",
      "load: control token:    215 '[control_213]' is not marked as EOG\n",
      "load: control token:    218 '[control_216]' is not marked as EOG\n",
      "load: control token:    219 '[control_217]' is not marked as EOG\n",
      "load: control token:    222 '[control_220]' is not marked as EOG\n",
      "load: control token:    503 '[control_501]' is not marked as EOG\n",
      "load: control token:    502 '[control_500]' is not marked as EOG\n",
      "load: control token:    223 '[control_221]' is not marked as EOG\n",
      "load: control token:    224 '[control_222]' is not marked as EOG\n",
      "load: control token:    505 '[control_503]' is not marked as EOG\n",
      "load: control token:    504 '[control_502]' is not marked as EOG\n",
      "load: control token:    225 '[control_223]' is not marked as EOG\n",
      "load: control token:    226 '[control_224]' is not marked as EOG\n",
      "load: control token:    507 '[control_505]' is not marked as EOG\n",
      "load: control token:    227 '[control_225]' is not marked as EOG\n",
      "load: control token:    506 '[control_504]' is not marked as EOG\n",
      "load: control token:    660 '[control_658]' is not marked as EOG\n",
      "load: control token:    447 '[control_445]' is not marked as EOG\n",
      "load: control token:    234 '[control_232]' is not marked as EOG\n",
      "load: control token:    661 '[control_659]' is not marked as EOG\n",
      "load: control token:    446 '[control_444]' is not marked as EOG\n",
      "load: control token:    235 '[control_233]' is not marked as EOG\n",
      "load: control token:    445 '[control_443]' is not marked as EOG\n",
      "load: control token:    236 '[control_234]' is not marked as EOG\n",
      "load: control token:    444 '[control_442]' is not marked as EOG\n",
      "load: control token:    237 '[control_235]' is not marked as EOG\n",
      "load: control token:    443 '[control_441]' is not marked as EOG\n",
      "load: control token:    238 '[control_236]' is not marked as EOG\n",
      "load: control token:    401 '[control_399]' is not marked as EOG\n",
      "load: control token:    442 '[control_440]' is not marked as EOG\n",
      "load: control token:    239 '[control_237]' is not marked as EOG\n",
      "load: control token:    400 '[control_398]' is not marked as EOG\n",
      "load: control token:    341 '[control_339]' is not marked as EOG\n",
      "load: control token:    724 '[control_722]' is not marked as EOG\n",
      "load: control token:    522 '[control_520]' is not marked as EOG\n",
      "load: control token:    243 '[control_241]' is not marked as EOG\n",
      "load: control token:    525 '[control_523]' is not marked as EOG\n",
      "load: control token:    244 '[control_242]' is not marked as EOG\n",
      "load: control token:    245 '[control_243]' is not marked as EOG\n",
      "load: control token:    524 '[control_522]' is not marked as EOG\n",
      "load: control token:    246 '[control_244]' is not marked as EOG\n",
      "load: control token:    527 '[control_525]' is not marked as EOG\n",
      "load: control token:    526 '[control_524]' is not marked as EOG\n",
      "load: control token:    247 '[control_245]' is not marked as EOG\n",
      "load: control token:    529 '[control_527]' is not marked as EOG\n",
      "load: control token:    248 '[control_246]' is not marked as EOG\n",
      "load: control token:    249 '[control_247]' is not marked as EOG\n",
      "load: control token:    528 '[control_526]' is not marked as EOG\n",
      "load: control token:    332 '[control_330]' is not marked as EOG\n",
      "load: control token:    531 '[control_529]' is not marked as EOG\n",
      "load: control token:    250 '[control_248]' is not marked as EOG\n",
      "load: control token:    254 '[control_252]' is not marked as EOG\n",
      "load: control token:    513 '[control_511]' is not marked as EOG\n",
      "load: control token:    255 '[control_253]' is not marked as EOG\n",
      "load: control token:    512 '[control_510]' is not marked as EOG\n",
      "load: control token:    519 '[control_517]' is not marked as EOG\n",
      "load: control token:    256 '[control_254]' is not marked as EOG\n",
      "load: control token:    518 '[control_516]' is not marked as EOG\n",
      "load: control token:    257 '[control_255]' is not marked as EOG\n",
      "load: control token:    517 '[control_515]' is not marked as EOG\n",
      "load: control token:    258 '[control_256]' is not marked as EOG\n",
      "load: control token:    516 '[control_514]' is not marked as EOG\n",
      "load: control token:    259 '[control_257]' is not marked as EOG\n",
      "load: control token:    320 '[control_318]' is not marked as EOG\n",
      "load: control token:    543 '[control_541]' is not marked as EOG\n",
      "load: control token:    262 '[control_260]' is not marked as EOG\n",
      "load: control token:    321 '[control_319]' is not marked as EOG\n",
      "load: control token:    542 '[control_540]' is not marked as EOG\n",
      "load: control token:    263 '[control_261]' is not marked as EOG\n",
      "load: control token:    264 '[control_262]' is not marked as EOG\n",
      "load: control token:    545 '[control_543]' is not marked as EOG\n",
      "load: control token:    544 '[control_542]' is not marked as EOG\n",
      "load: control token:    265 '[control_263]' is not marked as EOG\n",
      "load: control token:    547 '[control_545]' is not marked as EOG\n",
      "load: control token:    266 '[control_264]' is not marked as EOG\n",
      "load: control token:    267 '[control_265]' is not marked as EOG\n",
      "load: control token:    546 '[control_544]' is not marked as EOG\n",
      "load: control token:    310 '[control_308]' is not marked as EOG\n",
      "load: control token:    733 '[control_731]' is not marked as EOG\n",
      "load: control token:    539 '[control_537]' is not marked as EOG\n",
      "load: control token:    272 '[control_270]' is not marked as EOG\n",
      "load: control token:    311 '[control_309]' is not marked as EOG\n",
      "load: control token:    732 '[control_730]' is not marked as EOG\n",
      "load: control token:    273 '[control_271]' is not marked as EOG\n",
      "load: control token:    538 '[control_536]' is not marked as EOG\n",
      "load: control token:    537 '[control_535]' is not marked as EOG\n",
      "load: control token:    274 '[control_272]' is not marked as EOG\n",
      "load: control token:    536 '[control_534]' is not marked as EOG\n",
      "load: control token:    275 '[control_273]' is not marked as EOG\n",
      "load: control token:    535 '[control_533]' is not marked as EOG\n",
      "load: control token:    276 '[control_274]' is not marked as EOG\n",
      "load: control token:    534 '[control_532]' is not marked as EOG\n",
      "load: control token:    277 '[control_275]' is not marked as EOG\n",
      "load: control token:    533 '[control_531]' is not marked as EOG\n",
      "load: control token:    278 '[control_276]' is not marked as EOG\n",
      "load: control token:    532 '[control_530]' is not marked as EOG\n",
      "load: control token:    279 '[control_277]' is not marked as EOG\n",
      "load: control token:    741 '[control_739]' is not marked as EOG\n",
      "load: control token:    302 '[control_300]' is not marked as EOG\n",
      "load: control token:    280 '[control_278]' is not marked as EOG\n",
      "load: control token:    303 '[control_301]' is not marked as EOG\n",
      "load: control token:    740 '[control_738]' is not marked as EOG\n",
      "load: control token:    281 '[control_279]' is not marked as EOG\n",
      "load: control token:    282 '[control_280]' is not marked as EOG\n",
      "load: control token:    283 '[control_281]' is not marked as EOG\n",
      "load: control token:    286 '[control_284]' is not marked as EOG\n",
      "load: control token:    287 '[control_285]' is not marked as EOG\n",
      "load: control token:    288 '[control_286]' is not marked as EOG\n",
      "load: control token:    289 '[control_287]' is not marked as EOG\n",
      "load: control token:    292 '[control_290]' is not marked as EOG\n",
      "load: control token:    293 '[control_291]' is not marked as EOG\n",
      "load: control token:    294 '[control_292]' is not marked as EOG\n",
      "load: control token:    295 '[control_293]' is not marked as EOG\n",
      "load: control token:    296 '[control_294]' is not marked as EOG\n",
      "load: control token:    297 '[control_295]' is not marked as EOG\n",
      "load: control token:    298 '[control_296]' is not marked as EOG\n",
      "load: control token:    299 '[control_297]' is not marked as EOG\n",
      "load: control token:    300 '[control_298]' is not marked as EOG\n",
      "load: control token:    301 '[control_299]' is not marked as EOG\n",
      "load: control token:    304 '[control_302]' is not marked as EOG\n",
      "load: control token:    305 '[control_303]' is not marked as EOG\n",
      "load: control token:    306 '[control_304]' is not marked as EOG\n",
      "load: control token:    307 '[control_305]' is not marked as EOG\n",
      "load: control token:    308 '[control_306]' is not marked as EOG\n",
      "load: control token:    309 '[control_307]' is not marked as EOG\n",
      "load: control token:    323 '[control_321]' is not marked as EOG\n",
      "load: control token:    324 '[control_322]' is not marked as EOG\n",
      "load: control token:    325 '[control_323]' is not marked as EOG\n",
      "load: control token:    326 '[control_324]' is not marked as EOG\n",
      "load: control token:    327 '[control_325]' is not marked as EOG\n",
      "load: control token:    328 '[control_326]' is not marked as EOG\n",
      "load: control token:    329 '[control_327]' is not marked as EOG\n",
      "load: control token:    330 '[control_328]' is not marked as EOG\n",
      "load: control token:    331 '[control_329]' is not marked as EOG\n",
      "load: control token:    334 '[control_332]' is not marked as EOG\n",
      "load: control token:    731 '[control_729]' is not marked as EOG\n",
      "load: control token:    730 '[control_728]' is not marked as EOG\n",
      "load: control token:    335 '[control_333]' is not marked as EOG\n",
      "load: control token:    336 '[control_334]' is not marked as EOG\n",
      "load: control token:    337 '[control_335]' is not marked as EOG\n",
      "load: control token:    338 '[control_336]' is not marked as EOG\n",
      "load: control token:    339 '[control_337]' is not marked as EOG\n",
      "load: control token:    350 '[control_348]' is not marked as EOG\n",
      "load: control token:    351 '[control_349]' is not marked as EOG\n",
      "load: control token:    352 '[control_350]' is not marked as EOG\n",
      "load: control token:    353 '[control_351]' is not marked as EOG\n",
      "load: control token:    354 '[control_352]' is not marked as EOG\n",
      "load: control token:    355 '[control_353]' is not marked as EOG\n",
      "load: control token:    356 '[control_354]' is not marked as EOG\n",
      "load: control token:    357 '[control_355]' is not marked as EOG\n",
      "load: control token:    358 '[control_356]' is not marked as EOG\n",
      "load: control token:    359 '[control_357]' is not marked as EOG\n",
      "load: control token:    360 '[control_358]' is not marked as EOG\n",
      "load: control token:    361 '[control_359]' is not marked as EOG\n",
      "load: control token:    375 '[control_373]' is not marked as EOG\n",
      "load: control token:    378 '[control_376]' is not marked as EOG\n",
      "load: control token:    379 '[control_377]' is not marked as EOG\n",
      "load: control token:    460 '[control_458]' is not marked as EOG\n",
      "load: control token:    382 '[control_380]' is not marked as EOG\n",
      "load: control token:    461 '[control_459]' is not marked as EOG\n",
      "load: control token:    383 '[control_381]' is not marked as EOG\n",
      "load: control token:    386 '[control_384]' is not marked as EOG\n",
      "load: control token:    387 '[control_385]' is not marked as EOG\n",
      "load: control token:    388 '[control_386]' is not marked as EOG\n",
      "load: control token:    389 '[control_387]' is not marked as EOG\n",
      "load: control token:    420 '[control_418]' is not marked as EOG\n",
      "load: control token:    421 '[control_419]' is not marked as EOG\n",
      "load: control token:    422 '[control_420]' is not marked as EOG\n",
      "load: control token:    423 '[control_421]' is not marked as EOG\n",
      "load: control token:    424 '[control_422]' is not marked as EOG\n",
      "load: control token:    426 '[control_424]' is not marked as EOG\n",
      "load: control token:    427 '[control_425]' is not marked as EOG\n",
      "load: control token:    428 '[control_426]' is not marked as EOG\n",
      "load: control token:    429 '[control_427]' is not marked as EOG\n",
      "load: control token:    430 '[control_428]' is not marked as EOG\n",
      "load: control token:    431 '[control_429]' is not marked as EOG\n",
      "load: control token:    432 '[control_430]' is not marked as EOG\n",
      "load: control token:    433 '[control_431]' is not marked as EOG\n",
      "load: control token:    434 '[control_432]' is not marked as EOG\n",
      "load: control token:    435 '[control_433]' is not marked as EOG\n",
      "load: control token:    436 '[control_434]' is not marked as EOG\n",
      "load: control token:    437 '[control_435]' is not marked as EOG\n",
      "load: control token:    438 '[control_436]' is not marked as EOG\n",
      "load: control token:    439 '[control_437]' is not marked as EOG\n",
      "load: control token:    440 '[control_438]' is not marked as EOG\n",
      "load: control token:    441 '[control_439]' is not marked as EOG\n",
      "load: control token:    470 '[control_468]' is not marked as EOG\n",
      "load: control token:    471 '[control_469]' is not marked as EOG\n",
      "load: control token:    472 '[control_470]' is not marked as EOG\n",
      "load: control token:    473 '[control_471]' is not marked as EOG\n",
      "load: control token:    474 '[control_472]' is not marked as EOG\n",
      "load: control token:    475 '[control_473]' is not marked as EOG\n",
      "load: control token:    478 '[control_476]' is not marked as EOG\n",
      "load: control token:    479 '[control_477]' is not marked as EOG\n",
      "load: control token:    617 '[control_615]' is not marked as EOG\n",
      "load: control token:    482 '[control_480]' is not marked as EOG\n",
      "load: control token:    616 '[control_614]' is not marked as EOG\n",
      "load: control token:    483 '[control_481]' is not marked as EOG\n",
      "load: control token:    619 '[control_617]' is not marked as EOG\n",
      "load: control token:    484 '[control_482]' is not marked as EOG\n",
      "load: control token:    618 '[control_616]' is not marked as EOG\n",
      "load: control token:    485 '[control_483]' is not marked as EOG\n",
      "load: control token:    613 '[control_611]' is not marked as EOG\n",
      "load: control token:    486 '[control_484]' is not marked as EOG\n",
      "load: control token:    612 '[control_610]' is not marked as EOG\n",
      "load: control token:    487 '[control_485]' is not marked as EOG\n",
      "load: control token:    615 '[control_613]' is not marked as EOG\n",
      "load: control token:    488 '[control_486]' is not marked as EOG\n",
      "load: control token:    489 '[control_487]' is not marked as EOG\n",
      "load: control token:    614 '[control_612]' is not marked as EOG\n",
      "load: control token:    490 '[control_488]' is not marked as EOG\n",
      "load: control token:    491 '[control_489]' is not marked as EOG\n",
      "load: control token:    665 '[control_663]' is not marked as EOG\n",
      "load: control token:    492 '[control_490]' is not marked as EOG\n",
      "load: control token:    664 '[control_662]' is not marked as EOG\n",
      "load: control token:    493 '[control_491]' is not marked as EOG\n",
      "load: control token:    663 '[control_661]' is not marked as EOG\n",
      "load: control token:    494 '[control_492]' is not marked as EOG\n",
      "load: control token:    662 '[control_660]' is not marked as EOG\n",
      "load: control token:    495 '[control_493]' is not marked as EOG\n",
      "load: control token:    669 '[control_667]' is not marked as EOG\n",
      "load: control token:    496 '[control_494]' is not marked as EOG\n",
      "load: control token:    668 '[control_666]' is not marked as EOG\n",
      "load: control token:    497 '[control_495]' is not marked as EOG\n",
      "load: control token:    667 '[control_665]' is not marked as EOG\n",
      "load: control token:    498 '[control_496]' is not marked as EOG\n",
      "load: control token:    666 '[control_664]' is not marked as EOG\n",
      "load: control token:    499 '[control_497]' is not marked as EOG\n",
      "load: control token:    500 '[control_498]' is not marked as EOG\n",
      "load: control token:    501 '[control_499]' is not marked as EOG\n",
      "load: control token:    540 '[control_538]' is not marked as EOG\n",
      "load: control token:    541 '[control_539]' is not marked as EOG\n",
      "load: control token:    552 '[control_550]' is not marked as EOG\n",
      "load: control token:    553 '[control_551]' is not marked as EOG\n",
      "load: control token:    554 '[control_552]' is not marked as EOG\n",
      "load: control token:    555 '[control_553]' is not marked as EOG\n",
      "load: control token:    556 '[control_554]' is not marked as EOG\n",
      "load: control token:    557 '[control_555]' is not marked as EOG\n",
      "load: control token:    558 '[control_556]' is not marked as EOG\n",
      "load: control token:    559 '[control_557]' is not marked as EOG\n",
      "load: control token:    560 '[control_558]' is not marked as EOG\n",
      "load: control token:    561 '[control_559]' is not marked as EOG\n",
      "load: control token:    562 '[control_560]' is not marked as EOG\n",
      "load: control token:    563 '[control_561]' is not marked as EOG\n",
      "load: control token:    564 '[control_562]' is not marked as EOG\n",
      "load: control token:    565 '[control_563]' is not marked as EOG\n",
      "load: control token:    566 '[control_564]' is not marked as EOG\n",
      "load: control token:    567 '[control_565]' is not marked as EOG\n",
      "load: control token:    568 '[control_566]' is not marked as EOG\n",
      "load: control token:    569 '[control_567]' is not marked as EOG\n",
      "load: control token:    570 '[control_568]' is not marked as EOG\n",
      "load: control token:    571 '[control_569]' is not marked as EOG\n",
      "load: control token:    572 '[control_570]' is not marked as EOG\n",
      "load: control token:    573 '[control_571]' is not marked as EOG\n",
      "load: control token:    574 '[control_572]' is not marked as EOG\n",
      "load: control token:    575 '[control_573]' is not marked as EOG\n",
      "load: control token:    576 '[control_574]' is not marked as EOG\n",
      "load: control token:    577 '[control_575]' is not marked as EOG\n",
      "load: control token:    578 '[control_576]' is not marked as EOG\n",
      "load: control token:    579 '[control_577]' is not marked as EOG\n",
      "load: control token:    580 '[control_578]' is not marked as EOG\n",
      "load: control token:    581 '[control_579]' is not marked as EOG\n",
      "load: control token:    582 '[control_580]' is not marked as EOG\n",
      "load: control token:    583 '[control_581]' is not marked as EOG\n",
      "load: control token:    584 '[control_582]' is not marked as EOG\n",
      "load: control token:    585 '[control_583]' is not marked as EOG\n",
      "load: control token:    586 '[control_584]' is not marked as EOG\n",
      "load: control token:    587 '[control_585]' is not marked as EOG\n",
      "load: control token:    588 '[control_586]' is not marked as EOG\n",
      "load: control token:    589 '[control_587]' is not marked as EOG\n",
      "load: control token:    590 '[control_588]' is not marked as EOG\n",
      "load: control token:    591 '[control_589]' is not marked as EOG\n",
      "load: control token:    592 '[control_590]' is not marked as EOG\n",
      "load: control token:    593 '[control_591]' is not marked as EOG\n",
      "load: control token:    594 '[control_592]' is not marked as EOG\n",
      "load: control token:    595 '[control_593]' is not marked as EOG\n",
      "load: control token:    596 '[control_594]' is not marked as EOG\n",
      "load: control token:    690 '[control_688]' is not marked as EOG\n",
      "load: control token:    597 '[control_595]' is not marked as EOG\n",
      "load: control token:    691 '[control_689]' is not marked as EOG\n",
      "load: control token:    598 '[control_596]' is not marked as EOG\n",
      "load: control token:    599 '[control_597]' is not marked as EOG\n",
      "load: control token:    600 '[control_598]' is not marked as EOG\n",
      "load: control token:    686 '[control_684]' is not marked as EOG\n",
      "load: control token:    601 '[control_599]' is not marked as EOG\n",
      "load: control token:    687 '[control_685]' is not marked as EOG\n",
      "load: control token:    711 '[control_709]' is not marked as EOG\n",
      "load: control token:    602 '[control_600]' is not marked as EOG\n",
      "load: control token:    710 '[control_708]' is not marked as EOG\n",
      "load: control token:    603 '[control_601]' is not marked as EOG\n",
      "load: control token:    604 '[control_602]' is not marked as EOG\n",
      "load: control token:    605 '[control_603]' is not marked as EOG\n",
      "load: control token:    606 '[control_604]' is not marked as EOG\n",
      "load: control token:    607 '[control_605]' is not marked as EOG\n",
      "load: control token:    608 '[control_606]' is not marked as EOG\n",
      "load: control token:    609 '[control_607]' is not marked as EOG\n",
      "load: control token:    703 '[control_701]' is not marked as EOG\n",
      "load: control token:    610 '[control_608]' is not marked as EOG\n",
      "load: control token:    702 '[control_700]' is not marked as EOG\n",
      "load: control token:    611 '[control_609]' is not marked as EOG\n",
      "load: control token:    620 '[control_618]' is not marked as EOG\n",
      "load: control token:    621 '[control_619]' is not marked as EOG\n",
      "load: control token:    622 '[control_620]' is not marked as EOG\n",
      "load: control token:    770 '[control_768]' is not marked as EOG\n",
      "load: control token:    623 '[control_621]' is not marked as EOG\n",
      "load: control token:    625 '[control_623]' is not marked as EOG\n",
      "load: control token:    626 '[control_624]' is not marked as EOG\n",
      "load: control token:    627 '[control_625]' is not marked as EOG\n",
      "load: control token:    628 '[control_626]' is not marked as EOG\n",
      "load: control token:    629 '[control_627]' is not marked as EOG\n",
      "load: control token:    763 '[control_761]' is not marked as EOG\n",
      "load: control token:    630 '[control_628]' is not marked as EOG\n",
      "load: control token:    762 '[control_760]' is not marked as EOG\n",
      "load: control token:    631 '[control_629]' is not marked as EOG\n",
      "load: control token:    632 '[control_630]' is not marked as EOG\n",
      "load: control token:    633 '[control_631]' is not marked as EOG\n",
      "load: control token:    634 '[control_632]' is not marked as EOG\n",
      "load: control token:    635 '[control_633]' is not marked as EOG\n",
      "load: control token:    636 '[control_634]' is not marked as EOG\n",
      "load: control token:    637 '[control_635]' is not marked as EOG\n",
      "load: control token:    638 '[control_636]' is not marked as EOG\n",
      "load: control token:    721 '[control_719]' is not marked as EOG\n",
      "load: control token:    639 '[control_637]' is not marked as EOG\n",
      "load: control token:    720 '[control_718]' is not marked as EOG\n",
      "load: control token:    719 '[control_717]' is not marked as EOG\n",
      "load: control token:    640 '[control_638]' is not marked as EOG\n",
      "load: control token:    718 '[control_716]' is not marked as EOG\n",
      "load: control token:    641 '[control_639]' is not marked as EOG\n",
      "load: control token:    642 '[control_640]' is not marked as EOG\n",
      "load: control token:    643 '[control_641]' is not marked as EOG\n",
      "load: control token:    644 '[control_642]' is not marked as EOG\n",
      "load: control token:    645 '[control_643]' is not marked as EOG\n",
      "load: control token:    646 '[control_644]' is not marked as EOG\n",
      "load: control token:    647 '[control_645]' is not marked as EOG\n",
      "load: control token:    648 '[control_646]' is not marked as EOG\n",
      "load: control token:    649 '[control_647]' is not marked as EOG\n",
      "load: control token:    650 '[control_648]' is not marked as EOG\n",
      "load: control token:    651 '[control_649]' is not marked as EOG\n",
      "load: control token:    652 '[control_650]' is not marked as EOG\n",
      "load: control token:    653 '[control_651]' is not marked as EOG\n",
      "load: control token:    654 '[control_652]' is not marked as EOG\n",
      "load: control token:    658 '[control_656]' is not marked as EOG\n",
      "load: control token:    659 '[control_657]' is not marked as EOG\n",
      "load: control token:    670 '[control_668]' is not marked as EOG\n",
      "load: control token:    671 '[control_669]' is not marked as EOG\n",
      "load: control token:    672 '[control_670]' is not marked as EOG\n",
      "load: control token:    673 '[control_671]' is not marked as EOG\n",
      "load: control token:    674 '[control_672]' is not marked as EOG\n",
      "load: control token:    675 '[control_673]' is not marked as EOG\n",
      "load: control token:    676 '[control_674]' is not marked as EOG\n",
      "load: control token:    677 '[control_675]' is not marked as EOG\n",
      "load: control token:    678 '[control_676]' is not marked as EOG\n",
      "load: control token:    679 '[control_677]' is not marked as EOG\n",
      "load: control token:    680 '[control_678]' is not marked as EOG\n",
      "load: control token:    681 '[control_679]' is not marked as EOG\n",
      "load: control token:    682 '[control_680]' is not marked as EOG\n",
      "load: control token:    683 '[control_681]' is not marked as EOG\n",
      "load: control token:    684 '[control_682]' is not marked as EOG\n",
      "load: control token:    685 '[control_683]' is not marked as EOG\n",
      "load: control token:    688 '[control_686]' is not marked as EOG\n",
      "load: control token:    689 '[control_687]' is not marked as EOG\n",
      "load: control token:    700 '[control_698]' is not marked as EOG\n",
      "load: control token:    701 '[control_699]' is not marked as EOG\n",
      "load: control token:    704 '[control_702]' is not marked as EOG\n",
      "load: control token:    705 '[control_703]' is not marked as EOG\n",
      "load: control token:    706 '[control_704]' is not marked as EOG\n",
      "load: control token:    707 '[control_705]' is not marked as EOG\n",
      "load: control token:    708 '[control_706]' is not marked as EOG\n",
      "load: control token:    709 '[control_707]' is not marked as EOG\n",
      "load: control token:    712 '[control_710]' is not marked as EOG\n",
      "load: control token:    713 '[control_711]' is not marked as EOG\n",
      "load: control token:    714 '[control_712]' is not marked as EOG\n",
      "load: control token:    715 '[control_713]' is not marked as EOG\n",
      "load: control token:    716 '[control_714]' is not marked as EOG\n",
      "load: control token:    717 '[control_715]' is not marked as EOG\n",
      "load: control token:    722 '[control_720]' is not marked as EOG\n",
      "load: control token:    723 '[control_721]' is not marked as EOG\n",
      "load: control token:    726 '[control_724]' is not marked as EOG\n",
      "load: control token:    727 '[control_725]' is not marked as EOG\n",
      "load: control token:    728 '[control_726]' is not marked as EOG\n",
      "load: control token:    729 '[control_727]' is not marked as EOG\n",
      "load: control token:    734 '[control_732]' is not marked as EOG\n",
      "load: control token:    735 '[control_733]' is not marked as EOG\n",
      "load: control token:    736 '[control_734]' is not marked as EOG\n",
      "load: control token:    737 '[control_735]' is not marked as EOG\n",
      "load: control token:    738 '[control_736]' is not marked as EOG\n",
      "load: control token:    739 '[control_737]' is not marked as EOG\n",
      "load: control token:    742 '[control_740]' is not marked as EOG\n",
      "load: control token:    743 '[control_741]' is not marked as EOG\n",
      "load: control token:    744 '[control_742]' is not marked as EOG\n",
      "load: control token:    745 '[control_743]' is not marked as EOG\n",
      "load: control token:    746 '[control_744]' is not marked as EOG\n",
      "load: control token:    747 '[control_745]' is not marked as EOG\n",
      "load: control token:    748 '[control_746]' is not marked as EOG\n",
      "load: control token:    749 '[control_747]' is not marked as EOG\n",
      "load: control token:    750 '[control_748]' is not marked as EOG\n",
      "load: control token:    751 '[control_749]' is not marked as EOG\n",
      "load: control token:    752 '[control_750]' is not marked as EOG\n",
      "load: control token:    753 '[control_751]' is not marked as EOG\n",
      "load: control token:    754 '[control_752]' is not marked as EOG\n",
      "load: control token:    755 '[control_753]' is not marked as EOG\n",
      "load: control token:    756 '[control_754]' is not marked as EOG\n",
      "load: control token:    757 '[control_755]' is not marked as EOG\n",
      "load: control token:    764 '[control_762]' is not marked as EOG\n",
      "load: control token:    765 '[control_763]' is not marked as EOG\n",
      "load: control token:    766 '[control_764]' is not marked as EOG\n",
      "load: control token:    767 '[control_765]' is not marked as EOG\n",
      "load: control token:    768 '[control_766]' is not marked as EOG\n",
      "load: control token:    769 '[control_767]' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 771\n",
      "load: token to piece cache size = 0.1731 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.25 B\n",
      "print_info: general.name     = models--mistralai--Mistral-7B-Instruct-v0.3\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32768\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: LF token         = 781 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU\n",
      "load_tensors: layer   1 assigned to device CPU\n",
      "load_tensors: layer   2 assigned to device CPU\n",
      "load_tensors: layer   3 assigned to device CPU\n",
      "load_tensors: layer   4 assigned to device CPU\n",
      "load_tensors: layer   5 assigned to device CPU\n",
      "load_tensors: layer   6 assigned to device CPU\n",
      "load_tensors: layer   7 assigned to device CPU\n",
      "load_tensors: layer   8 assigned to device CPU\n",
      "load_tensors: layer   9 assigned to device CPU\n",
      "load_tensors: layer  10 assigned to device CPU\n",
      "load_tensors: layer  11 assigned to device CPU\n",
      "load_tensors: layer  12 assigned to device CPU\n",
      "load_tensors: layer  13 assigned to device CPU\n",
      "load_tensors: layer  14 assigned to device CPU\n",
      "load_tensors: layer  15 assigned to device CPU\n",
      "load_tensors: layer  16 assigned to device CPU\n",
      "load_tensors: layer  17 assigned to device CPU\n",
      "load_tensors: layer  18 assigned to device CPU\n",
      "load_tensors: layer  19 assigned to device CPU\n",
      "load_tensors: layer  20 assigned to device CPU\n",
      "load_tensors: layer  21 assigned to device CPU\n",
      "load_tensors: layer  22 assigned to device CPU\n",
      "load_tensors: layer  23 assigned to device CPU\n",
      "load_tensors: layer  24 assigned to device CPU\n",
      "load_tensors: layer  25 assigned to device CPU\n",
      "load_tensors: layer  26 assigned to device CPU\n",
      "load_tensors: layer  27 assigned to device CPU\n",
      "load_tensors: layer  28 assigned to device CPU\n",
      "load_tensors: layer  29 assigned to device CPU\n",
      "load_tensors: layer  30 assigned to device CPU\n",
      "load_tensors: layer  31 assigned to device CPU\n",
      "load_tensors: layer  32 assigned to device CPU\n",
      "load_tensors: tensor 'token_embd.weight' (f16) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size = 13825.02 MiB\n",
      "...................................................................................................\n",
      "llama_init_from_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 4096\n",
      "llama_init_from_model: n_ctx_per_seq = 4096\n",
      "llama_init_from_model: n_batch       = 64\n",
      "llama_init_from_model: n_ubatch      = 32\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 1000000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 4096, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
      "llama_init_from_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_init_from_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_init_from_model:        CPU compute buffer size =    19.00 MiB\n",
      "llama_init_from_model: graph nodes  = 1030\n",
      "llama_init_from_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.name': 'models--mistralai--Mistral-7B-Instruct-v0.3', 'general.architecture': 'llama', 'llama.block_count': '32', 'llama.context_length': '32768', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '1', 'llama.attention.head_count_kv': '8', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '1000000.000000', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.vocab_size': '32768', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.model': 'llama', 'tokenizer.ggml.pre': 'default', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\"}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from llama_cpp import Llama\n",
    "from tqdm import tqdm\n",
    "\n",
    "llm = Llama(model_path=model_path, n_gpu_layers=50, n_ctx=4096, n_batch=32)  # Adjust GPU layers if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE_SENTIMENT = (\n",
    "    \"You are a sentiment classification assistant. Your task is to analyze the sentiment of a comment \"\n",
    "    \"and classify it into one of three categories: 'Positif', 'Negatif', or 'Neutre'.\\n\\n\"\n",
    "    \"### Sentiment Classification Rules:\\n\"\n",
    "    \"- **Positif**: If the comment expresses satisfaction, praise, or something good.\\n\"\n",
    "    \"- **Negatif**: If the comment expresses dissatisfaction, criticism, or a complaint or a something not good.\\n\"\n",
    "    \"- **Neutre**: If the comment is vague, neutral, or lacks strong sentiment.\\n\\n\"\n",
    "    \"### Instructions:\\n\"\n",
    "    \"1. Read the comment carefully.\\n\"\n",
    "    \"2. Return only one of the three labels: **Positif, Negatif, or Neutre**.\\n\"\n",
    "    \"3. Do NOT provide explanations.\\n\\n\"\n",
    "    \"### Supported Languages:\\n\"\n",
    "    \"- Arabic (including Algerian Darija)\\n\"\n",
    "    \"- French\\n\"\n",
    "    \"- English\\n\\n\"\n",
    "    \"### Example:\\n\"\n",
    "    \"- **Comment:** 'أنترنت مليحة'\\n\"\n",
    "    \"- **Output:** 'Positif'\\n\"\n",
    "    \"- **Comment:** 'الخدمة سيئة جدا وبطيئة'\\n\"\n",
    "    \"- **Output:** 'Negatif'\\n\"\n",
    "    \"- **Comment:** 'هل يوجد عرض جديد؟'\\n\"\n",
    "    \"- **Output:** 'Neutre'\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 Function to Predict Sentiment\n",
    "def classify_sentiment(comment):\n",
    "    if not isinstance(comment, str) or comment.strip() == \"\":\n",
    "        return \"Neutre\"  # Default for empty comments\n",
    "    \n",
    "    prompt = f\"{SYSTEM_MESSAGE_SENTIMENT}\\n\\nComment: {comment}\\nSentiment:\"\n",
    "    \n",
    "    response = llm(prompt, max_tokens=5, stop=[\"\\n\"])\n",
    "    sentiment = response[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    # Ensure output is one of the three classes\n",
    "    if sentiment not in [\"Positif\", \"Negatif\", \"Neutre\"]:\n",
    "        return \"Neutre\"\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3487 [00:00<?, ?it/s]Llama.generate: 307 prefix-match hit, remaining 254 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   73947.73 ms /   273 tokens (  270.87 ms per token,     3.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2844.20 ms /     3 runs   (  948.07 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   61926.00 ms /   276 tokens\n",
      "  0%|          | 2/3487 [01:01<29:58:39, 30.97s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5077.10 ms /    22 tokens (  230.78 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2941.92 ms /     3 runs   (  980.64 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    8021.36 ms /    25 tokens\n",
      "  0%|          | 3/3487 [01:09<20:43:09, 21.41s/it]Llama.generate: 315 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2908.73 ms /    13 tokens (  223.75 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.18 ms /     3 runs   (  900.06 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5611.49 ms /    16 tokens\n",
      "  0%|          | 4/3487 [01:15<15:00:48, 15.52s/it]Llama.generate: 315 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2459.49 ms /    12 tokens (  204.96 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.34 ms /     3 runs   (  886.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5121.48 ms /    15 tokens\n",
      "  0%|          | 5/3487 [01:20<11:30:57, 11.91s/it]Llama.generate: 315 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13106.45 ms /    65 tokens (  201.64 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.59 ms /     3 runs   (  888.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15774.78 ms /    68 tokens\n",
      "  0%|          | 6/3487 [01:36<12:45:25, 13.19s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3809.21 ms /    19 tokens (  200.48 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.68 ms /     3 runs   (  903.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6523.97 ms /    22 tokens\n",
      "  0%|          | 7/3487 [01:43<10:40:58, 11.05s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5004.26 ms /    25 tokens (  200.17 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2868.68 ms /     3 runs   (  956.23 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    7875.59 ms /    28 tokens\n",
      "  0%|          | 8/3487 [01:50<9:43:01, 10.05s/it] Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3008.11 ms /    13 tokens (  231.39 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4229.67 ms /     3 runs   ( 1409.89 ms per token,     0.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    7241.90 ms /    16 tokens\n",
      "  0%|          | 9/3487 [01:58<8:52:26,  9.19s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2785.49 ms /    11 tokens (  253.23 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2874.16 ms /     3 runs   (  958.05 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    5662.55 ms /    14 tokens\n",
      "  0%|          | 10/3487 [02:03<7:49:45,  8.11s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9898.33 ms /    52 tokens (  190.35 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.64 ms /     3 runs   (  875.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12526.70 ms /    55 tokens\n",
      "  0%|          | 11/3487 [02:16<9:07:51,  9.46s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4527.93 ms /    24 tokens (  188.66 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.04 ms /     3 runs   (  887.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7191.89 ms /    27 tokens\n",
      "  0%|          | 12/3487 [02:23<8:28:02,  8.77s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15945.34 ms /    69 tokens (  231.09 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3939.70 ms /     3 runs   ( 1313.23 ms per token,     0.76 tokens per second)\n",
      "llama_perf_context_print:       total time =   19888.81 ms /    72 tokens\n",
      "  0%|          | 13/3487 [02:43<11:42:44, 12.14s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3351.47 ms /    17 tokens (  197.15 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.38 ms /     3 runs   (  892.13 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6031.68 ms /    20 tokens\n",
      "  0%|          | 14/3487 [02:49<9:56:06, 10.30s/it] Llama.generate: 307 prefix-match hit, remaining 208 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   39268.58 ms /   208 tokens (  188.79 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.43 ms /     3 runs   (  900.48 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   41972.50 ms /   211 tokens\n",
      "  0%|          | 15/3487 [03:31<19:08:04, 19.84s/it]Llama.generate: 307 prefix-match hit, remaining 161 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   30710.57 ms /   161 tokens (  190.75 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2766.87 ms /     3 runs   (  922.29 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   33480.01 ms /   164 tokens\n",
      "  0%|          | 16/3487 [04:04<23:05:13, 23.95s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10636.24 ms /    50 tokens (  212.72 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2730.22 ms /     3 runs   (  910.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   13369.36 ms /    53 tokens\n",
      "  0%|          | 17/3487 [04:18<20:01:13, 20.77s/it]Llama.generate: 309 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4353.88 ms /    22 tokens (  197.90 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.14 ms /     3 runs   (  891.05 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7029.66 ms /    25 tokens\n",
      "  1%|          | 18/3487 [04:25<16:02:23, 16.65s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7900.61 ms /    41 tokens (  192.70 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.00 ms /     3 runs   (  888.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10569.08 ms /    44 tokens\n",
      "  1%|          | 19/3487 [04:35<14:16:47, 14.82s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9227.92 ms /    49 tokens (  188.32 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.86 ms /     3 runs   (  873.29 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11850.97 ms /    52 tokens\n",
      "  1%|          | 20/3487 [04:47<13:25:07, 13.93s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6930.03 ms /    34 tokens (  203.82 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.15 ms /     3 runs   (  872.05 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9548.53 ms /    37 tokens\n",
      "  1%|          | 21/3487 [04:57<12:09:00, 12.62s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4357.40 ms /    23 tokens (  189.45 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.15 ms /     3 runs   (  873.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6980.87 ms /    26 tokens\n",
      "  1%|          | 22/3487 [05:04<10:31:14, 10.93s/it]Llama.generate: 308 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6086.55 ms /    32 tokens (  190.20 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.00 ms /     3 runs   (  870.33 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8700.50 ms /    35 tokens\n",
      "  1%|          | 23/3487 [05:13<9:52:33, 10.26s/it] Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3389.55 ms /    18 tokens (  188.31 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.97 ms /     3 runs   (  881.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6038.35 ms /    21 tokens\n",
      "  1%|          | 24/3487 [05:19<8:39:21,  9.00s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9175.74 ms /    48 tokens (  191.16 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.70 ms /     3 runs   (  879.57 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11816.82 ms /    51 tokens\n",
      "  1%|          | 25/3487 [05:30<9:28:09,  9.85s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2082.99 ms /    10 tokens (  208.30 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.97 ms /     3 runs   (  872.66 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4703.49 ms /    13 tokens\n",
      "  1%|          | 26/3487 [05:35<7:59:09,  8.31s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5680.47 ms /    27 tokens (  210.39 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.66 ms /     3 runs   (  887.89 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8347.59 ms /    30 tokens\n",
      "  1%|          | 27/3487 [05:44<7:59:50,  8.32s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3487.77 ms /    18 tokens (  193.77 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2905.53 ms /     3 runs   (  968.51 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6396.62 ms /    21 tokens\n",
      "  1%|          | 28/3487 [05:50<7:26:36,  7.75s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4400.52 ms /    20 tokens (  220.03 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.10 ms /     3 runs   (  910.37 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7134.45 ms /    23 tokens\n",
      "  1%|          | 29/3487 [05:57<7:16:07,  7.57s/it]Llama.generate: 306 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15392.98 ms /    80 tokens (  192.41 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.19 ms /     3 runs   (  874.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18018.58 ms /    83 tokens\n",
      "  1%|          | 30/3487 [06:15<10:16:48, 10.71s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5551.04 ms /    29 tokens (  191.42 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.51 ms /     3 runs   (  890.50 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8225.15 ms /    32 tokens\n",
      "  1%|          | 31/3487 [06:23<9:33:53,  9.96s/it] Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1768.44 ms /     8 tokens (  221.06 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.16 ms /     3 runs   (  881.05 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4413.93 ms /    11 tokens\n",
      "  1%|          | 32/3487 [06:28<7:58:00,  8.30s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4087.29 ms /    21 tokens (  194.63 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.30 ms /     3 runs   (  873.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6709.64 ms /    24 tokens\n",
      "  1%|          | 33/3487 [06:34<7:30:33,  7.83s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4019.75 ms /    20 tokens (  200.99 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2768.06 ms /     3 runs   (  922.69 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6790.35 ms /    23 tokens\n",
      "  1%|          | 34/3487 [06:41<7:12:40,  7.52s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7134.22 ms /    34 tokens (  209.83 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.38 ms /     3 runs   (  879.79 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9776.52 ms /    37 tokens\n",
      "  1%|          | 35/3487 [06:51<7:51:41,  8.20s/it]Llama.generate: 307 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15562.10 ms /    80 tokens (  194.53 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.57 ms /     3 runs   (  874.52 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18188.46 ms /    83 tokens\n",
      "  1%|          | 36/3487 [07:09<10:44:06, 11.20s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4043.43 ms /    21 tokens (  192.54 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.27 ms /     3 runs   (  875.09 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6671.52 ms /    24 tokens\n",
      "  1%|          | 37/3487 [07:16<9:26:01,  9.84s/it] Llama.generate: 306 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21004.87 ms /   102 tokens (  205.93 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3181.33 ms /     3 runs   ( 1060.44 ms per token,     0.94 tokens per second)\n",
      "llama_perf_context_print:       total time =   24189.69 ms /   105 tokens\n",
      "  1%|          | 38/3487 [07:40<13:33:24, 14.15s/it]Llama.generate: 307 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16262.21 ms /    78 tokens (  208.49 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2785.95 ms /     3 runs   (  928.65 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   19050.51 ms /    81 tokens\n",
      "  1%|          | 39/3487 [07:59<14:57:48, 15.62s/it]Llama.generate: 307 prefix-match hit, remaining 181 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   35943.44 ms /   181 tokens (  198.58 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.15 ms /     3 runs   (  898.72 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   38642.44 ms /   184 tokens\n",
      "  1%|          | 40/3487 [08:38<21:34:26, 22.53s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6096.49 ms /    31 tokens (  196.66 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2776.26 ms /     3 runs   (  925.42 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8875.36 ms /    34 tokens\n",
      "  1%|          | 41/3487 [08:47<17:38:55, 18.44s/it]Llama.generate: 306 prefix-match hit, remaining 134 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26070.55 ms /   134 tokens (  194.56 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3081.97 ms /     3 runs   ( 1027.32 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =   29154.94 ms /   137 tokens\n",
      "  1%|          | 42/3487 [09:16<20:43:20, 21.65s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10110.52 ms /    51 tokens (  198.25 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.60 ms /     3 runs   (  873.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12734.87 ms /    54 tokens\n",
      "  1%|          | 43/3487 [09:29<18:09:32, 18.98s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3317.38 ms /    16 tokens (  207.34 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.76 ms /     3 runs   (  873.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5942.14 ms /    19 tokens\n",
      "  1%|▏         | 44/3487 [09:35<14:24:54, 15.07s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1836.75 ms /     7 tokens (  262.39 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.05 ms /     3 runs   (  875.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4465.30 ms /    10 tokens\n",
      "  1%|▏         | 45/3487 [09:39<11:22:47, 11.90s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7532.14 ms /    38 tokens (  198.21 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.82 ms /     3 runs   (  877.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10166.98 ms /    41 tokens\n",
      "  1%|▏         | 46/3487 [09:49<10:52:53, 11.38s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6835.38 ms /    31 tokens (  220.50 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.27 ms /     3 runs   (  891.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9511.10 ms /    34 tokens\n",
      "  1%|▏         | 47/3487 [09:59<10:20:40, 10.83s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6106.22 ms /    31 tokens (  196.97 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.42 ms /     3 runs   (  873.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8729.24 ms /    34 tokens\n",
      "  1%|▏         | 48/3487 [10:08<9:44:34, 10.20s/it] Llama.generate: 308 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4945.91 ms /    25 tokens (  197.84 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.82 ms /     3 runs   (  879.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7588.73 ms /    28 tokens\n",
      "  1%|▏         | 49/3487 [10:15<8:59:40,  9.42s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7416.86 ms /    37 tokens (  200.46 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.68 ms /     3 runs   (  874.89 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10044.11 ms /    40 tokens\n",
      "  1%|▏         | 50/3487 [10:25<9:10:24,  9.61s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3421.39 ms /    17 tokens (  201.26 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.97 ms /     3 runs   (  879.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6062.36 ms /    20 tokens\n",
      "  1%|▏         | 51/3487 [10:31<8:09:29,  8.55s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2438.52 ms /    10 tokens (  243.85 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.72 ms /     3 runs   (  884.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5095.75 ms /    13 tokens\n",
      "  1%|▏         | 52/3487 [10:36<7:10:14,  7.52s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12035.78 ms /    62 tokens (  194.13 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.36 ms /     3 runs   (  891.45 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14712.36 ms /    65 tokens\n",
      "  2%|▏         | 53/3487 [10:51<9:13:52,  9.68s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5419.02 ms /    27 tokens (  200.70 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.53 ms /     3 runs   (  884.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8076.52 ms /    30 tokens\n",
      "  2%|▏         | 54/3487 [10:59<8:46:22,  9.20s/it]Llama.generate: 306 prefix-match hit, remaining 170 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   32811.79 ms /   170 tokens (  193.01 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.52 ms /     3 runs   (  874.84 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   35439.52 ms /   173 tokens\n",
      "  2%|▏         | 55/3487 [11:35<16:16:38, 17.07s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9873.07 ms /    51 tokens (  193.59 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.62 ms /     3 runs   (  879.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12514.83 ms /    54 tokens\n",
      "  2%|▏         | 56/3487 [11:47<14:58:19, 15.71s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7806.10 ms /    39 tokens (  200.16 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.11 ms /     3 runs   (  877.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10442.45 ms /    42 tokens\n",
      "  2%|▏         | 57/3487 [11:58<13:27:54, 14.13s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10761.30 ms /    56 tokens (  192.17 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2605.66 ms /     3 runs   (  868.55 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   13369.74 ms /    59 tokens\n",
      "  2%|▏         | 58/3487 [12:11<13:14:45, 13.91s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9267.69 ms /    47 tokens (  197.18 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2832.12 ms /     3 runs   (  944.04 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   12102.21 ms /    50 tokens\n",
      "  2%|▏         | 59/3487 [12:23<12:43:45, 13.37s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5186.11 ms /    25 tokens (  207.44 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.31 ms /     3 runs   (  915.77 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7936.53 ms /    28 tokens\n",
      "  2%|▏         | 60/3487 [12:31<11:10:40, 11.74s/it]Llama.generate: 307 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17017.64 ms /    84 tokens (  202.59 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.51 ms /     3 runs   (  883.17 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19670.60 ms /    87 tokens\n",
      "  2%|▏         | 61/3487 [12:51<13:26:25, 14.12s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1797.92 ms /     8 tokens (  224.74 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.41 ms /     3 runs   (  877.80 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4433.60 ms /    11 tokens\n",
      "  2%|▏         | 62/3487 [12:55<10:40:24, 11.22s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7076.26 ms /    33 tokens (  214.43 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.34 ms /     3 runs   (  879.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9717.50 ms /    36 tokens\n",
      "  2%|▏         | 63/3487 [13:05<10:14:43, 10.77s/it]Llama.generate: 306 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12185.11 ms /    63 tokens (  193.41 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.97 ms /     3 runs   (  881.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14832.83 ms /    66 tokens\n",
      "  2%|▏         | 64/3487 [13:20<11:24:10, 11.99s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7947.53 ms /    40 tokens (  198.69 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.18 ms /     3 runs   (  875.06 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10575.50 ms /    43 tokens\n",
      "  2%|▏         | 65/3487 [13:30<10:59:52, 11.57s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8279.51 ms /    41 tokens (  201.94 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.05 ms /     3 runs   (  878.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10918.98 ms /    44 tokens\n",
      "  2%|▏         | 66/3487 [13:41<10:48:43, 11.38s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7473.10 ms /    37 tokens (  201.98 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.78 ms /     3 runs   (  880.93 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10118.97 ms /    40 tokens\n",
      "  2%|▏         | 67/3487 [13:51<10:27:08, 11.00s/it]Llama.generate: 306 prefix-match hit, remaining 136 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27219.48 ms /   136 tokens (  200.14 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2814.46 ms /     3 runs   (  938.15 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   30036.64 ms /   139 tokens\n",
      "  2%|▏         | 68/3487 [14:21<15:52:30, 16.72s/it]Llama.generate: 306 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13440.88 ms /    65 tokens (  206.78 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.47 ms /     3 runs   (  883.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16095.18 ms /    68 tokens\n",
      "  2%|▏         | 69/3487 [14:38<15:41:46, 16.53s/it]Llama.generate: 306 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11265.79 ms /    58 tokens (  194.24 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.30 ms /     3 runs   (  883.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13919.50 ms /    61 tokens\n",
      "  2%|▏         | 70/3487 [14:51<14:57:01, 15.75s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7219.91 ms /    33 tokens (  218.79 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.40 ms /     3 runs   (  882.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9870.35 ms /    36 tokens\n",
      "  2%|▏         | 71/3487 [15:01<13:16:27, 13.99s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2930.58 ms /    14 tokens (  209.33 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.95 ms /     3 runs   (  880.98 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5576.18 ms /    17 tokens\n",
      "  2%|▏         | 72/3487 [15:07<10:52:42, 11.47s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3574.36 ms /    18 tokens (  198.58 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.70 ms /     3 runs   (  890.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6250.16 ms /    21 tokens\n",
      "  2%|▏         | 73/3487 [15:13<9:23:38,  9.91s/it] Llama.generate: 307 prefix-match hit, remaining 122 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24862.20 ms /   122 tokens (  203.79 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.30 ms /     3 runs   (  879.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27504.45 ms /   125 tokens\n",
      "  2%|▏         | 74/3487 [15:41<14:23:57, 15.19s/it]Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11052.60 ms /    57 tokens (  193.91 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.25 ms /     3 runs   (  887.08 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13716.67 ms /    60 tokens\n",
      "  2%|▏         | 75/3487 [15:54<13:58:43, 14.75s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4532.95 ms /    24 tokens (  188.87 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.25 ms /     3 runs   (  885.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7192.15 ms /    27 tokens\n",
      "  2%|▏         | 76/3487 [16:02<11:49:45, 12.48s/it]Llama.generate: 308 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4537.94 ms /    23 tokens (  197.30 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2813.35 ms /     3 runs   (  937.78 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7353.89 ms /    26 tokens\n",
      "  2%|▏         | 77/3487 [16:09<10:22:13, 10.95s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1403.45 ms /     6 tokens (  233.91 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.16 ms /     3 runs   (  885.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4062.50 ms /     9 tokens\n",
      "  2%|▏         | 78/3487 [16:13<8:24:48,  8.88s/it] Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3798.65 ms /    19 tokens (  199.93 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.35 ms /     3 runs   (  889.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6468.45 ms /    22 tokens\n",
      "  2%|▏         | 79/3487 [16:20<7:43:37,  8.16s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11820.05 ms /    62 tokens (  190.65 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.54 ms /     3 runs   (  873.18 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14441.73 ms /    65 tokens\n",
      "  2%|▏         | 80/3487 [16:34<9:30:37, 10.05s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12910.68 ms /    67 tokens (  192.70 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.71 ms /     3 runs   (  873.90 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15534.91 ms /    70 tokens\n",
      "  2%|▏         | 81/3487 [16:50<11:04:01, 11.70s/it]Llama.generate: 307 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25233.42 ms /   133 tokens (  189.72 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.75 ms /     3 runs   (  878.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27872.07 ms /   136 tokens\n",
      "  2%|▏         | 82/3487 [17:17<15:39:18, 16.55s/it]Llama.generate: 307 prefix-match hit, remaining 132 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25651.77 ms /   132 tokens (  194.33 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3293.86 ms /     3 runs   ( 1097.95 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =   28948.54 ms /   135 tokens\n",
      "  2%|▏         | 83/3487 [17:46<19:10:13, 20.27s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14596.79 ms /    67 tokens (  217.86 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2826.12 ms /     3 runs   (  942.04 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   17425.91 ms /    70 tokens\n",
      "  2%|▏         | 84/3487 [18:04<18:21:34, 19.42s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3166.52 ms /    13 tokens (  243.58 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2823.36 ms /     3 runs   (  941.12 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5993.08 ms /    16 tokens\n",
      "  2%|▏         | 85/3487 [18:10<14:33:00, 15.40s/it]Llama.generate: 312 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1448.06 ms /     5 tokens (  289.61 ms per token,     3.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2718.11 ms /     3 runs   (  906.04 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4169.29 ms /     8 tokens\n",
      "  2%|▏         | 86/3487 [18:14<11:21:59, 12.03s/it]Llama.generate: 312 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1149.40 ms /     4 tokens (  287.35 ms per token,     3.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2783.29 ms /     3 runs   (  927.76 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    3935.16 ms /     7 tokens\n",
      "  2%|▏         | 87/3487 [18:18<9:04:21,  9.61s/it] Llama.generate: 310 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2327.65 ms /    10 tokens (  232.76 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.94 ms /     3 runs   (  913.31 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5069.95 ms /    13 tokens\n",
      "  3%|▎         | 88/3487 [18:23<7:47:14,  8.25s/it]Llama.generate: 310 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1407.30 ms /     6 tokens (  234.55 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.20 ms /     3 runs   (  883.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4060.07 ms /     9 tokens\n",
      "  3%|▎         | 89/3487 [18:27<6:36:07,  6.99s/it]Llama.generate: 312 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1921.31 ms /     9 tokens (  213.48 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.15 ms /     3 runs   (  878.72 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4559.95 ms /    12 tokens\n",
      "  3%|▎         | 90/3487 [18:32<5:54:45,  6.27s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11997.95 ms /    62 tokens (  193.52 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.44 ms /     3 runs   (  883.81 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14651.43 ms /    65 tokens\n",
      "  3%|▎         | 91/3487 [18:46<8:17:09,  8.78s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4897.92 ms /    25 tokens (  195.92 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.42 ms /     3 runs   (  878.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7537.52 ms /    28 tokens\n",
      "  3%|▎         | 92/3487 [18:54<7:55:58,  8.41s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2451.04 ms /    11 tokens (  222.82 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.59 ms /     3 runs   (  900.53 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5155.89 ms /    14 tokens\n",
      "  3%|▎         | 93/3487 [18:59<7:00:43,  7.44s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3278.33 ms /    16 tokens (  204.90 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.52 ms /     3 runs   (  880.17 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5921.25 ms /    19 tokens\n",
      "  3%|▎         | 94/3487 [19:05<6:35:01,  6.99s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2204.07 ms /    10 tokens (  220.41 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.30 ms /     3 runs   (  884.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4859.41 ms /    13 tokens\n",
      "  3%|▎         | 95/3487 [19:10<5:59:01,  6.35s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3548.81 ms /    18 tokens (  197.16 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.82 ms /     3 runs   (  876.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6181.55 ms /    21 tokens\n",
      "  3%|▎         | 96/3487 [19:16<5:56:12,  6.30s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2836.97 ms /    14 tokens (  202.64 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3193.90 ms /     3 runs   ( 1064.63 ms per token,     0.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    6033.45 ms /    17 tokens\n",
      "  3%|▎         | 97/3487 [19:22<5:51:41,  6.22s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2978.58 ms /    14 tokens (  212.76 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.33 ms /     3 runs   (  887.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5643.96 ms /    17 tokens\n",
      "  3%|▎         | 98/3487 [19:28<5:41:53,  6.05s/it]Llama.generate: 307 prefix-match hit, remaining 125 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23717.44 ms /   125 tokens (  189.74 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.25 ms /     3 runs   (  878.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   26354.44 ms /   128 tokens\n",
      "  3%|▎         | 99/3487 [19:54<11:25:50, 12.15s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5522.44 ms /    29 tokens (  190.43 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.85 ms /     3 runs   (  880.95 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8167.84 ms /    32 tokens\n",
      "  3%|▎         | 100/3487 [20:02<10:18:25, 10.96s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7077.99 ms /    33 tokens (  214.48 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.20 ms /     3 runs   (  875.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9707.93 ms /    36 tokens\n",
      "  3%|▎         | 101/3487 [20:12<9:57:15, 10.58s/it] Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4555.86 ms /    24 tokens (  189.83 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.07 ms /     3 runs   (  887.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7222.03 ms /    27 tokens\n",
      "  3%|▎         | 102/3487 [20:19<9:00:19,  9.58s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5164.65 ms /    27 tokens (  191.28 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.62 ms /     3 runs   (  876.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7798.04 ms /    30 tokens\n",
      "  3%|▎         | 103/3487 [20:27<8:30:11,  9.05s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6054.86 ms /    32 tokens (  189.21 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.01 ms /     3 runs   (  889.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8726.27 ms /    35 tokens\n",
      "  3%|▎         | 104/3487 [20:36<8:24:48,  8.95s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3876.23 ms /    19 tokens (  204.01 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.53 ms /     3 runs   (  876.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6507.59 ms /    22 tokens\n",
      "  3%|▎         | 105/3487 [20:42<7:43:26,  8.22s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3876.19 ms /    20 tokens (  193.81 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.85 ms /     3 runs   (  874.28 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6502.02 ms /    23 tokens\n",
      "  3%|▎         | 106/3487 [20:49<7:14:21,  7.71s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3905.16 ms /    19 tokens (  205.53 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.95 ms /     3 runs   (  880.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6549.32 ms /    22 tokens\n",
      "  3%|▎         | 107/3487 [20:55<6:54:45,  7.36s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2685.22 ms /    13 tokens (  206.56 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.90 ms /     3 runs   (  889.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5357.74 ms /    16 tokens\n",
      "  3%|▎         | 108/3487 [21:01<6:20:54,  6.76s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8849.21 ms /    46 tokens (  192.37 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.34 ms /     3 runs   (  887.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11513.39 ms /    49 tokens\n",
      "  3%|▎         | 109/3487 [21:12<7:41:08,  8.19s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13131.88 ms /    66 tokens (  198.97 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.00 ms /     3 runs   (  907.33 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   15856.70 ms /    69 tokens\n",
      "  3%|▎         | 110/3487 [21:28<9:50:37, 10.49s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2845.90 ms /    13 tokens (  218.92 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.09 ms /     3 runs   (  894.03 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5530.51 ms /    16 tokens\n",
      "  3%|▎         | 111/3487 [21:34<8:26:47,  9.01s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1623.88 ms /     7 tokens (  231.98 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.79 ms /     3 runs   (  886.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4287.58 ms /    10 tokens\n",
      "  3%|▎         | 112/3487 [21:38<7:07:08,  7.59s/it]Llama.generate: 306 prefix-match hit, remaining 146 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27364.50 ms /   146 tokens (  187.43 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.41 ms /     3 runs   (  888.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   30032.47 ms /   149 tokens\n",
      "  3%|▎         | 113/3487 [22:08<13:25:42, 14.33s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2408.93 ms /    12 tokens (  200.74 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.78 ms /     3 runs   (  878.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5046.23 ms /    15 tokens\n",
      "  3%|▎         | 114/3487 [22:13<10:49:03, 11.55s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4026.88 ms /    21 tokens (  191.76 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.57 ms /     3 runs   (  892.52 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6707.57 ms /    24 tokens\n",
      "  3%|▎         | 115/3487 [22:20<9:27:26, 10.10s/it] Llama.generate: 306 prefix-match hit, remaining 229 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   43628.67 ms /   229 tokens (  190.52 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.12 ms /     3 runs   (  890.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   46302.19 ms /   232 tokens\n",
      "  3%|▎         | 116/3487 [23:06<19:37:41, 20.96s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6025.07 ms /    32 tokens (  188.28 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.53 ms /     3 runs   (  879.51 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8666.90 ms /    35 tokens\n",
      "  3%|▎         | 117/3487 [23:15<16:10:18, 17.28s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7046.61 ms /    35 tokens (  201.33 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.66 ms /     3 runs   (  879.89 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9689.00 ms /    38 tokens\n",
      "  3%|▎         | 118/3487 [23:24<14:02:21, 15.00s/it]Llama.generate: 307 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19481.15 ms /    98 tokens (  198.79 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2770.26 ms /     3 runs   (  923.42 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   22255.21 ms /   101 tokens\n",
      "  3%|▎         | 119/3487 [23:47<16:04:24, 17.18s/it]Llama.generate: 307 prefix-match hit, remaining 88 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28304.07 ms /    88 tokens (  321.64 ms per token,     3.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12804.07 ms /     3 runs   ( 4268.02 ms per token,     0.23 tokens per second)\n",
      "llama_perf_context_print:       total time =   41138.56 ms /    91 tokens\n",
      "  3%|▎         | 120/3487 [24:28<22:48:28, 24.39s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4218.40 ms /    13 tokens (  324.49 ms per token,     3.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4448.98 ms /     3 runs   ( 1482.99 ms per token,     0.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    8678.05 ms /    16 tokens\n",
      "  3%|▎         | 121/3487 [24:37<18:24:26, 19.69s/it]Llama.generate: 306 prefix-match hit, remaining 88 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19329.04 ms /    88 tokens (  219.65 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2865.94 ms /     3 runs   (  955.31 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   22198.56 ms /    91 tokens\n",
      "  3%|▎         | 122/3487 [24:59<19:06:34, 20.44s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7983.42 ms /    33 tokens (  241.92 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.47 ms /     3 runs   (  881.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10632.02 ms /    36 tokens\n",
      "  4%|▎         | 123/3487 [25:09<16:21:20, 17.50s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5804.03 ms /    30 tokens (  193.47 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.64 ms /     3 runs   (  900.22 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8507.62 ms /    33 tokens\n",
      "  4%|▎         | 124/3487 [25:18<13:49:58, 14.81s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7473.67 ms /    37 tokens (  201.99 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2791.13 ms /     3 runs   (  930.38 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   10267.60 ms /    40 tokens\n",
      "  4%|▎         | 125/3487 [25:28<12:33:33, 13.45s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3636.85 ms /    16 tokens (  227.30 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3381.99 ms /     3 runs   ( 1127.33 ms per token,     0.89 tokens per second)\n",
      "llama_perf_context_print:       total time =    7022.38 ms /    19 tokens\n",
      "  4%|▎         | 126/3487 [25:35<10:45:31, 11.52s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1774.72 ms /     6 tokens (  295.79 ms per token,     3.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2807.33 ms /     3 runs   (  935.78 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4585.11 ms /     9 tokens\n",
      "  4%|▎         | 127/3487 [25:40<8:49:00,  9.45s/it] Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4611.23 ms /    22 tokens (  209.60 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.64 ms /     3 runs   (  881.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7259.30 ms /    25 tokens\n",
      "  4%|▎         | 128/3487 [25:47<8:12:16,  8.79s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5516.42 ms /    28 tokens (  197.01 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.12 ms /     3 runs   (  888.37 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8183.65 ms /    31 tokens\n",
      "  4%|▎         | 129/3487 [25:55<8:02:03,  8.61s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13580.24 ms /    70 tokens (  194.00 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.68 ms /     3 runs   (  897.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   16276.82 ms /    73 tokens\n",
      "  4%|▎         | 130/3487 [26:12<10:10:44, 10.92s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7483.00 ms /    33 tokens (  226.76 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.72 ms /     3 runs   (  875.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10114.22 ms /    36 tokens\n",
      "  4%|▍         | 131/3487 [26:22<9:57:20, 10.68s/it] Llama.generate: 313 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1907.32 ms /     8 tokens (  238.41 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.30 ms /     3 runs   (  880.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4551.12 ms /    11 tokens\n",
      "  4%|▍         | 132/3487 [26:26<8:14:31,  8.84s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7670.45 ms /    37 tokens (  207.31 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.65 ms /     3 runs   (  874.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10297.70 ms /    40 tokens\n",
      "  4%|▍         | 133/3487 [26:37<8:38:54,  9.28s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4134.35 ms /    20 tokens (  206.72 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.78 ms /     3 runs   (  880.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6777.69 ms /    23 tokens\n",
      "  4%|▍         | 134/3487 [26:43<7:56:51,  8.53s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1282.45 ms /     5 tokens (  256.49 ms per token,     3.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.78 ms /     3 runs   (  875.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    3911.05 ms /     8 tokens\n",
      "  4%|▍         | 135/3487 [26:47<6:39:27,  7.15s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3166.18 ms /    15 tokens (  211.08 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.32 ms /     3 runs   (  872.77 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5787.32 ms /    18 tokens\n",
      "  4%|▍         | 136/3487 [26:53<6:16:41,  6.74s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5900.37 ms /    30 tokens (  196.68 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.89 ms /     3 runs   (  880.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8544.00 ms /    33 tokens\n",
      "  4%|▍         | 137/3487 [27:02<6:46:52,  7.29s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7699.69 ms /    38 tokens (  202.62 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.88 ms /     3 runs   (  876.63 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10332.61 ms /    41 tokens\n",
      "  4%|▍         | 138/3487 [27:12<7:37:53,  8.20s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4007.29 ms /    20 tokens (  200.36 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.09 ms /     3 runs   (  878.36 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6644.98 ms /    23 tokens\n",
      "  4%|▍         | 139/3487 [27:19<7:11:49,  7.74s/it]Llama.generate: 307 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10953.11 ms /    55 tokens (  199.15 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.94 ms /     3 runs   (  903.98 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   13667.78 ms /    58 tokens\n",
      "  4%|▍         | 140/3487 [27:32<8:51:03,  9.52s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3075.49 ms /    15 tokens (  205.03 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2925.53 ms /     3 runs   (  975.18 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6003.75 ms /    18 tokens\n",
      "  4%|▍         | 141/3487 [27:38<7:52:11,  8.47s/it]Llama.generate: 313 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1771.89 ms /     8 tokens (  221.49 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.89 ms /     3 runs   (  875.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4402.65 ms /    11 tokens\n",
      "  4%|▍         | 142/3487 [27:43<6:44:13,  7.25s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2531.22 ms /    12 tokens (  210.93 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.66 ms /     3 runs   (  875.89 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5162.02 ms /    15 tokens\n",
      "  4%|▍         | 143/3487 [27:48<6:09:19,  6.63s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3018.81 ms /    14 tokens (  215.63 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.44 ms /     3 runs   (  877.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5654.49 ms /    17 tokens\n",
      "  4%|▍         | 144/3487 [27:54<5:53:05,  6.34s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4349.13 ms /    21 tokens (  207.10 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.39 ms /     3 runs   (  878.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6987.34 ms /    24 tokens\n",
      "  4%|▍         | 145/3487 [28:01<6:04:00,  6.54s/it]Llama.generate: 307 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11679.34 ms /    60 tokens (  194.66 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.97 ms /     3 runs   (  872.32 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14298.85 ms /    63 tokens\n",
      "  4%|▍         | 146/3487 [28:15<8:13:43,  8.87s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7763.19 ms /    39 tokens (  199.06 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.42 ms /     3 runs   (  875.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10391.50 ms /    42 tokens\n",
      "  4%|▍         | 147/3487 [28:25<8:39:11,  9.33s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9083.12 ms /    46 tokens (  197.46 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2737.61 ms /     3 runs   (  912.54 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   11823.31 ms /    49 tokens\n",
      "  4%|▍         | 148/3487 [28:37<9:20:51, 10.08s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13673.40 ms /    69 tokens (  198.17 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.33 ms /     3 runs   (  875.44 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16302.36 ms /    72 tokens\n",
      "  4%|▍         | 149/3487 [28:53<11:04:43, 11.95s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12330.15 ms /    62 tokens (  198.87 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2732.20 ms /     3 runs   (  910.73 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   15064.84 ms /    65 tokens\n",
      "  4%|▍         | 150/3487 [29:09<11:56:39, 12.89s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12284.68 ms /    63 tokens (  194.99 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2771.35 ms /     3 runs   (  923.78 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   15058.37 ms /    66 tokens\n",
      "  4%|▍         | 151/3487 [29:24<12:32:51, 13.54s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6250.98 ms /    29 tokens (  215.55 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.12 ms /     3 runs   (  893.71 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8934.77 ms /    32 tokens\n",
      "  4%|▍         | 152/3487 [29:33<11:16:00, 12.16s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10231.44 ms /    52 tokens (  196.76 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.17 ms /     3 runs   (  875.72 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12861.80 ms /    55 tokens\n",
      "  4%|▍         | 153/3487 [29:45<11:27:38, 12.37s/it]Llama.generate: 306 prefix-match hit, remaining 121 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23328.63 ms /   121 tokens (  192.80 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.59 ms /     3 runs   (  874.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   25953.83 ms /   124 tokens\n",
      "  4%|▍         | 154/3487 [30:11<15:13:51, 16.45s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7300.47 ms /    31 tokens (  235.50 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3237.90 ms /     3 runs   ( 1079.30 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =   10542.70 ms /    34 tokens\n",
      "  4%|▍         | 155/3487 [30:22<13:35:18, 14.68s/it]Llama.generate: 306 prefix-match hit, remaining 220 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   44626.20 ms /   220 tokens (  202.85 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.65 ms /     3 runs   (  882.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   47277.89 ms /   223 tokens\n",
      "  4%|▍         | 156/3487 [31:09<22:38:08, 24.46s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13237.37 ms /    70 tokens (  189.11 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.28 ms /     3 runs   (  874.09 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15862.33 ms /    73 tokens\n",
      "  5%|▍         | 157/3487 [31:25<20:14:38, 21.89s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9535.00 ms /    49 tokens (  194.59 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.57 ms /     3 runs   (  884.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12192.52 ms /    52 tokens\n",
      "  5%|▍         | 158/3487 [31:37<17:33:04, 18.98s/it]Llama.generate: 307 prefix-match hit, remaining 193 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   36347.25 ms /   193 tokens (  188.33 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.98 ms /     3 runs   (  874.66 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   38973.60 ms /   196 tokens\n",
      "  5%|▍         | 159/3487 [32:16<23:05:35, 24.98s/it]Llama.generate: 307 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16028.91 ms /    78 tokens (  205.50 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3205.52 ms /     3 runs   ( 1068.51 ms per token,     0.94 tokens per second)\n",
      "llama_perf_context_print:       total time =   19237.80 ms /    81 tokens\n",
      "  5%|▍         | 160/3487 [32:36<21:29:48, 23.26s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4330.81 ms /    20 tokens (  216.54 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.39 ms /     3 runs   (  882.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6979.61 ms /    23 tokens\n",
      "  5%|▍         | 161/3487 [32:42<16:58:47, 18.38s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2727.85 ms /    13 tokens (  209.83 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.42 ms /     3 runs   (  878.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5364.76 ms /    16 tokens\n",
      "  5%|▍         | 162/3487 [32:48<13:22:14, 14.48s/it]Llama.generate: 307 prefix-match hit, remaining 132 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24970.34 ms /   132 tokens (  189.17 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.89 ms /     3 runs   (  874.63 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27596.41 ms /   135 tokens\n",
      "  5%|▍         | 163/3487 [33:15<17:00:12, 18.42s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7656.22 ms /    39 tokens (  196.31 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3252.11 ms /     3 runs   ( 1084.04 ms per token,     0.92 tokens per second)\n",
      "llama_perf_context_print:       total time =   10910.98 ms /    42 tokens\n",
      "  5%|▍         | 164/3487 [33:26<14:55:23, 16.17s/it]Llama.generate: 306 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17568.81 ms /    87 tokens (  201.94 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3280.58 ms /     3 runs   ( 1093.53 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =   20851.82 ms /    90 tokens\n",
      "  5%|▍         | 165/3487 [33:47<16:13:13, 17.58s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6898.62 ms /     7 tokens (  985.52 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6078.46 ms /     3 runs   ( 2026.15 ms per token,     0.49 tokens per second)\n",
      "llama_perf_context_print:       total time =   12982.22 ms /    10 tokens\n",
      "  5%|▍         | 166/3487 [34:02<15:25:11, 16.72s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10786.49 ms /    38 tokens (  283.85 ms per token,     3.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3230.34 ms /     3 runs   ( 1076.78 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =   14020.56 ms /    41 tokens\n",
      "  5%|▍         | 167/3487 [34:16<14:40:34, 15.91s/it]Llama.generate: 307 prefix-match hit, remaining 104 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   36040.72 ms /   104 tokens (  346.55 ms per token,     2.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3818.79 ms /     3 runs   ( 1272.93 ms per token,     0.79 tokens per second)\n",
      "llama_perf_context_print:       total time =   39864.57 ms /   107 tokens\n",
      "  5%|▍         | 168/3487 [34:56<21:18:03, 23.10s/it]Llama.generate: 307 prefix-match hit, remaining 81 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17712.53 ms /    81 tokens (  218.67 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3399.30 ms /     3 runs   ( 1133.10 ms per token,     0.88 tokens per second)\n",
      "llama_perf_context_print:       total time =   21115.63 ms /    84 tokens\n",
      "  5%|▍         | 169/3487 [35:17<20:44:59, 22.51s/it]Llama.generate: 307 prefix-match hit, remaining 156 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   45801.50 ms /   156 tokens (  293.60 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2806.82 ms /     3 runs   (  935.61 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   48612.39 ms /   159 tokens\n",
      "  5%|▍         | 170/3487 [36:06<27:57:41, 30.35s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8070.40 ms /    40 tokens (  201.76 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.57 ms /     3 runs   (  873.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10694.85 ms /    43 tokens\n",
      "  5%|▍         | 171/3487 [36:16<22:31:32, 24.45s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8794.91 ms /    47 tokens (  187.13 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.57 ms /     3 runs   (  880.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11437.71 ms /    50 tokens\n",
      "  5%|▍         | 172/3487 [36:28<18:55:32, 20.55s/it]Llama.generate: 307 prefix-match hit, remaining 92 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17098.03 ms /    92 tokens (  185.85 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.46 ms /     3 runs   (  879.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19738.95 ms /    95 tokens\n",
      "  5%|▍         | 173/3487 [36:48<18:41:54, 20.31s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5529.32 ms /    28 tokens (  197.48 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.37 ms /     3 runs   (  877.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8163.92 ms /    31 tokens\n",
      "  5%|▍         | 174/3487 [36:56<15:20:28, 16.67s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4816.90 ms /    25 tokens (  192.68 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.02 ms /     3 runs   (  875.01 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7444.76 ms /    28 tokens\n",
      "  5%|▌         | 175/3487 [37:03<12:47:35, 13.91s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7630.38 ms /    40 tokens (  190.76 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.99 ms /     3 runs   (  888.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10297.14 ms /    43 tokens\n",
      "  5%|▌         | 176/3487 [37:13<11:47:45, 12.83s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2341.22 ms /    11 tokens (  212.84 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.83 ms /     3 runs   (  882.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4992.79 ms /    14 tokens\n",
      "  5%|▌         | 177/3487 [37:19<9:41:19, 10.54s/it] Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5358.81 ms /    28 tokens (  191.39 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.55 ms /     3 runs   (  878.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7997.11 ms /    31 tokens\n",
      "  5%|▌         | 178/3487 [37:27<8:59:20,  9.78s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4457.84 ms /    22 tokens (  202.63 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.95 ms /     3 runs   (  894.32 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7144.10 ms /    25 tokens\n",
      "  5%|▌         | 179/3487 [37:34<8:15:43,  8.99s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7298.70 ms /    35 tokens (  208.53 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.12 ms /     3 runs   (  873.04 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9920.93 ms /    38 tokens\n",
      "  5%|▌         | 180/3487 [37:44<8:31:05,  9.27s/it]Llama.generate: 306 prefix-match hit, remaining 88 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16495.83 ms /    88 tokens (  187.45 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.47 ms /     3 runs   (  900.16 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   19199.18 ms /    91 tokens\n",
      "  5%|▌         | 181/3487 [38:03<11:15:08, 12.25s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2196.96 ms /    11 tokens (  199.72 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.24 ms /     3 runs   (  872.41 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4818.32 ms /    14 tokens\n",
      "  5%|▌         | 182/3487 [38:08<9:12:12, 10.03s/it] Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5474.69 ms /    29 tokens (  188.78 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.40 ms /     3 runs   (  879.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8114.24 ms /    32 tokens\n",
      "  5%|▌         | 183/3487 [38:16<8:40:36,  9.45s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8155.24 ms /    42 tokens (  194.17 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.96 ms /     3 runs   (  875.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10784.57 ms /    45 tokens\n",
      "  5%|▌         | 184/3487 [38:27<9:02:33,  9.86s/it]Llama.generate: 306 prefix-match hit, remaining 114 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21430.36 ms /   114 tokens (  187.99 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.91 ms /     3 runs   (  873.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   24055.40 ms /   117 tokens\n",
      "  5%|▌         | 185/3487 [38:51<12:56:58, 14.12s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16102.77 ms /    86 tokens (  187.24 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.11 ms /     3 runs   (  873.04 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   18724.65 ms /    89 tokens\n",
      "  5%|▌         | 186/3487 [39:10<14:12:53, 15.50s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12713.82 ms /    67 tokens (  189.76 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.92 ms /     3 runs   (  880.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15357.58 ms /    70 tokens\n",
      "  5%|▌         | 187/3487 [39:25<14:10:24, 15.46s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13206.38 ms /    67 tokens (  197.11 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2801.51 ms /     3 runs   (  933.84 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   16010.43 ms /    70 tokens\n",
      "  5%|▌         | 188/3487 [39:41<14:19:22, 15.63s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8167.41 ms /    40 tokens (  204.19 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.46 ms /     3 runs   (  878.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10805.71 ms /    43 tokens\n",
      "  5%|▌         | 189/3487 [39:52<12:59:43, 14.19s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5124.29 ms /    27 tokens (  189.79 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2718.68 ms /     3 runs   (  906.23 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7846.91 ms /    30 tokens\n",
      "  5%|▌         | 190/3487 [40:00<11:15:07, 12.29s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4407.67 ms /    22 tokens (  200.35 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.10 ms /     3 runs   (  870.70 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7022.59 ms /    25 tokens\n",
      "  5%|▌         | 191/3487 [40:07<9:48:20, 10.71s/it] Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9404.75 ms /    50 tokens (  188.09 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.18 ms /     3 runs   (  874.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12031.63 ms /    53 tokens\n",
      "  6%|▌         | 192/3487 [40:19<10:10:04, 11.11s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4131.79 ms /    21 tokens (  196.75 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.54 ms /     3 runs   (  880.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6774.98 ms /    24 tokens\n",
      "  6%|▌         | 193/3487 [40:25<8:58:40,  9.81s/it] Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5545.84 ms /    29 tokens (  191.24 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2752.61 ms /     3 runs   (  917.54 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8300.25 ms /    32 tokens\n",
      "  6%|▌         | 194/3487 [40:34<8:33:44,  9.36s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3791.16 ms /    18 tokens (  210.62 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.93 ms /     3 runs   (  894.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6478.40 ms /    21 tokens\n",
      "  6%|▌         | 195/3487 [40:40<7:46:17,  8.50s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4535.04 ms /    24 tokens (  188.96 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.49 ms /     3 runs   (  880.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7179.86 ms /    27 tokens\n",
      "  6%|▌         | 196/3487 [40:47<7:24:36,  8.11s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8830.04 ms /    47 tokens (  187.87 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.51 ms /     3 runs   (  882.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11479.80 ms /    50 tokens\n",
      "  6%|▌         | 197/3487 [40:59<8:20:05,  9.12s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1922.45 ms /     9 tokens (  213.61 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.17 ms /     3 runs   (  881.06 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4568.56 ms /    12 tokens\n",
      "  6%|▌         | 198/3487 [41:03<7:05:15,  7.76s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8270.74 ms /    42 tokens (  196.92 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.79 ms /     3 runs   (  870.93 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10885.75 ms /    45 tokens\n",
      "  6%|▌         | 199/3487 [41:14<7:56:41,  8.70s/it]Llama.generate: 306 prefix-match hit, remaining 238 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   44017.07 ms /   238 tokens (  184.95 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.78 ms /     3 runs   (  898.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   46716.50 ms /   241 tokens\n",
      "  6%|▌         | 200/3487 [42:01<18:21:35, 20.11s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11406.44 ms /    62 tokens (  183.97 ms per token,     5.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.06 ms /     3 runs   (  877.69 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14042.42 ms /    65 tokens\n",
      "  6%|▌         | 201/3487 [42:15<16:41:44, 18.29s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10976.51 ms /    59 tokens (  186.04 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.58 ms /     3 runs   (  899.19 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   13676.24 ms /    62 tokens\n",
      "  6%|▌         | 202/3487 [42:29<15:25:47, 16.91s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6857.52 ms /    33 tokens (  207.80 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.96 ms /     3 runs   (  872.32 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9477.78 ms /    36 tokens\n",
      "  6%|▌         | 203/3487 [42:38<13:23:36, 14.68s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4145.86 ms /    19 tokens (  218.20 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2604.45 ms /     3 runs   (  868.15 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6753.04 ms /    22 tokens\n",
      "  6%|▌         | 204/3487 [42:45<11:13:22, 12.31s/it]Llama.generate: 306 prefix-match hit, remaining 110 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20443.02 ms /   110 tokens (  185.85 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.60 ms /     3 runs   (  873.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   23066.77 ms /   113 tokens\n",
      "  6%|▌         | 205/3487 [43:08<14:09:52, 15.54s/it]Llama.generate: 306 prefix-match hit, remaining 129 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24231.89 ms /   129 tokens (  187.84 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.23 ms /     3 runs   (  878.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   26868.88 ms /   132 tokens\n",
      "  6%|▌         | 206/3487 [43:35<17:15:37, 18.94s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7384.70 ms /    38 tokens (  194.33 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.86 ms /     3 runs   (  870.95 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9999.51 ms /    41 tokens\n",
      "  6%|▌         | 207/3487 [43:45<14:48:51, 16.26s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7513.94 ms /    38 tokens (  197.74 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.48 ms /     3 runs   (  872.16 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10132.91 ms /    41 tokens\n",
      "  6%|▌         | 208/3487 [43:55<13:08:16, 14.42s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9887.38 ms /    53 tokens (  186.55 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2817.98 ms /     3 runs   (  939.33 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   12708.69 ms /    56 tokens\n",
      "  6%|▌         | 209/3487 [44:08<12:40:05, 13.91s/it]Llama.generate: 307 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16115.72 ms /    86 tokens (  187.39 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.48 ms /     3 runs   (  882.49 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18766.19 ms /    89 tokens\n",
      "  6%|▌         | 210/3487 [44:27<13:59:30, 15.37s/it]Llama.generate: 307 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11606.35 ms /    61 tokens (  190.27 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2776.37 ms /     3 runs   (  925.46 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   14385.41 ms /    64 tokens\n",
      "  6%|▌         | 211/3487 [44:41<13:43:17, 15.08s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2275.17 ms /    11 tokens (  206.83 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.95 ms /     3 runs   (  890.32 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4948.97 ms /    14 tokens\n",
      "  6%|▌         | 212/3487 [44:46<10:57:19, 12.04s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8806.32 ms /    46 tokens (  191.44 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2605.75 ms /     3 runs   (  868.58 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11414.68 ms /    49 tokens\n",
      "  6%|▌         | 213/3487 [44:57<10:46:58, 11.86s/it]Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10792.84 ms /    57 tokens (  189.35 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.58 ms /     3 runs   (  873.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13417.00 ms /    60 tokens\n",
      "  6%|▌         | 214/3487 [45:11<11:12:26, 12.33s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7326.37 ms /    38 tokens (  192.80 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.93 ms /     3 runs   (  872.98 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9948.03 ms /    41 tokens\n",
      "  6%|▌         | 215/3487 [45:21<10:33:26, 11.62s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9429.96 ms /    37 tokens (  254.86 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4424.51 ms /     3 runs   ( 1474.84 ms per token,     0.68 tokens per second)\n",
      "llama_perf_context_print:       total time =   13857.28 ms /    40 tokens\n",
      "  6%|▌         | 216/3487 [45:35<11:10:03, 12.29s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10788.34 ms /    39 tokens (  276.62 ms per token,     3.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.55 ms /     3 runs   (  879.52 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13430.21 ms /    42 tokens\n",
      "  6%|▌         | 217/3487 [45:48<11:28:39, 12.64s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5622.11 ms /    28 tokens (  200.79 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2785.65 ms /     3 runs   (  928.55 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8411.12 ms /    31 tokens\n",
      "  6%|▋         | 218/3487 [45:57<10:19:34, 11.37s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6804.65 ms /    32 tokens (  212.65 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.66 ms /     3 runs   (  880.89 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9449.77 ms /    35 tokens\n",
      "  6%|▋         | 219/3487 [46:06<9:48:07, 10.80s/it] Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7681.37 ms /    40 tokens (  192.03 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.60 ms /     3 runs   (  874.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10306.60 ms /    43 tokens\n",
      "  6%|▋         | 220/3487 [46:16<9:40:05, 10.65s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3589.07 ms /    18 tokens (  199.39 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.58 ms /     3 runs   (  873.19 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6211.34 ms /    21 tokens\n",
      "  6%|▋         | 221/3487 [46:23<8:27:29,  9.32s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7283.19 ms /    37 tokens (  196.84 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.31 ms /     3 runs   (  882.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9934.22 ms /    40 tokens\n",
      "  6%|▋         | 222/3487 [46:33<8:37:25,  9.51s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6062.06 ms /    32 tokens (  189.44 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.95 ms /     3 runs   (  882.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8712.67 ms /    35 tokens\n",
      "  6%|▋         | 223/3487 [46:41<8:24:23,  9.27s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1829.85 ms /     8 tokens (  228.73 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2605.68 ms /     3 runs   (  868.56 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4437.71 ms /    11 tokens\n",
      "  6%|▋         | 224/3487 [46:46<7:05:29,  7.82s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12895.89 ms /    66 tokens (  195.39 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.50 ms /     3 runs   (  877.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15531.45 ms /    69 tokens\n",
      "  6%|▋         | 225/3487 [47:01<9:11:13, 10.14s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13712.85 ms /    72 tokens (  190.46 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.32 ms /     3 runs   (  871.11 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   16328.85 ms /    75 tokens\n",
      "  6%|▋         | 226/3487 [47:18<10:52:07, 12.00s/it]Llama.generate: 306 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14894.29 ms /    76 tokens (  195.98 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2862.60 ms /     3 runs   (  954.20 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   17790.51 ms /    79 tokens\n",
      "  7%|▋         | 227/3487 [47:35<12:26:31, 13.74s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10332.81 ms /    52 tokens (  198.71 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.64 ms /     3 runs   (  880.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12976.01 ms /    55 tokens\n",
      "  7%|▋         | 228/3487 [47:48<12:13:58, 13.51s/it]Llama.generate: 314 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5059.67 ms /    27 tokens (  187.40 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.87 ms /     3 runs   (  873.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7683.98 ms /    30 tokens\n",
      "  7%|▋         | 229/3487 [47:56<10:38:55, 11.77s/it]Llama.generate: 308 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2927.19 ms /    14 tokens (  209.09 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.33 ms /     3 runs   (  873.11 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5549.51 ms /    17 tokens\n",
      "  7%|▋         | 230/3487 [48:02<8:57:35,  9.90s/it] Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13883.79 ms /    72 tokens (  192.83 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.57 ms /     3 runs   (  871.52 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   16500.83 ms /    75 tokens\n",
      "  7%|▋         | 231/3487 [48:18<10:45:00, 11.89s/it]Llama.generate: 306 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14729.96 ms /    78 tokens (  188.85 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.89 ms /     3 runs   (  870.96 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   17344.96 ms /    81 tokens\n",
      "  7%|▋         | 232/3487 [48:35<12:13:47, 13.53s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10147.25 ms /    54 tokens (  187.91 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.85 ms /     3 runs   (  881.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12794.73 ms /    57 tokens\n",
      "  7%|▋         | 233/3487 [48:48<12:01:46, 13.31s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4501.86 ms /    24 tokens (  187.58 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.75 ms /     3 runs   (  870.58 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7116.05 ms /    27 tokens\n",
      "  7%|▋         | 234/3487 [48:55<10:20:57, 11.45s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8897.21 ms /    45 tokens (  197.72 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.48 ms /     3 runs   (  870.83 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11511.91 ms /    48 tokens\n",
      "  7%|▋         | 235/3487 [49:07<10:21:50, 11.47s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7272.18 ms /    38 tokens (  191.37 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.54 ms /     3 runs   (  880.51 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9916.58 ms /    41 tokens\n",
      "  7%|▋         | 236/3487 [49:17<9:56:30, 11.01s/it] Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4037.21 ms /    21 tokens (  192.25 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.57 ms /     3 runs   (  880.52 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6681.18 ms /    24 tokens\n",
      "  7%|▋         | 237/3487 [49:24<8:46:08,  9.71s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13715.88 ms /    72 tokens (  190.50 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.13 ms /     3 runs   (  884.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16372.32 ms /    75 tokens\n",
      "  7%|▋         | 238/3487 [49:40<10:34:18, 11.71s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5535.87 ms /    29 tokens (  190.89 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.23 ms /     3 runs   (  881.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8182.47 ms /    32 tokens\n",
      "  7%|▋         | 239/3487 [49:48<9:36:55, 10.66s/it] Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5211.78 ms /    27 tokens (  193.03 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.84 ms /     3 runs   (  884.28 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7867.19 ms /    30 tokens\n",
      "  7%|▋         | 240/3487 [49:56<8:51:35,  9.82s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8066.45 ms /    41 tokens (  196.74 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.91 ms /     3 runs   (  874.64 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10693.01 ms /    44 tokens\n",
      "  7%|▋         | 241/3487 [50:07<9:05:43, 10.09s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7236.24 ms /    36 tokens (  201.01 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.30 ms /     3 runs   (  878.10 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9872.96 ms /    39 tokens\n",
      "  7%|▋         | 242/3487 [50:17<9:02:11, 10.03s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3891.88 ms /    20 tokens (  194.59 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.76 ms /     3 runs   (  880.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6534.64 ms /    23 tokens\n",
      "  7%|▋         | 243/3487 [50:23<8:05:32,  8.98s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5710.37 ms /    29 tokens (  196.91 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.13 ms /     3 runs   (  878.04 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8347.08 ms /    32 tokens\n",
      "  7%|▋         | 244/3487 [50:31<7:55:15,  8.79s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9210.17 ms /    48 tokens (  191.88 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2751.22 ms /     3 runs   (  917.07 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   11964.35 ms /    51 tokens\n",
      "  7%|▋         | 245/3487 [50:43<8:46:39,  9.75s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3549.23 ms /    17 tokens (  208.78 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2770.23 ms /     3 runs   (  923.41 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6322.04 ms /    20 tokens\n",
      "  7%|▋         | 246/3487 [50:50<7:51:10,  8.72s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6100.01 ms /    31 tokens (  196.77 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.60 ms /     3 runs   (  881.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8746.71 ms /    34 tokens\n",
      "  7%|▋         | 247/3487 [50:59<7:51:33,  8.73s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4883.60 ms /    23 tokens (  212.33 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.95 ms /     3 runs   (  898.98 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7583.34 ms /    26 tokens\n",
      "  7%|▋         | 248/3487 [51:06<7:33:27,  8.40s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8439.04 ms /    44 tokens (  191.80 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.91 ms /     3 runs   (  875.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11069.95 ms /    47 tokens\n",
      "  7%|▋         | 249/3487 [51:17<8:16:40,  9.20s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5501.67 ms /    29 tokens (  189.71 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.74 ms /     3 runs   (  880.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8145.35 ms /    32 tokens\n",
      "  7%|▋         | 250/3487 [51:25<7:59:31,  8.89s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2866.16 ms /    13 tokens (  220.47 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.32 ms /     3 runs   (  878.44 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5504.00 ms /    16 tokens\n",
      "  7%|▋         | 251/3487 [51:31<7:04:44,  7.88s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1878.59 ms /     8 tokens (  234.82 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.58 ms /     3 runs   (  878.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4515.74 ms /    11 tokens\n",
      "  7%|▋         | 252/3487 [51:35<6:10:22,  6.87s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7311.18 ms /    37 tokens (  197.60 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.87 ms /     3 runs   (  882.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9961.67 ms /    40 tokens\n",
      "  7%|▋         | 253/3487 [51:45<7:00:26,  7.80s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1716.19 ms /     7 tokens (  245.17 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.23 ms /     3 runs   (  882.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4367.17 ms /    10 tokens\n",
      "  7%|▋         | 254/3487 [51:50<6:04:54,  6.77s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1764.11 ms /     8 tokens (  220.51 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.26 ms /     3 runs   (  881.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4412.09 ms /    11 tokens\n",
      "  7%|▋         | 255/3487 [51:54<5:26:45,  6.07s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2006.92 ms /     8 tokens (  250.87 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.19 ms /     3 runs   (  888.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4673.76 ms /    11 tokens\n",
      "  7%|▋         | 256/3487 [51:59<5:04:18,  5.65s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1374.64 ms /     6 tokens (  229.11 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.57 ms /     3 runs   (  878.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4012.00 ms /     9 tokens\n",
      "  7%|▋         | 257/3487 [52:03<4:37:50,  5.16s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2950.66 ms /    14 tokens (  210.76 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.47 ms /     3 runs   (  876.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5583.71 ms /    17 tokens\n",
      "  7%|▋         | 258/3487 [52:08<4:44:43,  5.29s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9538.30 ms /    50 tokens (  190.77 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.45 ms /     3 runs   (  885.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12197.29 ms /    53 tokens\n",
      "  7%|▋         | 259/3487 [52:21<6:36:15,  7.37s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8075.53 ms /    41 tokens (  196.96 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.25 ms /     3 runs   (  879.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10715.35 ms /    44 tokens\n",
      "  7%|▋         | 260/3487 [52:31<7:30:18,  8.37s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4972.29 ms /    25 tokens (  198.89 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.59 ms /     3 runs   (  881.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7620.55 ms /    28 tokens\n",
      "  7%|▋         | 261/3487 [52:39<7:18:10,  8.15s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12255.57 ms /    63 tokens (  194.53 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.17 ms /     3 runs   (  880.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14899.45 ms /    66 tokens\n",
      "  8%|▊         | 262/3487 [52:54<9:07:00, 10.18s/it]Llama.generate: 307 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20331.80 ms /   107 tokens (  190.02 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.54 ms /     3 runs   (  880.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   22975.37 ms /   110 tokens\n",
      "  8%|▊         | 263/3487 [53:17<12:33:16, 14.02s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3879.48 ms /    20 tokens (  193.97 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.20 ms /     3 runs   (  882.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6528.90 ms /    23 tokens\n",
      "  8%|▊         | 264/3487 [53:23<10:32:29, 11.77s/it]Llama.generate: 307 prefix-match hit, remaining 193 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   37242.97 ms /   193 tokens (  192.97 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.72 ms /     3 runs   (  885.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   39900.76 ms /   196 tokens\n",
      "  8%|▊         | 265/3487 [54:03<18:05:32, 20.21s/it]Llama.generate: 312 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15483.72 ms /    82 tokens (  188.83 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2755.28 ms /     3 runs   (  918.43 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   18272.80 ms /    85 tokens\n",
      "  8%|▊         | 266/3487 [54:22<17:34:03, 19.63s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13635.49 ms /    70 tokens (  194.79 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.27 ms /     3 runs   (  877.42 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16269.72 ms /    73 tokens\n",
      "  8%|▊         | 267/3487 [54:38<16:39:41, 18.63s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1977.99 ms /     9 tokens (  219.78 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.44 ms /     3 runs   (  886.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4640.13 ms /    12 tokens\n",
      "  8%|▊         | 268/3487 [54:43<12:54:22, 14.43s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13697.60 ms /    70 tokens (  195.68 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.61 ms /     3 runs   (  883.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16350.77 ms /    73 tokens\n",
      "  8%|▊         | 269/3487 [54:59<13:25:06, 15.01s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2585.68 ms /    12 tokens (  215.47 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.39 ms /     3 runs   (  885.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5244.39 ms /    15 tokens\n",
      "  8%|▊         | 270/3487 [55:04<10:47:53, 12.08s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5559.91 ms /    28 tokens (  198.57 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.90 ms /     3 runs   (  884.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8215.99 ms /    31 tokens\n",
      "  8%|▊         | 271/3487 [55:12<9:45:37, 10.93s/it] Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7927.24 ms /    41 tokens (  193.35 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.28 ms /     3 runs   (  881.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10574.68 ms /    44 tokens\n",
      "  8%|▊         | 272/3487 [55:23<9:39:55, 10.82s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2386.89 ms /    11 tokens (  216.99 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.93 ms /     3 runs   (  873.31 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5009.16 ms /    14 tokens\n",
      "  8%|▊         | 273/3487 [55:28<8:06:25,  9.08s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9541.92 ms /    48 tokens (  198.79 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.70 ms /     3 runs   (  887.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12207.13 ms /    51 tokens\n",
      "  8%|▊         | 274/3487 [55:40<8:56:38, 10.02s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7050.12 ms /    35 tokens (  201.43 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.71 ms /     3 runs   (  876.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9681.21 ms /    38 tokens\n",
      "  8%|▊         | 275/3487 [55:50<8:51:09,  9.92s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3601.03 ms /    18 tokens (  200.06 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.25 ms /     3 runs   (  878.42 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6239.42 ms /    21 tokens\n",
      "  8%|▊         | 276/3487 [55:56<7:52:00,  8.82s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14754.93 ms /    74 tokens (  199.39 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.20 ms /     3 runs   (  875.07 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17382.74 ms /    77 tokens\n",
      "  8%|▊         | 277/3487 [56:14<10:09:24, 11.39s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3586.34 ms /    18 tokens (  199.24 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.22 ms /     3 runs   (  876.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6218.73 ms /    21 tokens\n",
      "  8%|▊         | 278/3487 [56:20<8:46:52,  9.85s/it] Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7078.78 ms /    35 tokens (  202.25 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.61 ms /     3 runs   (  880.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9723.45 ms /    38 tokens\n",
      "  8%|▊         | 279/3487 [56:30<8:44:46,  9.82s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4264.36 ms /    21 tokens (  203.06 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.50 ms /     3 runs   (  880.50 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6908.24 ms /    24 tokens\n",
      "  8%|▊         | 280/3487 [56:36<7:58:08,  8.95s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8367.14 ms /    43 tokens (  194.58 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.55 ms /     3 runs   (  877.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11001.24 ms /    46 tokens\n",
      "  8%|▊         | 281/3487 [56:47<8:31:04,  9.56s/it]Llama.generate: 307 prefix-match hit, remaining 127 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24027.55 ms /   127 tokens (  189.19 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.87 ms /     3 runs   (  882.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   26677.87 ms /   130 tokens\n",
      "  8%|▊         | 282/3487 [57:14<13:05:16, 14.70s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9994.30 ms /    52 tokens (  192.20 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.68 ms /     3 runs   (  909.89 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   12727.32 ms /    55 tokens\n",
      "  8%|▊         | 283/3487 [57:27<12:34:02, 14.12s/it]Llama.generate: 306 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13905.96 ms /    71 tokens (  195.86 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.89 ms /     3 runs   (  887.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16571.85 ms /    74 tokens\n",
      "  8%|▊         | 284/3487 [57:43<13:13:13, 14.86s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8073.70 ms /    39 tokens (  207.02 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.67 ms /     3 runs   (  886.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10734.94 ms /    42 tokens\n",
      "  8%|▊         | 285/3487 [57:54<12:07:06, 13.62s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4453.69 ms /    22 tokens (  202.44 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.74 ms /     3 runs   (  883.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7105.46 ms /    25 tokens\n",
      "  8%|▊         | 286/3487 [58:01<10:23:09, 11.68s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5441.85 ms /    28 tokens (  194.35 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.74 ms /     3 runs   (  874.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8068.63 ms /    31 tokens\n",
      "  8%|▊         | 287/3487 [58:09<9:25:15, 10.60s/it] Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2028.17 ms /     8 tokens (  253.52 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.08 ms /     3 runs   (  876.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4658.07 ms /    11 tokens\n",
      "  8%|▊         | 288/3487 [58:14<7:50:12,  8.82s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3827.37 ms /    19 tokens (  201.44 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.13 ms /     3 runs   (  882.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6476.95 ms /    22 tokens\n",
      "  8%|▊         | 289/3487 [58:21<7:12:44,  8.12s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9202.63 ms /    47 tokens (  195.80 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.86 ms /     3 runs   (  885.29 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11861.16 ms /    50 tokens\n",
      "  8%|▊         | 290/3487 [58:32<8:12:32,  9.24s/it]Llama.generate: 307 prefix-match hit, remaining 193 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   37110.15 ms /   193 tokens (  192.28 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2880.08 ms /     3 runs   (  960.03 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   39992.72 ms /   196 tokens\n",
      "  8%|▊         | 291/3487 [59:13<16:24:27, 18.48s/it]Llama.generate: 307 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14927.71 ms /    79 tokens (  188.96 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.79 ms /     3 runs   (  881.26 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17574.09 ms /    82 tokens\n",
      "  8%|▊         | 292/3487 [59:30<16:09:48, 18.21s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5374.05 ms /    28 tokens (  191.93 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.61 ms /     3 runs   (  881.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8020.76 ms /    31 tokens\n",
      "  8%|▊         | 293/3487 [59:38<13:26:53, 15.16s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13359.28 ms /    69 tokens (  193.61 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.88 ms /     3 runs   (  882.96 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16010.73 ms /    72 tokens\n",
      "  8%|▊         | 294/3487 [59:54<13:40:23, 15.42s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7158.30 ms /    34 tokens (  210.54 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.84 ms /     3 runs   (  874.95 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9785.26 ms /    37 tokens\n",
      "  8%|▊         | 295/3487 [1:00:04<12:10:53, 13.74s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3336.95 ms /    16 tokens (  208.56 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.14 ms /     3 runs   (  876.05 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5967.47 ms /    19 tokens\n",
      "  8%|▊         | 296/3487 [1:00:10<10:06:47, 11.41s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2888.14 ms /    14 tokens (  206.30 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.65 ms /     3 runs   (  887.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5553.78 ms /    17 tokens\n",
      "  9%|▊         | 297/3487 [1:00:16<8:33:22,  9.66s/it] Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2073.77 ms /     9 tokens (  230.42 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.44 ms /     3 runs   (  878.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4711.06 ms /    12 tokens\n",
      "  9%|▊         | 298/3487 [1:00:20<7:14:30,  8.18s/it]Llama.generate: 307 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16481.80 ms /    87 tokens (  189.45 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2602.15 ms /     3 runs   (  867.38 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   19086.37 ms /    90 tokens\n",
      "  9%|▊         | 299/3487 [1:00:39<10:08:25, 11.45s/it]Llama.generate: 306 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11549.78 ms /    61 tokens (  189.34 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2606.58 ms /     3 runs   (  868.86 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14159.08 ms /    64 tokens\n",
      "  9%|▊         | 300/3487 [1:00:53<10:51:29, 12.27s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3789.64 ms /    19 tokens (  199.45 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.60 ms /     3 runs   (  879.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6429.66 ms /    22 tokens\n",
      "  9%|▊         | 301/3487 [1:01:00<9:18:26, 10.52s/it] Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5499.85 ms /    27 tokens (  203.70 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.95 ms /     3 runs   (  885.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8158.18 ms /    30 tokens\n",
      "  9%|▊         | 302/3487 [1:01:08<8:40:51,  9.81s/it]Llama.generate: 307 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24991.26 ms /   133 tokens (  187.90 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2606.74 ms /     3 runs   (  868.91 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   27600.27 ms /   136 tokens\n",
      "  9%|▊         | 303/3487 [1:01:36<13:24:31, 15.16s/it]Llama.generate: 307 prefix-match hit, remaining 194 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   36274.08 ms /   194 tokens (  186.98 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.24 ms /     3 runs   (  872.75 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   38894.96 ms /   197 tokens\n",
      "  9%|▊         | 304/3487 [1:02:15<19:42:05, 22.28s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7890.25 ms /    40 tokens (  197.26 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.99 ms /     3 runs   (  870.66 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10504.81 ms /    43 tokens\n",
      "  9%|▊         | 305/3487 [1:02:25<16:34:29, 18.75s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8562.05 ms /    45 tokens (  190.27 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.85 ms /     3 runs   (  876.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11193.90 ms /    48 tokens\n",
      "  9%|▉         | 306/3487 [1:02:36<14:34:03, 16.49s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11205.64 ms /    59 tokens (  189.93 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2880.39 ms /     3 runs   (  960.13 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   14088.48 ms /    62 tokens\n",
      "  9%|▉         | 307/3487 [1:02:50<13:55:46, 15.77s/it]Llama.generate: 306 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14488.48 ms /    77 tokens (  188.16 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2610.63 ms /     3 runs   (  870.21 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   17133.55 ms /    80 tokens\n",
      "  9%|▉         | 308/3487 [1:03:08<14:17:21, 16.18s/it]Llama.generate: 307 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15048.72 ms /    80 tokens (  188.11 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.92 ms /     3 runs   (  876.64 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17720.26 ms /    83 tokens\n",
      "  9%|▉         | 309/3487 [1:03:25<14:41:40, 16.65s/it]Llama.generate: 307 prefix-match hit, remaining 99 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18917.45 ms /    99 tokens (  191.09 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2606.43 ms /     3 runs   (  868.81 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   21527.51 ms /   102 tokens\n",
      "  9%|▉         | 310/3487 [1:03:47<15:59:04, 18.11s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1747.26 ms /     7 tokens (  249.61 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.16 ms /     3 runs   (  871.39 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4363.53 ms /    10 tokens\n",
      "  9%|▉         | 311/3487 [1:03:51<12:20:35, 13.99s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7171.41 ms /    36 tokens (  199.21 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.79 ms /     3 runs   (  878.93 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9810.90 ms /    39 tokens\n",
      "  9%|▉         | 312/3487 [1:04:01<11:14:06, 12.74s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7018.32 ms /    33 tokens (  212.68 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.61 ms /     3 runs   (  875.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9646.19 ms /    36 tokens\n",
      "  9%|▉         | 313/3487 [1:04:11<10:24:58, 11.81s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2805.38 ms /    13 tokens (  215.80 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.39 ms /     3 runs   (  874.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5432.19 ms /    16 tokens\n",
      "  9%|▉         | 314/3487 [1:04:16<8:44:07,  9.91s/it] Llama.generate: 306 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19054.24 ms /   100 tokens (  190.54 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.74 ms /     3 runs   (  874.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21679.39 ms /   103 tokens\n",
      "  9%|▉         | 315/3487 [1:04:38<11:50:43, 13.44s/it]Llama.generate: 307 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13864.37 ms /    73 tokens (  189.92 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2610.30 ms /     3 runs   (  870.10 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   16477.52 ms /    76 tokens\n",
      "  9%|▉         | 316/3487 [1:04:54<12:38:44, 14.36s/it]Llama.generate: 307 prefix-match hit, remaining 134 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25321.90 ms /   134 tokens (  188.97 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.18 ms /     3 runs   (  876.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27954.47 ms /   137 tokens\n",
      "  9%|▉         | 317/3487 [1:05:22<16:14:08, 18.44s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9206.96 ms /    49 tokens (  187.90 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2610.33 ms /     3 runs   (  870.11 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11820.10 ms /    52 tokens\n",
      "  9%|▉         | 318/3487 [1:05:34<14:29:06, 16.46s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9292.85 ms /    49 tokens (  189.65 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.41 ms /     3 runs   (  871.14 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11908.75 ms /    52 tokens\n",
      "  9%|▉         | 319/3487 [1:05:46<13:16:57, 15.09s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5324.11 ms /    28 tokens (  190.15 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.00 ms /     3 runs   (  873.00 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7946.04 ms /    31 tokens\n",
      "  9%|▉         | 320/3487 [1:05:54<11:23:37, 12.95s/it]Llama.generate: 307 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17851.95 ms /    93 tokens (  191.96 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.86 ms /     3 runs   (  873.29 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   20474.45 ms /    96 tokens\n",
      "  9%|▉         | 321/3487 [1:06:14<13:22:36, 15.21s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10904.65 ms /    59 tokens (  184.82 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.86 ms /     3 runs   (  871.29 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   13521.48 ms /    62 tokens\n",
      "  9%|▉         | 322/3487 [1:06:28<12:55:45, 14.71s/it]Llama.generate: 306 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16266.99 ms /    87 tokens (  186.98 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.36 ms /     3 runs   (  871.79 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   18884.71 ms /    90 tokens\n",
      "  9%|▉         | 323/3487 [1:06:47<14:01:41, 15.96s/it]Llama.generate: 307 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13598.67 ms /    71 tokens (  191.53 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.58 ms /     3 runs   (  873.53 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16222.05 ms /    74 tokens\n",
      "  9%|▉         | 324/3487 [1:07:03<14:05:39, 16.04s/it]Llama.generate: 309 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7886.53 ms /    41 tokens (  192.35 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2608.59 ms /     3 runs   (  869.53 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10497.02 ms /    44 tokens\n",
      "  9%|▉         | 325/3487 [1:07:14<12:37:52, 14.38s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8139.48 ms /    42 tokens (  193.80 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2601.26 ms /     3 runs   (  867.09 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10743.69 ms /    45 tokens\n",
      "  9%|▉         | 326/3487 [1:07:24<11:40:16, 13.29s/it]Llama.generate: 306 prefix-match hit, remaining 106 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20128.37 ms /   106 tokens (  189.89 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.68 ms /     3 runs   (  878.23 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   22765.77 ms /   109 tokens\n",
      "  9%|▉         | 327/3487 [1:07:47<14:09:51, 16.14s/it]Llama.generate: 306 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10549.35 ms /    55 tokens (  191.81 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.44 ms /     3 runs   (  876.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13182.54 ms /    58 tokens\n",
      "  9%|▉         | 328/3487 [1:08:00<13:23:03, 15.25s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7251.63 ms /    37 tokens (  195.99 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2609.70 ms /     3 runs   (  869.90 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9864.20 ms /    40 tokens\n",
      "  9%|▉         | 329/3487 [1:08:10<11:57:51, 13.64s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3715.72 ms /    19 tokens (  195.56 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.46 ms /     3 runs   (  871.15 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6331.26 ms /    22 tokens\n",
      "  9%|▉         | 330/3487 [1:08:17<10:02:53, 11.46s/it]Llama.generate: 307 prefix-match hit, remaining 147 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27608.57 ms /   147 tokens (  187.81 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.39 ms /     3 runs   (  872.13 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   30227.61 ms /   150 tokens\n",
      "  9%|▉         | 331/3487 [1:08:47<14:59:00, 17.09s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5558.13 ms /    30 tokens (  185.27 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.34 ms /     3 runs   (  870.45 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8172.12 ms /    33 tokens\n",
      " 10%|▉         | 332/3487 [1:08:55<12:38:11, 14.42s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1533.60 ms /     6 tokens (  255.60 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.10 ms /     3 runs   (  882.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4181.86 ms /     9 tokens\n",
      " 10%|▉         | 333/3487 [1:08:59<9:56:37, 11.35s/it] Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11000.77 ms /    59 tokens (  186.45 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2765.74 ms /     3 runs   (  921.91 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   13769.18 ms /    62 tokens\n",
      " 10%|▉         | 334/3487 [1:09:13<10:34:42, 12.08s/it]Llama.generate: 307 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15043.97 ms /    80 tokens (  188.05 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.16 ms /     3 runs   (  876.05 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17674.52 ms /    83 tokens\n",
      " 10%|▉         | 335/3487 [1:09:31<12:02:49, 13.76s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6966.65 ms /    34 tokens (  204.90 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.35 ms /     3 runs   (  871.45 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9583.73 ms /    37 tokens\n",
      " 10%|▉         | 336/3487 [1:09:40<10:56:57, 12.51s/it]Llama.generate: 306 prefix-match hit, remaining 81 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15819.07 ms /    81 tokens (  195.30 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.39 ms /     3 runs   (  908.13 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   18546.35 ms /    84 tokens\n",
      " 10%|▉         | 337/3487 [1:09:59<12:31:58, 14.32s/it]Llama.generate: 307 prefix-match hit, remaining 99 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19511.66 ms /    99 tokens (  197.09 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.66 ms /     3 runs   (  899.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   22214.10 ms /   102 tokens\n",
      " 10%|▉         | 338/3487 [1:10:21<14:36:07, 16.69s/it]Llama.generate: 307 prefix-match hit, remaining 188 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   37490.14 ms /   188 tokens (  199.42 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.97 ms /     3 runs   (  880.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   40133.53 ms /   191 tokens\n",
      " 10%|▉         | 339/3487 [1:11:01<20:44:56, 23.73s/it]Llama.generate: 307 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11185.95 ms /    55 tokens (  203.38 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.94 ms /     3 runs   (  879.98 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13828.17 ms /    58 tokens\n",
      " 10%|▉         | 340/3487 [1:11:15<18:08:52, 20.76s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4097.17 ms /    20 tokens (  204.86 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.72 ms /     3 runs   (  879.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6737.64 ms /    23 tokens\n",
      " 10%|▉         | 341/3487 [1:11:22<14:28:07, 16.56s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7430.09 ms /    35 tokens (  212.29 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.76 ms /     3 runs   (  874.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10057.42 ms /    38 tokens\n",
      " 10%|▉         | 342/3487 [1:11:32<12:45:45, 14.61s/it]Llama.generate: 307 prefix-match hit, remaining 81 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16398.70 ms /    81 tokens (  202.45 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.73 ms /     3 runs   (  877.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19034.07 ms /    84 tokens\n",
      " 10%|▉         | 343/3487 [1:11:51<13:55:13, 15.94s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5131.58 ms /    25 tokens (  205.26 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.13 ms /     3 runs   (  874.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7757.32 ms /    28 tokens\n",
      " 10%|▉         | 344/3487 [1:11:59<11:46:29, 13.49s/it]Llama.generate: 307 prefix-match hit, remaining 96 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19057.17 ms /    96 tokens (  198.51 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.41 ms /     3 runs   (  873.80 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21681.12 ms /    99 tokens\n",
      " 10%|▉         | 345/3487 [1:12:20<13:55:09, 15.95s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4706.48 ms /    23 tokens (  204.63 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2852.14 ms /     3 runs   (  950.71 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    7560.94 ms /    26 tokens\n",
      " 10%|▉         | 346/3487 [1:12:28<11:43:47, 13.44s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7367.57 ms /    35 tokens (  210.50 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.69 ms /     3 runs   (  873.90 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9991.59 ms /    38 tokens\n",
      " 10%|▉         | 347/3487 [1:12:38<10:49:29, 12.41s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4821.90 ms /    24 tokens (  200.91 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.44 ms /     3 runs   (  872.81 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7442.82 ms /    27 tokens\n",
      " 10%|▉         | 348/3487 [1:12:45<9:31:26, 10.92s/it] Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2823.60 ms /    13 tokens (  217.20 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.35 ms /     3 runs   (  903.78 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5537.27 ms /    16 tokens\n",
      " 10%|█         | 349/3487 [1:12:51<8:06:52,  9.31s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2212.65 ms /     7 tokens (  316.09 ms per token,     3.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.08 ms /     3 runs   (  879.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4852.45 ms /    10 tokens\n",
      " 10%|█         | 350/3487 [1:12:56<6:56:57,  7.97s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9945.58 ms /    50 tokens (  198.91 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.95 ms /     3 runs   (  878.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12583.81 ms /    53 tokens\n",
      " 10%|█         | 351/3487 [1:13:08<8:09:12,  9.36s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12339.63 ms /    64 tokens (  192.81 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.89 ms /     3 runs   (  888.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15009.34 ms /    67 tokens\n",
      " 10%|█         | 352/3487 [1:13:23<9:37:44, 11.06s/it]Llama.generate: 306 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20030.25 ms /   102 tokens (  196.38 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.37 ms /     3 runs   (  877.79 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   22698.48 ms /   105 tokens\n",
      " 10%|█         | 353/3487 [1:13:46<12:40:05, 14.55s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6190.89 ms /    31 tokens (  199.71 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.43 ms /     3 runs   (  885.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8850.34 ms /    34 tokens\n",
      " 10%|█         | 354/3487 [1:13:55<11:10:40, 12.84s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1830.52 ms /     8 tokens (  228.81 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.19 ms /     3 runs   (  902.06 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4538.85 ms /    11 tokens\n",
      " 10%|█         | 355/3487 [1:14:00<9:00:32, 10.36s/it] Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2545.83 ms /    11 tokens (  231.44 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.16 ms /     3 runs   (  878.05 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5182.86 ms /    14 tokens\n",
      " 10%|█         | 356/3487 [1:14:05<7:39:34,  8.81s/it]Llama.generate: 306 prefix-match hit, remaining 123 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24362.26 ms /   123 tokens (  198.07 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.16 ms /     3 runs   (  879.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27003.18 ms /   126 tokens\n",
      " 10%|█         | 357/3487 [1:14:32<12:24:19, 14.27s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4277.45 ms /    21 tokens (  203.69 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.27 ms /     3 runs   (  889.42 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6948.17 ms /    24 tokens\n",
      " 10%|█         | 358/3487 [1:14:39<10:29:40, 12.07s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1962.36 ms /     8 tokens (  245.29 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.64 ms /     3 runs   (  879.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4605.18 ms /    11 tokens\n",
      " 10%|█         | 359/3487 [1:14:43<8:32:45,  9.84s/it] Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11669.15 ms /    59 tokens (  197.78 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.58 ms /     3 runs   (  882.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14320.85 ms /    62 tokens\n",
      " 10%|█         | 360/3487 [1:14:58<9:43:23, 11.19s/it]Llama.generate: 307 prefix-match hit, remaining 181 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   35089.50 ms /   181 tokens (  193.86 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.31 ms /     3 runs   (  881.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   37738.33 ms /   184 tokens\n",
      " 10%|█         | 361/3487 [1:15:35<16:38:13, 19.16s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7496.08 ms /    36 tokens (  208.22 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.15 ms /     3 runs   (  882.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10146.62 ms /    39 tokens\n",
      " 10%|█         | 362/3487 [1:15:46<14:17:13, 16.46s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3440.09 ms /    16 tokens (  215.01 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.47 ms /     3 runs   (  891.49 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6116.82 ms /    19 tokens\n",
      " 10%|█         | 363/3487 [1:15:52<11:35:32, 13.36s/it]Llama.generate: 307 prefix-match hit, remaining 188 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   36757.10 ms /   188 tokens (  195.52 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.86 ms /     3 runs   (  885.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   39418.07 ms /   191 tokens\n",
      " 10%|█         | 364/3487 [1:16:31<18:22:23, 21.18s/it]Llama.generate: 307 prefix-match hit, remaining 134 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25942.63 ms /   134 tokens (  193.60 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.39 ms /     3 runs   (  879.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   28582.43 ms /   137 tokens\n",
      " 10%|█         | 365/3487 [1:17:00<20:17:43, 23.40s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12034.86 ms /    62 tokens (  194.11 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.49 ms /     3 runs   (  881.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14680.87 ms /    65 tokens\n",
      " 10%|█         | 366/3487 [1:17:14<18:01:21, 20.79s/it]Llama.generate: 307 prefix-match hit, remaining 161 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   31964.61 ms /   161 tokens (  198.54 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3253.57 ms /     3 runs   ( 1084.52 ms per token,     0.92 tokens per second)\n",
      "llama_perf_context_print:       total time =   35221.05 ms /   164 tokens\n",
      " 11%|█         | 367/3487 [1:17:50<21:46:17, 25.12s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10499.31 ms /    46 tokens (  228.25 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2792.01 ms /     3 runs   (  930.67 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   13293.97 ms /    49 tokens\n",
      " 11%|█         | 368/3487 [1:18:03<18:41:35, 21.58s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9474.12 ms /    42 tokens (  225.57 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2770.31 ms /     3 runs   (  923.44 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   12247.39 ms /    45 tokens\n",
      " 11%|█         | 369/3487 [1:18:15<16:15:56, 18.78s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4113.79 ms /    20 tokens (  205.69 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.89 ms /     3 runs   (  877.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6750.64 ms /    23 tokens\n",
      " 11%|█         | 370/3487 [1:18:22<13:08:17, 15.17s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8047.65 ms /    39 tokens (  206.35 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.87 ms /     3 runs   (  876.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10680.74 ms /    42 tokens\n",
      " 11%|█         | 371/3487 [1:18:33<11:58:08, 13.83s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5351.37 ms /    27 tokens (  198.20 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.77 ms /     3 runs   (  890.92 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8027.11 ms /    30 tokens\n",
      " 11%|█         | 372/3487 [1:18:41<10:27:40, 12.09s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2820.76 ms /    13 tokens (  216.98 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.60 ms /     3 runs   (  884.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5477.69 ms /    16 tokens\n",
      " 11%|█         | 373/3487 [1:18:46<8:44:39, 10.11s/it] Llama.generate: 307 prefix-match hit, remaining 187 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   36057.02 ms /   187 tokens (  192.82 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.89 ms /     3 runs   (  884.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   38713.92 ms /   190 tokens\n",
      " 11%|█         | 374/3487 [1:19:25<16:09:53, 18.69s/it]Llama.generate: 307 prefix-match hit, remaining 229 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   44272.86 ms /   229 tokens (  193.33 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.59 ms /     3 runs   (  876.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   46906.55 ms /   232 tokens\n",
      " 11%|█         | 375/3487 [1:20:12<23:28:43, 27.16s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6413.57 ms /    32 tokens (  200.42 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.08 ms /     3 runs   (  889.03 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9083.73 ms /    35 tokens\n",
      " 11%|█         | 376/3487 [1:20:21<18:47:14, 21.74s/it]Llama.generate: 307 prefix-match hit, remaining 145 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27681.10 ms /   145 tokens (  190.90 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.35 ms /     3 runs   (  883.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   30334.79 ms /   148 tokens\n",
      " 11%|█         | 377/3487 [1:20:51<21:00:38, 24.32s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4150.01 ms /    20 tokens (  207.50 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.88 ms /     3 runs   (  878.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6788.28 ms /    23 tokens\n",
      " 11%|█         | 378/3487 [1:20:58<16:27:49, 19.06s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8141.61 ms /    40 tokens (  203.54 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.81 ms /     3 runs   (  874.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10769.08 ms /    43 tokens\n",
      " 11%|█         | 379/3487 [1:21:09<14:18:44, 16.58s/it]Llama.generate: 306 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21341.52 ms /   108 tokens (  197.61 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.06 ms /     3 runs   (  882.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   24008.57 ms /   111 tokens\n",
      " 11%|█         | 380/3487 [1:21:33<16:14:03, 18.81s/it]Llama.generate: 307 prefix-match hit, remaining 185 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   35384.18 ms /   185 tokens (  191.27 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.61 ms /     3 runs   (  878.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   38021.63 ms /   188 tokens\n",
      " 11%|█         | 381/3487 [1:22:11<21:12:14, 24.58s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5054.15 ms /    25 tokens (  202.17 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.98 ms /     3 runs   (  880.66 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7699.23 ms /    28 tokens\n",
      " 11%|█         | 382/3487 [1:22:19<16:49:57, 19.52s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14485.27 ms /    74 tokens (  195.75 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.77 ms /     3 runs   (  875.59 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17114.99 ms /    77 tokens\n",
      " 11%|█         | 383/3487 [1:22:36<16:12:30, 18.80s/it]Llama.generate: 306 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14231.84 ms /    73 tokens (  194.96 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.82 ms /     3 runs   (  875.61 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16861.13 ms /    76 tokens\n",
      " 11%|█         | 384/3487 [1:22:53<15:42:15, 18.22s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5146.73 ms /    26 tokens (  197.95 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2870.20 ms /     3 runs   (  956.73 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    8019.98 ms /    29 tokens\n",
      " 11%|█         | 385/3487 [1:23:01<13:03:53, 15.16s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7124.19 ms /    33 tokens (  215.88 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.72 ms /     3 runs   (  879.57 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9766.01 ms /    36 tokens\n",
      " 11%|█         | 386/3487 [1:23:10<11:40:07, 13.55s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8841.14 ms /    34 tokens (  260.03 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2775.52 ms /     3 runs   (  925.17 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   11619.19 ms /    37 tokens\n",
      " 11%|█         | 387/3487 [1:23:22<11:10:12, 12.97s/it]Llama.generate: 306 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20329.97 ms /   105 tokens (  193.62 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.32 ms /     3 runs   (  889.77 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   23002.11 ms /   108 tokens\n",
      " 11%|█         | 388/3487 [1:23:45<13:45:34, 15.98s/it]Llama.generate: 307 prefix-match hit, remaining 91 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17307.41 ms /    91 tokens (  190.19 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.37 ms /     3 runs   (  879.12 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19978.48 ms /    94 tokens\n",
      " 11%|█         | 389/3487 [1:24:05<14:47:20, 17.19s/it]Llama.generate: 307 prefix-match hit, remaining 101 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20247.48 ms /   101 tokens (  200.47 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2786.59 ms /     3 runs   (  928.86 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   23037.25 ms /   104 tokens\n",
      " 11%|█         | 390/3487 [1:24:28<16:17:50, 18.94s/it]Llama.generate: 307 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14018.95 ms /    66 tokens (  212.41 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2793.52 ms /     3 runs   (  931.17 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   16847.34 ms /    69 tokens\n",
      " 11%|█         | 391/3487 [1:24:45<15:45:12, 18.32s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9408.84 ms /    46 tokens (  204.54 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2787.95 ms /     3 runs   (  929.32 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   12199.55 ms /    49 tokens\n",
      " 11%|█         | 392/3487 [1:24:57<14:10:23, 16.49s/it]Llama.generate: 307 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20522.93 ms /   102 tokens (  201.21 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.23 ms /     3 runs   (  882.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23173.93 ms /   105 tokens\n",
      " 11%|█▏        | 393/3487 [1:25:20<15:54:11, 18.50s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5239.68 ms /    26 tokens (  201.53 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.43 ms /     3 runs   (  873.14 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7861.75 ms /    29 tokens\n",
      " 11%|█▏        | 394/3487 [1:25:28<13:09:26, 15.31s/it]Llama.generate: 307 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14742.89 ms /    77 tokens (  191.47 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.30 ms /     3 runs   (  876.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17376.71 ms /    80 tokens\n",
      " 11%|█▏        | 395/3487 [1:25:46<13:41:42, 15.95s/it]Llama.generate: 306 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20683.71 ms /   108 tokens (  191.52 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.26 ms /     3 runs   (  878.75 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   23323.11 ms /   111 tokens\n",
      " 11%|█▏        | 396/3487 [1:26:09<15:35:38, 18.16s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12036.67 ms /    62 tokens (  194.14 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.14 ms /     3 runs   (  874.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14662.02 ms /    65 tokens\n",
      " 11%|█▏        | 397/3487 [1:26:24<14:41:54, 17.12s/it]Llama.generate: 306 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13935.85 ms /    73 tokens (  190.90 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.10 ms /     3 runs   (  874.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16560.26 ms /    76 tokens\n",
      " 11%|█▏        | 398/3487 [1:26:40<14:33:03, 16.96s/it]Llama.generate: 306 prefix-match hit, remaining 145 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27510.33 ms /   145 tokens (  189.73 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.48 ms /     3 runs   (  871.49 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   30127.11 ms /   148 tokens\n",
      " 11%|█▏        | 399/3487 [1:27:10<17:56:13, 20.91s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11581.00 ms /    60 tokens (  193.02 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.57 ms /     3 runs   (  870.52 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14195.23 ms /    63 tokens\n",
      " 11%|█▏        | 400/3487 [1:27:25<16:12:20, 18.90s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3033.30 ms /    14 tokens (  216.66 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.03 ms /     3 runs   (  900.34 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5736.65 ms /    17 tokens\n",
      " 11%|█▏        | 401/3487 [1:27:30<12:49:05, 14.95s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6289.90 ms /    32 tokens (  196.56 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.20 ms /     3 runs   (  882.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8938.93 ms /    35 tokens\n",
      " 12%|█▏        | 402/3487 [1:27:39<11:16:11, 13.15s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9187.78 ms /    47 tokens (  195.48 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.51 ms /     3 runs   (  881.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11834.67 ms /    50 tokens\n",
      " 12%|█▏        | 403/3487 [1:27:51<10:55:48, 12.76s/it]Llama.generate: 308 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13794.25 ms /    68 tokens (  202.86 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.34 ms /     3 runs   (  871.11 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   16410.43 ms /    71 tokens\n",
      " 12%|█▏        | 404/3487 [1:28:07<11:51:59, 13.86s/it]Llama.generate: 308 prefix-match hit, remaining 189 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   35525.20 ms /   189 tokens (  187.96 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.54 ms /     3 runs   (  873.51 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   38148.52 ms /   192 tokens\n",
      " 12%|█▏        | 405/3487 [1:28:46<18:06:13, 21.15s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13087.52 ms /    67 tokens (  195.34 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.79 ms /     3 runs   (  878.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15724.83 ms /    70 tokens\n",
      " 12%|█▏        | 406/3487 [1:29:01<16:42:29, 19.52s/it]Llama.generate: 307 prefix-match hit, remaining 140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26724.80 ms /   140 tokens (  190.89 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.83 ms /     3 runs   (  871.61 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   29342.39 ms /   143 tokens\n",
      " 12%|█▏        | 407/3487 [1:29:31<19:13:31, 22.47s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11042.43 ms /    57 tokens (  193.73 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.30 ms /     3 runs   (  874.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13668.17 ms /    60 tokens\n",
      " 12%|█▏        | 408/3487 [1:29:44<16:57:43, 19.83s/it]Llama.generate: 308 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10781.34 ms /    56 tokens (  192.52 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2758.31 ms /     3 runs   (  919.44 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   13542.66 ms /    59 tokens\n",
      " 12%|█▏        | 409/3487 [1:29:58<15:21:05, 17.95s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8335.16 ms /    42 tokens (  198.46 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.71 ms /     3 runs   (  910.57 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   11069.77 ms /    45 tokens\n",
      " 12%|█▏        | 410/3487 [1:30:09<13:35:00, 15.89s/it]Llama.generate: 306 prefix-match hit, remaining 85 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20430.49 ms /    85 tokens (  240.36 ms per token,     4.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2908.52 ms /     3 runs   (  969.51 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   23342.20 ms /    88 tokens\n",
      " 12%|█▏        | 411/3487 [1:30:32<15:29:27, 18.13s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9377.99 ms /    46 tokens (  203.87 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.18 ms /     3 runs   (  891.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12054.56 ms /    49 tokens\n",
      " 12%|█▏        | 412/3487 [1:30:44<13:55:53, 16.31s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3066.98 ms /    15 tokens (  204.47 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.96 ms /     3 runs   (  901.65 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5774.60 ms /    18 tokens\n",
      " 12%|█▏        | 413/3487 [1:30:50<11:13:48, 13.15s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7241.00 ms /    34 tokens (  212.97 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.52 ms /     3 runs   (  889.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9911.94 ms /    37 tokens\n",
      " 12%|█▏        | 414/3487 [1:31:00<10:23:57, 12.18s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5920.76 ms /    30 tokens (  197.36 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.76 ms /     3 runs   (  881.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8566.98 ms /    33 tokens\n",
      " 12%|█▏        | 415/3487 [1:31:09<9:28:20, 11.10s/it] Llama.generate: 313 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7646.76 ms /    35 tokens (  218.48 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.60 ms /     3 runs   (  900.53 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10351.07 ms /    38 tokens\n",
      " 12%|█▏        | 416/3487 [1:31:19<9:16:48, 10.88s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9577.97 ms /    48 tokens (  199.54 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.91 ms /     3 runs   (  889.64 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12249.84 ms /    51 tokens\n",
      " 12%|█▏        | 417/3487 [1:31:31<9:37:47, 11.29s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7584.29 ms /    38 tokens (  199.59 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.30 ms /     3 runs   (  884.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10239.84 ms /    41 tokens\n",
      " 12%|█▏        | 418/3487 [1:31:42<9:21:34, 10.98s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10529.56 ms /    53 tokens (  198.67 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.53 ms /     3 runs   (  881.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13176.03 ms /    56 tokens\n",
      " 12%|█▏        | 419/3487 [1:31:55<9:55:11, 11.64s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4148.99 ms /    20 tokens (  207.45 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.27 ms /     3 runs   (  889.42 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6819.81 ms /    23 tokens\n",
      " 12%|█▏        | 420/3487 [1:32:02<8:41:12, 10.20s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5404.58 ms /    27 tokens (  200.17 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.10 ms /     3 runs   (  882.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8054.60 ms /    30 tokens\n",
      " 12%|█▏        | 421/3487 [1:32:10<8:08:19,  9.56s/it]Llama.generate: 308 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5405.67 ms /    27 tokens (  200.21 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.75 ms /     3 runs   (  891.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8083.45 ms /    30 tokens\n",
      " 12%|█▏        | 422/3487 [1:32:18<7:45:45,  9.12s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5729.72 ms /    28 tokens (  204.63 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.84 ms /     3 runs   (  881.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8377.01 ms /    31 tokens\n",
      " 12%|█▏        | 423/3487 [1:32:26<7:34:21,  8.90s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7237.17 ms /    35 tokens (  206.78 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.65 ms /     3 runs   (  879.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9877.23 ms /    38 tokens\n",
      " 12%|█▏        | 424/3487 [1:32:36<7:49:19,  9.19s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10311.50 ms /    53 tokens (  194.56 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.34 ms /     3 runs   (  892.11 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12990.31 ms /    56 tokens\n",
      " 12%|█▏        | 425/3487 [1:32:49<8:47:25, 10.33s/it]Llama.generate: 306 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20079.38 ms /   100 tokens (  200.79 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.30 ms /     3 runs   (  890.43 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   22753.51 ms /   103 tokens\n",
      " 12%|█▏        | 426/3487 [1:33:12<11:57:54, 14.07s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7414.17 ms /    36 tokens (  205.95 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.47 ms /     3 runs   (  886.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10077.24 ms /    39 tokens\n",
      " 12%|█▏        | 427/3487 [1:33:22<10:56:40, 12.88s/it]Llama.generate: 308 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9195.97 ms /    46 tokens (  199.91 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.31 ms /     3 runs   (  882.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11845.02 ms /    49 tokens\n",
      " 12%|█▏        | 428/3487 [1:33:34<10:40:49, 12.57s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3089.22 ms /    14 tokens (  220.66 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.96 ms /     3 runs   (  883.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5744.27 ms /    17 tokens\n",
      " 12%|█▏        | 429/3487 [1:33:40<8:56:21, 10.52s/it] Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3487.72 ms /    16 tokens (  217.98 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.43 ms /     3 runs   (  896.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6179.38 ms /    19 tokens\n",
      " 12%|█▏        | 430/3487 [1:33:46<7:49:57,  9.22s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10088.18 ms /    51 tokens (  197.81 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2714.87 ms /     3 runs   (  904.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   12805.64 ms /    54 tokens\n",
      " 12%|█▏        | 431/3487 [1:33:59<8:44:39, 10.30s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8205.36 ms /    40 tokens (  205.13 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.02 ms /     3 runs   (  884.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10862.40 ms /    43 tokens\n",
      " 12%|█▏        | 432/3487 [1:34:09<8:53:14, 10.47s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2375.55 ms /    11 tokens (  215.96 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.45 ms /     3 runs   (  884.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5030.28 ms /    14 tokens\n",
      " 12%|█▏        | 433/3487 [1:34:14<7:30:04,  8.84s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4657.49 ms /    23 tokens (  202.50 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.98 ms /     3 runs   (  889.66 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7329.14 ms /    26 tokens\n",
      " 12%|█▏        | 434/3487 [1:34:22<7:06:59,  8.39s/it]Llama.generate: 307 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17627.66 ms /    90 tokens (  195.86 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.69 ms /     3 runs   (  896.90 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   20321.91 ms /    93 tokens\n",
      " 12%|█▏        | 435/3487 [1:34:42<10:09:03, 11.97s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2173.37 ms /     9 tokens (  241.49 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.90 ms /     3 runs   (  890.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4849.10 ms /    12 tokens\n",
      " 13%|█▎        | 436/3487 [1:34:47<8:20:18,  9.84s/it] Llama.generate: 306 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10392.64 ms /    53 tokens (  196.09 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.33 ms /     3 runs   (  891.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13069.63 ms /    56 tokens\n",
      " 13%|█▎        | 437/3487 [1:35:00<9:09:31, 10.81s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8175.54 ms /    41 tokens (  199.40 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.18 ms /     3 runs   (  887.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10838.76 ms /    44 tokens\n",
      " 13%|█▎        | 438/3487 [1:35:11<9:09:54, 10.82s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1727.53 ms /     7 tokens (  246.79 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.39 ms /     3 runs   (  887.80 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4393.52 ms /    10 tokens\n",
      " 13%|█▎        | 439/3487 [1:35:15<7:31:54,  8.90s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3982.12 ms /    18 tokens (  221.23 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.35 ms /     3 runs   (  894.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6669.17 ms /    21 tokens\n",
      " 13%|█▎        | 440/3487 [1:35:22<6:57:57,  8.23s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2782.22 ms /    13 tokens (  214.02 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.44 ms /     3 runs   (  876.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5413.20 ms /    16 tokens\n",
      " 13%|█▎        | 441/3487 [1:35:27<6:15:03,  7.39s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8357.89 ms /    42 tokens (  199.00 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.40 ms /     3 runs   (  879.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10998.54 ms /    45 tokens\n",
      " 13%|█▎        | 442/3487 [1:35:38<7:10:02,  8.47s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5328.56 ms /    27 tokens (  197.35 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.80 ms /     3 runs   (  887.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7993.07 ms /    30 tokens\n",
      " 13%|█▎        | 443/3487 [1:35:46<7:02:44,  8.33s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5884.12 ms /    29 tokens (  202.90 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.01 ms /     3 runs   (  874.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8511.23 ms /    32 tokens\n",
      " 13%|█▎        | 444/3487 [1:35:55<7:05:55,  8.40s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4545.04 ms /    23 tokens (  197.61 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.30 ms /     3 runs   (  873.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7168.00 ms /    26 tokens\n",
      " 13%|█▎        | 445/3487 [1:36:02<6:47:09,  8.03s/it]Llama.generate: 306 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10769.11 ms /    55 tokens (  195.80 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.12 ms /     3 runs   (  870.37 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   13382.51 ms /    58 tokens\n",
      " 13%|█▎        | 446/3487 [1:36:16<8:08:30,  9.64s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4912.46 ms /    23 tokens (  213.59 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.79 ms /     3 runs   (  875.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7540.33 ms /    26 tokens\n",
      " 13%|█▎        | 447/3487 [1:36:23<7:36:34,  9.01s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3703.92 ms /    18 tokens (  205.77 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.26 ms /     3 runs   (  874.42 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6329.60 ms /    21 tokens\n",
      " 13%|█▎        | 448/3487 [1:36:29<6:55:47,  8.21s/it]Llama.generate: 316 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2879.39 ms /    14 tokens (  205.67 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.38 ms /     3 runs   (  876.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5510.36 ms /    17 tokens\n",
      " 13%|█▎        | 449/3487 [1:36:35<6:14:48,  7.40s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8087.09 ms /    40 tokens (  202.18 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.48 ms /     3 runs   (  873.16 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10709.81 ms /    43 tokens\n",
      " 13%|█▎        | 450/3487 [1:36:46<7:05:01,  8.40s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5090.43 ms /    26 tokens (  195.79 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.38 ms /     3 runs   (  874.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7716.34 ms /    29 tokens\n",
      " 13%|█▎        | 451/3487 [1:36:53<6:54:58,  8.20s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4211.52 ms /    21 tokens (  200.55 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.05 ms /     3 runs   (  878.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6849.79 ms /    24 tokens\n",
      " 13%|█▎        | 452/3487 [1:37:00<6:34:26,  7.80s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2093.45 ms /     9 tokens (  232.61 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.33 ms /     3 runs   (  876.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4726.21 ms /    12 tokens\n",
      " 13%|█▎        | 453/3487 [1:37:05<5:48:18,  6.89s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1960.02 ms /     8 tokens (  245.00 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.07 ms /     3 runs   (  872.02 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4579.01 ms /    11 tokens\n",
      " 13%|█▎        | 454/3487 [1:37:10<5:13:19,  6.20s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5007.57 ms /    25 tokens (  200.30 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.82 ms /     3 runs   (  877.61 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7642.58 ms /    28 tokens\n",
      " 13%|█▎        | 455/3487 [1:37:17<5:35:15,  6.63s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2825.93 ms /    13 tokens (  217.38 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.64 ms /     3 runs   (  871.21 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5441.34 ms /    16 tokens\n",
      " 13%|█▎        | 456/3487 [1:37:23<5:17:10,  6.28s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2385.59 ms /    10 tokens (  238.56 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.73 ms /     3 runs   (  881.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5033.83 ms /    13 tokens\n",
      " 13%|█▎        | 457/3487 [1:37:28<4:58:19,  5.91s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1946.65 ms /     9 tokens (  216.29 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.82 ms /     3 runs   (  877.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4583.23 ms /    12 tokens\n",
      " 13%|█▎        | 458/3487 [1:37:32<4:38:16,  5.51s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2770.95 ms /    13 tokens (  213.15 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.53 ms /     3 runs   (  874.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5396.11 ms /    16 tokens\n",
      " 13%|█▎        | 459/3487 [1:37:38<4:36:33,  5.48s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3168.60 ms /    14 tokens (  226.33 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.07 ms /     3 runs   (  878.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5805.62 ms /    17 tokens\n",
      " 13%|█▎        | 460/3487 [1:37:44<4:42:04,  5.59s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2387.09 ms /    10 tokens (  238.71 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.72 ms /     3 runs   (  878.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5026.65 ms /    13 tokens\n",
      " 13%|█▎        | 461/3487 [1:37:49<4:34:02,  5.43s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2089.12 ms /     9 tokens (  232.12 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.95 ms /     3 runs   (  872.32 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4708.30 ms /    12 tokens\n",
      " 13%|█▎        | 462/3487 [1:37:53<4:23:05,  5.22s/it]Llama.generate: 312 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2541.74 ms /     9 tokens (  282.42 ms per token,     3.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.43 ms /     3 runs   (  875.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5170.99 ms /    12 tokens\n",
      " 13%|█▎        | 463/3487 [1:37:59<4:22:54,  5.22s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1569.81 ms /     6 tokens (  261.64 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2912.79 ms /     3 runs   (  970.93 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    4486.14 ms /     9 tokens\n",
      " 13%|█▎        | 464/3487 [1:38:03<4:11:57,  5.00s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3080.76 ms /    15 tokens (  205.38 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.94 ms /     3 runs   (  877.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5716.04 ms /    18 tokens\n",
      " 13%|█▎        | 465/3487 [1:38:09<4:23:17,  5.23s/it]Llama.generate: 312 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1239.75 ms /     4 tokens (  309.94 ms per token,     3.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.62 ms /     3 runs   (  884.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    3895.58 ms /     7 tokens\n",
      " 13%|█▎        | 466/3487 [1:38:13<4:03:13,  4.83s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8318.57 ms /    41 tokens (  202.89 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.37 ms /     3 runs   (  871.79 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10937.24 ms /    44 tokens\n",
      " 13%|█▎        | 467/3487 [1:38:24<5:35:29,  6.67s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1919.44 ms /     8 tokens (  239.93 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.87 ms /     3 runs   (  874.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4544.13 ms /    11 tokens\n",
      " 13%|█▎        | 468/3487 [1:38:28<5:03:58,  6.04s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7684.77 ms /    38 tokens (  202.23 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.70 ms /     3 runs   (  871.90 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10303.09 ms /    41 tokens\n",
      " 13%|█▎        | 469/3487 [1:38:39<6:08:19,  7.32s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13509.49 ms /    65 tokens (  207.84 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.17 ms /     3 runs   (  874.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16134.92 ms /    68 tokens\n",
      " 13%|█▎        | 470/3487 [1:38:55<8:21:16,  9.97s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9460.23 ms /    48 tokens (  197.09 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.56 ms /     3 runs   (  871.19 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12076.74 ms /    51 tokens\n",
      " 14%|█▎        | 471/3487 [1:39:07<8:53:00, 10.60s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5891.25 ms /    30 tokens (  196.38 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.86 ms /     3 runs   (  872.62 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8512.40 ms /    33 tokens\n",
      " 14%|█▎        | 472/3487 [1:39:15<8:21:26,  9.98s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5424.14 ms /    27 tokens (  200.89 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.62 ms /     3 runs   (  873.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8048.65 ms /    30 tokens\n",
      " 14%|█▎        | 473/3487 [1:39:23<7:52:19,  9.40s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5059.75 ms /    25 tokens (  202.39 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.60 ms /     3 runs   (  878.53 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7698.33 ms /    28 tokens\n",
      " 14%|█▎        | 474/3487 [1:39:31<7:27:06,  8.90s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4792.69 ms /    24 tokens (  199.70 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.39 ms /     3 runs   (  875.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7420.81 ms /    27 tokens\n",
      " 14%|█▎        | 475/3487 [1:39:39<7:04:46,  8.46s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4811.45 ms /    23 tokens (  209.19 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.19 ms /     3 runs   (  879.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7452.14 ms /    26 tokens\n",
      " 14%|█▎        | 476/3487 [1:39:46<6:49:34,  8.16s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1948.52 ms /     8 tokens (  243.56 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.29 ms /     3 runs   (  878.10 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4585.86 ms /    11 tokens\n",
      " 14%|█▎        | 477/3487 [1:39:51<5:55:46,  7.09s/it]Llama.generate: 306 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11820.94 ms /    61 tokens (  193.79 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.22 ms /     3 runs   (  878.41 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14458.85 ms /    64 tokens\n",
      " 14%|█▎        | 478/3487 [1:40:05<7:46:38,  9.30s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3773.23 ms /    17 tokens (  221.95 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.63 ms /     3 runs   (  876.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6403.77 ms /    20 tokens\n",
      " 14%|█▎        | 479/3487 [1:40:12<7:02:58,  8.44s/it]Llama.generate: 306 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16388.34 ms /    84 tokens (  195.10 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.45 ms /     3 runs   (  875.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19017.12 ms /    87 tokens\n",
      " 14%|█▍        | 480/3487 [1:40:31<9:42:01, 11.61s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8999.86 ms /    45 tokens (  200.00 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.81 ms /     3 runs   (  872.94 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11621.03 ms /    48 tokens\n",
      " 14%|█▍        | 481/3487 [1:40:42<9:42:05, 11.62s/it]Llama.generate: 307 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11315.86 ms /    58 tokens (  195.10 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.46 ms /     3 runs   (  876.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13947.32 ms /    61 tokens\n",
      " 14%|█▍        | 482/3487 [1:40:56<10:17:02, 12.32s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9224.18 ms /    47 tokens (  196.26 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.88 ms /     3 runs   (  871.96 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11843.06 ms /    50 tokens\n",
      " 14%|█▍        | 483/3487 [1:41:08<10:10:14, 12.19s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4646.68 ms /    23 tokens (  202.03 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.79 ms /     3 runs   (  872.60 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7267.15 ms /    26 tokens\n",
      " 14%|█▍        | 484/3487 [1:41:15<8:56:16, 10.71s/it] Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8028.63 ms /    38 tokens (  211.28 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.10 ms /     3 runs   (  874.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10655.68 ms /    41 tokens\n",
      " 14%|█▍        | 485/3487 [1:41:26<8:55:51, 10.71s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9797.66 ms /    50 tokens (  195.95 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2608.96 ms /     3 runs   (  869.65 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12409.21 ms /    53 tokens\n",
      " 14%|█▍        | 486/3487 [1:41:38<9:21:17, 11.22s/it]Llama.generate: 307 prefix-match hit, remaining 117 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   22269.51 ms /   117 tokens (  190.34 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.04 ms /     3 runs   (  879.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   24911.95 ms /   120 tokens\n",
      " 14%|█▍        | 487/3487 [1:42:03<12:46:35, 15.33s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4612.84 ms /    22 tokens (  209.67 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.12 ms /     3 runs   (  871.04 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7228.11 ms /    25 tokens\n",
      " 14%|█▍        | 488/3487 [1:42:11<10:44:55, 12.90s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14288.82 ms /    74 tokens (  193.09 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2748.41 ms /     3 runs   (  916.14 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   17039.79 ms /    77 tokens\n",
      " 14%|█▍        | 489/3487 [1:42:28<11:46:49, 14.15s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3144.12 ms /    15 tokens (  209.61 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.06 ms /     3 runs   (  884.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5801.07 ms /    18 tokens\n",
      " 14%|█▍        | 490/3487 [1:42:33<9:41:38, 11.64s/it] Llama.generate: 308 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9190.13 ms /    47 tokens (  195.53 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.57 ms /     3 runs   (  872.19 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11809.22 ms /    50 tokens\n",
      " 14%|█▍        | 491/3487 [1:42:45<9:44:01, 11.70s/it]Llama.generate: 308 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4110.36 ms /    20 tokens (  205.52 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.82 ms /     3 runs   (  884.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6765.81 ms /    23 tokens\n",
      " 14%|█▍        | 492/3487 [1:42:52<8:30:06, 10.22s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5734.77 ms /    29 tokens (  197.75 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.56 ms /     3 runs   (  874.52 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8361.04 ms /    32 tokens\n",
      " 14%|█▍        | 493/3487 [1:43:00<8:02:15,  9.66s/it]Llama.generate: 307 prefix-match hit, remaining 132 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25745.85 ms /   132 tokens (  195.04 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.09 ms /     3 runs   (  872.03 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   28364.63 ms /   135 tokens\n",
      " 14%|█▍        | 494/3487 [1:43:29<12:42:05, 15.28s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7938.36 ms /    40 tokens (  198.46 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.13 ms /     3 runs   (  872.38 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10557.97 ms /    43 tokens\n",
      " 14%|█▍        | 495/3487 [1:43:39<11:31:21, 13.86s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8295.72 ms /    42 tokens (  197.52 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.97 ms /     3 runs   (  876.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10927.14 ms /    45 tokens\n",
      " 14%|█▍        | 496/3487 [1:43:50<10:47:18, 12.99s/it]Llama.generate: 308 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19563.89 ms /    98 tokens (  199.63 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.28 ms /     3 runs   (  872.76 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   22184.55 ms /   101 tokens\n",
      " 14%|█▍        | 497/3487 [1:44:12<13:04:46, 15.75s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8407.34 ms /    42 tokens (  200.17 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.83 ms /     3 runs   (  874.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11034.85 ms /    45 tokens\n",
      " 14%|█▍        | 498/3487 [1:44:23<11:54:13, 14.34s/it]Llama.generate: 307 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13488.64 ms /    68 tokens (  198.36 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.58 ms /     3 runs   (  872.86 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   16143.04 ms /    71 tokens\n",
      " 14%|█▍        | 499/3487 [1:44:40<12:21:08, 14.88s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4090.32 ms /    19 tokens (  215.28 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.25 ms /     3 runs   (  875.42 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6718.93 ms /    22 tokens\n",
      " 14%|█▍        | 500/3487 [1:44:46<10:19:03, 12.44s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3443.77 ms /    17 tokens (  202.57 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.62 ms /     3 runs   (  871.87 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6062.87 ms /    20 tokens\n",
      " 14%|█▍        | 501/3487 [1:44:52<8:43:50, 10.53s/it] Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9604.61 ms /    49 tokens (  196.01 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.53 ms /     3 runs   (  875.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12232.93 ms /    52 tokens\n",
      " 14%|█▍        | 502/3487 [1:45:05<9:09:44, 11.05s/it]Llama.generate: 306 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19600.91 ms /   100 tokens (  196.01 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.96 ms /     3 runs   (  874.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   22228.78 ms /   103 tokens\n",
      " 14%|█▍        | 503/3487 [1:45:27<11:56:55, 14.42s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9764.55 ms /    49 tokens (  199.28 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.71 ms /     3 runs   (  899.90 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   12466.84 ms /    52 tokens\n",
      " 14%|█▍        | 504/3487 [1:45:39<11:27:45, 13.83s/it]Llama.generate: 306 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19573.60 ms /   100 tokens (  195.74 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.78 ms /     3 runs   (  873.26 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   22196.19 ms /   103 tokens\n",
      " 14%|█▍        | 505/3487 [1:46:02<13:32:22, 16.35s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4790.96 ms /    24 tokens (  199.62 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.90 ms /     3 runs   (  880.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7434.26 ms /    27 tokens\n",
      " 15%|█▍        | 506/3487 [1:46:09<11:19:24, 13.67s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4642.79 ms /    23 tokens (  201.86 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.19 ms /     3 runs   (  873.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7265.36 ms /    26 tokens\n",
      " 15%|█▍        | 507/3487 [1:46:16<9:43:46, 11.75s/it] Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9796.99 ms /    48 tokens (  204.10 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3218.90 ms /     3 runs   ( 1072.97 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =   13019.25 ms /    51 tokens\n",
      " 15%|█▍        | 508/3487 [1:46:29<10:02:35, 12.14s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9915.82 ms /    33 tokens (  300.48 ms per token,     3.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2844.14 ms /     3 runs   (  948.05 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   12763.26 ms /    36 tokens\n",
      " 15%|█▍        | 509/3487 [1:46:42<10:11:49, 12.33s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3061.79 ms /    14 tokens (  218.70 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.90 ms /     3 runs   (  889.30 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5732.10 ms /    17 tokens\n",
      " 15%|█▍        | 510/3487 [1:46:48<8:33:34, 10.35s/it] Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13669.38 ms /    65 tokens (  210.30 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.06 ms /     3 runs   (  893.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16350.69 ms /    68 tokens\n",
      " 15%|█▍        | 511/3487 [1:47:04<10:02:50, 12.15s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9131.15 ms /    46 tokens (  198.50 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.39 ms /     3 runs   (  895.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11820.55 ms /    49 tokens\n",
      " 15%|█▍        | 512/3487 [1:47:16<9:57:50, 12.06s/it] Llama.generate: 306 prefix-match hit, remaining 136 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26427.47 ms /   136 tokens (  194.32 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.38 ms /     3 runs   (  884.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   29084.92 ms /   139 tokens\n",
      " 15%|█▍        | 513/3487 [1:47:45<14:11:25, 17.18s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10270.37 ms /    51 tokens (  201.38 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.05 ms /     3 runs   (  888.68 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12939.00 ms /    54 tokens\n",
      " 15%|█▍        | 514/3487 [1:47:58<13:08:15, 15.91s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7623.42 ms /    35 tokens (  217.81 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.79 ms /     3 runs   (  888.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10291.89 ms /    38 tokens\n",
      " 15%|█▍        | 515/3487 [1:48:08<11:44:37, 14.23s/it]Llama.generate: 307 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11719.64 ms /    60 tokens (  195.33 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.43 ms /     3 runs   (  889.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14392.51 ms /    63 tokens\n",
      " 15%|█▍        | 516/3487 [1:48:23<11:47:00, 14.28s/it]Llama.generate: 306 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17443.62 ms /    90 tokens (  193.82 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2814.39 ms /     3 runs   (  938.13 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   20260.91 ms /    93 tokens\n",
      " 15%|█▍        | 517/3487 [1:48:43<13:15:43, 16.08s/it]Llama.generate: 306 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14499.58 ms /    73 tokens (  198.62 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2744.56 ms /     3 runs   (  914.85 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   17247.00 ms /    76 tokens\n",
      " 15%|█▍        | 518/3487 [1:49:00<13:32:59, 16.43s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7249.03 ms /    35 tokens (  207.12 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.49 ms /     3 runs   (  893.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9933.88 ms /    38 tokens\n",
      " 15%|█▍        | 519/3487 [1:49:10<11:56:26, 14.48s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10011.19 ms /    50 tokens (  200.22 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.00 ms /     3 runs   (  891.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12687.94 ms /    53 tokens\n",
      " 15%|█▍        | 520/3487 [1:49:23<11:29:40, 13.95s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4603.70 ms /    22 tokens (  209.26 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.99 ms /     3 runs   (  894.33 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7290.03 ms /    25 tokens\n",
      " 15%|█▍        | 521/3487 [1:49:30<9:50:51, 11.95s/it] Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9607.47 ms /    47 tokens (  204.41 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.47 ms /     3 runs   (  895.82 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12297.23 ms /    50 tokens\n",
      " 15%|█▍        | 522/3487 [1:49:43<9:55:53, 12.06s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10373.61 ms /    52 tokens (  199.49 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.55 ms /     3 runs   (  900.18 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   13077.14 ms /    55 tokens\n",
      " 15%|█▍        | 523/3487 [1:49:56<10:10:54, 12.37s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9268.29 ms /    46 tokens (  201.48 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.53 ms /     3 runs   (  889.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11939.14 ms /    49 tokens\n",
      " 15%|█▌        | 524/3487 [1:50:08<10:04:59, 12.25s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7324.07 ms /    35 tokens (  209.26 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.18 ms /     3 runs   (  892.73 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10004.70 ms /    38 tokens\n",
      " 15%|█▌        | 525/3487 [1:50:18<9:31:38, 11.58s/it] Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4661.55 ms /    22 tokens (  211.89 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.88 ms /     3 runs   (  899.63 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7363.36 ms /    25 tokens\n",
      " 15%|█▌        | 526/3487 [1:50:25<8:29:09, 10.32s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4179.96 ms /    20 tokens (  209.00 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.64 ms /     3 runs   (  896.88 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6873.93 ms /    23 tokens\n",
      " 15%|█▌        | 527/3487 [1:50:32<7:38:09,  9.29s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7481.55 ms /    36 tokens (  207.82 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.43 ms /     3 runs   (  902.81 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10192.85 ms /    39 tokens\n",
      " 15%|█▌        | 528/3487 [1:50:42<7:51:30,  9.56s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5312.97 ms /    25 tokens (  212.52 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.21 ms /     3 runs   (  892.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7992.77 ms /    28 tokens\n",
      " 15%|█▌        | 529/3487 [1:50:50<7:28:15,  9.09s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4078.74 ms /    19 tokens (  214.67 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2815.58 ms /     3 runs   (  938.53 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6897.18 ms /    22 tokens\n",
      " 15%|█▌        | 530/3487 [1:50:57<6:55:46,  8.44s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4736.11 ms /    22 tokens (  215.28 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2730.95 ms /     3 runs   (  910.32 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7469.70 ms /    25 tokens\n",
      " 15%|█▌        | 531/3487 [1:51:05<6:41:29,  8.15s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3918.81 ms /    18 tokens (  217.71 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.96 ms /     3 runs   (  893.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6603.15 ms /    21 tokens\n",
      " 15%|█▌        | 532/3487 [1:51:11<6:18:38,  7.69s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3684.27 ms /    17 tokens (  216.72 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.78 ms /     3 runs   (  897.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6380.73 ms /    20 tokens\n",
      " 15%|█▌        | 533/3487 [1:51:18<5:59:46,  7.31s/it]Llama.generate: 307 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11383.82 ms /    56 tokens (  203.28 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2736.20 ms /     3 runs   (  912.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   14122.25 ms /    59 tokens\n",
      " 15%|█▌        | 534/3487 [1:51:32<7:40:22,  9.35s/it]Llama.generate: 307 prefix-match hit, remaining 144 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   29015.77 ms /   144 tokens (  201.50 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.75 ms /     3 runs   (  879.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   31656.84 ms /   147 tokens\n",
      " 15%|█▌        | 535/3487 [1:52:03<13:09:33, 16.05s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12046.35 ms /    63 tokens (  191.21 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.98 ms /     3 runs   (  907.66 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   14771.58 ms /    66 tokens\n",
      " 15%|█▌        | 536/3487 [1:52:18<12:50:36, 15.67s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11159.39 ms /    57 tokens (  195.78 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.31 ms /     3 runs   (  882.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13808.76 ms /    60 tokens\n",
      " 15%|█▌        | 537/3487 [1:52:32<12:23:02, 15.11s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8462.74 ms /    43 tokens (  196.81 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.04 ms /     3 runs   (  876.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11095.00 ms /    46 tokens\n",
      " 15%|█▌        | 538/3487 [1:52:43<11:23:41, 13.91s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3564.14 ms /    17 tokens (  209.66 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.64 ms /     3 runs   (  877.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6200.49 ms /    20 tokens\n",
      " 15%|█▌        | 539/3487 [1:52:49<9:29:54, 11.60s/it] Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5100.58 ms /    25 tokens (  204.02 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.08 ms /     3 runs   (  878.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7737.25 ms /    28 tokens\n",
      " 15%|█▌        | 540/3487 [1:52:57<8:32:55, 10.44s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8319.66 ms /    42 tokens (  198.09 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2888.33 ms /     3 runs   (  962.78 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   11210.34 ms /    45 tokens\n",
      " 16%|█▌        | 541/3487 [1:53:08<8:44:11, 10.68s/it]Llama.generate: 307 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14981.23 ms /    78 tokens (  192.07 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.41 ms /     3 runs   (  874.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17607.16 ms /    81 tokens\n",
      " 16%|█▌        | 542/3487 [1:53:26<10:26:11, 12.76s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7239.23 ms /    36 tokens (  201.09 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.54 ms /     3 runs   (  883.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9892.37 ms /    39 tokens\n",
      " 16%|█▌        | 543/3487 [1:53:36<9:43:55, 11.90s/it] Llama.generate: 306 prefix-match hit, remaining 146 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27792.45 ms /   146 tokens (  190.36 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.09 ms /     3 runs   (  879.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   30434.25 ms /   149 tokens\n",
      " 16%|█▌        | 544/3487 [1:54:06<14:16:34, 17.46s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9349.54 ms /    48 tokens (  194.78 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.81 ms /     3 runs   (  877.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11986.10 ms /    51 tokens\n",
      " 16%|█▌        | 545/3487 [1:54:18<12:55:48, 15.82s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5821.83 ms /    30 tokens (  194.06 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.92 ms /     3 runs   (  879.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8464.89 ms /    33 tokens\n",
      " 16%|█▌        | 546/3487 [1:54:27<11:07:28, 13.62s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7591.03 ms /    38 tokens (  199.76 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.59 ms /     3 runs   (  891.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10266.78 ms /    41 tokens\n",
      " 16%|█▌        | 547/3487 [1:54:37<10:18:07, 12.61s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13241.00 ms /    67 tokens (  197.63 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.85 ms /     3 runs   (  886.28 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15933.86 ms /    70 tokens\n",
      " 16%|█▌        | 548/3487 [1:54:53<11:06:51, 13.61s/it]Llama.generate: 306 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17827.56 ms /    94 tokens (  189.65 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.85 ms /     3 runs   (  881.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20474.88 ms /    97 tokens\n",
      " 16%|█▌        | 549/3487 [1:55:13<12:47:32, 15.67s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3457.97 ms /    17 tokens (  203.41 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.62 ms /     3 runs   (  879.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6099.84 ms /    20 tokens\n",
      " 16%|█▌        | 550/3487 [1:55:20<10:26:46, 12.80s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4650.46 ms /    23 tokens (  202.19 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.93 ms /     3 runs   (  883.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7305.13 ms /    26 tokens\n",
      " 16%|█▌        | 551/3487 [1:55:27<9:06:00, 11.16s/it] Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11221.05 ms /    59 tokens (  190.19 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2849.41 ms /     3 runs   (  949.80 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   14073.19 ms /    62 tokens\n",
      " 16%|█▌        | 552/3487 [1:55:41<9:48:44, 12.04s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6281.47 ms /    28 tokens (  224.34 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3106.90 ms /     3 runs   ( 1035.63 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    9391.75 ms /    31 tokens\n",
      " 16%|█▌        | 553/3487 [1:55:50<9:09:56, 11.25s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8351.73 ms /    40 tokens (  208.79 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2780.00 ms /     3 runs   (  926.67 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   11135.01 ms /    43 tokens\n",
      " 16%|█▌        | 554/3487 [1:56:01<9:08:16, 11.22s/it]Llama.generate: 306 prefix-match hit, remaining 303 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   58481.56 ms /   303 tokens (  193.01 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.92 ms /     3 runs   (  886.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   61143.25 ms /   306 tokens\n",
      " 16%|█▌        | 555/3487 [1:57:03<21:20:11, 26.20s/it]Llama.generate: 306 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17895.54 ms /    94 tokens (  190.38 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2843.08 ms /     3 runs   (  947.69 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   20740.93 ms /    97 tokens\n",
      " 16%|█▌        | 556/3487 [1:57:23<19:59:55, 24.56s/it]Llama.generate: 307 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11658.05 ms /    58 tokens (  201.00 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2851.38 ms /     3 runs   (  950.46 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   14512.83 ms /    61 tokens\n",
      " 16%|█▌        | 557/3487 [1:57:38<17:32:26, 21.55s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5230.38 ms /    25 tokens (  209.22 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.26 ms /     3 runs   (  890.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7903.87 ms /    28 tokens\n",
      " 16%|█▌        | 558/3487 [1:57:46<14:12:23, 17.46s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13787.30 ms /    69 tokens (  199.82 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2785.35 ms /     3 runs   (  928.45 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   16574.85 ms /    72 tokens\n",
      " 16%|█▌        | 559/3487 [1:58:02<13:59:15, 17.20s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4390.70 ms /    20 tokens (  219.53 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2973.38 ms /     3 runs   (  991.13 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    7366.71 ms /    23 tokens\n",
      " 16%|█▌        | 560/3487 [1:58:10<11:35:13, 14.25s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6168.15 ms /    28 tokens (  220.29 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2798.34 ms /     3 runs   (  932.78 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    8969.31 ms /    31 tokens\n",
      " 16%|█▌        | 561/3487 [1:58:19<10:17:51, 12.67s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5674.02 ms /    23 tokens (  246.70 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3691.85 ms /     3 runs   ( 1230.62 ms per token,     0.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    9369.34 ms /    26 tokens\n",
      " 16%|█▌        | 562/3487 [1:58:28<9:29:33, 11.68s/it] Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11532.08 ms /    41 tokens (  281.27 ms per token,     3.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3102.87 ms /     3 runs   ( 1034.29 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =   14638.43 ms /    44 tokens\n",
      " 16%|█▌        | 563/3487 [1:58:43<10:12:44, 12.57s/it]Llama.generate: 307 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12454.00 ms /    58 tokens (  214.72 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2938.68 ms /     3 runs   (  979.56 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =   15395.43 ms /    61 tokens\n",
      " 16%|█▌        | 564/3487 [1:58:58<10:53:56, 13.42s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7262.55 ms /    32 tokens (  226.95 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2923.45 ms /     3 runs   (  974.48 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   10189.03 ms /    35 tokens\n",
      " 16%|█▌        | 565/3487 [1:59:08<10:06:35, 12.46s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8131.07 ms /    33 tokens (  246.40 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2797.80 ms /     3 runs   (  932.60 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   10931.87 ms /    36 tokens\n",
      " 16%|█▌        | 566/3487 [1:59:19<9:44:16, 12.00s/it] Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5910.95 ms /    28 tokens (  211.11 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.73 ms /     3 runs   (  896.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8602.72 ms /    31 tokens\n",
      " 16%|█▋        | 567/3487 [1:59:28<8:54:33, 10.98s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7583.38 ms /    32 tokens (  236.98 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2916.16 ms /     3 runs   (  972.05 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   10501.59 ms /    35 tokens\n",
      " 16%|█▋        | 568/3487 [1:59:38<8:47:45, 10.85s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8438.00 ms /    42 tokens (  200.90 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.25 ms /     3 runs   (  879.75 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11079.88 ms /    45 tokens\n",
      " 16%|█▋        | 569/3487 [1:59:50<8:51:05, 10.92s/it]Llama.generate: 307 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14851.09 ms /    76 tokens (  195.41 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.80 ms /     3 runs   (  898.27 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   17548.57 ms /    79 tokens\n",
      " 16%|█▋        | 570/3487 [2:00:07<10:28:09, 12.92s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6286.97 ms /    32 tokens (  196.47 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.53 ms /     3 runs   (  890.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8961.74 ms /    35 tokens\n",
      " 16%|█▋        | 571/3487 [2:00:16<9:30:19, 11.74s/it] Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2797.17 ms /    13 tokens (  215.17 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.55 ms /     3 runs   (  882.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5446.46 ms /    16 tokens\n",
      " 16%|█▋        | 572/3487 [2:00:22<7:58:35,  9.85s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4166.36 ms /    21 tokens (  198.40 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.64 ms /     3 runs   (  878.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6804.43 ms /    24 tokens\n",
      " 16%|█▋        | 573/3487 [2:00:28<7:14:09,  8.94s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2062.71 ms /     9 tokens (  229.19 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.71 ms /     3 runs   (  880.90 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4708.45 ms /    12 tokens\n",
      " 16%|█▋        | 574/3487 [2:00:33<6:12:31,  7.67s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4928.18 ms /    25 tokens (  197.13 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2837.39 ms /     3 runs   (  945.80 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7768.39 ms /    28 tokens\n",
      " 16%|█▋        | 575/3487 [2:00:41<6:13:55,  7.70s/it]Llama.generate: 306 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15042.09 ms /    79 tokens (  190.41 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.63 ms /     3 runs   (  871.54 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   17658.57 ms /    82 tokens\n",
      " 17%|█▋        | 576/3487 [2:00:59<8:38:47, 10.69s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4156.02 ms /    20 tokens (  207.80 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.63 ms /     3 runs   (  881.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6803.08 ms /    23 tokens\n",
      " 17%|█▋        | 577/3487 [2:01:05<7:42:08,  9.53s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9814.37 ms /    51 tokens (  192.44 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.44 ms /     3 runs   (  878.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12452.47 ms /    54 tokens\n",
      " 17%|█▋        | 578/3487 [2:01:18<8:24:39, 10.41s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4171.46 ms /    21 tokens (  198.64 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2885.92 ms /     3 runs   (  961.97 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    7061.02 ms /    24 tokens\n",
      " 17%|█▋        | 579/3487 [2:01:25<7:35:56,  9.41s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3661.49 ms /    18 tokens (  203.42 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.87 ms /     3 runs   (  873.29 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6283.93 ms /    21 tokens\n",
      " 17%|█▋        | 580/3487 [2:01:31<6:50:30,  8.47s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8990.46 ms /    47 tokens (  191.29 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.59 ms /     3 runs   (  881.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11639.57 ms /    50 tokens\n",
      " 17%|█▋        | 581/3487 [2:01:43<7:36:28,  9.42s/it]Llama.generate: 306 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11575.07 ms /    61 tokens (  189.76 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.20 ms /     3 runs   (  871.07 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14190.80 ms /    64 tokens\n",
      " 17%|█▋        | 582/3487 [2:01:57<8:45:39, 10.86s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4202.85 ms /    21 tokens (  200.14 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.79 ms /     3 runs   (  873.26 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6825.05 ms /    24 tokens\n",
      " 17%|█▋        | 583/3487 [2:02:04<7:47:04,  9.65s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9474.96 ms /    49 tokens (  193.37 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2607.77 ms /     3 runs   (  869.26 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12084.72 ms /    52 tokens\n",
      " 17%|█▋        | 584/3487 [2:02:16<8:22:20, 10.38s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7845.67 ms /    40 tokens (  196.14 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.56 ms /     3 runs   (  873.19 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10468.38 ms /    43 tokens\n",
      " 17%|█▋        | 585/3487 [2:02:26<8:23:32, 10.41s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2340.44 ms /    11 tokens (  212.77 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.29 ms /     3 runs   (  872.43 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4960.19 ms /    14 tokens\n",
      " 17%|█▋        | 586/3487 [2:02:31<7:04:24,  8.78s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7936.56 ms /    40 tokens (  198.41 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.77 ms /     3 runs   (  872.26 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10556.34 ms /    43 tokens\n",
      " 17%|█▋        | 587/3487 [2:02:42<7:30:09,  9.31s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3495.66 ms /    17 tokens (  205.63 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.00 ms /     3 runs   (  880.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6140.60 ms /    20 tokens\n",
      " 17%|█▋        | 588/3487 [2:02:48<6:44:09,  8.36s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5702.30 ms /    28 tokens (  203.65 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.64 ms /     3 runs   (  887.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8366.73 ms /    31 tokens\n",
      " 17%|█▋        | 589/3487 [2:02:56<6:44:10,  8.37s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9001.64 ms /    47 tokens (  191.52 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.63 ms /     3 runs   (  878.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11639.25 ms /    50 tokens\n",
      " 17%|█▋        | 590/3487 [2:03:08<7:31:58,  9.36s/it]Llama.generate: 306 prefix-match hit, remaining 388 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   72813.98 ms /   388 tokens (  187.66 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.87 ms /     3 runs   (  879.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   75455.54 ms /   391 tokens\n",
      " 17%|█▋        | 591/3487 [2:04:24<23:29:01, 29.19s/it]Llama.generate: 306 prefix-match hit, remaining 197 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   37301.09 ms /   197 tokens (  189.35 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.35 ms /     3 runs   (  878.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   39939.56 ms /   200 tokens\n",
      " 17%|█▋        | 592/3487 [2:05:04<26:04:14, 32.42s/it]Llama.generate: 309 prefix-match hit, remaining 137 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25600.48 ms /   137 tokens (  186.86 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.30 ms /     3 runs   (  874.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   28227.05 ms /   140 tokens\n",
      " 17%|█▋        | 593/3487 [2:05:32<25:03:10, 31.16s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3971.67 ms /    19 tokens (  209.04 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.04 ms /     3 runs   (  870.35 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6586.21 ms /    22 tokens\n",
      " 17%|█▋        | 594/3487 [2:05:38<19:07:14, 23.79s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5243.28 ms /    27 tokens (  194.20 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.04 ms /     3 runs   (  871.68 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7860.45 ms /    30 tokens\n",
      " 17%|█▋        | 595/3487 [2:05:46<15:16:34, 19.02s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11953.22 ms /    63 tokens (  189.73 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.66 ms /     3 runs   (  877.89 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14590.08 ms /    66 tokens\n",
      " 17%|█▋        | 596/3487 [2:06:01<14:12:24, 17.69s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9674.16 ms /    50 tokens (  193.48 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.46 ms /     3 runs   (  871.15 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12291.01 ms /    53 tokens\n",
      " 17%|█▋        | 597/3487 [2:06:13<12:54:13, 16.07s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7057.01 ms /    35 tokens (  201.63 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2607.33 ms /     3 runs   (  869.11 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9667.48 ms /    38 tokens\n",
      " 17%|█▋        | 598/3487 [2:06:23<11:21:33, 14.16s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7404.67 ms /    34 tokens (  217.78 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.07 ms /     3 runs   (  883.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10056.64 ms /    37 tokens\n",
      " 17%|█▋        | 599/3487 [2:06:33<10:22:15, 12.93s/it]Llama.generate: 306 prefix-match hit, remaining 143 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26905.87 ms /   143 tokens (  188.15 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.42 ms /     3 runs   (  871.47 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   29522.68 ms /   146 tokens\n",
      " 17%|█▋        | 600/3487 [2:07:02<14:21:44, 17.91s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6306.11 ms /    32 tokens (  197.07 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.14 ms /     3 runs   (  875.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8934.45 ms /    35 tokens\n",
      " 17%|█▋        | 601/3487 [2:07:11<12:12:03, 15.22s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7368.55 ms /    38 tokens (  193.91 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.10 ms /     3 runs   (  871.03 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9983.82 ms /    41 tokens\n",
      " 17%|█▋        | 602/3487 [2:07:21<10:56:26, 13.65s/it]Llama.generate: 308 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10343.86 ms /    54 tokens (  191.55 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2607.10 ms /     3 runs   (  869.03 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12953.66 ms /    57 tokens\n",
      " 17%|█▋        | 603/3487 [2:07:34<10:46:15, 13.45s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5626.78 ms /    28 tokens (  200.96 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2610.49 ms /     3 runs   (  870.16 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8240.04 ms /    31 tokens\n",
      " 17%|█▋        | 604/3487 [2:07:43<9:31:07, 11.89s/it] Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4188.35 ms /    21 tokens (  199.45 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.38 ms /     3 runs   (  874.79 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6815.31 ms /    24 tokens\n",
      " 17%|█▋        | 605/3487 [2:07:49<8:17:57, 10.37s/it]Llama.generate: 308 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5173.66 ms /    26 tokens (  198.99 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.01 ms /     3 runs   (  879.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7815.71 ms /    29 tokens\n",
      " 17%|█▋        | 606/3487 [2:07:57<7:41:09,  9.60s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12145.75 ms /    64 tokens (  189.78 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2609.85 ms /     3 runs   (  869.95 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14757.89 ms /    67 tokens\n",
      " 17%|█▋        | 607/3487 [2:08:12<8:55:19, 11.15s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7414.28 ms /    35 tokens (  211.84 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.16 ms /     3 runs   (  873.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10037.42 ms /    38 tokens\n",
      " 17%|█▋        | 608/3487 [2:08:22<8:39:12, 10.82s/it]Llama.generate: 308 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7131.74 ms /    35 tokens (  203.76 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.03 ms /     3 runs   (  870.68 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9746.53 ms /    38 tokens\n",
      " 17%|█▋        | 609/3487 [2:08:32<8:23:41, 10.50s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8321.88 ms /    42 tokens (  198.14 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.28 ms /     3 runs   (  883.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10975.97 ms /    45 tokens\n",
      " 17%|█▋        | 610/3487 [2:08:43<8:30:28, 10.65s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6050.34 ms /    31 tokens (  195.17 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.25 ms /     3 runs   (  874.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8675.42 ms /    34 tokens\n",
      " 18%|█▊        | 611/3487 [2:08:51<8:02:06, 10.06s/it]Llama.generate: 307 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13056.12 ms /    66 tokens (  197.82 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.13 ms /     3 runs   (  872.38 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   15675.73 ms /    69 tokens\n",
      " 18%|█▊        | 612/3487 [2:09:07<9:22:48, 11.75s/it]Llama.generate: 307 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20284.16 ms /   103 tokens (  196.93 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.26 ms /     3 runs   (  872.75 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   22905.26 ms /   106 tokens\n",
      " 18%|█▊        | 613/3487 [2:09:30<12:03:06, 15.10s/it]Llama.generate: 306 prefix-match hit, remaining 387 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   73591.69 ms /   387 tokens (  190.16 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.23 ms /     3 runs   (  880.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   76234.48 ms /   390 tokens\n",
      " 18%|█▊        | 614/3487 [2:10:46<26:41:15, 33.44s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10053.58 ms /    51 tokens (  197.13 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.43 ms /     3 runs   (  875.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12682.49 ms /    54 tokens\n",
      " 18%|█▊        | 615/3487 [2:10:59<21:42:42, 27.22s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3881.06 ms /    19 tokens (  204.27 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.17 ms /     3 runs   (  875.06 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6508.95 ms /    22 tokens\n",
      " 18%|█▊        | 616/3487 [2:11:06<16:45:07, 21.01s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7154.10 ms /    35 tokens (  204.40 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.04 ms /     3 runs   (  872.01 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9772.63 ms /    38 tokens\n",
      " 18%|█▊        | 617/3487 [2:11:15<14:03:42, 17.64s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3653.31 ms /    17 tokens (  214.90 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.65 ms /     3 runs   (  880.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6297.65 ms /    20 tokens\n",
      " 18%|█▊        | 618/3487 [2:11:22<11:20:50, 14.24s/it]Llama.generate: 307 prefix-match hit, remaining 91 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17550.26 ms /    91 tokens (  192.86 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.05 ms /     3 runs   (  871.35 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   20198.43 ms /    94 tokens\n",
      " 18%|█▊        | 619/3487 [2:11:42<12:46:10, 16.03s/it]Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8521.79 ms /    44 tokens (  193.68 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.50 ms /     3 runs   (  879.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11163.36 ms /    47 tokens\n",
      " 18%|█▊        | 620/3487 [2:11:53<11:36:43, 14.58s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10108.39 ms /    53 tokens (  190.72 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.42 ms /     3 runs   (  872.81 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12729.20 ms /    56 tokens\n",
      " 18%|█▊        | 621/3487 [2:12:06<11:10:04, 14.03s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7515.28 ms /    38 tokens (  197.77 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.27 ms /     3 runs   (  873.09 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10137.46 ms /    41 tokens\n",
      " 18%|█▊        | 622/3487 [2:12:16<10:14:12, 12.86s/it]Llama.generate: 308 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14037.29 ms /    73 tokens (  192.29 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.82 ms /     3 runs   (  887.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16701.55 ms /    76 tokens\n",
      " 18%|█▊        | 623/3487 [2:12:33<11:10:00, 14.04s/it]Llama.generate: 306 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10451.60 ms /    53 tokens (  197.20 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.63 ms /     3 runs   (  887.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13115.80 ms /    56 tokens\n",
      " 18%|█▊        | 624/3487 [2:12:46<10:56:46, 13.76s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4732.19 ms /    24 tokens (  197.17 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.19 ms /     3 runs   (  888.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7400.73 ms /    27 tokens\n",
      " 18%|█▊        | 625/3487 [2:12:53<9:26:03, 11.87s/it] Llama.generate: 307 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19519.84 ms /   102 tokens (  191.37 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2890.83 ms /     3 runs   (  963.61 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   22413.59 ms /   105 tokens\n",
      " 18%|█▊        | 626/3487 [2:13:16<11:56:51, 15.03s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4776.89 ms /    24 tokens (  199.04 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.01 ms /     3 runs   (  880.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7422.11 ms /    27 tokens\n",
      " 18%|█▊        | 627/3487 [2:13:23<10:07:54, 12.75s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10276.75 ms /    52 tokens (  197.63 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.99 ms /     3 runs   (  879.00 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12916.27 ms /    55 tokens\n",
      " 18%|█▊        | 628/3487 [2:13:36<10:10:06, 12.80s/it]Llama.generate: 307 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13145.94 ms /    66 tokens (  199.18 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.93 ms /     3 runs   (  882.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15797.58 ms /    69 tokens\n",
      " 18%|█▊        | 629/3487 [2:13:52<10:52:45, 13.70s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7509.90 ms /    35 tokens (  214.57 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.07 ms /     3 runs   (  880.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10153.33 ms /    38 tokens\n",
      " 18%|█▊        | 630/3487 [2:14:02<10:01:55, 12.64s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6330.99 ms /    32 tokens (  197.84 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.45 ms /     3 runs   (  887.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8996.39 ms /    35 tokens\n",
      " 18%|█▊        | 631/3487 [2:14:11<9:09:47, 11.55s/it] Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5905.03 ms /    29 tokens (  203.62 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.10 ms /     3 runs   (  881.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8551.19 ms /    32 tokens\n",
      " 18%|█▊        | 632/3487 [2:14:20<8:26:54, 10.65s/it]Llama.generate: 308 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4777.35 ms /    24 tokens (  199.06 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.34 ms /     3 runs   (  882.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7428.64 ms /    27 tokens\n",
      " 18%|█▊        | 633/3487 [2:14:27<7:40:51,  9.69s/it]Llama.generate: 307 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11366.60 ms /    58 tokens (  195.98 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.77 ms /     3 runs   (  890.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14041.11 ms /    61 tokens\n",
      " 18%|█▊        | 634/3487 [2:14:41<8:42:53, 11.00s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9794.85 ms /    50 tokens (  195.90 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.14 ms /     3 runs   (  883.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12446.91 ms /    53 tokens\n",
      " 18%|█▊        | 635/3487 [2:14:53<9:03:29, 11.43s/it]Llama.generate: 306 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19514.42 ms /   100 tokens (  195.14 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3440.74 ms /     3 runs   ( 1146.91 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =   22958.60 ms /   103 tokens\n",
      " 18%|█▊        | 636/3487 [2:15:16<11:47:43, 14.89s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7558.29 ms /    24 tokens (  314.93 ms per token,     3.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3295.53 ms /     3 runs   ( 1098.51 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =   10856.95 ms /    27 tokens\n",
      " 18%|█▊        | 637/3487 [2:15:27<10:50:07, 13.69s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8433.33 ms /    33 tokens (  255.56 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.44 ms /     3 runs   (  892.48 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11114.03 ms /    36 tokens\n",
      " 18%|█▊        | 638/3487 [2:15:38<10:13:24, 12.92s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6710.16 ms /    32 tokens (  209.69 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2881.81 ms /     3 runs   (  960.60 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    9594.77 ms /    35 tokens\n",
      " 18%|█▊        | 639/3487 [2:15:48<9:26:29, 11.93s/it] Llama.generate: 307 prefix-match hit, remaining 206 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   39876.26 ms /   206 tokens (  193.57 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3006.19 ms /     3 runs   ( 1002.06 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =   42884.86 ms /   209 tokens\n",
      " 18%|█▊        | 640/3487 [2:16:31<16:47:00, 21.22s/it]Llama.generate: 308 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4440.89 ms /    20 tokens (  222.04 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2758.68 ms /     3 runs   (  919.56 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7202.28 ms /    23 tokens\n",
      " 18%|█▊        | 641/3487 [2:16:38<13:27:15, 17.02s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3761.52 ms /    18 tokens (  208.97 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.46 ms /     3 runs   (  904.49 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6477.90 ms /    21 tokens\n",
      " 18%|█▊        | 642/3487 [2:16:45<10:57:09, 13.86s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3544.27 ms /    16 tokens (  221.52 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.10 ms /     3 runs   (  892.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6223.48 ms /    19 tokens\n",
      " 18%|█▊        | 643/3487 [2:16:51<9:08:26, 11.57s/it] Llama.generate: 306 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20737.90 ms /   108 tokens (  192.02 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.41 ms /     3 runs   (  898.47 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   23435.79 ms /   111 tokens\n",
      " 18%|█▊        | 644/3487 [2:17:14<11:57:02, 15.13s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8434.37 ms /    42 tokens (  200.82 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.23 ms /     3 runs   (  897.74 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11130.09 ms /    45 tokens\n",
      " 18%|█▊        | 645/3487 [2:17:26<11:00:02, 13.93s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5961.60 ms /    29 tokens (  205.57 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3251.55 ms /     3 runs   ( 1083.85 ms per token,     0.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    9216.18 ms /    32 tokens\n",
      " 19%|█▊        | 646/3487 [2:17:35<9:52:54, 12.52s/it] Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5684.04 ms /    24 tokens (  236.84 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2940.28 ms /     3 runs   (  980.09 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    8627.56 ms /    27 tokens\n",
      " 19%|█▊        | 647/3487 [2:17:43<8:57:33, 11.36s/it]Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12709.28 ms /    57 tokens (  222.97 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2839.14 ms /     3 runs   (  946.38 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   15550.32 ms /    60 tokens\n",
      " 19%|█▊        | 648/3487 [2:17:59<9:57:02, 12.62s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11635.88 ms /    51 tokens (  228.15 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2803.59 ms /     3 runs   (  934.53 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   14442.53 ms /    54 tokens\n",
      " 19%|█▊        | 649/3487 [2:18:13<10:22:50, 13.17s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5067.03 ms /    22 tokens (  230.32 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.26 ms /     3 runs   (  905.75 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7787.41 ms /    25 tokens\n",
      " 19%|█▊        | 650/3487 [2:18:21<9:06:27, 11.56s/it] Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4488.76 ms /    20 tokens (  224.44 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.64 ms /     3 runs   (  903.88 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7203.40 ms /    23 tokens\n",
      " 19%|█▊        | 651/3487 [2:18:28<8:04:38, 10.25s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14469.30 ms /    72 tokens (  200.96 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.10 ms /     3 runs   (  894.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   17155.59 ms /    75 tokens\n",
      " 19%|█▊        | 652/3487 [2:18:46<9:42:25, 12.33s/it]Llama.generate: 308 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3978.18 ms /    19 tokens (  209.38 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2745.48 ms /     3 runs   (  915.16 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6727.01 ms /    22 tokens\n",
      " 19%|█▊        | 653/3487 [2:18:52<8:22:59, 10.65s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7892.00 ms /    38 tokens (  207.68 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.17 ms /     3 runs   (  896.39 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10584.05 ms /    41 tokens\n",
      " 19%|█▉        | 654/3487 [2:19:03<8:22:00, 10.63s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7587.13 ms /    38 tokens (  199.66 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.10 ms /     3 runs   (  897.70 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10282.49 ms /    41 tokens\n",
      " 19%|█▉        | 655/3487 [2:19:13<8:17:02, 10.53s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7346.74 ms /    34 tokens (  216.08 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.10 ms /     3 runs   (  891.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10023.86 ms /    37 tokens\n",
      " 19%|█▉        | 656/3487 [2:19:23<8:09:48, 10.38s/it]Llama.generate: 312 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4548.50 ms /    22 tokens (  206.75 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.24 ms /     3 runs   (  892.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7228.50 ms /    25 tokens\n",
      " 19%|█▉        | 657/3487 [2:19:30<7:25:08,  9.44s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7399.55 ms /    35 tokens (  211.42 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.90 ms /     3 runs   (  898.30 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10096.63 ms /    38 tokens\n",
      " 19%|█▉        | 658/3487 [2:19:41<7:34:24,  9.64s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3683.04 ms /    18 tokens (  204.61 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.54 ms /     3 runs   (  891.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6361.76 ms /    21 tokens\n",
      " 19%|█▉        | 659/3487 [2:19:47<6:48:03,  8.66s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1619.50 ms /     5 tokens (  323.90 ms per token,     3.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.05 ms /     3 runs   (  898.02 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4316.03 ms /     8 tokens\n",
      " 19%|█▉        | 660/3487 [2:19:51<5:47:05,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4138.19 ms /    20 tokens (  206.91 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.89 ms /     3 runs   (  896.30 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6829.98 ms /    23 tokens\n",
      " 19%|█▉        | 661/3487 [2:19:58<5:39:29,  7.21s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4490.11 ms /    21 tokens (  213.81 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.03 ms /     3 runs   (  894.34 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7175.44 ms /    24 tokens\n",
      " 19%|█▉        | 662/3487 [2:20:05<5:39:01,  7.20s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7522.33 ms /    37 tokens (  203.31 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.67 ms /     3 runs   (  915.89 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10272.57 ms /    40 tokens\n",
      " 19%|█▉        | 663/3487 [2:20:16<6:22:24,  8.12s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6055.62 ms /    30 tokens (  201.85 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.31 ms /     3 runs   (  886.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8716.63 ms /    33 tokens\n",
      " 19%|█▉        | 664/3487 [2:20:24<6:30:43,  8.30s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7820.45 ms /    39 tokens (  200.52 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.79 ms /     3 runs   (  877.93 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10456.77 ms /    42 tokens\n",
      " 19%|█▉        | 665/3487 [2:20:35<7:01:03,  8.95s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1672.31 ms /     6 tokens (  278.72 ms per token,     3.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.16 ms /     3 runs   (  879.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4313.14 ms /     9 tokens\n",
      " 19%|█▉        | 666/3487 [2:20:39<5:56:01,  7.57s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7359.54 ms /    36 tokens (  204.43 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.88 ms /     3 runs   (  878.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9997.21 ms /    39 tokens\n",
      " 19%|█▉        | 667/3487 [2:20:49<6:30:12,  8.30s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5194.53 ms /    25 tokens (  207.78 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.96 ms /     3 runs   (  881.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7842.07 ms /    28 tokens\n",
      " 19%|█▉        | 668/3487 [2:20:57<6:23:42,  8.17s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5230.04 ms /    27 tokens (  193.71 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.85 ms /     3 runs   (  892.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7910.49 ms /    30 tokens\n",
      " 19%|█▉        | 669/3487 [2:21:05<6:20:03,  8.09s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6417.29 ms /    32 tokens (  200.54 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.72 ms /     3 runs   (  887.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9082.70 ms /    35 tokens\n",
      " 19%|█▉        | 670/3487 [2:21:14<6:33:58,  8.39s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4060.72 ms /    20 tokens (  203.04 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.81 ms /     3 runs   (  887.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6726.64 ms /    23 tokens\n",
      " 19%|█▉        | 671/3487 [2:21:21<6:10:32,  7.89s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5419.12 ms /    27 tokens (  200.71 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.96 ms /     3 runs   (  875.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8048.31 ms /    30 tokens\n",
      " 19%|█▉        | 672/3487 [2:21:29<6:12:41,  7.94s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7439.33 ms /    35 tokens (  212.55 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.92 ms /     3 runs   (  908.64 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   10167.47 ms /    38 tokens\n",
      " 19%|█▉        | 673/3487 [2:21:39<6:43:57,  8.61s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7253.15 ms /    34 tokens (  213.33 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.02 ms /     3 runs   (  877.01 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9886.27 ms /    37 tokens\n",
      " 19%|█▉        | 674/3487 [2:21:49<7:01:51,  9.00s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2422.99 ms /    10 tokens (  242.30 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.22 ms /     3 runs   (  891.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5100.13 ms /    13 tokens\n",
      " 19%|█▉        | 675/3487 [2:21:54<6:07:00,  7.83s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7496.81 ms /    37 tokens (  202.62 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.62 ms /     3 runs   (  877.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10133.16 ms /    40 tokens\n",
      " 19%|█▉        | 676/3487 [2:22:04<6:39:21,  8.52s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4867.34 ms /    24 tokens (  202.81 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.80 ms /     3 runs   (  879.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7508.07 ms /    27 tokens\n",
      " 19%|█▉        | 677/3487 [2:22:12<6:25:04,  8.22s/it]Llama.generate: 307 prefix-match hit, remaining 113 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21454.00 ms /   113 tokens (  189.86 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.64 ms /     3 runs   (  879.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   24127.52 ms /   116 tokens\n",
      " 19%|█▉        | 678/3487 [2:22:36<10:08:27, 13.00s/it]Llama.generate: 307 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19245.06 ms /    98 tokens (  196.38 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.30 ms /     3 runs   (  878.10 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21882.22 ms /   101 tokens\n",
      " 19%|█▉        | 679/3487 [2:22:58<12:13:05, 15.66s/it]Llama.generate: 306 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20372.71 ms /   107 tokens (  190.40 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2887.90 ms /     3 runs   (  962.63 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   23263.81 ms /   110 tokens\n",
      " 20%|█▉        | 680/3487 [2:23:21<13:59:37, 17.95s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4084.39 ms /    20 tokens (  204.22 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.61 ms /     3 runs   (  882.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6735.89 ms /    23 tokens\n",
      " 20%|█▉        | 681/3487 [2:23:28<11:22:08, 14.59s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2984.16 ms /    13 tokens (  229.55 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.53 ms /     3 runs   (  878.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5620.92 ms /    16 tokens\n",
      " 20%|█▉        | 682/3487 [2:23:33<9:16:15, 11.90s/it] Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4483.89 ms /    22 tokens (  203.81 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.72 ms /     3 runs   (  879.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7125.79 ms /    25 tokens\n",
      " 20%|█▉        | 683/3487 [2:23:40<8:09:15, 10.47s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4895.41 ms /    24 tokens (  203.98 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2830.00 ms /     3 runs   (  943.33 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7727.95 ms /    27 tokens\n",
      " 20%|█▉        | 684/3487 [2:23:48<7:30:46,  9.65s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6390.20 ms /    31 tokens (  206.14 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.19 ms /     3 runs   (  892.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9069.36 ms /    34 tokens\n",
      " 20%|█▉        | 685/3487 [2:23:57<7:22:37,  9.48s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6342.43 ms /    31 tokens (  204.59 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.43 ms /     3 runs   (  890.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9017.40 ms /    34 tokens\n",
      " 20%|█▉        | 686/3487 [2:24:06<7:16:09,  9.34s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13503.70 ms /    70 tokens (  192.91 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2772.83 ms /     3 runs   (  924.28 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   16279.29 ms /    73 tokens\n",
      " 20%|█▉        | 687/3487 [2:24:23<8:57:50, 11.53s/it]Llama.generate: 306 prefix-match hit, remaining 153 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   29701.85 ms /   153 tokens (  194.13 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.11 ms /     3 runs   (  880.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   32345.83 ms /   156 tokens\n",
      " 20%|█▉        | 688/3487 [2:24:55<13:49:34, 17.78s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1894.73 ms /     8 tokens (  236.84 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.33 ms /     3 runs   (  884.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4551.82 ms /    11 tokens\n",
      " 20%|█▉        | 689/3487 [2:25:00<10:44:18, 13.82s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9491.58 ms /    47 tokens (  201.95 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.55 ms /     3 runs   (  886.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12153.88 ms /    50 tokens\n",
      " 20%|█▉        | 690/3487 [2:25:12<10:21:23, 13.33s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4267.38 ms /    21 tokens (  203.21 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.41 ms /     3 runs   (  881.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6913.05 ms /    24 tokens\n",
      " 20%|█▉        | 691/3487 [2:25:19<8:51:35, 11.41s/it] Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2498.13 ms /    10 tokens (  249.81 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2609.75 ms /     3 runs   (  869.92 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5110.99 ms /    13 tokens\n",
      " 20%|█▉        | 692/3487 [2:25:24<7:23:59,  9.53s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1854.35 ms /     8 tokens (  231.79 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.12 ms /     3 runs   (  875.04 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4481.85 ms /    11 tokens\n",
      " 20%|█▉        | 693/3487 [2:25:29<6:13:24,  8.02s/it]Llama.generate: 306 prefix-match hit, remaining 125 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23683.94 ms /   125 tokens (  189.47 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.58 ms /     3 runs   (  886.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   26347.35 ms /   128 tokens\n",
      " 20%|█▉        | 694/3487 [2:25:55<10:29:19, 13.52s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5780.79 ms /    29 tokens (  199.34 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.32 ms /     3 runs   (  880.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8425.12 ms /    32 tokens\n",
      " 20%|█▉        | 695/3487 [2:26:03<9:18:05, 11.99s/it] Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1567.90 ms /     5 tokens (  313.58 ms per token,     3.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.40 ms /     3 runs   (  878.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4205.85 ms /     8 tokens\n",
      " 20%|█▉        | 696/3487 [2:26:08<7:29:19,  9.66s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5478.74 ms /    28 tokens (  195.67 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.86 ms /     3 runs   (  876.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8111.01 ms /    31 tokens\n",
      " 20%|█▉        | 697/3487 [2:26:16<7:07:39,  9.20s/it]Llama.generate: 306 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19993.21 ms /   105 tokens (  190.41 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2867.37 ms /     3 runs   (  955.79 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   22863.28 ms /   108 tokens\n",
      " 20%|██        | 698/3487 [2:26:39<10:18:12, 13.30s/it]Llama.generate: 306 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10425.05 ms /    53 tokens (  196.70 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.81 ms /     3 runs   (  873.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13049.10 ms /    56 tokens\n",
      " 20%|██        | 699/3487 [2:26:52<10:14:36, 13.23s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5449.23 ms /    27 tokens (  201.82 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.86 ms /     3 runs   (  880.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8123.09 ms /    30 tokens\n",
      " 20%|██        | 700/3487 [2:27:00<9:03:22, 11.70s/it] Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6100.70 ms /    31 tokens (  196.80 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.76 ms /     3 runs   (  874.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8725.62 ms /    34 tokens\n",
      " 20%|██        | 701/3487 [2:27:09<8:22:20, 10.82s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4198.45 ms /    20 tokens (  209.92 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.87 ms /     3 runs   (  875.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6828.00 ms /    23 tokens\n",
      " 20%|██        | 702/3487 [2:27:15<7:26:41,  9.62s/it]Llama.generate: 308 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4990.03 ms /    25 tokens (  199.60 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.65 ms /     3 runs   (  872.88 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7611.25 ms /    28 tokens\n",
      " 20%|██        | 703/3487 [2:27:23<6:58:37,  9.02s/it]Llama.generate: 308 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13777.75 ms /    70 tokens (  196.83 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.57 ms /     3 runs   (  880.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16422.47 ms /    73 tokens\n",
      " 20%|██        | 704/3487 [2:27:39<8:41:33, 11.24s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13179.31 ms /    65 tokens (  202.76 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.41 ms /     3 runs   (  890.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15884.11 ms /    68 tokens\n",
      " 20%|██        | 705/3487 [2:27:55<9:46:00, 12.64s/it]Llama.generate: 307 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11889.53 ms /    60 tokens (  198.16 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.96 ms /     3 runs   (  875.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14520.47 ms /    63 tokens\n",
      " 20%|██        | 706/3487 [2:28:10<10:12:05, 13.21s/it]Llama.generate: 307 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11453.33 ms /    60 tokens (  190.89 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.73 ms /     3 runs   (  874.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14079.05 ms /    63 tokens\n",
      " 20%|██        | 707/3487 [2:28:24<10:24:08, 13.47s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6625.99 ms /    32 tokens (  207.06 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.85 ms /     3 runs   (  883.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9279.04 ms /    35 tokens\n",
      " 20%|██        | 708/3487 [2:28:33<9:25:47, 12.22s/it] Llama.generate: 308 prefix-match hit, remaining 150 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   29089.81 ms /   150 tokens (  193.93 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.84 ms /     3 runs   (  892.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   31769.31 ms /   153 tokens\n",
      " 20%|██        | 709/3487 [2:29:05<13:57:17, 18.08s/it]Llama.generate: 307 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11825.40 ms /    60 tokens (  197.09 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.95 ms /     3 runs   (  889.65 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14497.00 ms /    63 tokens\n",
      " 20%|██        | 710/3487 [2:29:19<13:07:19, 17.01s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7549.54 ms /    38 tokens (  198.67 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.74 ms /     3 runs   (  892.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10230.69 ms /    41 tokens\n",
      " 20%|██        | 711/3487 [2:29:30<11:33:02, 14.98s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7437.31 ms /    36 tokens (  206.59 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.87 ms /     3 runs   (  872.62 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10057.21 ms /    39 tokens\n",
      " 20%|██        | 712/3487 [2:29:40<10:24:36, 13.50s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5749.97 ms /    29 tokens (  198.27 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.97 ms /     3 runs   (  880.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8393.34 ms /    32 tokens\n",
      " 20%|██        | 713/3487 [2:29:48<9:13:35, 11.97s/it] Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4412.74 ms /    21 tokens (  210.13 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.53 ms /     3 runs   (  875.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7040.35 ms /    24 tokens\n",
      " 20%|██        | 714/3487 [2:29:55<8:05:05, 10.50s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5289.01 ms /    27 tokens (  195.89 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.89 ms /     3 runs   (  872.63 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7909.78 ms /    30 tokens\n",
      " 21%|██        | 715/3487 [2:30:03<7:29:10,  9.72s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5795.26 ms /    29 tokens (  199.84 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.07 ms /     3 runs   (  881.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8442.39 ms /    32 tokens\n",
      " 21%|██        | 716/3487 [2:30:12<7:11:24,  9.34s/it]Llama.generate: 307 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20337.01 ms /   105 tokens (  193.69 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.55 ms /     3 runs   (  873.18 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   22959.82 ms /   108 tokens\n",
      " 21%|██        | 717/3487 [2:30:35<10:19:58, 13.43s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5528.64 ms /    27 tokens (  204.76 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.55 ms /     3 runs   (  884.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8185.36 ms /    30 tokens\n",
      " 21%|██        | 718/3487 [2:30:43<9:07:16, 11.86s/it] Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4754.92 ms /    24 tokens (  198.12 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2822.60 ms /     3 runs   (  940.87 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7580.01 ms /    27 tokens\n",
      " 21%|██        | 719/3487 [2:30:50<8:07:59, 10.58s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5982.54 ms /    29 tokens (  206.29 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.98 ms /     3 runs   (  877.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8619.16 ms /    32 tokens\n",
      " 21%|██        | 720/3487 [2:30:59<7:40:50,  9.99s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2477.95 ms /     9 tokens (  275.33 ms per token,     3.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.64 ms /     3 runs   (  877.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5113.30 ms /    12 tokens\n",
      " 21%|██        | 721/3487 [2:31:04<6:33:16,  8.53s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6260.99 ms /    31 tokens (  201.97 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.08 ms /     3 runs   (  871.69 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8878.74 ms /    34 tokens\n",
      " 21%|██        | 722/3487 [2:31:13<6:38:03,  8.64s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3137.11 ms /    15 tokens (  209.14 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.95 ms /     3 runs   (  871.65 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5754.76 ms /    18 tokens\n",
      " 21%|██        | 723/3487 [2:31:19<5:58:10,  7.78s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4826.18 ms /    23 tokens (  209.83 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.89 ms /     3 runs   (  871.63 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7443.25 ms /    26 tokens\n",
      " 21%|██        | 724/3487 [2:31:26<5:53:34,  7.68s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3000.27 ms /    14 tokens (  214.30 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.26 ms /     3 runs   (  874.42 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5625.69 ms /    17 tokens\n",
      " 21%|██        | 725/3487 [2:31:32<5:25:12,  7.06s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3800.99 ms /    18 tokens (  211.17 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.98 ms /     3 runs   (  883.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6453.75 ms /    21 tokens\n",
      " 21%|██        | 726/3487 [2:31:38<5:16:47,  6.88s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8603.78 ms /    41 tokens (  209.85 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.69 ms /     3 runs   (  873.23 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11226.13 ms /    44 tokens\n",
      " 21%|██        | 727/3487 [2:31:50<6:16:40,  8.19s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7224.32 ms /    34 tokens (  212.48 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.16 ms /     3 runs   (  888.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9893.63 ms /    37 tokens\n",
      " 21%|██        | 728/3487 [2:31:59<6:40:12,  8.70s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8449.82 ms /    42 tokens (  201.19 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.55 ms /     3 runs   (  872.85 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11070.59 ms /    45 tokens\n",
      " 21%|██        | 729/3487 [2:32:11<7:12:49,  9.42s/it]Llama.generate: 308 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11878.27 ms /    62 tokens (  191.58 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.95 ms /     3 runs   (  877.98 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14513.98 ms /    65 tokens\n",
      " 21%|██        | 730/3487 [2:32:25<8:23:04, 10.95s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3833.89 ms /    18 tokens (  212.99 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.28 ms /     3 runs   (  872.43 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6453.51 ms /    21 tokens\n",
      " 21%|██        | 731/3487 [2:32:32<7:21:04,  9.60s/it]Llama.generate: 306 prefix-match hit, remaining 153 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28917.44 ms /   153 tokens (  189.00 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.17 ms /     3 runs   (  879.06 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   31556.72 ms /   156 tokens\n",
      " 21%|██        | 732/3487 [2:33:03<12:23:25, 16.19s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1695.35 ms /     6 tokens (  282.56 ms per token,     3.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.40 ms /     3 runs   (  880.80 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4340.27 ms /     9 tokens\n",
      " 21%|██        | 733/3487 [2:33:07<9:40:06, 12.64s/it] Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4639.77 ms /    23 tokens (  201.73 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.04 ms /     3 runs   (  877.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7275.66 ms /    26 tokens\n",
      " 21%|██        | 734/3487 [2:33:15<8:26:13, 11.03s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2705.17 ms /    12 tokens (  225.43 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.50 ms /     3 runs   (  877.17 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5339.21 ms /    15 tokens\n",
      " 21%|██        | 735/3487 [2:33:20<7:07:48,  9.33s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3639.05 ms /    18 tokens (  202.17 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.61 ms /     3 runs   (  877.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6274.90 ms /    21 tokens\n",
      " 21%|██        | 736/3487 [2:33:26<6:25:46,  8.41s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4075.26 ms /    19 tokens (  214.49 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2904.16 ms /     3 runs   (  968.05 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6982.02 ms /    22 tokens\n",
      " 21%|██        | 737/3487 [2:33:33<6:06:03,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5858.92 ms /    30 tokens (  195.30 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.37 ms /     3 runs   (  870.79 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8473.81 ms /    33 tokens\n",
      " 21%|██        | 738/3487 [2:33:42<6:12:43,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4787.36 ms /    23 tokens (  208.15 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.06 ms /     3 runs   (  874.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7412.27 ms /    26 tokens\n",
      " 21%|██        | 739/3487 [2:33:49<6:02:46,  7.92s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5580.22 ms /    28 tokens (  199.29 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.53 ms /     3 runs   (  895.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8270.42 ms /    31 tokens\n",
      " 21%|██        | 740/3487 [2:33:58<6:07:33,  8.03s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2755.68 ms /    12 tokens (  229.64 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.38 ms /     3 runs   (  870.79 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5370.67 ms /    15 tokens\n",
      " 21%|██▏       | 741/3487 [2:34:03<5:31:02,  7.23s/it]Llama.generate: 311 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4218.72 ms /    21 tokens (  200.89 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.80 ms /     3 runs   (  874.93 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6845.57 ms /    24 tokens\n",
      " 21%|██▏       | 742/3487 [2:34:10<5:25:42,  7.12s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9563.90 ms /    48 tokens (  199.25 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.31 ms /     3 runs   (  871.10 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12180.12 ms /    51 tokens\n",
      " 21%|██▏       | 743/3487 [2:34:22<6:35:08,  8.64s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9085.68 ms /    46 tokens (  197.51 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.27 ms /     3 runs   (  878.76 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11724.14 ms /    49 tokens\n",
      " 21%|██▏       | 744/3487 [2:34:34<7:17:24,  9.57s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2539.02 ms /    10 tokens (  253.90 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.06 ms /     3 runs   (  886.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5201.71 ms /    13 tokens\n",
      " 21%|██▏       | 745/3487 [2:34:39<6:17:30,  8.26s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2935.62 ms /    14 tokens (  209.69 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.03 ms /     3 runs   (  883.01 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5587.71 ms /    17 tokens\n",
      " 21%|██▏       | 746/3487 [2:34:44<5:40:52,  7.46s/it]Llama.generate: 307 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13341.85 ms /    66 tokens (  202.15 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.02 ms /     3 runs   (  875.34 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15970.86 ms /    69 tokens\n",
      " 21%|██▏       | 747/3487 [2:35:00<7:37:24, 10.02s/it]Llama.generate: 308 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2574.57 ms /    12 tokens (  214.55 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.46 ms /     3 runs   (  890.49 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5248.51 ms /    15 tokens\n",
      " 21%|██▏       | 748/3487 [2:35:06<6:32:03,  8.59s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4898.44 ms /    24 tokens (  204.10 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.96 ms /     3 runs   (  871.32 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7515.27 ms /    27 tokens\n",
      " 21%|██▏       | 749/3487 [2:35:13<6:17:20,  8.27s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3021.55 ms /    14 tokens (  215.82 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.63 ms /     3 runs   (  873.21 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5643.87 ms /    17 tokens\n",
      " 22%|██▏       | 750/3487 [2:35:19<5:41:51,  7.49s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2091.55 ms /     6 tokens (  348.59 ms per token,     2.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.41 ms /     3 runs   (  880.80 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4737.87 ms /     9 tokens\n",
      " 22%|██▏       | 751/3487 [2:35:24<5:04:34,  6.68s/it]Llama.generate: 306 prefix-match hit, remaining 619 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =  117823.99 ms /   619 tokens (  190.35 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.16 ms /     3 runs   (  882.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =  120475.27 ms /   622 tokens\n",
      " 22%|██▏       | 752/3487 [2:37:24<31:00:45, 40.82s/it]Llama.generate: 306 prefix-match hit, remaining 148 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27864.13 ms /   148 tokens (  188.27 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.62 ms /     3 runs   (  875.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   30493.41 ms /   151 tokens\n",
      " 22%|██▏       | 753/3487 [2:37:55<28:39:01, 37.73s/it]Llama.generate: 307 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11073.52 ms /    56 tokens (  197.74 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.42 ms /     3 runs   (  880.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13717.94 ms /    59 tokens\n",
      " 22%|██▏       | 754/3487 [2:38:08<23:10:27, 30.53s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5246.50 ms /    27 tokens (  194.31 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.88 ms /     3 runs   (  872.96 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7867.88 ms /    30 tokens\n",
      " 22%|██▏       | 755/3487 [2:38:16<18:00:32, 23.73s/it]Llama.generate: 308 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4869.29 ms /    24 tokens (  202.89 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.01 ms /     3 runs   (  874.00 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7494.42 ms /    27 tokens\n",
      " 22%|██▏       | 756/3487 [2:38:24<14:18:33, 18.86s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4056.25 ms /    20 tokens (  202.81 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.71 ms /     3 runs   (  882.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6705.54 ms /    23 tokens\n",
      " 22%|██▏       | 757/3487 [2:38:30<11:32:24, 15.22s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6278.31 ms /    30 tokens (  209.28 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.74 ms /     3 runs   (  878.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8916.80 ms /    33 tokens\n",
      " 22%|██▏       | 758/3487 [2:38:39<10:06:44, 13.34s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3454.63 ms /    16 tokens (  215.91 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.45 ms /     3 runs   (  879.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6095.99 ms /    19 tokens\n",
      " 22%|██▏       | 759/3487 [2:38:46<8:27:50, 11.17s/it] Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5215.33 ms /    25 tokens (  208.61 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.09 ms /     3 runs   (  871.70 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7832.85 ms /    28 tokens\n",
      " 22%|██▏       | 760/3487 [2:38:53<7:42:15, 10.17s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3144.74 ms /    15 tokens (  209.65 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.87 ms /     3 runs   (  891.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5821.34 ms /    18 tokens\n",
      " 22%|██▏       | 761/3487 [2:38:59<6:42:54,  8.87s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4147.99 ms /    19 tokens (  218.32 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.64 ms /     3 runs   (  873.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6772.59 ms /    22 tokens\n",
      " 22%|██▏       | 762/3487 [2:39:06<6:14:19,  8.24s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4101.31 ms /    20 tokens (  205.07 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.80 ms /     3 runs   (  877.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6734.95 ms /    23 tokens\n",
      " 22%|██▏       | 763/3487 [2:39:13<5:54:13,  7.80s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4132.85 ms /    19 tokens (  217.52 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.18 ms /     3 runs   (  887.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6798.96 ms /    22 tokens\n",
      " 22%|██▏       | 764/3487 [2:39:20<5:40:32,  7.50s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2054.48 ms /     9 tokens (  228.28 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.29 ms /     3 runs   (  880.10 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4697.48 ms /    12 tokens\n",
      " 22%|██▏       | 765/3487 [2:39:24<5:02:47,  6.67s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4071.97 ms /    19 tokens (  214.31 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.88 ms /     3 runs   (  880.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6715.21 ms /    22 tokens\n",
      " 22%|██▏       | 766/3487 [2:39:31<5:03:20,  6.69s/it]Llama.generate: 306 prefix-match hit, remaining 172 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   32497.59 ms /   172 tokens (  188.94 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.09 ms /     3 runs   (  882.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   35146.33 ms /   175 tokens\n",
      " 22%|██▏       | 767/3487 [2:40:06<11:30:23, 15.23s/it]Llama.generate: 307 prefix-match hit, remaining 99 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19369.53 ms /    99 tokens (  195.65 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.08 ms /     3 runs   (  871.03 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   21985.11 ms /   102 tokens\n",
      " 22%|██▏       | 768/3487 [2:40:28<13:02:05, 17.26s/it]Llama.generate: 307 prefix-match hit, remaining 121 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   22863.85 ms /   121 tokens (  188.96 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.73 ms /     3 runs   (  872.91 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   25484.52 ms /   124 tokens\n",
      " 22%|██▏       | 769/3487 [2:40:54<14:53:41, 19.73s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7223.88 ms /    33 tokens (  218.91 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.60 ms /     3 runs   (  872.20 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9842.84 ms /    36 tokens\n",
      " 22%|██▏       | 770/3487 [2:41:04<12:39:36, 16.77s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4779.36 ms /    24 tokens (  199.14 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.55 ms /     3 runs   (  882.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7428.02 ms /    27 tokens\n",
      " 22%|██▏       | 771/3487 [2:41:11<10:32:30, 13.97s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3780.22 ms /    18 tokens (  210.01 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.15 ms /     3 runs   (  872.72 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6401.43 ms /    21 tokens\n",
      " 22%|██▏       | 772/3487 [2:41:17<8:49:35, 11.70s/it] Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6074.29 ms /    31 tokens (  195.94 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.72 ms /     3 runs   (  879.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8714.81 ms /    34 tokens\n",
      " 22%|██▏       | 773/3487 [2:41:26<8:09:24, 10.82s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4002.23 ms /    19 tokens (  210.64 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.32 ms /     3 runs   (  882.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6650.99 ms /    22 tokens\n",
      " 22%|██▏       | 774/3487 [2:41:33<7:12:48,  9.57s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6300.00 ms /    32 tokens (  196.87 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.71 ms /     3 runs   (  874.57 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8925.88 ms /    35 tokens\n",
      " 22%|██▏       | 775/3487 [2:41:42<7:03:59,  9.38s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8084.76 ms /    39 tokens (  207.30 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.62 ms /     3 runs   (  882.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10734.09 ms /    42 tokens\n",
      " 22%|██▏       | 776/3487 [2:41:53<7:22:17,  9.79s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2508.69 ms /    11 tokens (  228.06 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.45 ms /     3 runs   (  875.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5136.86 ms /    14 tokens\n",
      " 22%|██▏       | 777/3487 [2:41:58<6:19:13,  8.40s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2568.46 ms /    10 tokens (  256.85 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.40 ms /     3 runs   (  878.80 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5207.78 ms /    13 tokens\n",
      " 22%|██▏       | 778/3487 [2:42:03<5:36:00,  7.44s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10176.28 ms /    50 tokens (  203.53 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.03 ms /     3 runs   (  874.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12802.80 ms /    53 tokens\n",
      " 22%|██▏       | 779/3487 [2:42:16<6:48:34,  9.05s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2965.86 ms /    13 tokens (  228.14 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.43 ms /     3 runs   (  880.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5608.96 ms /    16 tokens\n",
      " 22%|██▏       | 780/3487 [2:42:21<6:01:56,  8.02s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2072.64 ms /     9 tokens (  230.29 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.58 ms /     3 runs   (  885.19 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4730.74 ms /    12 tokens\n",
      " 22%|██▏       | 781/3487 [2:42:26<5:17:24,  7.04s/it]Llama.generate: 308 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1731.53 ms /     6 tokens (  288.59 ms per token,     3.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2754.78 ms /     3 runs   (  918.26 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4488.44 ms /     9 tokens\n",
      " 22%|██▏       | 782/3487 [2:42:31<4:42:55,  6.28s/it]Llama.generate: 307 prefix-match hit, remaining 166 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   33955.94 ms /   166 tokens (  204.55 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.39 ms /     3 runs   (  902.13 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   36665.25 ms /   169 tokens\n",
      " 22%|██▏       | 783/3487 [2:43:07<11:34:13, 15.40s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5517.83 ms /    27 tokens (  204.36 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.77 ms /     3 runs   (  886.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8179.54 ms /    30 tokens\n",
      " 22%|██▏       | 784/3487 [2:43:15<9:56:27, 13.24s/it] Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11564.92 ms /    60 tokens (  192.75 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.19 ms /     3 runs   (  890.73 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14239.88 ms /    63 tokens\n",
      " 23%|██▎       | 785/3487 [2:43:30<10:09:51, 13.54s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7802.22 ms /    36 tokens (  216.73 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.28 ms /     3 runs   (  873.09 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10424.45 ms /    39 tokens\n",
      " 23%|██▎       | 786/3487 [2:43:40<9:27:38, 12.61s/it] Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3962.10 ms /    19 tokens (  208.53 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.96 ms /     3 runs   (  882.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6611.14 ms /    22 tokens\n",
      " 23%|██▎       | 787/3487 [2:43:47<8:06:33, 10.81s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2944.77 ms /    13 tokens (  226.52 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.52 ms /     3 runs   (  882.17 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5593.67 ms /    16 tokens\n",
      " 23%|██▎       | 788/3487 [2:43:52<6:56:03,  9.25s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3680.52 ms /    18 tokens (  204.47 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.13 ms /     3 runs   (  887.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6344.18 ms /    21 tokens\n",
      " 23%|██▎       | 789/3487 [2:43:59<6:16:51,  8.38s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4380.58 ms /    20 tokens (  219.03 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.90 ms /     3 runs   (  880.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7025.90 ms /    23 tokens\n",
      " 23%|██▎       | 790/3487 [2:44:06<5:58:58,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4876.56 ms /    24 tokens (  203.19 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.41 ms /     3 runs   (  879.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7516.79 ms /    27 tokens\n",
      " 23%|██▎       | 791/3487 [2:44:13<5:52:37,  7.85s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7295.15 ms /    33 tokens (  221.07 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2613.13 ms /     3 runs   (  871.04 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9910.45 ms /    36 tokens\n",
      " 23%|██▎       | 792/3487 [2:44:23<6:20:23,  8.47s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2518.72 ms /    11 tokens (  228.97 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.05 ms /     3 runs   (  876.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5149.19 ms /    14 tokens\n",
      " 23%|██▎       | 793/3487 [2:44:28<5:35:38,  7.48s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2498.65 ms /    10 tokens (  249.86 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.58 ms /     3 runs   (  883.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5151.60 ms /    13 tokens\n",
      " 23%|██▎       | 794/3487 [2:44:34<5:04:47,  6.79s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1558.79 ms /     5 tokens (  311.76 ms per token,     3.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.28 ms /     3 runs   (  887.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4222.87 ms /     8 tokens\n",
      " 23%|██▎       | 795/3487 [2:44:38<4:30:13,  6.02s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2555.76 ms /    10 tokens (  255.58 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.32 ms /     3 runs   (  883.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5207.69 ms /    13 tokens\n",
      " 23%|██▎       | 796/3487 [2:44:43<4:19:15,  5.78s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11320.83 ms /    59 tokens (  191.88 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.33 ms /     3 runs   (  883.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13973.38 ms /    62 tokens\n",
      " 23%|██▎       | 797/3487 [2:44:57<6:09:28,  8.24s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8230.30 ms /    41 tokens (  200.74 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.89 ms /     3 runs   (  871.63 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10847.82 ms /    44 tokens\n",
      " 23%|██▎       | 798/3487 [2:45:08<6:44:55,  9.04s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5282.53 ms /    27 tokens (  195.65 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.19 ms /     3 runs   (  878.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7921.26 ms /    30 tokens\n",
      " 23%|██▎       | 799/3487 [2:45:16<6:29:53,  8.70s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7725.74 ms /    38 tokens (  203.31 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.81 ms /     3 runs   (  875.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10353.19 ms /    41 tokens\n",
      " 23%|██▎       | 800/3487 [2:45:26<6:52:02,  9.20s/it]Llama.generate: 311 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4464.92 ms /    22 tokens (  202.95 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.65 ms /     3 runs   (  876.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7095.85 ms /    25 tokens\n",
      " 23%|██▎       | 801/3487 [2:45:33<6:23:42,  8.57s/it]Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8685.51 ms /    44 tokens (  197.40 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.16 ms /     3 runs   (  877.72 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11321.59 ms /    47 tokens\n",
      " 23%|██▎       | 802/3487 [2:45:45<7:00:35,  9.40s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5307.98 ms /    27 tokens (  196.59 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.68 ms /     3 runs   (  872.56 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7928.12 ms /    30 tokens\n",
      " 23%|██▎       | 803/3487 [2:45:53<6:40:47,  8.96s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5852.68 ms /    29 tokens (  201.82 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.03 ms /     3 runs   (  896.01 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8543.86 ms /    32 tokens\n",
      " 23%|██▎       | 804/3487 [2:46:01<6:35:11,  8.84s/it]Llama.generate: 307 prefix-match hit, remaining 209 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   39353.76 ms /   209 tokens (  188.30 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.22 ms /     3 runs   (  878.07 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   41990.98 ms /   212 tokens\n",
      " 23%|██▎       | 805/3487 [2:46:43<13:59:45, 18.79s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9114.85 ms /    42 tokens (  217.02 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2876.61 ms /     3 runs   (  958.87 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   11993.98 ms /    45 tokens\n",
      " 23%|██▎       | 806/3487 [2:46:55<12:28:28, 16.75s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8099.43 ms /    37 tokens (  218.90 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.40 ms /     3 runs   (  872.80 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10720.24 ms /    40 tokens\n",
      " 23%|██▎       | 807/3487 [2:47:06<11:07:31, 14.94s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6333.29 ms /    32 tokens (  197.92 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.36 ms /     3 runs   (  886.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8994.88 ms /    35 tokens\n",
      " 23%|██▎       | 808/3487 [2:47:15<9:47:42, 13.16s/it] Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5821.33 ms /    29 tokens (  200.74 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.24 ms /     3 runs   (  901.75 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8528.92 ms /    32 tokens\n",
      " 23%|██▎       | 809/3487 [2:47:23<8:45:34, 11.78s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2282.15 ms /     7 tokens (  326.02 ms per token,     3.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.09 ms /     3 runs   (  897.03 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4975.65 ms /    10 tokens\n",
      " 23%|██▎       | 810/3487 [2:47:28<7:14:30,  9.74s/it]Llama.generate: 313 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3711.65 ms /     4 runs   (  927.91 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    3713.89 ms /     5 tokens\n",
      " 23%|██▎       | 811/3487 [2:47:32<5:53:50,  7.93s/it]Llama.generate: 313 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3720.00 ms /     4 runs   (  930.00 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    3726.46 ms /     5 tokens\n",
      " 23%|██▎       | 812/3487 [2:47:36<4:57:30,  6.67s/it]Llama.generate: 313 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3777.39 ms /     4 runs   (  944.35 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    3780.16 ms /     5 tokens\n",
      " 23%|██▎       | 813/3487 [2:47:40<4:18:47,  5.81s/it]Llama.generate: 313 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3686.26 ms /     4 runs   (  921.57 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    3688.44 ms /     5 tokens\n",
      " 23%|██▎       | 814/3487 [2:47:43<3:50:30,  5.17s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2765.66 ms /    12 tokens (  230.47 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.23 ms /     3 runs   (  890.08 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5438.73 ms /    15 tokens\n",
      " 23%|██▎       | 815/3487 [2:47:49<3:54:03,  5.26s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4891.18 ms /    24 tokens (  203.80 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.74 ms /     3 runs   (  889.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7562.63 ms /    27 tokens\n",
      " 23%|██▎       | 816/3487 [2:47:56<4:24:54,  5.95s/it]Llama.generate: 306 prefix-match hit, remaining 169 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   32130.34 ms /   169 tokens (  190.12 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.80 ms /     3 runs   (  877.93 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   34766.74 ms /   172 tokens\n",
      " 23%|██▎       | 817/3487 [2:48:31<10:49:40, 14.60s/it]Llama.generate: 307 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16615.02 ms /    83 tokens (  200.18 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2726.42 ms /     3 runs   (  908.81 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   19343.73 ms /    86 tokens\n",
      " 23%|██▎       | 818/3487 [2:48:50<11:52:51, 16.03s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1583.38 ms /     6 tokens (  263.90 ms per token,     3.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.35 ms /     3 runs   (  886.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4245.55 ms /     9 tokens\n",
      " 23%|██▎       | 819/3487 [2:48:55<9:15:33, 12.49s/it] Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10101.46 ms /    48 tokens (  210.45 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2903.70 ms /     3 runs   (  967.90 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   13008.04 ms /    51 tokens\n",
      " 24%|██▎       | 820/3487 [2:49:08<9:22:19, 12.65s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4875.86 ms /    22 tokens (  221.63 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2841.87 ms /     3 runs   (  947.29 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7720.68 ms /    25 tokens\n",
      " 24%|██▎       | 821/3487 [2:49:15<8:16:31, 11.17s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5295.80 ms /    25 tokens (  211.83 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.72 ms /     3 runs   (  900.57 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8000.50 ms /    28 tokens\n",
      " 24%|██▎       | 822/3487 [2:49:23<7:34:09, 10.22s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3983.83 ms /    19 tokens (  209.68 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2861.20 ms /     3 runs   (  953.73 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    6847.86 ms /    22 tokens\n",
      " 24%|██▎       | 823/3487 [2:49:30<6:49:32,  9.22s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4922.55 ms /    23 tokens (  214.02 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.93 ms /     3 runs   (  883.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7574.93 ms /    26 tokens\n",
      " 24%|██▎       | 824/3487 [2:49:38<6:27:33,  8.73s/it]Llama.generate: 306 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12155.96 ms /    63 tokens (  192.95 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.00 ms /     3 runs   (  884.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14810.70 ms /    66 tokens\n",
      " 24%|██▎       | 825/3487 [2:49:53<7:48:25, 10.56s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8066.66 ms /    39 tokens (  206.84 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2730.89 ms /     3 runs   (  910.30 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   10800.02 ms /    42 tokens\n",
      " 24%|██▎       | 826/3487 [2:50:04<7:51:36, 10.63s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5416.63 ms /    25 tokens (  216.67 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2815.26 ms /     3 runs   (  938.42 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    8234.54 ms /    28 tokens\n",
      " 24%|██▎       | 827/3487 [2:50:12<7:19:38,  9.92s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6060.12 ms /    30 tokens (  202.00 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.51 ms /     3 runs   (  885.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8719.08 ms /    33 tokens\n",
      " 24%|██▎       | 828/3487 [2:50:21<7:03:39,  9.56s/it]Llama.generate: 306 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10163.09 ms /    53 tokens (  191.76 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.39 ms /     3 runs   (  883.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12814.48 ms /    56 tokens\n",
      " 24%|██▍       | 829/3487 [2:50:33<7:46:52, 10.54s/it]Llama.generate: 306 prefix-match hit, remaining 124 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23728.83 ms /   124 tokens (  191.36 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2771.51 ms /     3 runs   (  923.84 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   26503.62 ms /   127 tokens\n",
      " 24%|██▍       | 830/3487 [2:51:00<11:18:54, 15.33s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2529.68 ms /    11 tokens (  229.97 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3100.55 ms /     3 runs   ( 1033.52 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    5633.24 ms /    14 tokens\n",
      " 24%|██▍       | 831/3487 [2:51:05<9:10:00, 12.42s/it] Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3232.31 ms /    13 tokens (  248.64 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2759.57 ms /     3 runs   (  919.86 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5995.19 ms /    16 tokens\n",
      " 24%|██▍       | 832/3487 [2:51:11<7:44:33, 10.50s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8976.90 ms /    44 tokens (  204.02 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.11 ms /     3 runs   (  915.70 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   11726.88 ms /    47 tokens\n",
      " 24%|██▍       | 833/3487 [2:51:23<8:00:48, 10.87s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1720.62 ms /     6 tokens (  286.77 ms per token,     3.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.44 ms /     3 runs   (  889.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4390.19 ms /     9 tokens\n",
      " 24%|██▍       | 834/3487 [2:51:28<6:34:46,  8.93s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3324.54 ms /    13 tokens (  255.73 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.35 ms /     3 runs   (  894.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6009.63 ms /    16 tokens\n",
      " 24%|██▍       | 835/3487 [2:51:34<5:56:02,  8.06s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2699.57 ms /    11 tokens (  245.42 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.54 ms /     3 runs   (  887.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5365.29 ms /    14 tokens\n",
      " 24%|██▍       | 836/3487 [2:51:39<5:20:21,  7.25s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2140.02 ms /     9 tokens (  237.78 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.45 ms /     3 runs   (  895.82 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4830.49 ms /    12 tokens\n",
      " 24%|██▍       | 837/3487 [2:51:44<4:48:42,  6.54s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3127.89 ms /    12 tokens (  260.66 ms per token,     3.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.03 ms /     3 runs   (  906.68 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5850.16 ms /    15 tokens\n",
      " 24%|██▍       | 838/3487 [2:51:50<4:39:38,  6.33s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3017.47 ms /    14 tokens (  215.53 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2765.19 ms /     3 runs   (  921.73 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5785.96 ms /    17 tokens\n",
      " 24%|██▍       | 839/3487 [2:51:56<4:32:25,  6.17s/it]Llama.generate: 307 prefix-match hit, remaining 99 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19717.15 ms /    99 tokens (  199.16 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2923.80 ms /     3 runs   (  974.60 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   22644.11 ms /   102 tokens\n",
      " 24%|██▍       | 840/3487 [2:52:18<8:10:26, 11.12s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3094.07 ms /    14 tokens (  221.00 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.41 ms /     3 runs   (  885.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5753.06 ms /    17 tokens\n",
      " 24%|██▍       | 841/3487 [2:52:24<6:59:24,  9.51s/it]Llama.generate: 317 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3051.57 ms /    13 tokens (  234.74 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.16 ms /     3 runs   (  883.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5705.13 ms /    16 tokens\n",
      " 24%|██▍       | 842/3487 [2:52:30<6:09:00,  8.37s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2673.03 ms /    12 tokens (  222.75 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.77 ms /     3 runs   (  889.26 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5343.57 ms /    15 tokens\n",
      " 24%|██▍       | 843/3487 [2:52:35<5:28:56,  7.46s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2371.69 ms /    10 tokens (  237.17 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.03 ms /     3 runs   (  879.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5013.38 ms /    13 tokens\n",
      " 24%|██▍       | 844/3487 [2:52:40<4:56:32,  6.73s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2018.35 ms /     8 tokens (  252.29 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.97 ms /     3 runs   (  886.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4680.19 ms /    11 tokens\n",
      " 24%|██▍       | 845/3487 [2:52:45<4:29:25,  6.12s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2936.25 ms /    13 tokens (  225.87 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.48 ms /     3 runs   (  883.49 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5589.18 ms /    16 tokens\n",
      " 24%|██▍       | 846/3487 [2:52:50<4:22:25,  5.96s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5853.44 ms /    29 tokens (  201.84 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.79 ms /     3 runs   (  882.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8504.96 ms /    32 tokens\n",
      " 24%|██▍       | 847/3487 [2:52:59<4:56:00,  6.73s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10219.31 ms /    52 tokens (  196.53 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.15 ms /     3 runs   (  876.72 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12852.13 ms /    55 tokens\n",
      " 24%|██▍       | 848/3487 [2:53:12<6:16:49,  8.57s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7683.89 ms /    38 tokens (  202.21 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.01 ms /     3 runs   (  885.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10343.34 ms /    41 tokens\n",
      " 24%|██▍       | 849/3487 [2:53:22<6:40:13,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5028.67 ms /    25 tokens (  201.15 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.59 ms /     3 runs   (  886.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7690.51 ms /    28 tokens\n",
      " 24%|██▍       | 850/3487 [2:53:30<6:21:34,  8.68s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4915.98 ms /    24 tokens (  204.83 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.16 ms /     3 runs   (  885.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7575.64 ms /    27 tokens\n",
      " 24%|██▍       | 851/3487 [2:53:37<6:06:56,  8.35s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5441.46 ms /    26 tokens (  209.29 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.20 ms /     3 runs   (  890.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8115.43 ms /    29 tokens\n",
      " 24%|██▍       | 852/3487 [2:53:45<6:03:45,  8.28s/it]Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11036.80 ms /    57 tokens (  193.63 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.71 ms /     3 runs   (  902.90 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   13748.68 ms /    60 tokens\n",
      " 24%|██▍       | 853/3487 [2:53:59<7:15:41,  9.92s/it]Llama.generate: 306 prefix-match hit, remaining 140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26613.98 ms /   140 tokens (  190.10 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.20 ms /     3 runs   (  877.07 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   29248.47 ms /   143 tokens\n",
      " 24%|██▍       | 854/3487 [2:54:28<11:30:03, 15.72s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11817.02 ms /    60 tokens (  196.95 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.56 ms /     3 runs   (  886.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14479.08 ms /    63 tokens\n",
      " 25%|██▍       | 855/3487 [2:54:43<11:13:29, 15.35s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9300.10 ms /    47 tokens (  197.87 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.66 ms /     3 runs   (  879.89 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11942.53 ms /    50 tokens\n",
      " 25%|██▍       | 856/3487 [2:54:55<10:28:29, 14.33s/it]Llama.generate: 307 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20398.55 ms /   107 tokens (  190.64 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.37 ms /     3 runs   (  881.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23046.79 ms /   110 tokens\n",
      " 25%|██▍       | 857/3487 [2:55:18<12:22:56, 16.95s/it]Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11135.64 ms /    57 tokens (  195.36 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.60 ms /     3 runs   (  873.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13759.63 ms /    60 tokens\n",
      " 25%|██▍       | 858/3487 [2:55:32<11:40:50, 15.99s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5139.26 ms /    26 tokens (  197.66 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.82 ms /     3 runs   (  888.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7808.54 ms /    29 tokens\n",
      " 25%|██▍       | 859/3487 [2:55:40<9:53:06, 13.54s/it] Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4851.16 ms /    24 tokens (  202.13 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.59 ms /     3 runs   (  877.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7484.97 ms /    27 tokens\n",
      " 25%|██▍       | 860/3487 [2:55:47<8:33:26, 11.73s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7932.02 ms /    38 tokens (  208.74 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.27 ms /     3 runs   (  878.09 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10569.02 ms /    41 tokens\n",
      " 25%|██▍       | 861/3487 [2:55:58<8:18:11, 11.38s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2770.07 ms /    12 tokens (  230.84 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.49 ms /     3 runs   (  888.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5439.24 ms /    15 tokens\n",
      " 25%|██▍       | 862/3487 [2:56:03<7:00:06,  9.60s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2374.68 ms /    10 tokens (  237.47 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.33 ms /     3 runs   (  884.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5029.53 ms /    13 tokens\n",
      " 25%|██▍       | 863/3487 [2:56:08<6:00:03,  8.23s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9319.51 ms /    46 tokens (  202.60 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.99 ms /     3 runs   (  884.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11973.93 ms /    49 tokens\n",
      " 25%|██▍       | 864/3487 [2:56:20<6:49:03,  9.36s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2077.21 ms /     9 tokens (  230.80 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.21 ms /     3 runs   (  887.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4743.57 ms /    12 tokens\n",
      " 25%|██▍       | 865/3487 [2:56:25<5:48:56,  7.98s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2129.99 ms /     8 tokens (  266.25 ms per token,     3.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.01 ms /     3 runs   (  886.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4790.03 ms /    11 tokens\n",
      " 25%|██▍       | 866/3487 [2:56:30<5:07:02,  7.03s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2070.92 ms /     9 tokens (  230.10 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.31 ms /     3 runs   (  886.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4732.09 ms /    12 tokens\n",
      " 25%|██▍       | 867/3487 [2:56:34<4:36:58,  6.34s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9673.34 ms /    48 tokens (  201.53 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.62 ms /     3 runs   (  887.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12337.95 ms /    51 tokens\n",
      " 25%|██▍       | 868/3487 [2:56:47<5:55:29,  8.14s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5666.33 ms /    27 tokens (  209.86 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.26 ms /     3 runs   (  888.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8333.57 ms /    30 tokens\n",
      " 25%|██▍       | 869/3487 [2:56:55<5:57:57,  8.20s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2743.40 ms /    12 tokens (  228.62 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.42 ms /     3 runs   (  894.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5430.20 ms /    15 tokens\n",
      " 25%|██▍       | 870/3487 [2:57:01<5:21:36,  7.37s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3580.92 ms /    17 tokens (  210.64 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.76 ms /     3 runs   (  881.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6228.31 ms /    20 tokens\n",
      " 25%|██▍       | 871/3487 [2:57:07<5:06:37,  7.03s/it]Llama.generate: 308 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3067.08 ms /    13 tokens (  235.93 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.87 ms /     3 runs   (  882.96 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5718.25 ms /    16 tokens\n",
      " 25%|██▌       | 872/3487 [2:57:13<4:49:25,  6.64s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2624.29 ms /    12 tokens (  218.69 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.92 ms /     3 runs   (  883.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5277.63 ms /    15 tokens\n",
      " 25%|██▌       | 873/3487 [2:57:18<4:31:37,  6.23s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3316.87 ms /    15 tokens (  221.12 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.54 ms /     3 runs   (  883.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5971.37 ms /    18 tokens\n",
      " 25%|██▌       | 874/3487 [2:57:24<4:28:11,  6.16s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7857.23 ms /    38 tokens (  206.77 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.82 ms /     3 runs   (  907.94 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   10583.48 ms /    41 tokens\n",
      " 25%|██▌       | 875/3487 [2:57:34<5:25:59,  7.49s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3349.84 ms /    15 tokens (  223.32 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.45 ms /     3 runs   (  887.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6015.72 ms /    18 tokens\n",
      " 25%|██▌       | 876/3487 [2:57:40<5:06:45,  7.05s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2448.27 ms /    10 tokens (  244.83 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.24 ms /     3 runs   (  890.08 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5120.91 ms /    13 tokens\n",
      " 25%|██▌       | 877/3487 [2:57:46<4:41:34,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4332.52 ms /    20 tokens (  216.63 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.17 ms /     3 runs   (  894.39 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7018.16 ms /    23 tokens\n",
      " 25%|██▌       | 878/3487 [2:57:53<4:48:41,  6.64s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8545.98 ms /    43 tokens (  198.74 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.70 ms /     3 runs   (  899.57 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11246.97 ms /    46 tokens\n",
      " 25%|██▌       | 879/3487 [2:58:04<5:48:45,  8.02s/it]Llama.generate: 306 prefix-match hit, remaining 101 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19684.48 ms /   101 tokens (  194.90 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.65 ms /     3 runs   (  877.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   22321.13 ms /   104 tokens\n",
      " 25%|██▌       | 880/3487 [2:58:26<8:55:06, 12.32s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9151.17 ms /    46 tokens (  198.94 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.76 ms /     3 runs   (  881.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11797.77 ms /    49 tokens\n",
      " 25%|██▌       | 881/3487 [2:58:38<8:48:15, 12.16s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2820.70 ms /    12 tokens (  235.06 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.90 ms /     3 runs   (  884.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5478.07 ms /    15 tokens\n",
      " 25%|██▌       | 882/3487 [2:58:43<7:21:06, 10.16s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5233.10 ms /    26 tokens (  201.27 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.85 ms /     3 runs   (  887.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7899.69 ms /    29 tokens\n",
      " 25%|██▌       | 883/3487 [2:58:51<6:51:36,  9.48s/it]Llama.generate: 307 prefix-match hit, remaining 104 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20502.36 ms /   104 tokens (  197.14 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.82 ms /     3 runs   (  881.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23149.06 ms /   107 tokens\n",
      " 25%|██▌       | 884/3487 [2:59:14<9:49:26, 13.59s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5307.30 ms /    27 tokens (  196.57 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.98 ms /     3 runs   (  881.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7954.98 ms /    30 tokens\n",
      " 25%|██▌       | 885/3487 [2:59:22<8:36:03, 11.90s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3143.09 ms /    14 tokens (  224.51 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.91 ms /     3 runs   (  876.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5774.98 ms /    17 tokens\n",
      " 25%|██▌       | 886/3487 [2:59:28<7:16:18, 10.06s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4827.61 ms /    24 tokens (  201.15 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.87 ms /     3 runs   (  878.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7467.31 ms /    27 tokens\n",
      " 25%|██▌       | 887/3487 [2:59:36<6:42:28,  9.29s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4127.74 ms /    17 tokens (  242.81 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.89 ms /     3 runs   (  875.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6756.51 ms /    20 tokens\n",
      " 25%|██▌       | 888/3487 [2:59:42<6:09:31,  8.53s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5241.68 ms /    26 tokens (  201.60 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.04 ms /     3 runs   (  874.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7867.49 ms /    29 tokens\n",
      " 25%|██▌       | 889/3487 [2:59:50<6:00:52,  8.33s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3203.75 ms /    14 tokens (  228.84 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.98 ms /     3 runs   (  879.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5846.67 ms /    17 tokens\n",
      " 26%|██▌       | 890/3487 [2:59:56<5:28:32,  7.59s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5832.01 ms /    29 tokens (  201.10 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.43 ms /     3 runs   (  877.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8468.66 ms /    32 tokens\n",
      " 26%|██▌       | 891/3487 [3:00:05<5:39:55,  7.86s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7315.53 ms /    33 tokens (  221.68 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.92 ms /     3 runs   (  883.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9968.79 ms /    36 tokens\n",
      " 26%|██▌       | 892/3487 [3:00:15<6:07:18,  8.49s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13696.08 ms /    66 tokens (  207.52 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.54 ms /     3 runs   (  877.51 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16331.07 ms /    69 tokens\n",
      " 26%|██▌       | 893/3487 [3:00:31<7:48:56, 10.85s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1988.18 ms /     7 tokens (  284.03 ms per token,     3.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.93 ms /     3 runs   (  884.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4645.36 ms /    10 tokens\n",
      " 26%|██▌       | 894/3487 [3:00:36<6:28:27,  8.99s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2902.63 ms /    13 tokens (  223.28 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.57 ms /     3 runs   (  882.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5552.96 ms /    16 tokens\n",
      " 26%|██▌       | 895/3487 [3:00:41<5:43:53,  7.96s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5233.06 ms /    25 tokens (  209.32 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.96 ms /     3 runs   (  873.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7856.98 ms /    28 tokens\n",
      " 26%|██▌       | 896/3487 [3:00:49<5:42:31,  7.93s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6329.46 ms /    31 tokens (  204.18 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.84 ms /     3 runs   (  873.95 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8953.73 ms /    34 tokens\n",
      " 26%|██▌       | 897/3487 [3:00:58<5:55:43,  8.24s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1973.39 ms /     8 tokens (  246.67 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.48 ms /     3 runs   (  874.16 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4598.25 ms /    11 tokens\n",
      " 26%|██▌       | 898/3487 [3:01:03<5:08:32,  7.15s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8262.65 ms /    41 tokens (  201.53 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.24 ms /     3 runs   (  870.41 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10876.21 ms /    44 tokens\n",
      " 26%|██▌       | 899/3487 [3:01:14<5:56:44,  8.27s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4258.40 ms /    21 tokens (  202.78 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.06 ms /     3 runs   (  876.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6888.55 ms /    24 tokens\n",
      " 26%|██▌       | 900/3487 [3:01:20<5:38:50,  7.86s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4195.14 ms /    20 tokens (  209.76 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.41 ms /     3 runs   (  878.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6833.14 ms /    23 tokens\n",
      " 26%|██▌       | 901/3487 [3:01:27<5:25:34,  7.55s/it]Llama.generate: 307 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16144.26 ms /    83 tokens (  194.51 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.54 ms /     3 runs   (  875.51 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18773.55 ms /    86 tokens\n",
      " 26%|██▌       | 902/3487 [3:01:46<7:50:57, 10.93s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9647.87 ms /    48 tokens (  201.00 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2853.59 ms /     3 runs   (  951.20 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   12504.05 ms /    51 tokens\n",
      " 26%|██▌       | 903/3487 [3:01:59<8:11:36, 11.41s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1863.29 ms /     7 tokens (  266.18 ms per token,     3.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.03 ms /     3 runs   (  915.68 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4612.98 ms /    10 tokens\n",
      " 26%|██▌       | 904/3487 [3:02:03<6:43:43,  9.38s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2302.83 ms /     8 tokens (  287.85 ms per token,     3.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.58 ms /     3 runs   (  889.19 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5003.57 ms /    11 tokens\n",
      " 26%|██▌       | 905/3487 [3:02:08<5:47:37,  8.08s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2134.87 ms /     8 tokens (  266.86 ms per token,     3.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.40 ms /     3 runs   (  881.80 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4783.09 ms /    11 tokens\n",
      " 26%|██▌       | 906/3487 [3:02:13<5:05:07,  7.09s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5401.90 ms /    27 tokens (  200.07 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.13 ms /     3 runs   (  875.04 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8030.60 ms /    30 tokens\n",
      " 26%|██▌       | 907/3487 [3:02:21<5:17:13,  7.38s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1747.69 ms /     6 tokens (  291.28 ms per token,     3.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.48 ms /     3 runs   (  877.16 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4381.48 ms /     9 tokens\n",
      " 26%|██▌       | 908/3487 [3:02:26<4:38:35,  6.48s/it]Llama.generate: 307 prefix-match hit, remaining 91 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17388.56 ms /    91 tokens (  191.08 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.00 ms /     3 runs   (  870.67 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   20003.12 ms /    94 tokens\n",
      " 26%|██▌       | 909/3487 [3:02:46<7:32:53, 10.54s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9099.44 ms /    45 tokens (  202.21 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.12 ms /     3 runs   (  873.37 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11722.12 ms /    48 tokens\n",
      " 26%|██▌       | 910/3487 [3:02:57<7:48:02, 10.90s/it]Llama.generate: 307 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14907.10 ms /    78 tokens (  191.12 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.24 ms /     3 runs   (  872.41 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   17527.01 ms /    81 tokens\n",
      " 26%|██▌       | 911/3487 [3:03:15<9:13:21, 12.89s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4256.71 ms /    20 tokens (  212.84 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.76 ms /     3 runs   (  879.59 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6897.79 ms /    23 tokens\n",
      " 26%|██▌       | 912/3487 [3:03:22<7:56:05, 11.09s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2630.04 ms /    12 tokens (  219.17 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.74 ms /     3 runs   (  878.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5268.41 ms /    15 tokens\n",
      " 26%|██▌       | 913/3487 [3:03:27<6:41:01,  9.35s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8082.90 ms /    38 tokens (  212.71 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2611.75 ms /     3 runs   (  870.58 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10697.12 ms /    41 tokens\n",
      " 26%|██▌       | 914/3487 [3:03:38<6:58:18,  9.75s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7626.12 ms /    38 tokens (  200.69 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.83 ms /     3 runs   (  877.61 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10261.50 ms /    41 tokens\n",
      " 26%|██▌       | 915/3487 [3:03:48<7:04:45,  9.91s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4088.81 ms /    19 tokens (  215.20 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.02 ms /     3 runs   (  878.34 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6726.48 ms /    22 tokens\n",
      " 26%|██▋       | 916/3487 [3:03:55<6:23:49,  8.96s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4883.73 ms /    24 tokens (  203.49 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2854.29 ms /     3 runs   (  951.43 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    7740.60 ms /    27 tokens\n",
      " 26%|██▋       | 917/3487 [3:04:02<6:08:10,  8.60s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7979.62 ms /    39 tokens (  204.61 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.46 ms /     3 runs   (  876.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10611.33 ms /    42 tokens\n",
      " 26%|██▋       | 918/3487 [3:04:13<6:34:02,  9.20s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10180.31 ms /    52 tokens (  195.78 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.52 ms /     3 runs   (  872.51 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   12800.35 ms /    55 tokens\n",
      " 26%|██▋       | 919/3487 [3:04:26<7:20:11, 10.28s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7219.87 ms /    33 tokens (  218.78 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.69 ms /     3 runs   (  889.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9890.94 ms /    36 tokens\n",
      " 26%|██▋       | 920/3487 [3:04:36<7:15:03, 10.17s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2273.98 ms /     9 tokens (  252.66 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.89 ms /     3 runs   (  871.63 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4891.66 ms /    12 tokens\n",
      " 26%|██▋       | 921/3487 [3:04:41<6:07:18,  8.59s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4840.06 ms /    24 tokens (  201.67 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.03 ms /     3 runs   (  875.34 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7469.11 ms /    27 tokens\n",
      " 26%|██▋       | 922/3487 [3:04:48<5:52:55,  8.26s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4922.77 ms /    24 tokens (  205.12 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.14 ms /     3 runs   (  873.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7545.96 ms /    27 tokens\n",
      " 26%|██▋       | 923/3487 [3:04:56<5:43:47,  8.05s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3680.90 ms /    17 tokens (  216.52 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.12 ms /     3 runs   (  883.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6335.75 ms /    20 tokens\n",
      " 26%|██▋       | 924/3487 [3:05:02<5:21:51,  7.53s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4797.17 ms /    24 tokens (  199.88 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.61 ms /     3 runs   (  874.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7422.25 ms /    27 tokens\n",
      " 27%|██▋       | 925/3487 [3:05:09<5:20:24,  7.50s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3037.84 ms /    13 tokens (  233.68 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.46 ms /     3 runs   (  874.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5662.85 ms /    16 tokens\n",
      " 27%|██▋       | 926/3487 [3:05:15<4:56:49,  6.95s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1809.52 ms /     7 tokens (  258.50 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.09 ms /     3 runs   (  875.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4438.81 ms /    10 tokens\n",
      " 27%|██▋       | 927/3487 [3:05:20<4:24:36,  6.20s/it]Llama.generate: 307 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20709.82 ms /   108 tokens (  191.76 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.59 ms /     3 runs   (  882.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23361.09 ms /   111 tokens\n",
      " 27%|██▋       | 928/3487 [3:05:43<8:04:09, 11.35s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1966.54 ms /     7 tokens (  280.93 ms per token,     3.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.97 ms /     3 runs   (  879.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4609.71 ms /    10 tokens\n",
      " 27%|██▋       | 929/3487 [3:05:48<6:37:49,  9.33s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1955.83 ms /     8 tokens (  244.48 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.42 ms /     3 runs   (  878.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4592.47 ms /    11 tokens\n",
      " 27%|██▋       | 930/3487 [3:05:52<5:37:11,  7.91s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5733.82 ms /    28 tokens (  204.78 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.40 ms /     3 runs   (  875.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8363.07 ms /    31 tokens\n",
      " 27%|██▋       | 931/3487 [3:06:01<5:42:55,  8.05s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3092.22 ms /    13 tokens (  237.86 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.74 ms /     3 runs   (  873.25 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5714.64 ms /    16 tokens\n",
      " 27%|██▋       | 932/3487 [3:06:06<5:13:04,  7.35s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5829.01 ms /    30 tokens (  194.30 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.81 ms /     3 runs   (  876.60 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8461.37 ms /    33 tokens\n",
      " 27%|██▋       | 933/3487 [3:06:15<5:27:12,  7.69s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6320.01 ms /    31 tokens (  203.87 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.01 ms /     3 runs   (  873.34 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8942.88 ms /    34 tokens\n",
      " 27%|██▋       | 934/3487 [3:06:24<5:43:13,  8.07s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4081.34 ms /    20 tokens (  204.07 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.45 ms /     3 runs   (  878.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6720.15 ms /    23 tokens\n",
      " 27%|██▋       | 935/3487 [3:06:30<5:26:02,  7.67s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7638.93 ms /    37 tokens (  206.46 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.35 ms /     3 runs   (  884.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10294.85 ms /    40 tokens\n",
      " 27%|██▋       | 936/3487 [3:06:41<5:59:31,  8.46s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13180.16 ms /    67 tokens (  196.72 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.88 ms /     3 runs   (  875.63 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15810.17 ms /    70 tokens\n",
      " 27%|██▋       | 937/3487 [3:06:57<7:33:15, 10.66s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3074.44 ms /    13 tokens (  236.50 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.95 ms /     3 runs   (  875.98 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5705.14 ms /    16 tokens\n",
      " 27%|██▋       | 938/3487 [3:07:02<6:29:59,  9.18s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2288.10 ms /     8 tokens (  286.01 ms per token,     3.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2870.06 ms /     3 runs   (  956.69 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    5160.59 ms /    11 tokens\n",
      " 27%|██▋       | 939/3487 [3:07:07<5:38:43,  7.98s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5871.27 ms /    29 tokens (  202.46 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.16 ms /     3 runs   (  874.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8497.12 ms /    32 tokens\n",
      " 27%|██▋       | 940/3487 [3:07:16<5:45:18,  8.13s/it]Llama.generate: 308 prefix-match hit, remaining 99 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19244.37 ms /    99 tokens (  194.39 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2604.95 ms /     3 runs   (  868.32 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   21851.39 ms /   102 tokens\n",
      " 27%|██▋       | 941/3487 [3:07:38<8:39:53, 12.25s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6220.33 ms /    31 tokens (  200.66 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.16 ms /     3 runs   (  885.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8879.23 ms /    34 tokens\n",
      " 27%|██▋       | 942/3487 [3:07:47<7:56:52, 11.24s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6500.24 ms /    32 tokens (  203.13 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.39 ms /     3 runs   (  881.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9146.57 ms /    35 tokens\n",
      " 27%|██▋       | 943/3487 [3:07:56<7:30:10, 10.62s/it]Llama.generate: 307 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14701.15 ms /    76 tokens (  193.44 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2818.49 ms /     3 runs   (  939.50 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   17553.66 ms /    79 tokens\n",
      " 27%|██▋       | 944/3487 [3:08:13<8:58:17, 12.70s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2285.94 ms /     8 tokens (  285.74 ms per token,     3.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3037.03 ms /     3 runs   ( 1012.34 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    5325.75 ms /    11 tokens\n",
      " 27%|██▋       | 945/3487 [3:08:19<7:24:28, 10.49s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2103.71 ms /     8 tokens (  262.96 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.07 ms /     3 runs   (  910.36 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4837.94 ms /    11 tokens\n",
      " 27%|██▋       | 946/3487 [3:08:24<6:12:36,  8.80s/it]Llama.generate: 306 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18102.06 ms /    90 tokens (  201.13 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.84 ms /     3 runs   (  886.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20765.49 ms /    93 tokens\n",
      " 27%|██▋       | 947/3487 [3:08:44<8:44:33, 12.39s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16666.41 ms /    86 tokens (  193.80 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2794.31 ms /     3 runs   (  931.44 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   19465.12 ms /    89 tokens\n",
      " 27%|██▋       | 948/3487 [3:09:04<10:14:21, 14.52s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9744.15 ms /    49 tokens (  198.86 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.62 ms /     3 runs   (  874.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12370.64 ms /    52 tokens\n",
      " 27%|██▋       | 949/3487 [3:09:16<9:46:57, 13.88s/it] Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16575.47 ms /    86 tokens (  192.74 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.12 ms /     3 runs   (  872.37 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   19195.56 ms /    89 tokens\n",
      " 27%|██▋       | 950/3487 [3:09:35<10:54:17, 15.47s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2504.14 ms /    11 tokens (  227.65 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.42 ms /     3 runs   (  885.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5162.88 ms /    14 tokens\n",
      " 27%|██▋       | 951/3487 [3:09:41<8:43:22, 12.38s/it] Llama.generate: 306 prefix-match hit, remaining 199 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   38906.02 ms /   199 tokens (  195.51 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.24 ms /     3 runs   (  905.75 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   41625.54 ms /   202 tokens\n",
      " 27%|██▋       | 952/3487 [3:10:22<14:53:58, 21.16s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11559.97 ms /    59 tokens (  195.93 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.21 ms /     3 runs   (  882.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14210.18 ms /    62 tokens\n",
      " 27%|██▋       | 953/3487 [3:10:36<13:25:40, 19.08s/it]Llama.generate: 311 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3811.95 ms /    18 tokens (  211.77 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.17 ms /     3 runs   (  898.39 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6509.89 ms /    21 tokens\n",
      " 27%|██▋       | 954/3487 [3:10:43<10:46:18, 15.31s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4493.66 ms /    21 tokens (  213.98 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.12 ms /     3 runs   (  881.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7141.69 ms /    24 tokens\n",
      " 27%|██▋       | 955/3487 [3:10:50<9:02:46, 12.86s/it] Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2082.96 ms /     9 tokens (  231.44 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.30 ms /     3 runs   (  885.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4742.98 ms /    12 tokens\n",
      " 27%|██▋       | 956/3487 [3:10:55<7:20:17, 10.44s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6392.01 ms /    31 tokens (  206.19 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.20 ms /     3 runs   (  895.73 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9082.17 ms /    34 tokens\n",
      " 27%|██▋       | 957/3487 [3:11:04<7:03:04, 10.03s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10232.24 ms /    48 tokens (  213.17 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2888.29 ms /     3 runs   (  962.76 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   13123.56 ms /    51 tokens\n",
      " 27%|██▋       | 958/3487 [3:11:17<7:42:05, 10.96s/it]Llama.generate: 306 prefix-match hit, remaining 97 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20384.64 ms /    97 tokens (  210.15 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.87 ms /     3 runs   (  875.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   23015.83 ms /   100 tokens\n",
      " 28%|██▊       | 959/3487 [3:11:40<10:14:22, 14.58s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13653.58 ms /    69 tokens (  197.88 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.41 ms /     3 runs   (  881.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16299.56 ms /    72 tokens\n",
      " 28%|██▊       | 960/3487 [3:11:56<10:35:56, 15.10s/it]Llama.generate: 306 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15016.29 ms /    76 tokens (  197.58 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.56 ms /     3 runs   (  895.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   17707.14 ms /    79 tokens\n",
      " 28%|██▊       | 961/3487 [3:12:14<11:08:43, 15.88s/it]Llama.generate: 306 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14691.34 ms /    75 tokens (  195.88 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.84 ms /     3 runs   (  897.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   17386.60 ms /    78 tokens\n",
      " 28%|██▊       | 962/3487 [3:12:32<11:27:31, 16.34s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4909.61 ms /    21 tokens (  233.79 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.07 ms /     3 runs   (  889.69 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7581.80 ms /    24 tokens\n",
      " 28%|██▊       | 963/3487 [3:12:39<9:36:52, 13.71s/it] Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10729.33 ms /    24 tokens (  447.06 ms per token,     2.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3611.84 ms /     3 runs   ( 1203.94 ms per token,     0.83 tokens per second)\n",
      "llama_perf_context_print:       total time =   14345.36 ms /    27 tokens\n",
      " 28%|██▊       | 964/3487 [3:12:54<9:44:44, 13.91s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8638.99 ms /    24 tokens (  359.96 ms per token,     2.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3081.55 ms /     3 runs   ( 1027.18 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =   11723.82 ms /    27 tokens\n",
      " 28%|██▊       | 965/3487 [3:13:05<9:17:08, 13.25s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3480.40 ms /    15 tokens (  232.03 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3089.09 ms /     3 runs   ( 1029.70 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    6572.40 ms /    18 tokens\n",
      " 28%|██▊       | 966/3487 [3:13:12<7:52:51, 11.25s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3434.32 ms /    14 tokens (  245.31 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.22 ms /     3 runs   (  886.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6097.65 ms /    17 tokens\n",
      " 28%|██▊       | 967/3487 [3:13:18<6:47:52,  9.71s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7327.26 ms /    33 tokens (  222.04 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.65 ms /     3 runs   (  885.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9986.27 ms /    36 tokens\n",
      " 28%|██▊       | 968/3487 [3:13:28<6:51:16,  9.80s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4814.05 ms /    22 tokens (  218.82 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.66 ms /     3 runs   (  892.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7495.21 ms /    25 tokens\n",
      " 28%|██▊       | 969/3487 [3:13:35<6:22:17,  9.11s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11959.97 ms /    62 tokens (  192.90 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.90 ms /     3 runs   (  886.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14622.02 ms /    65 tokens\n",
      " 28%|██▊       | 970/3487 [3:13:50<7:31:37, 10.77s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8098.78 ms /    39 tokens (  207.66 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.82 ms /     3 runs   (  884.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10756.37 ms /    42 tokens\n",
      " 28%|██▊       | 971/3487 [3:14:01<7:31:24, 10.76s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7945.11 ms /    38 tokens (  209.08 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.40 ms /     3 runs   (  882.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10593.98 ms /    41 tokens\n",
      " 28%|██▊       | 972/3487 [3:14:11<7:29:10, 10.72s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9579.47 ms /    45 tokens (  212.88 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.05 ms /     3 runs   (  883.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12231.23 ms /    48 tokens\n",
      " 28%|██▊       | 973/3487 [3:14:24<7:48:11, 11.17s/it]Llama.generate: 307 prefix-match hit, remaining 112 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   22791.74 ms /   112 tokens (  203.50 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2767.68 ms /     3 runs   (  922.56 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   25563.69 ms /   115 tokens\n",
      " 28%|██▊       | 974/3487 [3:14:49<10:48:55, 15.49s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2651.76 ms /    11 tokens (  241.07 ms per token,     4.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.47 ms /     3 runs   (  906.82 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5374.46 ms /    14 tokens\n",
      " 28%|██▊       | 975/3487 [3:14:55<8:41:42, 12.46s/it] Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7533.68 ms /    37 tokens (  203.61 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.11 ms /     3 runs   (  879.37 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10174.29 ms /    40 tokens\n",
      " 28%|██▊       | 976/3487 [3:15:05<8:12:53, 11.78s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4301.07 ms /    20 tokens (  215.05 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3057.84 ms /     3 runs   ( 1019.28 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    7364.63 ms /    23 tokens\n",
      " 28%|██▊       | 977/3487 [3:15:12<7:17:30, 10.46s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7664.07 ms /    31 tokens (  247.23 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2924.98 ms /     3 runs   (  974.99 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   10592.27 ms /    34 tokens\n",
      " 28%|██▊       | 978/3487 [3:15:23<7:19:09, 10.50s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5655.75 ms /    23 tokens (  245.90 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2851.15 ms /     3 runs   (  950.38 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    8510.41 ms /    26 tokens\n",
      " 28%|██▊       | 979/3487 [3:15:31<6:54:08,  9.91s/it]Llama.generate: 306 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20593.92 ms /   102 tokens (  201.90 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.21 ms /     3 runs   (  903.74 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   23308.41 ms /   105 tokens\n",
      " 28%|██▊       | 980/3487 [3:15:55<9:42:04, 13.93s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8731.46 ms /    42 tokens (  207.89 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.47 ms /     3 runs   (  889.49 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11402.73 ms /    45 tokens\n",
      " 28%|██▊       | 981/3487 [3:16:06<9:10:16, 13.17s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11243.45 ms /    57 tokens (  197.25 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.33 ms /     3 runs   (  889.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13914.33 ms /    60 tokens\n",
      " 28%|██▊       | 982/3487 [3:16:20<9:19:24, 13.40s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10123.38 ms /    47 tokens (  215.39 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2804.14 ms /     3 runs   (  934.71 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12929.76 ms /    50 tokens\n",
      " 28%|██▊       | 983/3487 [3:16:33<9:13:25, 13.26s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10682.25 ms /    54 tokens (  197.82 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.14 ms /     3 runs   (  882.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13331.35 ms /    57 tokens\n",
      " 28%|██▊       | 984/3487 [3:16:46<9:14:11, 13.28s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9210.89 ms /    41 tokens (  224.66 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2758.33 ms /     3 runs   (  919.44 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   11971.89 ms /    44 tokens\n",
      " 28%|██▊       | 985/3487 [3:16:58<8:57:40, 12.89s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2121.95 ms /     8 tokens (  265.24 ms per token,     3.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2743.70 ms /     3 runs   (  914.57 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4868.58 ms /    11 tokens\n",
      " 28%|██▊       | 986/3487 [3:17:03<7:17:13, 10.49s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4903.07 ms /    23 tokens (  213.18 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.13 ms /     3 runs   (  909.71 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7634.54 ms /    26 tokens\n",
      " 28%|██▊       | 987/3487 [3:17:11<6:41:29,  9.64s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2655.25 ms /    11 tokens (  241.39 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.95 ms /     3 runs   (  900.32 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5359.11 ms /    14 tokens\n",
      " 28%|██▊       | 988/3487 [3:17:16<5:48:01,  8.36s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8068.60 ms /    33 tokens (  244.50 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2746.24 ms /     3 runs   (  915.41 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10816.99 ms /    36 tokens\n",
      " 28%|██▊       | 989/3487 [3:17:27<6:18:43,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4442.84 ms /    21 tokens (  211.56 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2782.63 ms /     3 runs   (  927.54 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7227.90 ms /    24 tokens\n",
      " 28%|██▊       | 990/3487 [3:17:34<5:55:20,  8.54s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2849.81 ms /    11 tokens (  259.07 ms per token,     3.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.03 ms /     3 runs   (  888.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5518.05 ms /    14 tokens\n",
      " 28%|██▊       | 991/3487 [3:17:40<5:17:35,  7.63s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8150.51 ms /    40 tokens (  203.76 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2849.22 ms /     3 runs   (  949.74 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   11002.38 ms /    43 tokens\n",
      " 28%|██▊       | 992/3487 [3:17:51<5:59:35,  8.65s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3408.53 ms /    15 tokens (  227.24 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.84 ms /     3 runs   (  904.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6124.71 ms /    18 tokens\n",
      " 28%|██▊       | 993/3487 [3:17:57<5:28:07,  7.89s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4925.84 ms /    23 tokens (  214.17 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.63 ms /     3 runs   (  888.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7595.80 ms /    26 tokens\n",
      " 29%|██▊       | 994/3487 [3:18:04<5:24:23,  7.81s/it]Llama.generate: 306 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19902.51 ms /   102 tokens (  195.12 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.97 ms /     3 runs   (  884.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   22560.14 ms /   105 tokens\n",
      " 29%|██▊       | 995/3487 [3:18:27<8:28:11, 12.24s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3816.25 ms /    17 tokens (  224.49 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.87 ms /     3 runs   (  898.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6515.56 ms /    20 tokens\n",
      " 29%|██▊       | 996/3487 [3:18:34<7:16:49, 10.52s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5273.16 ms /    26 tokens (  202.81 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.54 ms /     3 runs   (  893.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7956.07 ms /    29 tokens\n",
      " 29%|██▊       | 997/3487 [3:18:42<6:44:49,  9.75s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3679.58 ms /    16 tokens (  229.97 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.64 ms /     3 runs   (  892.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6358.96 ms /    19 tokens\n",
      " 29%|██▊       | 998/3487 [3:18:48<6:02:30,  8.74s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4311.89 ms /    21 tokens (  205.33 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.32 ms /     3 runs   (  884.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6967.28 ms /    24 tokens\n",
      " 29%|██▊       | 999/3487 [3:18:55<5:40:26,  8.21s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2678.91 ms /    11 tokens (  243.54 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.91 ms /     3 runs   (  909.97 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5411.56 ms /    14 tokens\n",
      " 29%|██▊       | 1000/3487 [3:19:00<5:05:36,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9039.72 ms /    45 tokens (  200.88 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.43 ms /     3 runs   (  884.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11694.78 ms /    48 tokens\n",
      " 29%|██▊       | 1001/3487 [3:19:12<5:59:17,  8.67s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6063.76 ms /    30 tokens (  202.13 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.01 ms /     3 runs   (  895.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8753.40 ms /    33 tokens\n",
      " 29%|██▊       | 1002/3487 [3:19:21<6:00:16,  8.70s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4568.38 ms /    22 tokens (  207.65 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2905.89 ms /     3 runs   (  968.63 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    7476.95 ms /    25 tokens\n",
      " 29%|██▉       | 1003/3487 [3:19:28<5:45:03,  8.33s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3823.85 ms /    18 tokens (  212.44 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.97 ms /     3 runs   (  900.66 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6528.12 ms /    21 tokens\n",
      " 29%|██▉       | 1004/3487 [3:19:35<5:22:35,  7.80s/it]Llama.generate: 307 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12145.85 ms /    61 tokens (  199.11 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.12 ms /     3 runs   (  886.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14808.54 ms /    64 tokens\n",
      " 29%|██▉       | 1005/3487 [3:19:50<6:49:34,  9.90s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11870.94 ms /    60 tokens (  197.85 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.64 ms /     3 runs   (  911.88 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   14609.26 ms /    63 tokens\n",
      " 29%|██▉       | 1006/3487 [3:20:04<7:47:55, 11.32s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3283.09 ms /    13 tokens (  252.55 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2752.98 ms /     3 runs   (  917.66 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6038.52 ms /    16 tokens\n",
      " 29%|██▉       | 1007/3487 [3:20:10<6:42:26,  9.74s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2519.06 ms /    10 tokens (  251.91 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2859.83 ms /     3 runs   (  953.28 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    5381.09 ms /    13 tokens\n",
      " 29%|██▉       | 1008/3487 [3:20:16<5:48:25,  8.43s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4511.07 ms /    18 tokens (  250.61 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2785.31 ms /     3 runs   (  928.44 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7298.48 ms /    21 tokens\n",
      " 29%|██▉       | 1009/3487 [3:20:23<5:34:17,  8.09s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3951.44 ms /    17 tokens (  232.44 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2761.28 ms /     3 runs   (  920.43 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6715.87 ms /    20 tokens\n",
      " 29%|██▉       | 1010/3487 [3:20:30<5:17:13,  7.68s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8429.03 ms /    40 tokens (  210.73 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2754.98 ms /     3 runs   (  918.33 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   11186.27 ms /    43 tokens\n",
      " 29%|██▉       | 1011/3487 [3:20:41<6:00:38,  8.74s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9953.67 ms /    46 tokens (  216.38 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3054.04 ms /     3 runs   ( 1018.01 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =   13010.86 ms /    49 tokens\n",
      " 29%|██▉       | 1012/3487 [3:20:54<6:53:33, 10.03s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4066.67 ms /    14 tokens (  290.48 ms per token,     3.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2856.25 ms /     3 runs   (  952.08 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    6925.57 ms /    17 tokens\n",
      " 29%|██▉       | 1013/3487 [3:21:01<6:15:12,  9.10s/it]Llama.generate: 320 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3858.35 ms /     4 runs   (  964.59 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    3861.18 ms /     5 tokens\n",
      " 29%|██▉       | 1014/3487 [3:21:05<5:10:23,  7.53s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2497.37 ms /    10 tokens (  249.74 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.92 ms /     3 runs   (  903.64 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5210.64 ms /    13 tokens\n",
      " 29%|██▉       | 1015/3487 [3:21:10<4:41:42,  6.84s/it]Llama.generate: 308 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7364.74 ms /    31 tokens (  237.57 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.61 ms /     3 runs   (  899.54 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10066.67 ms /    34 tokens\n",
      " 29%|██▉       | 1016/3487 [3:21:20<5:21:35,  7.81s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8018.14 ms /    39 tokens (  205.59 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.32 ms /     3 runs   (  885.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10677.85 ms /    42 tokens\n",
      " 29%|██▉       | 1017/3487 [3:21:31<5:57:00,  8.67s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3075.94 ms /    14 tokens (  219.71 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2741.22 ms /     3 runs   (  913.74 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5819.70 ms /    17 tokens\n",
      " 29%|██▉       | 1018/3487 [3:21:37<5:21:44,  7.82s/it]Llama.generate: 320 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3833.74 ms /     4 runs   (  958.44 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    3836.23 ms /     5 tokens\n",
      " 29%|██▉       | 1019/3487 [3:21:40<4:32:34,  6.63s/it]Llama.generate: 307 prefix-match hit, remaining 96 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20064.41 ms /    96 tokens (  209.00 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3862.16 ms /     3 runs   ( 1287.39 ms per token,     0.78 tokens per second)\n",
      "llama_perf_context_print:       total time =   23929.66 ms /    99 tokens\n",
      " 29%|██▉       | 1020/3487 [3:22:04<8:06:00, 11.82s/it]Llama.generate: 311 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15386.52 ms /    66 tokens (  233.13 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.25 ms /     3 runs   (  897.42 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   18081.56 ms /    69 tokens\n",
      " 29%|██▉       | 1021/3487 [3:22:22<9:23:08, 13.70s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12476.42 ms /    62 tokens (  201.23 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.19 ms /     3 runs   (  893.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15158.25 ms /    65 tokens\n",
      " 29%|██▉       | 1022/3487 [3:22:38<9:40:58, 14.14s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13883.90 ms /    69 tokens (  201.22 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.98 ms /     3 runs   (  906.66 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   16606.53 ms /    72 tokens\n",
      " 29%|██▉       | 1023/3487 [3:22:54<10:11:36, 14.89s/it]Llama.generate: 315 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1633.49 ms /     4 tokens (  408.37 ms per token,     2.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2796.03 ms /     3 runs   (  932.01 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4431.98 ms /     7 tokens\n",
      " 29%|██▉       | 1024/3487 [3:22:59<8:02:38, 11.76s/it] Llama.generate: 311 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5467.11 ms /    27 tokens (  202.49 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.36 ms /     3 runs   (  879.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8107.50 ms /    30 tokens\n",
      " 29%|██▉       | 1025/3487 [3:23:07<7:17:36, 10.66s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2657.32 ms /    11 tokens (  241.57 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.21 ms /     3 runs   (  895.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5347.36 ms /    14 tokens\n",
      " 29%|██▉       | 1026/3487 [3:23:12<6:12:05,  9.07s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9259.99 ms /    47 tokens (  197.02 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.47 ms /     3 runs   (  894.16 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11944.83 ms /    50 tokens\n",
      " 29%|██▉       | 1027/3487 [3:23:24<6:47:22,  9.94s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2750.21 ms /    12 tokens (  229.18 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.53 ms /     3 runs   (  888.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5418.52 ms /    15 tokens\n",
      " 29%|██▉       | 1028/3487 [3:23:30<5:51:46,  8.58s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8177.73 ms /    41 tokens (  199.46 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.81 ms /     3 runs   (  882.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10827.87 ms /    44 tokens\n",
      " 30%|██▉       | 1029/3487 [3:23:40<6:19:18,  9.26s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2830.23 ms /    12 tokens (  235.85 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.05 ms /     3 runs   (  900.35 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5533.55 ms /    15 tokens\n",
      " 30%|██▉       | 1030/3487 [3:23:46<5:33:30,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2063.97 ms /     8 tokens (  258.00 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.87 ms /     3 runs   (  899.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4766.25 ms /    11 tokens\n",
      " 30%|██▉       | 1031/3487 [3:23:51<4:51:58,  7.13s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3635.04 ms /    13 tokens (  279.62 ms per token,     3.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2750.77 ms /     3 runs   (  916.92 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6388.98 ms /    16 tokens\n",
      " 30%|██▉       | 1032/3487 [3:23:57<4:43:13,  6.92s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6758.21 ms /    32 tokens (  211.19 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2784.58 ms /     3 runs   (  928.19 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    9545.31 ms /    35 tokens\n",
      " 30%|██▉       | 1033/3487 [3:24:07<5:15:24,  7.71s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2037.06 ms /     8 tokens (  254.63 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.12 ms /     3 runs   (  893.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4719.27 ms /    11 tokens\n",
      " 30%|██▉       | 1034/3487 [3:24:11<4:38:40,  6.82s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9614.16 ms /    47 tokens (  204.56 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.21 ms /     3 runs   (  882.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12264.03 ms /    50 tokens\n",
      " 30%|██▉       | 1035/3487 [3:24:24<5:45:49,  8.46s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6641.64 ms /    32 tokens (  207.55 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3023.50 ms /     3 runs   ( 1007.83 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    9667.60 ms /    35 tokens\n",
      " 30%|██▉       | 1036/3487 [3:24:33<6:00:33,  8.83s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3088.72 ms /    13 tokens (  237.59 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.63 ms /     3 runs   (  881.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5737.04 ms /    16 tokens\n",
      " 30%|██▉       | 1037/3487 [3:24:39<5:22:40,  7.90s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2169.44 ms /     8 tokens (  271.18 ms per token,     3.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.09 ms /     3 runs   (  885.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4827.38 ms /    11 tokens\n",
      " 30%|██▉       | 1038/3487 [3:24:44<4:45:01,  6.98s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2917.78 ms /    13 tokens (  224.44 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.27 ms /     3 runs   (  878.42 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5555.40 ms /    16 tokens\n",
      " 30%|██▉       | 1039/3487 [3:24:50<4:27:33,  6.56s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4689.20 ms /    22 tokens (  213.15 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.58 ms /     3 runs   (  883.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7343.57 ms /    25 tokens\n",
      " 30%|██▉       | 1040/3487 [3:24:57<4:37:10,  6.80s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3176.00 ms /    13 tokens (  244.31 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.76 ms /     3 runs   (  896.92 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5869.72 ms /    16 tokens\n",
      " 30%|██▉       | 1041/3487 [3:25:03<4:25:50,  6.52s/it]Llama.generate: 308 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4146.08 ms /    20 tokens (  207.30 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.45 ms /     3 runs   (  874.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6772.46 ms /    23 tokens\n",
      " 30%|██▉       | 1042/3487 [3:25:10<4:28:54,  6.60s/it]Llama.generate: 307 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20096.44 ms /   105 tokens (  191.39 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.55 ms /     3 runs   (  874.52 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   22753.73 ms /   108 tokens\n",
      " 30%|██▉       | 1043/3487 [3:25:32<7:46:17, 11.45s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2430.12 ms /    10 tokens (  243.01 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.88 ms /     3 runs   (  887.29 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5093.79 ms /    13 tokens\n",
      " 30%|██▉       | 1044/3487 [3:25:37<6:28:35,  9.54s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2055.07 ms /     7 tokens (  293.58 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.93 ms /     3 runs   (  882.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4705.03 ms /    10 tokens\n",
      " 30%|██▉       | 1045/3487 [3:25:42<5:29:49,  8.10s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13465.98 ms /    69 tokens (  195.16 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.30 ms /     3 runs   (  882.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16115.03 ms /    72 tokens\n",
      " 30%|██▉       | 1046/3487 [3:25:58<7:07:34, 10.51s/it]Llama.generate: 308 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4247.72 ms /    19 tokens (  223.56 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.27 ms /     3 runs   (  891.76 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6925.05 ms /    22 tokens\n",
      " 30%|███       | 1047/3487 [3:26:05<6:23:45,  9.44s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3787.64 ms /    18 tokens (  210.42 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.08 ms /     3 runs   (  874.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6412.49 ms /    21 tokens\n",
      " 30%|███       | 1048/3487 [3:26:12<5:46:48,  8.53s/it]Llama.generate: 309 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4407.66 ms /    21 tokens (  209.89 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.62 ms /     3 runs   (  875.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7036.52 ms /    24 tokens\n",
      " 30%|███       | 1049/3487 [3:26:19<5:28:33,  8.09s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4703.69 ms /    23 tokens (  204.51 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.15 ms /     3 runs   (  891.72 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7381.15 ms /    26 tokens\n",
      " 30%|███       | 1050/3487 [3:26:26<5:19:55,  7.88s/it]Llama.generate: 314 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3374.83 ms /    15 tokens (  224.99 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.38 ms /     3 runs   (  889.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6046.14 ms /    18 tokens\n",
      " 30%|███       | 1051/3487 [3:26:32<4:57:36,  7.33s/it]Llama.generate: 314 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3201.28 ms /    15 tokens (  213.42 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.01 ms /     3 runs   (  876.34 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5832.44 ms /    18 tokens\n",
      " 30%|███       | 1052/3487 [3:26:38<4:39:19,  6.88s/it]Llama.generate: 306 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11207.76 ms /    55 tokens (  203.78 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.43 ms /     3 runs   (  874.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13832.50 ms /    58 tokens\n",
      " 30%|███       | 1053/3487 [3:26:52<6:04:15,  8.98s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7787.29 ms /    37 tokens (  210.47 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.28 ms /     3 runs   (  886.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10448.15 ms /    40 tokens\n",
      " 30%|███       | 1054/3487 [3:27:02<6:22:04,  9.42s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4862.96 ms /    24 tokens (  202.62 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.59 ms /     3 runs   (  881.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7509.55 ms /    27 tokens\n",
      " 30%|███       | 1055/3487 [3:27:10<5:58:46,  8.85s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3115.94 ms /    13 tokens (  239.69 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.63 ms /     3 runs   (  873.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5740.15 ms /    16 tokens\n",
      " 30%|███       | 1056/3487 [3:27:16<5:20:53,  7.92s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6392.57 ms /    32 tokens (  199.77 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.65 ms /     3 runs   (  886.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9056.19 ms /    35 tokens\n",
      " 30%|███       | 1057/3487 [3:27:25<5:34:39,  8.26s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3560.41 ms /    15 tokens (  237.36 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.97 ms /     3 runs   (  898.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6260.25 ms /    18 tokens\n",
      " 30%|███       | 1058/3487 [3:27:31<5:10:18,  7.67s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10029.35 ms /    51 tokens (  196.65 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.14 ms /     3 runs   (  874.71 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12656.14 ms /    54 tokens\n",
      " 30%|███       | 1059/3487 [3:27:44<6:10:51,  9.16s/it]Llama.generate: 313 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3577.34 ms /    16 tokens (  223.58 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.09 ms /     3 runs   (  889.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6248.16 ms /    19 tokens\n",
      " 30%|███       | 1060/3487 [3:27:50<5:35:24,  8.29s/it]Llama.generate: 313 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3312.30 ms /    15 tokens (  220.82 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.53 ms /     3 runs   (  880.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5954.79 ms /    18 tokens\n",
      " 30%|███       | 1061/3487 [3:27:56<5:07:00,  7.59s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8183.64 ms /    41 tokens (  199.60 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.86 ms /     3 runs   (  870.95 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10799.03 ms /    44 tokens\n",
      " 30%|███       | 1062/3487 [3:28:07<5:45:51,  8.56s/it]Llama.generate: 307 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12105.92 ms /    61 tokens (  198.46 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.98 ms /     3 runs   (  913.33 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   14847.93 ms /    64 tokens\n",
      " 30%|███       | 1063/3487 [3:28:21<7:02:04, 10.45s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7371.45 ms /    34 tokens (  216.81 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.54 ms /     3 runs   (  901.51 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10079.50 ms /    37 tokens\n",
      " 31%|███       | 1064/3487 [3:28:31<6:57:33, 10.34s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5658.29 ms /    27 tokens (  209.57 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.85 ms /     3 runs   (  891.95 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8336.67 ms /    30 tokens\n",
      " 31%|███       | 1065/3487 [3:28:40<6:33:38,  9.75s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5763.87 ms /    29 tokens (  198.75 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.47 ms /     3 runs   (  899.16 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8464.19 ms /    32 tokens\n",
      " 31%|███       | 1066/3487 [3:28:48<6:17:59,  9.37s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3818.08 ms /    18 tokens (  212.12 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2607.33 ms /     3 runs   (  869.11 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    6427.81 ms /    21 tokens\n",
      " 31%|███       | 1067/3487 [3:28:55<5:42:21,  8.49s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4813.26 ms /    23 tokens (  209.27 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.14 ms /     3 runs   (  893.05 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7494.48 ms /    26 tokens\n",
      " 31%|███       | 1068/3487 [3:29:02<5:30:17,  8.19s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6323.61 ms /    31 tokens (  203.99 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.62 ms /     3 runs   (  874.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8951.02 ms /    34 tokens\n",
      " 31%|███       | 1069/3487 [3:29:11<5:39:27,  8.42s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1974.91 ms /     8 tokens (  246.86 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.08 ms /     3 runs   (  879.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4614.63 ms /    11 tokens\n",
      " 31%|███       | 1070/3487 [3:29:16<4:53:22,  7.28s/it]Llama.generate: 310 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13516.55 ms /    68 tokens (  198.77 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.36 ms /     3 runs   (  886.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16178.41 ms /    71 tokens\n",
      " 31%|███       | 1071/3487 [3:29:32<6:40:50,  9.95s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3783.52 ms /    17 tokens (  222.56 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.83 ms /     3 runs   (  887.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6448.83 ms /    20 tokens\n",
      " 31%|███       | 1072/3487 [3:29:39<5:58:27,  8.91s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2524.62 ms /    10 tokens (  252.46 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.08 ms /     3 runs   (  878.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5161.99 ms /    13 tokens\n",
      " 31%|███       | 1073/3487 [3:29:44<5:13:13,  7.79s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5798.68 ms /    27 tokens (  214.77 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.33 ms /     3 runs   (  879.44 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8440.80 ms /    30 tokens\n",
      " 31%|███       | 1074/3487 [3:29:52<5:21:07,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3293.93 ms /    15 tokens (  219.60 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.46 ms /     3 runs   (  882.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5943.45 ms /    18 tokens\n",
      " 31%|███       | 1075/3487 [3:29:58<4:56:30,  7.38s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2595.93 ms /    11 tokens (  235.99 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.88 ms /     3 runs   (  885.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5255.56 ms /    14 tokens\n",
      " 31%|███       | 1076/3487 [3:30:03<4:31:17,  6.75s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3221.21 ms /    14 tokens (  230.09 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.35 ms /     3 runs   (  880.12 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5864.06 ms /    17 tokens\n",
      " 31%|███       | 1077/3487 [3:30:09<4:20:35,  6.49s/it]Llama.generate: 307 prefix-match hit, remaining 101 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19331.03 ms /   101 tokens (  191.40 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.70 ms /     3 runs   (  873.90 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21955.35 ms /   104 tokens\n",
      " 31%|███       | 1078/3487 [3:30:31<7:26:53, 11.13s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10434.74 ms /    53 tokens (  196.88 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.12 ms /     3 runs   (  874.71 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13060.45 ms /    56 tokens\n",
      " 31%|███       | 1079/3487 [3:30:44<7:50:26, 11.72s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5984.88 ms /    30 tokens (  199.50 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.86 ms /     3 runs   (  903.95 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8699.00 ms /    33 tokens\n",
      " 31%|███       | 1080/3487 [3:30:53<7:13:57, 10.82s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3569.35 ms /    16 tokens (  223.08 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.11 ms /     3 runs   (  877.37 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6203.92 ms /    19 tokens\n",
      " 31%|███       | 1081/3487 [3:30:59<6:18:24,  9.44s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7141.25 ms /    33 tokens (  216.40 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.43 ms /     3 runs   (  875.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9769.01 ms /    36 tokens\n",
      " 31%|███       | 1082/3487 [3:31:09<6:22:19,  9.54s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2650.90 ms /    11 tokens (  240.99 ms per token,     4.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.38 ms /     3 runs   (  875.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5280.58 ms /    14 tokens\n",
      " 31%|███       | 1083/3487 [3:31:14<5:31:05,  8.26s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13033.49 ms /    65 tokens (  200.52 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.40 ms /     3 runs   (  876.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15696.77 ms /    68 tokens\n",
      " 31%|███       | 1084/3487 [3:31:30<7:00:24, 10.50s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2674.03 ms /    11 tokens (  243.09 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.81 ms /     3 runs   (  883.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5328.89 ms /    14 tokens\n",
      " 31%|███       | 1085/3487 [3:31:35<5:58:16,  8.95s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6151.85 ms /    31 tokens (  198.45 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.61 ms /     3 runs   (  893.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8834.19 ms /    34 tokens\n",
      " 31%|███       | 1086/3487 [3:31:44<5:56:49,  8.92s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3046.10 ms /    13 tokens (  234.32 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.83 ms /     3 runs   (  889.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5718.38 ms /    16 tokens\n",
      " 31%|███       | 1087/3487 [3:31:50<5:18:23,  7.96s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2833.01 ms /    13 tokens (  217.92 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.07 ms /     3 runs   (  891.69 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5510.09 ms /    16 tokens\n",
      " 31%|███       | 1088/3487 [3:31:55<4:48:58,  7.23s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4304.27 ms /    20 tokens (  215.21 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2768.87 ms /     3 runs   (  922.96 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7075.51 ms /    23 tokens\n",
      " 31%|███       | 1089/3487 [3:32:03<4:47:08,  7.18s/it]Llama.generate: 306 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13505.64 ms /    65 tokens (  207.78 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.09 ms /     3 runs   (  876.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16136.66 ms /    68 tokens\n",
      " 31%|███▏      | 1090/3487 [3:32:19<6:34:25,  9.87s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5091.67 ms /    25 tokens (  203.67 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.74 ms /     3 runs   (  891.25 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7768.22 ms /    28 tokens\n",
      " 31%|███▏      | 1091/3487 [3:32:26<6:09:08,  9.24s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3615.36 ms /    16 tokens (  225.96 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.86 ms /     3 runs   (  888.29 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6282.95 ms /    19 tokens\n",
      " 31%|███▏      | 1092/3487 [3:32:33<5:33:36,  8.36s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9582.03 ms /    48 tokens (  199.63 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4242.63 ms /     3 runs   ( 1414.21 ms per token,     0.71 tokens per second)\n",
      "llama_perf_context_print:       total time =   13827.70 ms /    51 tokens\n",
      " 31%|███▏      | 1093/3487 [3:32:47<6:39:04, 10.00s/it]Llama.generate: 307 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26049.41 ms /   103 tokens (  252.91 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4031.72 ms /     3 runs   ( 1343.91 ms per token,     0.74 tokens per second)\n",
      "llama_perf_context_print:       total time =   30084.72 ms /   106 tokens\n",
      " 31%|███▏      | 1094/3487 [3:33:17<10:39:21, 16.03s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8415.26 ms /    37 tokens (  227.44 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2773.58 ms /     3 runs   (  924.53 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   11191.72 ms /    40 tokens\n",
      " 31%|███▏      | 1095/3487 [3:33:28<9:41:20, 14.58s/it] Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13476.64 ms /    69 tokens (  195.31 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.92 ms /     3 runs   (  879.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16117.60 ms /    72 tokens\n",
      " 31%|███▏      | 1096/3487 [3:33:44<9:59:34, 15.05s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4689.71 ms /    23 tokens (  203.90 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.79 ms /     3 runs   (  887.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7355.24 ms /    26 tokens\n",
      " 31%|███▏      | 1097/3487 [3:33:51<8:27:30, 12.74s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11845.22 ms /    62 tokens (  191.05 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.11 ms /     3 runs   (  883.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14496.43 ms /    65 tokens\n",
      " 31%|███▏      | 1098/3487 [3:34:06<8:48:23, 13.27s/it]Llama.generate: 313 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14257.39 ms /    75 tokens (  190.10 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.21 ms /     3 runs   (  878.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16895.51 ms /    78 tokens\n",
      " 32%|███▏      | 1099/3487 [3:34:23<9:31:34, 14.36s/it]Llama.generate: 307 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15136.28 ms /    77 tokens (  196.58 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.97 ms /     3 runs   (  882.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17786.69 ms /    80 tokens\n",
      " 32%|███▏      | 1100/3487 [3:34:41<10:12:17, 15.39s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5163.39 ms /    25 tokens (  206.54 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.72 ms /     3 runs   (  891.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7839.58 ms /    28 tokens\n",
      " 32%|███▏      | 1101/3487 [3:34:48<8:42:03, 13.13s/it] Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4162.64 ms /    20 tokens (  208.13 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.90 ms /     3 runs   (  884.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6818.04 ms /    23 tokens\n",
      " 32%|███▏      | 1102/3487 [3:34:55<7:26:40, 11.24s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5064.54 ms /    24 tokens (  211.02 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2749.26 ms /     3 runs   (  916.42 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7815.85 ms /    27 tokens\n",
      " 32%|███▏      | 1103/3487 [3:35:03<6:45:48, 10.21s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9310.60 ms /    47 tokens (  198.10 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.18 ms /     3 runs   (  882.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11959.99 ms /    50 tokens\n",
      " 32%|███▏      | 1104/3487 [3:35:15<7:06:34, 10.74s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4168.98 ms /    21 tokens (  198.52 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.96 ms /     3 runs   (  893.32 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6851.58 ms /    24 tokens\n",
      " 32%|███▏      | 1105/3487 [3:35:22<6:20:09,  9.58s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11724.43 ms /    62 tokens (  189.10 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.77 ms /     3 runs   (  873.26 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14347.13 ms /    65 tokens\n",
      " 32%|███▏      | 1106/3487 [3:35:36<7:16:54, 11.01s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11127.72 ms /    59 tokens (  188.61 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.84 ms /     3 runs   (  877.28 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13761.57 ms /    62 tokens\n",
      " 32%|███▏      | 1107/3487 [3:35:50<7:49:33, 11.84s/it]Llama.generate: 308 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3601.58 ms /    17 tokens (  211.86 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.80 ms /     3 runs   (  882.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6251.11 ms /    20 tokens\n",
      " 32%|███▏      | 1108/3487 [3:35:56<6:43:00, 10.16s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10356.82 ms /    54 tokens (  191.79 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.45 ms /     3 runs   (  886.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13017.90 ms /    57 tokens\n",
      " 32%|███▏      | 1109/3487 [3:36:09<7:16:53, 11.02s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12872.58 ms /    67 tokens (  192.13 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.12 ms /     3 runs   (  876.37 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15504.65 ms /    70 tokens\n",
      " 32%|███▏      | 1110/3487 [3:36:25<8:10:04, 12.37s/it]Llama.generate: 307 prefix-match hit, remaining 145 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26794.52 ms /   145 tokens (  184.79 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.58 ms /     3 runs   (  878.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   29431.88 ms /   148 tokens\n",
      " 32%|███▏      | 1111/3487 [3:36:54<11:32:38, 17.49s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7203.97 ms /    35 tokens (  205.83 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.87 ms /     3 runs   (  873.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9828.11 ms /    38 tokens\n",
      " 32%|███▏      | 1112/3487 [3:37:04<10:01:28, 15.20s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8552.80 ms /    45 tokens (  190.06 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.03 ms /     3 runs   (  874.01 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11177.37 ms /    48 tokens\n",
      " 32%|███▏      | 1113/3487 [3:37:15<9:13:37, 13.99s/it] Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5638.91 ms /    27 tokens (  208.85 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.33 ms /     3 runs   (  877.44 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8273.58 ms /    30 tokens\n",
      " 32%|███▏      | 1114/3487 [3:37:24<8:05:37, 12.28s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13026.44 ms /    69 tokens (  188.79 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.13 ms /     3 runs   (  875.71 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15656.21 ms /    72 tokens\n",
      " 32%|███▏      | 1115/3487 [3:37:39<8:45:34, 13.29s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3973.51 ms /    19 tokens (  209.13 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2757.15 ms /     3 runs   (  919.05 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6733.35 ms /    22 tokens\n",
      " 32%|███▏      | 1116/3487 [3:37:46<7:27:41, 11.33s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5836.64 ms /    30 tokens (  194.55 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.27 ms /     3 runs   (  881.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8483.38 ms /    33 tokens\n",
      " 32%|███▏      | 1117/3487 [3:37:54<6:53:52, 10.48s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5290.07 ms /    27 tokens (  195.93 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2745.84 ms /     3 runs   (  915.28 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8038.87 ms /    30 tokens\n",
      " 32%|███▏      | 1118/3487 [3:38:03<6:24:55,  9.75s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4226.51 ms /    20 tokens (  211.33 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.24 ms /     3 runs   (  911.75 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6964.38 ms /    23 tokens\n",
      " 32%|███▏      | 1119/3487 [3:38:09<5:51:51,  8.92s/it]Llama.generate: 307 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14261.67 ms /    76 tokens (  187.65 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.15 ms /     3 runs   (  882.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16912.74 ms /    79 tokens\n",
      " 32%|███▏      | 1120/3487 [3:38:26<7:26:28, 11.32s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3048.19 ms /    15 tokens (  203.21 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.68 ms /     3 runs   (  878.56 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5686.37 ms /    18 tokens\n",
      " 32%|███▏      | 1121/3487 [3:38:32<6:19:45,  9.63s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4520.05 ms /    22 tokens (  205.46 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.09 ms /     3 runs   (  887.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7184.97 ms /    25 tokens\n",
      " 32%|███▏      | 1122/3487 [3:38:39<5:50:48,  8.90s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5086.11 ms /    25 tokens (  203.44 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.49 ms /     3 runs   (  877.16 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7720.00 ms /    28 tokens\n",
      " 32%|███▏      | 1123/3487 [3:38:47<5:36:46,  8.55s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7936.17 ms /    41 tokens (  193.57 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.91 ms /     3 runs   (  891.64 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10613.88 ms /    44 tokens\n",
      " 32%|███▏      | 1124/3487 [3:38:58<6:01:09,  9.17s/it]Llama.generate: 307 prefix-match hit, remaining 220 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   40066.74 ms /   220 tokens (  182.12 ms per token,     5.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2862.92 ms /     3 runs   (  954.31 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   42932.38 ms /   223 tokens\n",
      " 32%|███▏      | 1125/3487 [3:39:41<12:39:50, 19.30s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8037.37 ms /    41 tokens (  196.03 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.95 ms /     3 runs   (  874.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10664.82 ms /    44 tokens\n",
      " 32%|███▏      | 1126/3487 [3:39:51<10:57:38, 16.71s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8604.34 ms /    44 tokens (  195.55 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.21 ms /     3 runs   (  877.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11240.39 ms /    47 tokens\n",
      " 32%|███▏      | 1127/3487 [3:40:03<9:52:54, 15.07s/it] Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2176.74 ms /     9 tokens (  241.86 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.63 ms /     3 runs   (  897.21 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4870.81 ms /    12 tokens\n",
      " 32%|███▏      | 1128/3487 [3:40:07<7:52:24, 12.02s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2556.08 ms /    12 tokens (  213.01 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.62 ms /     3 runs   (  888.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5223.13 ms /    15 tokens\n",
      " 32%|███▏      | 1129/3487 [3:40:13<6:32:13,  9.98s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9187.80 ms /    48 tokens (  191.41 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.93 ms /     3 runs   (  877.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11822.77 ms /    51 tokens\n",
      " 32%|███▏      | 1130/3487 [3:40:24<6:53:52, 10.54s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9404.89 ms /    49 tokens (  191.94 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.43 ms /     3 runs   (  875.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12035.54 ms /    52 tokens\n",
      " 32%|███▏      | 1131/3487 [3:40:36<7:11:27, 10.99s/it]Llama.generate: 321 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5550.97 ms /    25 tokens (  222.04 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.52 ms /     3 runs   (  877.17 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8185.29 ms /    28 tokens\n",
      " 32%|███▏      | 1132/3487 [3:40:45<6:38:22, 10.15s/it]Llama.generate: 308 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13560.13 ms /    73 tokens (  185.76 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.82 ms /     3 runs   (  886.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16222.10 ms /    76 tokens\n",
      " 32%|███▏      | 1133/3487 [3:41:01<7:50:08, 11.98s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10327.27 ms /    54 tokens (  191.25 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.29 ms /     3 runs   (  875.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12955.97 ms /    57 tokens\n",
      " 33%|███▎      | 1134/3487 [3:41:14<8:01:28, 12.28s/it]Llama.generate: 307 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15800.15 ms /    86 tokens (  183.72 ms per token,     5.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.12 ms /     3 runs   (  874.04 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18424.77 ms /    89 tokens\n",
      " 33%|███▎      | 1135/3487 [3:41:32<9:13:40, 14.12s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6992.95 ms /    34 tokens (  205.67 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.15 ms /     3 runs   (  876.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9625.17 ms /    37 tokens\n",
      " 33%|███▎      | 1136/3487 [3:41:42<8:20:38, 12.78s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7736.39 ms /    40 tokens (  193.41 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.58 ms /     3 runs   (  886.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10399.93 ms /    43 tokens\n",
      " 33%|███▎      | 1137/3487 [3:41:52<7:52:34, 12.07s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5662.51 ms /    29 tokens (  195.26 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.54 ms /     3 runs   (  877.85 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8298.43 ms /    32 tokens\n",
      " 33%|███▎      | 1138/3487 [3:42:01<7:08:13, 10.94s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9869.51 ms /    52 tokens (  189.80 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.11 ms /     3 runs   (  877.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12505.15 ms /    55 tokens\n",
      " 33%|███▎      | 1139/3487 [3:42:13<7:26:31, 11.41s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3944.97 ms /    19 tokens (  207.63 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.13 ms /     3 runs   (  880.71 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6591.08 ms /    22 tokens\n",
      " 33%|███▎      | 1140/3487 [3:42:20<6:29:53,  9.97s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4346.08 ms /    22 tokens (  197.55 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.54 ms /     3 runs   (  879.85 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6987.94 ms /    25 tokens\n",
      " 33%|███▎      | 1141/3487 [3:42:27<5:54:52,  9.08s/it]Llama.generate: 306 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14554.84 ms /    78 tokens (  186.60 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.83 ms /     3 runs   (  879.61 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17196.61 ms /    81 tokens\n",
      " 33%|███▎      | 1142/3487 [3:42:44<7:30:02, 11.52s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2567.10 ms /    12 tokens (  213.92 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2952.89 ms /     3 runs   (  984.30 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    5522.79 ms /    15 tokens\n",
      " 33%|███▎      | 1143/3487 [3:42:50<6:19:42,  9.72s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3605.49 ms /    17 tokens (  212.09 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.30 ms /     3 runs   (  878.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6243.39 ms /    20 tokens\n",
      " 33%|███▎      | 1144/3487 [3:42:56<5:38:55,  8.68s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5457.24 ms /    23 tokens (  237.27 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3105.56 ms /     3 runs   ( 1035.19 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    8565.62 ms /    26 tokens\n",
      " 33%|███▎      | 1145/3487 [3:43:04<5:37:32,  8.65s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4701.15 ms /    23 tokens (  204.40 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.17 ms /     3 runs   (  889.39 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7371.75 ms /    26 tokens\n",
      " 33%|███▎      | 1146/3487 [3:43:12<5:22:34,  8.27s/it]Llama.generate: 306 prefix-match hit, remaining 97 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18424.03 ms /    97 tokens (  189.94 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.74 ms /     3 runs   (  874.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21050.60 ms /   100 tokens\n",
      " 33%|███▎      | 1147/3487 [3:43:33<7:52:04, 12.10s/it]Llama.generate: 307 prefix-match hit, remaining 144 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26304.10 ms /   144 tokens (  182.67 ms per token,     5.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.29 ms /     3 runs   (  881.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   28949.98 ms /   147 tokens\n",
      " 33%|███▎      | 1148/3487 [3:44:02<11:09:12, 17.17s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7558.88 ms /    38 tokens (  198.92 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.71 ms /     3 runs   (  881.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10206.72 ms /    41 tokens\n",
      " 33%|███▎      | 1149/3487 [3:44:12<9:47:38, 15.08s/it] Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9733.92 ms /    49 tokens (  198.65 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2726.21 ms /     3 runs   (  908.74 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   12462.58 ms /    52 tokens\n",
      " 33%|███▎      | 1150/3487 [3:44:24<9:16:53, 14.30s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4509.51 ms /    22 tokens (  204.98 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3072.33 ms /     3 runs   ( 1024.11 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    7584.71 ms /    25 tokens\n",
      " 33%|███▎      | 1151/3487 [3:44:32<7:58:22, 12.29s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9368.88 ms /    46 tokens (  203.67 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.15 ms /     3 runs   (  889.05 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12039.15 ms /    49 tokens\n",
      " 33%|███▎      | 1152/3487 [3:44:44<7:55:22, 12.22s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4323.24 ms /    22 tokens (  196.51 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.68 ms /     3 runs   (  882.89 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6974.87 ms /    25 tokens\n",
      " 33%|███▎      | 1153/3487 [3:44:51<6:54:06, 10.65s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3208.25 ms /    15 tokens (  213.88 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.86 ms /     3 runs   (  878.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5845.83 ms /    18 tokens\n",
      " 33%|███▎      | 1154/3487 [3:44:57<5:58:02,  9.21s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3489.91 ms /    16 tokens (  218.12 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.99 ms /     3 runs   (  880.66 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6134.67 ms /    19 tokens\n",
      " 33%|███▎      | 1155/3487 [3:45:03<5:22:07,  8.29s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2571.14 ms /    12 tokens (  214.26 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.91 ms /     3 runs   (  885.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5228.99 ms /    15 tokens\n",
      " 33%|███▎      | 1156/3487 [3:45:08<4:46:25,  7.37s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7269.48 ms /    36 tokens (  201.93 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.04 ms /     3 runs   (  881.68 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9917.02 ms /    39 tokens\n",
      " 33%|███▎      | 1157/3487 [3:45:18<5:16:01,  8.14s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13565.45 ms /    72 tokens (  188.41 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.36 ms /     3 runs   (  876.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16197.55 ms /    75 tokens\n",
      " 33%|███▎      | 1158/3487 [3:45:34<6:49:50, 10.56s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8131.63 ms /    42 tokens (  193.61 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.48 ms /     3 runs   (  876.16 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10762.24 ms /    45 tokens\n",
      " 33%|███▎      | 1159/3487 [3:45:45<6:52:06, 10.62s/it]Llama.generate: 307 prefix-match hit, remaining 172 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   31247.49 ms /   172 tokens (  181.67 ms per token,     5.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.64 ms /     3 runs   (  876.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   33878.93 ms /   175 tokens\n",
      " 33%|███▎      | 1160/3487 [3:46:19<11:22:59, 17.61s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7924.97 ms /    41 tokens (  193.29 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.03 ms /     3 runs   (  873.01 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10547.05 ms /    44 tokens\n",
      " 33%|███▎      | 1161/3487 [3:46:30<10:00:39, 15.49s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9306.36 ms /    50 tokens (  186.13 ms per token,     5.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.06 ms /     3 runs   (  875.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11934.18 ms /    53 tokens\n",
      " 33%|███▎      | 1162/3487 [3:46:42<9:19:05, 14.43s/it] Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5624.46 ms /    29 tokens (  193.95 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.34 ms /     3 runs   (  880.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8269.06 ms /    32 tokens\n",
      " 33%|███▎      | 1163/3487 [3:46:50<8:07:22, 12.58s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10926.93 ms /    59 tokens (  185.20 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.97 ms /     3 runs   (  873.66 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13550.40 ms /    62 tokens\n",
      " 33%|███▎      | 1164/3487 [3:47:03<8:18:28, 12.87s/it]Llama.generate: 306 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13854.16 ms /    72 tokens (  192.42 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.79 ms /     3 runs   (  892.26 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16533.45 ms /    75 tokens\n",
      " 33%|███▎      | 1165/3487 [3:47:20<9:00:50, 13.98s/it]Llama.generate: 306 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17415.46 ms /    94 tokens (  185.27 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.11 ms /     3 runs   (  886.37 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20077.60 ms /    97 tokens\n",
      " 33%|███▎      | 1166/3487 [3:47:40<10:11:31, 15.81s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8320.28 ms /    44 tokens (  189.10 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.40 ms /     3 runs   (  883.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10973.50 ms /    47 tokens\n",
      " 33%|███▎      | 1167/3487 [3:47:51<9:15:17, 14.36s/it] Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2942.90 ms /    14 tokens (  210.21 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.24 ms /     3 runs   (  890.75 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5617.87 ms /    17 tokens\n",
      " 33%|███▎      | 1168/3487 [3:47:57<7:33:45, 11.74s/it]Llama.generate: 306 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11569.35 ms /    58 tokens (  199.47 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.36 ms /     3 runs   (  902.45 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   14280.05 ms /    61 tokens\n",
      " 34%|███▎      | 1169/3487 [3:48:11<8:03:06, 12.50s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3306.29 ms /    15 tokens (  220.42 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2703.82 ms /     3 runs   (  901.27 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6012.85 ms /    18 tokens\n",
      " 34%|███▎      | 1170/3487 [3:48:17<6:47:46, 10.56s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8845.58 ms /    46 tokens (  192.30 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.99 ms /     3 runs   (  881.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11493.00 ms /    49 tokens\n",
      " 34%|███▎      | 1171/3487 [3:48:29<6:58:29, 10.84s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4549.59 ms /    22 tokens (  206.80 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.06 ms /     3 runs   (  893.35 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7232.27 ms /    25 tokens\n",
      " 34%|███▎      | 1172/3487 [3:48:36<6:16:36,  9.76s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8113.04 ms /    40 tokens (  202.83 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.65 ms /     3 runs   (  881.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10759.44 ms /    43 tokens\n",
      " 34%|███▎      | 1173/3487 [3:48:47<6:28:05, 10.06s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5056.51 ms /    25 tokens (  202.26 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2826.86 ms /     3 runs   (  942.29 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7886.07 ms /    28 tokens\n",
      " 34%|███▎      | 1174/3487 [3:48:54<6:02:50,  9.41s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3959.71 ms /    19 tokens (  208.41 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2810.81 ms /     3 runs   (  936.94 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6773.21 ms /    22 tokens\n",
      " 34%|███▎      | 1175/3487 [3:49:01<5:32:16,  8.62s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3472.70 ms /    17 tokens (  204.28 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2796.27 ms /     3 runs   (  932.09 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6271.27 ms /    20 tokens\n",
      " 34%|███▎      | 1176/3487 [3:49:07<5:05:01,  7.92s/it]Llama.generate: 306 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15429.64 ms /    83 tokens (  185.90 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.77 ms /     3 runs   (  883.92 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18084.17 ms /    86 tokens\n",
      " 34%|███▍      | 1177/3487 [3:49:26<7:02:25, 10.97s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2097.23 ms /     8 tokens (  262.15 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.75 ms /     3 runs   (  889.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4768.84 ms /    11 tokens\n",
      " 34%|███▍      | 1178/3487 [3:49:30<5:50:43,  9.11s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2121.95 ms /     8 tokens (  265.24 ms per token,     3.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.83 ms /     3 runs   (  884.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4779.66 ms /    11 tokens\n",
      " 34%|███▍      | 1179/3487 [3:49:35<5:00:39,  7.82s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3217.24 ms /    15 tokens (  214.48 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.32 ms /     3 runs   (  880.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5862.33 ms /    18 tokens\n",
      " 34%|███▍      | 1180/3487 [3:49:41<4:38:04,  7.23s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1575.49 ms /     6 tokens (  262.58 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2975.82 ms /     3 runs   (  991.94 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    4554.07 ms /     9 tokens\n",
      " 34%|███▍      | 1181/3487 [3:49:46<4:07:09,  6.43s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2580.88 ms /    12 tokens (  215.07 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.67 ms /     3 runs   (  880.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5224.09 ms /    15 tokens\n",
      " 34%|███▍      | 1182/3487 [3:49:51<3:53:16,  6.07s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3221.26 ms /    15 tokens (  214.75 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.42 ms /     3 runs   (  877.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5857.38 ms /    18 tokens\n",
      " 34%|███▍      | 1183/3487 [3:49:57<3:50:46,  6.01s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1760.13 ms /     6 tokens (  293.36 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.15 ms /     3 runs   (  887.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4424.67 ms /     9 tokens\n",
      " 34%|███▍      | 1184/3487 [3:50:01<3:32:31,  5.54s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1977.00 ms /     7 tokens (  282.43 ms per token,     3.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.12 ms /     3 runs   (  885.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4635.82 ms /    10 tokens\n",
      " 34%|███▍      | 1185/3487 [3:50:06<3:22:07,  5.27s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2110.04 ms /     8 tokens (  263.76 ms per token,     3.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.62 ms /     3 runs   (  877.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4745.36 ms /    11 tokens\n",
      " 34%|███▍      | 1186/3487 [3:50:10<3:16:08,  5.11s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4860.30 ms /    24 tokens (  202.51 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.25 ms /     3 runs   (  885.08 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7518.01 ms /    27 tokens\n",
      " 34%|███▍      | 1187/3487 [3:50:18<3:43:46,  5.84s/it]Llama.generate: 306 prefix-match hit, remaining 97 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18669.64 ms /    97 tokens (  192.47 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.64 ms /     3 runs   (  894.21 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   21354.85 ms /   100 tokens\n",
      " 34%|███▍      | 1188/3487 [3:50:39<6:42:08, 10.50s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3160.60 ms /    12 tokens (  263.38 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.92 ms /     3 runs   (  876.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5792.20 ms /    15 tokens\n",
      " 34%|███▍      | 1189/3487 [3:50:45<5:48:02,  9.09s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2764.49 ms /    12 tokens (  230.37 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2727.16 ms /     3 runs   (  909.05 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5493.88 ms /    15 tokens\n",
      " 34%|███▍      | 1190/3487 [3:50:51<5:06:42,  8.01s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6238.09 ms /    32 tokens (  194.94 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.88 ms /     3 runs   (  890.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8912.23 ms /    35 tokens\n",
      " 34%|███▍      | 1191/3487 [3:51:00<5:16:59,  8.28s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7238.40 ms /    34 tokens (  212.89 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.98 ms /     3 runs   (  883.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9891.72 ms /    37 tokens\n",
      " 34%|███▍      | 1192/3487 [3:51:10<5:35:25,  8.77s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7159.48 ms /    35 tokens (  204.56 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.22 ms /     3 runs   (  896.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9852.35 ms /    38 tokens\n",
      " 34%|███▍      | 1193/3487 [3:51:19<5:47:49,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3786.34 ms /    18 tokens (  210.35 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2786.14 ms /     3 runs   (  928.71 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6575.12 ms /    21 tokens\n",
      " 34%|███▍      | 1194/3487 [3:51:26<5:18:51,  8.34s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8029.09 ms /    39 tokens (  205.87 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.07 ms /     3 runs   (  879.36 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10669.95 ms /    42 tokens\n",
      " 34%|███▍      | 1195/3487 [3:51:37<5:45:28,  9.04s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4719.14 ms /    24 tokens (  196.63 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.09 ms /     3 runs   (  882.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7368.90 ms /    27 tokens\n",
      " 34%|███▍      | 1196/3487 [3:51:44<5:26:14,  8.54s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7308.41 ms /    36 tokens (  203.01 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.29 ms /     3 runs   (  887.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9972.49 ms /    39 tokens\n",
      " 34%|███▍      | 1197/3487 [3:51:54<5:42:32,  8.97s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7101.58 ms /    34 tokens (  208.87 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.50 ms /     3 runs   (  879.17 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9741.49 ms /    37 tokens\n",
      " 34%|███▍      | 1198/3487 [3:52:04<5:51:15,  9.21s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8931.22 ms /    47 tokens (  190.03 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.42 ms /     3 runs   (  879.81 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11572.58 ms /    50 tokens\n",
      " 34%|███▍      | 1199/3487 [3:52:15<6:18:15,  9.92s/it]Llama.generate: 306 prefix-match hit, remaining 111 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20420.25 ms /   111 tokens (  183.97 ms per token,     5.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.12 ms /     3 runs   (  883.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23074.12 ms /   114 tokens\n",
      " 34%|███▍      | 1200/3487 [3:52:38<8:48:36, 13.87s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3058.84 ms /    14 tokens (  218.49 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.10 ms /     3 runs   (  890.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5731.82 ms /    17 tokens\n",
      " 34%|███▍      | 1201/3487 [3:52:44<7:15:27, 11.43s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10158.18 ms /    54 tokens (  188.11 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.96 ms /     3 runs   (  883.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12810.58 ms /    57 tokens\n",
      " 34%|███▍      | 1202/3487 [3:52:57<7:31:08, 11.85s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5515.48 ms /    28 tokens (  196.98 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.95 ms /     3 runs   (  903.65 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8229.36 ms /    31 tokens\n",
      " 34%|███▍      | 1203/3487 [3:53:05<6:49:43, 10.76s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4154.18 ms /    20 tokens (  207.71 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2799.09 ms /     3 runs   (  933.03 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6955.64 ms /    23 tokens\n",
      " 35%|███▍      | 1204/3487 [3:53:12<6:06:11,  9.62s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3299.74 ms /    15 tokens (  219.98 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.05 ms /     3 runs   (  899.68 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6001.60 ms /    18 tokens\n",
      " 35%|███▍      | 1205/3487 [3:53:18<5:24:46,  8.54s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3999.72 ms /    19 tokens (  210.51 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.99 ms /     3 runs   (  878.33 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6637.08 ms /    22 tokens\n",
      " 35%|███▍      | 1206/3487 [3:53:25<5:03:02,  7.97s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3496.68 ms /    16 tokens (  218.54 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.37 ms /     3 runs   (  881.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6143.85 ms /    19 tokens\n",
      " 35%|███▍      | 1207/3487 [3:53:31<4:42:09,  7.43s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4678.11 ms /    21 tokens (  222.77 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.03 ms /     3 runs   (  890.34 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7351.20 ms /    24 tokens\n",
      " 35%|███▍      | 1208/3487 [3:53:38<4:41:16,  7.41s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3428.51 ms /    16 tokens (  214.28 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.33 ms /     3 runs   (  888.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6095.94 ms /    19 tokens\n",
      " 35%|███▍      | 1209/3487 [3:53:44<4:26:41,  7.02s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2073.71 ms /     8 tokens (  259.21 ms per token,     3.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.42 ms /     3 runs   (  884.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4728.46 ms /    11 tokens\n",
      " 35%|███▍      | 1210/3487 [3:53:49<4:00:32,  6.34s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8403.58 ms /    44 tokens (  190.99 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.15 ms /     3 runs   (  889.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11073.90 ms /    47 tokens\n",
      " 35%|███▍      | 1211/3487 [3:54:00<4:54:25,  7.76s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4634.19 ms /    23 tokens (  201.49 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.00 ms /     3 runs   (  881.00 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7279.80 ms /    26 tokens\n",
      " 35%|███▍      | 1212/3487 [3:54:08<4:48:53,  7.62s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4743.15 ms /    24 tokens (  197.63 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.58 ms /     3 runs   (  889.19 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7412.97 ms /    27 tokens\n",
      " 35%|███▍      | 1213/3487 [3:54:15<4:46:30,  7.56s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3106.59 ms /    14 tokens (  221.90 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.50 ms /     3 runs   (  888.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5775.76 ms /    17 tokens\n",
      " 35%|███▍      | 1214/3487 [3:54:21<4:26:12,  7.03s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3979.56 ms /    19 tokens (  209.45 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.37 ms /     3 runs   (  888.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6648.10 ms /    22 tokens\n",
      " 35%|███▍      | 1215/3487 [3:54:27<4:21:52,  6.92s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3263.91 ms /    15 tokens (  217.59 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.10 ms /     3 runs   (  888.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5932.77 ms /    18 tokens\n",
      " 35%|███▍      | 1216/3487 [3:54:33<4:10:40,  6.62s/it]Llama.generate: 307 prefix-match hit, remaining 145 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27397.32 ms /   145 tokens (  188.95 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.97 ms /     3 runs   (  887.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   30061.74 ms /   148 tokens\n",
      " 35%|███▍      | 1217/3487 [3:55:03<8:36:41, 13.66s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4609.45 ms /    23 tokens (  200.41 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.67 ms /     3 runs   (  889.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7281.73 ms /    26 tokens\n",
      " 35%|███▍      | 1218/3487 [3:55:11<7:24:13, 11.75s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3067.14 ms /    14 tokens (  219.08 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.76 ms /     3 runs   (  884.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5723.61 ms /    17 tokens\n",
      " 35%|███▍      | 1219/3487 [3:55:16<6:15:49,  9.94s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2172.07 ms /     9 tokens (  241.34 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.66 ms /     3 runs   (  884.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4826.78 ms /    12 tokens\n",
      " 35%|███▍      | 1220/3487 [3:55:21<5:17:46,  8.41s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2938.25 ms /    13 tokens (  226.02 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.99 ms /     3 runs   (  884.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5592.94 ms /    16 tokens\n",
      " 35%|███▌      | 1221/3487 [3:55:27<4:45:47,  7.57s/it]Llama.generate: 312 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2171.37 ms /     9 tokens (  241.26 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.82 ms /     3 runs   (  896.94 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4864.75 ms /    12 tokens\n",
      " 35%|███▌      | 1222/3487 [3:55:32<4:15:09,  6.76s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4881.95 ms /    24 tokens (  203.41 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.80 ms /     3 runs   (  881.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7528.29 ms /    27 tokens\n",
      " 35%|███▌      | 1223/3487 [3:55:39<4:23:51,  6.99s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2020.51 ms /     8 tokens (  252.56 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.68 ms /     3 runs   (  882.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4671.21 ms /    11 tokens\n",
      " 35%|███▌      | 1224/3487 [3:55:44<3:57:53,  6.31s/it]Llama.generate: 307 prefix-match hit, remaining 328 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   60062.36 ms /   328 tokens (  183.12 ms per token,     5.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.99 ms /     3 runs   (  884.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   62719.54 ms /   331 tokens\n",
      " 35%|███▌      | 1225/3487 [3:56:47<14:35:56, 23.23s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7687.30 ms /    39 tokens (  197.11 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.37 ms /     3 runs   (  882.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10338.36 ms /    42 tokens\n",
      " 35%|███▌      | 1226/3487 [3:56:57<12:09:51, 19.37s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9264.23 ms /    48 tokens (  193.00 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.41 ms /     3 runs   (  883.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11916.54 ms /    51 tokens\n",
      " 35%|███▌      | 1227/3487 [3:57:09<10:45:24, 17.13s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3174.15 ms /    15 tokens (  211.61 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.23 ms /     3 runs   (  882.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5825.17 ms /    18 tokens\n",
      " 35%|███▌      | 1228/3487 [3:57:15<8:37:28, 13.74s/it] Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1900.63 ms /     7 tokens (  271.52 ms per token,     3.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.82 ms /     3 runs   (  888.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4568.90 ms /    10 tokens\n",
      " 35%|███▌      | 1229/3487 [3:57:19<6:53:46, 10.99s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5136.60 ms /    26 tokens (  197.56 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.78 ms /     3 runs   (  880.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7781.27 ms /    29 tokens\n",
      " 35%|███▌      | 1230/3487 [3:57:27<6:17:24, 10.03s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3061.22 ms /    14 tokens (  218.66 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.83 ms /     3 runs   (  883.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5715.76 ms /    17 tokens\n",
      " 35%|███▌      | 1231/3487 [3:57:33<5:28:37,  8.74s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7115.09 ms /    34 tokens (  209.27 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.49 ms /     3 runs   (  886.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9777.15 ms /    37 tokens\n",
      " 35%|███▌      | 1232/3487 [3:57:43<5:40:18,  9.05s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7010.55 ms /    33 tokens (  212.44 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.18 ms /     3 runs   (  882.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9660.51 ms /    36 tokens\n",
      " 35%|███▌      | 1233/3487 [3:57:52<5:47:04,  9.24s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3028.24 ms /    14 tokens (  216.30 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.09 ms /     3 runs   (  882.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5677.49 ms /    17 tokens\n",
      " 35%|███▌      | 1234/3487 [3:57:58<5:06:53,  8.17s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7115.27 ms /    34 tokens (  209.27 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.02 ms /     3 runs   (  884.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9771.25 ms /    37 tokens\n",
      " 35%|███▌      | 1235/3487 [3:58:08<5:24:50,  8.65s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9617.64 ms /    49 tokens (  196.28 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2759.49 ms /     3 runs   (  919.83 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   12379.88 ms /    52 tokens\n",
      " 35%|███▌      | 1236/3487 [3:58:20<6:06:42,  9.77s/it]Llama.generate: 307 prefix-match hit, remaining 328 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   59837.18 ms /   328 tokens (  182.43 ms per token,     5.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.09 ms /     3 runs   (  896.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   62529.18 ms /   331 tokens\n",
      " 35%|███▌      | 1237/3487 [3:59:23<16:00:05, 25.60s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2074.63 ms /     7 tokens (  296.38 ms per token,     3.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.21 ms /     3 runs   (  907.74 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4800.72 ms /    10 tokens\n",
      " 36%|███▌      | 1238/3487 [3:59:28<12:05:52, 19.37s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9381.71 ms /    50 tokens (  187.63 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.02 ms /     3 runs   (  883.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12035.08 ms /    53 tokens\n",
      " 36%|███▌      | 1239/3487 [3:59:40<10:43:14, 17.17s/it]Llama.generate: 306 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18771.38 ms /    98 tokens (  191.54 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.47 ms /     3 runs   (  885.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   21431.70 ms /   101 tokens\n",
      " 36%|███▌      | 1240/3487 [4:00:01<11:30:56, 18.45s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13024.76 ms /    69 tokens (  188.76 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.61 ms /     3 runs   (  894.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15710.65 ms /    72 tokens\n",
      " 36%|███▌      | 1241/3487 [4:00:17<11:00:20, 17.64s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7491.41 ms /    35 tokens (  214.04 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.21 ms /     3 runs   (  877.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10126.75 ms /    38 tokens\n",
      " 36%|███▌      | 1242/3487 [4:00:27<9:35:47, 15.39s/it] Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8378.01 ms /    44 tokens (  190.41 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.94 ms /     3 runs   (  884.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11034.60 ms /    47 tokens\n",
      " 36%|███▌      | 1243/3487 [4:00:38<8:46:46, 14.08s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5956.40 ms /    31 tokens (  192.14 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.49 ms /     3 runs   (  872.16 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8575.73 ms /    34 tokens\n",
      " 36%|███▌      | 1244/3487 [4:00:47<7:44:51, 12.43s/it]Llama.generate: 309 prefix-match hit, remaining 138 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25323.61 ms /   138 tokens (  183.50 ms per token,     5.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.34 ms /     3 runs   (  880.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27968.38 ms /   141 tokens\n",
      " 36%|███▌      | 1245/3487 [4:01:15<10:38:51, 17.10s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11688.29 ms /    63 tokens (  185.53 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.04 ms /     3 runs   (  876.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14320.53 ms /    66 tokens\n",
      " 36%|███▌      | 1246/3487 [4:01:29<10:07:54, 16.28s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7773.42 ms /    40 tokens (  194.34 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.35 ms /     3 runs   (  874.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10399.08 ms /    43 tokens\n",
      " 36%|███▌      | 1247/3487 [4:01:39<9:01:54, 14.52s/it] Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7581.63 ms /    39 tokens (  194.40 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.06 ms /     3 runs   (  878.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10218.00 ms /    42 tokens\n",
      " 36%|███▌      | 1248/3487 [4:01:50<8:13:41, 13.23s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13807.48 ms /    74 tokens (  186.59 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.67 ms /     3 runs   (  878.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16445.14 ms /    77 tokens\n",
      " 36%|███▌      | 1249/3487 [4:02:06<8:49:31, 14.20s/it]Llama.generate: 306 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14959.52 ms /    80 tokens (  186.99 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2795.60 ms /     3 runs   (  931.87 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   17757.79 ms /    83 tokens\n",
      " 36%|███▌      | 1250/3487 [4:02:24<9:29:12, 15.27s/it]Llama.generate: 307 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11927.02 ms /    64 tokens (  186.36 ms per token,     5.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.15 ms /     3 runs   (  876.05 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14557.35 ms /    67 tokens\n",
      " 36%|███▌      | 1251/3487 [4:02:38<9:21:07, 15.06s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3050.59 ms /    14 tokens (  217.90 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.64 ms /     3 runs   (  880.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5695.41 ms /    17 tokens\n",
      " 36%|███▌      | 1252/3487 [4:02:44<7:36:19, 12.25s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10279.21 ms /    53 tokens (  193.95 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.31 ms /     3 runs   (  878.10 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12916.31 ms /    56 tokens\n",
      " 36%|███▌      | 1253/3487 [4:02:57<7:43:39, 12.45s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4467.17 ms /    22 tokens (  203.05 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.54 ms /     3 runs   (  873.85 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7091.00 ms /    25 tokens\n",
      " 36%|███▌      | 1254/3487 [4:03:04<6:43:39, 10.85s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5184.79 ms /    26 tokens (  199.41 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.23 ms /     3 runs   (  875.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7812.91 ms /    29 tokens\n",
      " 36%|███▌      | 1255/3487 [4:03:12<6:09:42,  9.94s/it]Llama.generate: 307 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10499.13 ms /    55 tokens (  190.89 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.89 ms /     3 runs   (  874.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13124.88 ms /    58 tokens\n",
      " 36%|███▌      | 1256/3487 [4:03:25<6:45:11, 10.90s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5767.65 ms /    30 tokens (  192.26 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.88 ms /     3 runs   (  878.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8406.90 ms /    33 tokens\n",
      " 36%|███▌      | 1257/3487 [4:03:33<6:17:21, 10.15s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6965.25 ms /    33 tokens (  211.07 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.11 ms /     3 runs   (  875.04 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9593.21 ms /    36 tokens\n",
      " 36%|███▌      | 1258/3487 [4:03:43<6:11:03,  9.99s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3026.83 ms /    14 tokens (  216.20 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.97 ms /     3 runs   (  876.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5660.26 ms /    17 tokens\n",
      " 36%|███▌      | 1259/3487 [4:03:49<5:22:45,  8.69s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3686.28 ms /    18 tokens (  204.79 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.02 ms /     3 runs   (  874.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6313.15 ms /    21 tokens\n",
      " 36%|███▌      | 1260/3487 [4:03:55<4:56:12,  7.98s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11418.82 ms /    59 tokens (  193.54 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.65 ms /     3 runs   (  897.55 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   14113.66 ms /    62 tokens\n",
      " 36%|███▌      | 1261/3487 [4:04:09<6:04:25,  9.82s/it]Llama.generate: 314 prefix-match hit, remaining 95 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17556.98 ms /    95 tokens (  184.81 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.44 ms /     3 runs   (  875.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   20186.30 ms /    98 tokens\n",
      " 36%|███▌      | 1262/3487 [4:04:29<7:59:39, 12.93s/it]Llama.generate: 307 prefix-match hit, remaining 304 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   55114.55 ms /   304 tokens (  181.30 ms per token,     5.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.38 ms /     3 runs   (  880.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   57792.22 ms /   307 tokens\n",
      " 36%|███▌      | 1263/3487 [4:05:27<16:18:41, 26.40s/it]Llama.generate: 307 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13878.85 ms /    74 tokens (  187.55 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.67 ms /     3 runs   (  872.89 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   16500.08 ms /    77 tokens\n",
      " 36%|███▌      | 1264/3487 [4:05:44<14:28:17, 23.44s/it]Llama.generate: 311 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4082.72 ms /    20 tokens (  204.14 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.84 ms /     3 runs   (  882.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6734.31 ms /    23 tokens\n",
      " 36%|███▋      | 1265/3487 [4:05:50<11:22:25, 18.43s/it]Llama.generate: 310 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4921.16 ms /    25 tokens (  196.85 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.82 ms /     3 runs   (  882.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7571.30 ms /    28 tokens\n",
      " 36%|███▋      | 1266/3487 [4:05:58<9:21:39, 15.17s/it] Llama.generate: 313 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4997.86 ms /    25 tokens (  199.91 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.66 ms /     3 runs   (  874.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7623.12 ms /    28 tokens\n",
      " 36%|███▋      | 1267/3487 [4:06:06<7:57:42, 12.91s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4638.42 ms /    24 tokens (  193.27 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.58 ms /     3 runs   (  882.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7288.31 ms /    27 tokens\n",
      " 36%|███▋      | 1268/3487 [4:06:13<6:55:11, 11.23s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1939.28 ms /     7 tokens (  277.04 ms per token,     3.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.76 ms /     3 runs   (  879.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4581.17 ms /    10 tokens\n",
      " 36%|███▋      | 1269/3487 [4:06:18<5:41:24,  9.24s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2008.36 ms /     8 tokens (  251.04 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.19 ms /     3 runs   (  877.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4643.90 ms /    11 tokens\n",
      " 36%|███▋      | 1270/3487 [4:06:22<4:50:25,  7.86s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4494.91 ms /    22 tokens (  204.31 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.90 ms /     3 runs   (  873.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7119.27 ms /    25 tokens\n",
      " 36%|███▋      | 1271/3487 [4:06:29<4:42:10,  7.64s/it]Llama.generate: 307 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14266.53 ms /    76 tokens (  187.72 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.83 ms /     3 runs   (  876.28 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16897.94 ms /    79 tokens\n",
      " 36%|███▋      | 1272/3487 [4:06:46<6:24:39, 10.42s/it]Llama.generate: 306 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10829.49 ms /    58 tokens (  186.72 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.34 ms /     3 runs   (  879.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13472.11 ms /    61 tokens\n",
      " 37%|███▋      | 1273/3487 [4:07:00<6:58:21, 11.34s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3868.38 ms /    19 tokens (  203.60 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.22 ms /     3 runs   (  883.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6520.19 ms /    22 tokens\n",
      " 37%|███▋      | 1274/3487 [4:07:06<6:04:58,  9.90s/it]Llama.generate: 307 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17076.85 ms /    93 tokens (  183.62 ms per token,     5.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.23 ms /     3 runs   (  875.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19706.85 ms /    96 tokens\n",
      " 37%|███▋      | 1275/3487 [4:07:26<7:53:24, 12.84s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4026.01 ms /    20 tokens (  201.30 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.92 ms /     3 runs   (  879.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6666.57 ms /    23 tokens\n",
      " 37%|███▋      | 1276/3487 [4:07:33<6:45:01, 10.99s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7203.38 ms /    36 tokens (  200.09 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2627.73 ms /     3 runs   (  875.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9833.60 ms /    39 tokens\n",
      " 37%|███▋      | 1277/3487 [4:07:42<6:32:07, 10.65s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2370.73 ms /    10 tokens (  237.07 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.26 ms /     3 runs   (  900.42 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5074.44 ms /    13 tokens\n",
      " 37%|███▋      | 1278/3487 [4:07:48<5:30:29,  8.98s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5610.92 ms /    26 tokens (  215.80 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.10 ms /     3 runs   (  880.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8253.26 ms /    29 tokens\n",
      " 37%|███▋      | 1279/3487 [4:07:56<5:22:25,  8.76s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5236.80 ms /    27 tokens (  193.96 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.21 ms /     3 runs   (  877.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7872.14 ms /    30 tokens\n",
      " 37%|███▋      | 1280/3487 [4:08:04<5:12:34,  8.50s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13571.84 ms /    72 tokens (  188.50 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2851.85 ms /     3 runs   (  950.62 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   16426.52 ms /    75 tokens\n",
      " 37%|███▋      | 1281/3487 [4:08:20<6:39:59, 10.88s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7105.04 ms /    35 tokens (  203.00 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.40 ms /     3 runs   (  883.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9757.11 ms /    38 tokens\n",
      " 37%|███▋      | 1282/3487 [4:08:30<6:27:32, 10.55s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5151.06 ms /    26 tokens (  198.12 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.07 ms /     3 runs   (  882.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7800.23 ms /    29 tokens\n",
      " 37%|███▋      | 1283/3487 [4:08:38<5:57:11,  9.72s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3458.47 ms /    16 tokens (  216.15 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.71 ms /     3 runs   (  876.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6091.23 ms /    19 tokens\n",
      " 37%|███▋      | 1284/3487 [4:08:44<5:17:05,  8.64s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5178.08 ms /    26 tokens (  199.16 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.68 ms /     3 runs   (  885.23 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7835.70 ms /    29 tokens\n",
      " 37%|███▋      | 1285/3487 [4:08:52<5:08:13,  8.40s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5231.56 ms /    27 tokens (  193.76 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.96 ms /     3 runs   (  892.65 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7911.70 ms /    30 tokens\n",
      " 37%|███▋      | 1286/3487 [4:09:00<5:02:49,  8.26s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2631.87 ms /    11 tokens (  239.26 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.74 ms /     3 runs   (  882.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5280.55 ms /    14 tokens\n",
      " 37%|███▋      | 1287/3487 [4:09:05<4:30:03,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4133.29 ms /    20 tokens (  206.66 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2622.07 ms /     3 runs   (  874.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6759.26 ms /    23 tokens\n",
      " 37%|███▋      | 1288/3487 [4:09:12<4:23:21,  7.19s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4207.13 ms /    21 tokens (  200.34 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.59 ms /     3 runs   (  883.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6860.17 ms /    24 tokens\n",
      " 37%|███▋      | 1289/3487 [4:09:18<4:19:45,  7.09s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4531.87 ms /    22 tokens (  205.99 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.96 ms /     3 runs   (  877.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7168.18 ms /    25 tokens\n",
      " 37%|███▋      | 1290/3487 [4:09:26<4:20:35,  7.12s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4006.22 ms /    19 tokens (  210.85 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.90 ms /     3 runs   (  885.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6665.54 ms /    22 tokens\n",
      " 37%|███▋      | 1291/3487 [4:09:32<4:15:57,  6.99s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2925.02 ms /    13 tokens (  225.00 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.19 ms /     3 runs   (  880.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5569.89 ms /    16 tokens\n",
      " 37%|███▋      | 1292/3487 [4:09:38<4:00:17,  6.57s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4210.19 ms /    21 tokens (  200.49 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.23 ms /     3 runs   (  878.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6848.57 ms /    24 tokens\n",
      " 37%|███▋      | 1293/3487 [4:09:45<4:03:20,  6.65s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5800.88 ms /    30 tokens (  193.36 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.07 ms /     3 runs   (  902.69 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8511.75 ms /    33 tokens\n",
      " 37%|███▋      | 1294/3487 [4:09:53<4:23:40,  7.21s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7338.17 ms /    31 tokens (  236.72 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.62 ms /     3 runs   (  881.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9986.34 ms /    34 tokens\n",
      " 37%|███▋      | 1295/3487 [4:10:03<4:54:03,  8.05s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3566.51 ms /    17 tokens (  209.79 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.26 ms /     3 runs   (  892.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6245.07 ms /    20 tokens\n",
      " 37%|███▋      | 1296/3487 [4:10:10<4:34:16,  7.51s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5946.41 ms /    30 tokens (  198.21 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.58 ms /     3 runs   (  888.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8614.51 ms /    33 tokens\n",
      " 37%|███▋      | 1297/3487 [4:10:18<4:46:19,  7.84s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6128.56 ms /    32 tokens (  191.52 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.98 ms /     3 runs   (  876.33 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8759.55 ms /    35 tokens\n",
      " 37%|███▋      | 1298/3487 [4:10:27<4:56:17,  8.12s/it]Llama.generate: 306 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10938.68 ms /    58 tokens (  188.60 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.20 ms /     3 runs   (  890.07 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13610.95 ms /    61 tokens\n",
      " 37%|███▋      | 1299/3487 [4:10:41<5:56:18,  9.77s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3485.07 ms /    16 tokens (  217.82 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.37 ms /     3 runs   (  879.79 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6127.24 ms /    19 tokens\n",
      " 37%|███▋      | 1300/3487 [4:10:47<5:16:22,  8.68s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2553.54 ms /    11 tokens (  232.14 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.08 ms /     3 runs   (  876.69 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5185.91 ms /    14 tokens\n",
      " 37%|███▋      | 1301/3487 [4:10:52<4:38:07,  7.63s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6102.94 ms /    31 tokens (  196.87 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.54 ms /     3 runs   (  884.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8759.76 ms /    34 tokens\n",
      " 37%|███▋      | 1302/3487 [4:11:01<4:50:23,  7.97s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4504.93 ms /    22 tokens (  204.77 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.15 ms /     3 runs   (  876.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7136.94 ms /    25 tokens\n",
      " 37%|███▋      | 1303/3487 [4:11:08<4:41:12,  7.73s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7670.10 ms /    39 tokens (  196.67 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.65 ms /     3 runs   (  874.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10297.38 ms /    42 tokens\n",
      " 37%|███▋      | 1304/3487 [4:11:18<5:09:14,  8.50s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5609.48 ms /    29 tokens (  193.43 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.16 ms /     3 runs   (  885.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8269.25 ms /    32 tokens\n",
      " 37%|███▋      | 1305/3487 [4:11:26<5:06:40,  8.43s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4726.59 ms /    24 tokens (  196.94 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.71 ms /     3 runs   (  885.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7385.44 ms /    27 tokens\n",
      " 37%|███▋      | 1306/3487 [4:11:34<4:55:11,  8.12s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7376.48 ms /    38 tokens (  194.12 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.51 ms /     3 runs   (  882.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10028.49 ms /    41 tokens\n",
      " 37%|███▋      | 1307/3487 [4:11:44<5:15:56,  8.70s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2711.49 ms /    12 tokens (  225.96 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.79 ms /     3 runs   (  884.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5369.11 ms /    15 tokens\n",
      " 38%|███▊      | 1308/3487 [4:11:49<4:39:38,  7.70s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5841.72 ms /    30 tokens (  194.72 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.78 ms /     3 runs   (  885.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8502.41 ms /    33 tokens\n",
      " 38%|███▊      | 1309/3487 [4:11:58<4:48:21,  7.94s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3641.23 ms /    17 tokens (  214.19 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.36 ms /     3 runs   (  888.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6339.53 ms /    20 tokens\n",
      " 38%|███▊      | 1310/3487 [4:12:04<4:30:51,  7.47s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9067.10 ms /    45 tokens (  201.49 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.54 ms /     3 runs   (  883.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11719.09 ms /    48 tokens\n",
      " 38%|███▊      | 1311/3487 [4:12:16<5:17:06,  8.74s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3350.30 ms /    15 tokens (  223.35 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.15 ms /     3 runs   (  883.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6002.66 ms /    18 tokens\n",
      " 38%|███▊      | 1312/3487 [4:12:22<4:47:13,  7.92s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7253.45 ms /    33 tokens (  219.80 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.36 ms /     3 runs   (  884.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9909.18 ms /    36 tokens\n",
      " 38%|███▊      | 1313/3487 [4:12:32<5:08:45,  8.52s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4584.72 ms /    23 tokens (  199.34 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.37 ms /     3 runs   (  880.79 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7229.56 ms /    26 tokens\n",
      " 38%|███▊      | 1314/3487 [4:12:39<4:54:39,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3476.35 ms /    16 tokens (  217.27 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.50 ms /     3 runs   (  885.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6135.55 ms /    19 tokens\n",
      " 38%|███▊      | 1315/3487 [4:12:45<4:32:53,  7.54s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7850.89 ms /    40 tokens (  196.27 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.41 ms /     3 runs   (  881.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10497.73 ms /    43 tokens\n",
      " 38%|███▊      | 1316/3487 [4:12:56<5:04:59,  8.43s/it]Llama.generate: 307 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9982.93 ms /    53 tokens (  188.36 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.53 ms /     3 runs   (  877.84 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12619.15 ms /    56 tokens\n",
      " 38%|███▊      | 1317/3487 [4:13:08<5:50:23,  9.69s/it]Llama.generate: 307 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15300.32 ms /    80 tokens (  191.25 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.60 ms /     3 runs   (  887.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17966.06 ms /    83 tokens\n",
      " 38%|███▊      | 1318/3487 [4:13:26<7:20:06, 12.17s/it]Llama.generate: 311 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4572.91 ms /    23 tokens (  198.82 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.61 ms /     3 runs   (  895.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7262.73 ms /    26 tokens\n",
      " 38%|███▊      | 1319/3487 [4:13:33<6:26:45, 10.70s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4184.04 ms /    21 tokens (  199.24 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.06 ms /     3 runs   (  882.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6832.50 ms /    24 tokens\n",
      " 38%|███▊      | 1320/3487 [4:13:40<5:44:43,  9.54s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2919.95 ms /    13 tokens (  224.61 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.95 ms /     3 runs   (  887.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5585.91 ms /    16 tokens\n",
      " 38%|███▊      | 1321/3487 [4:13:46<5:01:47,  8.36s/it]Llama.generate: 307 prefix-match hit, remaining 141 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26131.68 ms /   141 tokens (  185.33 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.17 ms /     3 runs   (  883.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   28785.17 ms /   144 tokens\n",
      " 38%|███▊      | 1322/3487 [4:14:15<8:42:50, 14.49s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4358.33 ms /    21 tokens (  207.54 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3281.50 ms /     3 runs   ( 1093.83 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =    7643.66 ms /    24 tokens\n",
      " 38%|███▊      | 1323/3487 [4:14:22<7:28:38, 12.44s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10049.27 ms /    43 tokens (  233.70 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3032.04 ms /     3 runs   ( 1010.68 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   13084.51 ms /    46 tokens\n",
      " 38%|███▊      | 1324/3487 [4:14:35<7:35:30, 12.64s/it]Llama.generate: 306 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16037.15 ms /    75 tokens (  213.83 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.74 ms /     3 runs   (  911.91 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   18776.34 ms /    78 tokens\n",
      " 38%|███▊      | 1325/3487 [4:14:54<8:41:47, 14.48s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5154.05 ms /    25 tokens (  206.16 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.83 ms /     3 runs   (  894.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7842.01 ms /    28 tokens\n",
      " 38%|███▊      | 1326/3487 [4:15:02<7:29:54, 12.49s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9330.05 ms /    47 tokens (  198.51 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2829.06 ms /     3 runs   (  943.02 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   12161.80 ms /    50 tokens\n",
      " 38%|███▊      | 1327/3487 [4:15:14<7:26:11, 12.39s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7031.79 ms /    33 tokens (  213.08 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.24 ms /     3 runs   (  882.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9682.19 ms /    36 tokens\n",
      " 38%|███▊      | 1328/3487 [4:15:24<6:56:47, 11.58s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4121.66 ms /    20 tokens (  206.08 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2814.03 ms /     3 runs   (  938.01 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6938.49 ms /    23 tokens\n",
      " 38%|███▊      | 1329/3487 [4:15:31<6:06:35, 10.19s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6207.35 ms /    31 tokens (  200.24 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.71 ms /     3 runs   (  893.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8889.84 ms /    34 tokens\n",
      " 38%|███▊      | 1330/3487 [4:15:40<5:52:27,  9.80s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4283.85 ms /    21 tokens (  203.99 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.80 ms /     3 runs   (  889.60 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6954.94 ms /    24 tokens\n",
      " 38%|███▊      | 1331/3487 [4:15:47<5:21:40,  8.95s/it]Llama.generate: 308 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3473.56 ms /    16 tokens (  217.10 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.89 ms /     3 runs   (  891.63 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6150.71 ms /    19 tokens\n",
      " 38%|███▊      | 1332/3487 [4:15:53<4:51:24,  8.11s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7807.80 ms /    39 tokens (  200.20 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.12 ms /     3 runs   (  882.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10456.13 ms /    42 tokens\n",
      " 38%|███▊      | 1333/3487 [4:16:03<5:16:36,  8.82s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2910.49 ms /    13 tokens (  223.88 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.39 ms /     3 runs   (  886.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5571.75 ms /    16 tokens\n",
      " 38%|███▊      | 1334/3487 [4:16:09<4:41:36,  7.85s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2580.32 ms /    11 tokens (  234.57 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.09 ms /     3 runs   (  893.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5263.28 ms /    14 tokens\n",
      " 38%|███▊      | 1335/3487 [4:16:14<4:13:43,  7.07s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4250.29 ms /    21 tokens (  202.39 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.11 ms /     3 runs   (  886.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6910.81 ms /    24 tokens\n",
      " 38%|███▊      | 1336/3487 [4:16:21<4:11:57,  7.03s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3962.34 ms /    19 tokens (  208.54 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.94 ms /     3 runs   (  885.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6622.63 ms /    22 tokens\n",
      " 38%|███▊      | 1337/3487 [4:16:28<4:07:34,  6.91s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2039.02 ms /     8 tokens (  254.88 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.76 ms /     3 runs   (  889.25 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4709.10 ms /    11 tokens\n",
      " 38%|███▊      | 1338/3487 [4:16:33<3:43:54,  6.25s/it]Llama.generate: 306 prefix-match hit, remaining 155 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28408.10 ms /   155 tokens (  183.28 ms per token,     5.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.46 ms /     3 runs   (  893.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   31090.68 ms /   158 tokens\n",
      " 38%|███▊      | 1339/3487 [4:17:04<8:10:40, 13.71s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7996.67 ms /    40 tokens (  199.92 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.39 ms /     3 runs   (  889.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10668.68 ms /    43 tokens\n",
      " 38%|███▊      | 1340/3487 [4:17:14<7:37:56, 12.80s/it]Llama.generate: 306 prefix-match hit, remaining 96 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18195.90 ms /    96 tokens (  189.54 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.71 ms /     3 runs   (  880.57 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   20840.21 ms /    99 tokens\n",
      " 38%|███▊      | 1341/3487 [4:17:35<9:04:07, 15.21s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3260.39 ms /    15 tokens (  217.36 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2728.01 ms /     3 runs   (  909.34 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5991.04 ms /    18 tokens\n",
      " 38%|███▊      | 1342/3487 [4:17:41<7:25:04, 12.45s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4824.05 ms /    24 tokens (  201.00 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.47 ms /     3 runs   (  903.16 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7536.27 ms /    27 tokens\n",
      " 39%|███▊      | 1343/3487 [4:17:49<6:32:17, 10.98s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3628.44 ms /    15 tokens (  241.90 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.39 ms /     3 runs   (  881.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6274.64 ms /    18 tokens\n",
      " 39%|███▊      | 1344/3487 [4:17:55<5:41:48,  9.57s/it]Llama.generate: 307 prefix-match hit, remaining 186 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   34135.12 ms /   186 tokens (  183.52 ms per token,     5.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.35 ms /     3 runs   (  890.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   36809.13 ms /   189 tokens\n",
      " 39%|███▊      | 1345/3487 [4:18:32<10:33:29, 17.74s/it]Llama.generate: 306 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   30472.49 ms /   133 tokens (  229.12 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.12 ms /     3 runs   (  910.38 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   33206.71 ms /   136 tokens\n",
      " 39%|███▊      | 1346/3487 [4:19:05<13:18:49, 22.39s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13431.61 ms /    69 tokens (  194.66 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.33 ms /     3 runs   (  896.11 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16122.30 ms /    72 tokens\n",
      " 39%|███▊      | 1347/3487 [4:19:21<12:11:30, 20.51s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4209.87 ms /    20 tokens (  210.49 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2805.59 ms /     3 runs   (  935.20 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7017.92 ms /    23 tokens\n",
      " 39%|███▊      | 1348/3487 [4:19:28<9:46:58, 16.47s/it] Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3381.56 ms /    15 tokens (  225.44 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3869.84 ms /     3 runs   ( 1289.94 ms per token,     0.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    7253.97 ms /    18 tokens\n",
      " 39%|███▊      | 1349/3487 [4:19:35<8:08:21, 13.71s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9982.81 ms /    42 tokens (  237.69 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2796.57 ms /     3 runs   (  932.19 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12781.85 ms /    45 tokens\n",
      " 39%|███▊      | 1350/3487 [4:19:48<7:58:22, 13.43s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4313.90 ms /    21 tokens (  205.42 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.11 ms /     3 runs   (  891.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6990.95 ms /    24 tokens\n",
      " 39%|███▊      | 1351/3487 [4:19:55<6:49:27, 11.50s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2215.28 ms /     9 tokens (  246.14 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.37 ms /     3 runs   (  885.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4875.96 ms /    12 tokens\n",
      " 39%|███▉      | 1352/3487 [4:20:00<5:38:38,  9.52s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4546.40 ms /    22 tokens (  206.65 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.67 ms /     3 runs   (  895.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7234.96 ms /    25 tokens\n",
      " 39%|███▉      | 1353/3487 [4:20:07<5:14:14,  8.84s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9907.98 ms /    50 tokens (  198.16 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.79 ms /     3 runs   (  901.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   12616.24 ms /    53 tokens\n",
      " 39%|███▉      | 1354/3487 [4:20:20<5:54:30,  9.97s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5250.96 ms /    27 tokens (  194.48 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.04 ms /     3 runs   (  893.68 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7934.73 ms /    30 tokens\n",
      " 39%|███▉      | 1355/3487 [4:20:28<5:32:43,  9.36s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4595.14 ms /    22 tokens (  208.87 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.58 ms /     3 runs   (  903.86 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7309.55 ms /    25 tokens\n",
      " 39%|███▉      | 1356/3487 [4:20:35<5:10:47,  8.75s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2625.07 ms /    10 tokens (  262.51 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2751.11 ms /     3 runs   (  917.04 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5379.05 ms /    13 tokens\n",
      " 39%|███▉      | 1357/3487 [4:20:41<4:34:50,  7.74s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5426.43 ms /    26 tokens (  208.71 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.07 ms /     3 runs   (  908.36 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8154.28 ms /    29 tokens\n",
      " 39%|███▉      | 1358/3487 [4:20:49<4:39:11,  7.87s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1754.08 ms /     6 tokens (  292.35 ms per token,     3.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.10 ms /     3 runs   (  897.03 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4448.11 ms /     9 tokens\n",
      " 39%|███▉      | 1359/3487 [4:20:53<4:02:45,  6.84s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13021.59 ms /    66 tokens (  197.30 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.43 ms /     3 runs   (  880.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15664.79 ms /    69 tokens\n",
      " 39%|███▉      | 1360/3487 [4:21:09<5:36:32,  9.49s/it]Llama.generate: 309 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9722.74 ms /    48 tokens (  202.56 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.19 ms /     3 runs   (  883.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12374.19 ms /    51 tokens\n",
      " 39%|███▉      | 1361/3487 [4:21:21<6:07:04, 10.36s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4320.50 ms /    21 tokens (  205.74 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.18 ms /     3 runs   (  894.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7005.88 ms /    24 tokens\n",
      " 39%|███▉      | 1362/3487 [4:21:28<5:31:21,  9.36s/it]Llama.generate: 308 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12922.59 ms /    65 tokens (  198.81 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.27 ms /     3 runs   (  887.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15587.49 ms /    68 tokens\n",
      " 39%|███▉      | 1363/3487 [4:21:44<6:37:28, 11.23s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3035.35 ms /    14 tokens (  216.81 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.10 ms /     3 runs   (  884.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5691.45 ms /    17 tokens\n",
      " 39%|███▉      | 1364/3487 [4:21:50<5:38:35,  9.57s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4210.18 ms /    21 tokens (  200.48 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.16 ms /     3 runs   (  891.05 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6885.91 ms /    24 tokens\n",
      " 39%|███▉      | 1365/3487 [4:21:56<5:10:02,  8.77s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13699.52 ms /    72 tokens (  190.27 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.38 ms /     3 runs   (  884.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16355.45 ms /    75 tokens\n",
      " 39%|███▉      | 1366/3487 [4:22:13<6:30:29, 11.05s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4217.68 ms /    21 tokens (  200.84 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.73 ms /     3 runs   (  883.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6872.04 ms /    24 tokens\n",
      " 39%|███▉      | 1367/3487 [4:22:20<5:46:09,  9.80s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2931.61 ms /    13 tokens (  225.51 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2714.76 ms /     3 runs   (  904.92 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5649.40 ms /    16 tokens\n",
      " 39%|███▉      | 1368/3487 [4:22:25<5:02:09,  8.56s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2980.23 ms /    13 tokens (  229.25 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.83 ms /     3 runs   (  888.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5650.24 ms /    16 tokens\n",
      " 39%|███▉      | 1369/3487 [4:22:31<4:31:20,  7.69s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1703.96 ms /     6 tokens (  283.99 ms per token,     3.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.27 ms /     3 runs   (  883.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4357.68 ms /     9 tokens\n",
      " 39%|███▉      | 1370/3487 [4:22:35<3:56:03,  6.69s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10695.42 ms /    56 tokens (  190.99 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.93 ms /     3 runs   (  887.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13361.86 ms /    59 tokens\n",
      " 39%|███▉      | 1371/3487 [4:22:49<5:06:36,  8.69s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3631.41 ms /    17 tokens (  213.61 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.04 ms /     3 runs   (  885.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6289.53 ms /    20 tokens\n",
      " 39%|███▉      | 1372/3487 [4:22:55<4:41:07,  7.97s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5078.44 ms /    25 tokens (  203.14 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.76 ms /     3 runs   (  887.92 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7744.23 ms /    28 tokens\n",
      " 39%|███▉      | 1373/3487 [4:23:03<4:38:39,  7.91s/it]Llama.generate: 307 prefix-match hit, remaining 85 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15653.86 ms /    85 tokens (  184.16 ms per token,     5.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.16 ms /     3 runs   (  875.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18282.00 ms /    88 tokens\n",
      " 39%|███▉      | 1374/3487 [4:23:21<6:28:12, 11.02s/it]Llama.generate: 307 prefix-match hit, remaining 186 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   34616.18 ms /   186 tokens (  186.11 ms per token,     5.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.57 ms /     3 runs   (  907.19 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   37340.18 ms /   189 tokens\n",
      " 39%|███▉      | 1375/3487 [4:23:58<11:06:00, 18.92s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4202.18 ms /    21 tokens (  200.10 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.88 ms /     3 runs   (  905.63 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6921.63 ms /    24 tokens\n",
      " 39%|███▉      | 1376/3487 [4:24:05<8:59:10, 15.32s/it] Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4648.18 ms /    22 tokens (  211.28 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.20 ms /     3 runs   (  878.07 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7284.90 ms /    25 tokens\n",
      " 39%|███▉      | 1377/3487 [4:24:13<7:34:09, 12.91s/it]Llama.generate: 315 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3420.64 ms /    13 tokens (  263.13 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.00 ms /     3 runs   (  898.67 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6118.60 ms /    16 tokens\n",
      " 40%|███▉      | 1378/3487 [4:24:19<6:22:22, 10.88s/it]Llama.generate: 307 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14958.85 ms /    77 tokens (  194.27 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2840.28 ms /     3 runs   (  946.76 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   17802.73 ms /    80 tokens\n",
      " 40%|███▉      | 1379/3487 [4:24:37<7:35:15, 12.96s/it]Llama.generate: 307 prefix-match hit, remaining 114 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21617.56 ms /   114 tokens (  189.63 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.81 ms /     3 runs   (  882.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   24269.27 ms /   117 tokens\n",
      " 40%|███▉      | 1380/3487 [4:25:01<9:34:18, 16.35s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4130.19 ms /    19 tokens (  217.38 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.11 ms /     3 runs   (  881.37 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6776.85 ms /    22 tokens\n",
      " 40%|███▉      | 1381/3487 [4:25:08<7:53:16, 13.48s/it]Llama.generate: 308 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10194.15 ms /    54 tokens (  188.78 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.09 ms /     3 runs   (  881.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12840.22 ms /    57 tokens\n",
      " 40%|███▉      | 1382/3487 [4:25:21<7:46:21, 13.29s/it]Llama.generate: 306 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17344.81 ms /    93 tokens (  186.50 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.85 ms /     3 runs   (  880.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   20020.07 ms /    96 tokens\n",
      " 40%|███▉      | 1383/3487 [4:25:41<8:56:58, 15.31s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4156.75 ms /    21 tokens (  197.94 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.05 ms /     3 runs   (  892.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6835.53 ms /    24 tokens\n",
      " 40%|███▉      | 1384/3487 [4:25:47<7:27:39, 12.77s/it]Llama.generate: 307 prefix-match hit, remaining 88 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16313.42 ms /    88 tokens (  185.38 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.54 ms /     3 runs   (  875.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18941.84 ms /    91 tokens\n",
      " 40%|███▉      | 1385/3487 [4:26:06<8:32:22, 14.63s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4503.93 ms /    23 tokens (  195.82 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.35 ms /     3 runs   (  882.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7154.61 ms /    26 tokens\n",
      " 40%|███▉      | 1386/3487 [4:26:14<7:13:45, 12.39s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10381.70 ms /    56 tokens (  185.39 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.14 ms /     3 runs   (  880.72 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13026.48 ms /    59 tokens\n",
      " 40%|███▉      | 1387/3487 [4:26:27<7:20:21, 12.58s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7755.67 ms /    40 tokens (  193.89 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.45 ms /     3 runs   (  875.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10384.84 ms /    43 tokens\n",
      " 40%|███▉      | 1388/3487 [4:26:37<6:57:10, 11.93s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3707.31 ms /    18 tokens (  205.96 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.41 ms /     3 runs   (  877.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6341.90 ms /    21 tokens\n",
      " 40%|███▉      | 1389/3487 [4:26:43<5:58:28, 10.25s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5061.68 ms /    25 tokens (  202.47 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3525.75 ms /     4 runs   (  881.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8591.09 ms /    29 tokens\n",
      " 40%|███▉      | 1390/3487 [4:26:52<5:40:57,  9.76s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2543.04 ms /    11 tokens (  231.19 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.17 ms /     3 runs   (  896.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5233.98 ms /    14 tokens\n",
      " 40%|███▉      | 1391/3487 [4:26:57<4:53:29,  8.40s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7517.37 ms /    35 tokens (  214.78 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.56 ms /     3 runs   (  876.85 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10150.48 ms /    38 tokens\n",
      " 40%|███▉      | 1392/3487 [4:27:07<5:11:44,  8.93s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3743.31 ms /    18 tokens (  207.96 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.20 ms /     3 runs   (  883.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6394.97 ms /    21 tokens\n",
      " 40%|███▉      | 1393/3487 [4:27:14<4:45:10,  8.17s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7440.92 ms /    38 tokens (  195.81 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.58 ms /     3 runs   (  875.53 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10069.91 ms /    41 tokens\n",
      " 40%|███▉      | 1394/3487 [4:27:24<5:05:00,  8.74s/it]Llama.generate: 308 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4767.75 ms /    24 tokens (  198.66 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.49 ms /     3 runs   (  879.16 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7407.71 ms /    27 tokens\n",
      " 40%|████      | 1395/3487 [4:27:31<4:50:59,  8.35s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4561.11 ms /    23 tokens (  198.31 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.73 ms /     3 runs   (  877.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7197.17 ms /    26 tokens\n",
      " 40%|████      | 1396/3487 [4:27:38<4:38:55,  8.00s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3318.63 ms /    15 tokens (  221.24 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.61 ms /     3 runs   (  905.87 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6038.77 ms /    18 tokens\n",
      " 40%|████      | 1397/3487 [4:27:44<4:18:20,  7.42s/it]Llama.generate: 315 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3130.21 ms /    13 tokens (  240.79 ms per token,     4.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2765.53 ms /     3 runs   (  921.84 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5897.79 ms /    16 tokens\n",
      " 40%|████      | 1398/3487 [4:27:50<4:02:28,  6.96s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2618.37 ms /    10 tokens (  261.84 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.68 ms /     3 runs   (  893.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5302.90 ms /    13 tokens\n",
      " 40%|████      | 1399/3487 [4:27:56<3:45:06,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7408.20 ms /    37 tokens (  200.22 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.75 ms /     3 runs   (  887.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10073.48 ms /    40 tokens\n",
      " 40%|████      | 1400/3487 [4:28:06<4:22:42,  7.55s/it]Llama.generate: 306 prefix-match hit, remaining 128 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23526.81 ms /   128 tokens (  183.80 ms per token,     5.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.26 ms /     3 runs   (  880.75 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   26171.76 ms /   131 tokens\n",
      " 40%|████      | 1401/3487 [4:28:32<7:36:51, 13.14s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5751.51 ms /    29 tokens (  198.33 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.38 ms /     3 runs   (  898.79 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8450.32 ms /    32 tokens\n",
      " 40%|████      | 1402/3487 [4:28:40<6:47:49, 11.74s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4503.64 ms /    22 tokens (  204.71 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.45 ms /     3 runs   (  903.48 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7216.43 ms /    25 tokens\n",
      " 40%|████      | 1403/3487 [4:28:48<6:00:37, 10.38s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5273.40 ms /    26 tokens (  202.82 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.90 ms /     3 runs   (  876.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7905.07 ms /    29 tokens\n",
      " 40%|████      | 1404/3487 [4:28:56<5:34:45,  9.64s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2769.20 ms /    12 tokens (  230.77 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.85 ms /     3 runs   (  894.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5455.50 ms /    15 tokens\n",
      " 40%|████      | 1405/3487 [4:29:01<4:51:05,  8.39s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7642.59 ms /    39 tokens (  195.96 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.27 ms /     3 runs   (  885.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10300.54 ms /    42 tokens\n",
      " 40%|████      | 1406/3487 [4:29:11<5:10:55,  8.96s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3014.90 ms /    14 tokens (  215.35 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2823.54 ms /     3 runs   (  941.18 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5841.33 ms /    17 tokens\n",
      " 40%|████      | 1407/3487 [4:29:17<4:38:22,  8.03s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7207.34 ms /    35 tokens (  205.92 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2616.78 ms /     3 runs   (  872.26 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9826.47 ms /    38 tokens\n",
      " 40%|████      | 1408/3487 [4:29:27<4:56:59,  8.57s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4458.56 ms /    22 tokens (  202.66 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.46 ms /     3 runs   (  877.15 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7092.38 ms /    25 tokens\n",
      " 40%|████      | 1409/3487 [4:29:34<4:41:33,  8.13s/it]Llama.generate: 306 prefix-match hit, remaining 113 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21010.58 ms /   113 tokens (  185.93 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4060.43 ms /     3 runs   ( 1353.48 ms per token,     0.74 tokens per second)\n",
      "llama_perf_context_print:       total time =   25074.05 ms /   116 tokens\n",
      " 40%|████      | 1410/3487 [4:29:59<7:37:29, 13.22s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6821.01 ms /    10 tokens (  682.10 ms per token,     1.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =   18325.30 ms /     3 runs   ( 6108.43 ms per token,     0.16 tokens per second)\n",
      "llama_perf_context_print:       total time =   25156.72 ms /    13 tokens\n",
      " 40%|████      | 1411/3487 [4:30:24<9:41:27, 16.81s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4162.59 ms /    14 tokens (  297.33 ms per token,     3.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3887.85 ms /     3 runs   ( 1295.95 ms per token,     0.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    8054.68 ms /    17 tokens\n",
      " 40%|████      | 1412/3487 [4:30:32<8:10:43, 14.19s/it]Llama.generate: 307 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15031.42 ms /    68 tokens (  221.05 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.82 ms /     3 runs   (  900.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   17736.03 ms /    71 tokens\n",
      " 41%|████      | 1413/3487 [4:30:50<8:47:21, 15.26s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8002.83 ms /    40 tokens (  200.07 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.87 ms /     3 runs   (  910.62 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   10736.94 ms /    43 tokens\n",
      " 41%|████      | 1414/3487 [4:31:01<8:00:21, 13.90s/it]Llama.generate: 309 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7591.76 ms /    37 tokens (  205.18 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.47 ms /     3 runs   (  893.82 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10276.14 ms /    40 tokens\n",
      " 41%|████      | 1415/3487 [4:31:11<7:22:38, 12.82s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10375.07 ms /    54 tokens (  192.13 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.79 ms /     3 runs   (  892.93 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13056.79 ms /    57 tokens\n",
      " 41%|████      | 1416/3487 [4:31:24<7:25:01, 12.89s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7219.20 ms /    34 tokens (  212.33 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.10 ms /     3 runs   (  886.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9880.17 ms /    37 tokens\n",
      " 41%|████      | 1417/3487 [4:31:34<6:53:44, 11.99s/it]Llama.generate: 316 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9249.46 ms /    49 tokens (  188.76 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.84 ms /     3 runs   (  873.28 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11871.61 ms /    52 tokens\n",
      " 41%|████      | 1418/3487 [4:31:46<6:52:21, 11.96s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6128.31 ms /    32 tokens (  191.51 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.64 ms /     3 runs   (  882.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8779.18 ms /    35 tokens\n",
      " 41%|████      | 1419/3487 [4:31:55<6:19:23, 11.01s/it]Llama.generate: 306 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15101.02 ms /    82 tokens (  184.16 ms per token,     5.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.72 ms /     3 runs   (  881.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17748.51 ms /    85 tokens\n",
      " 41%|████      | 1420/3487 [4:32:13<7:28:59, 13.03s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3119.64 ms /    15 tokens (  207.98 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.12 ms /     3 runs   (  886.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5782.10 ms /    18 tokens\n",
      " 41%|████      | 1421/3487 [4:32:18<6:13:57, 10.86s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9845.65 ms /    42 tokens (  234.42 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2867.75 ms /     3 runs   (  955.92 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   12715.59 ms /    45 tokens\n",
      " 41%|████      | 1422/3487 [4:32:31<6:33:00, 11.42s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2550.97 ms /    11 tokens (  231.91 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.49 ms /     3 runs   (  884.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5205.60 ms /    14 tokens\n",
      " 41%|████      | 1423/3487 [4:32:36<5:28:46,  9.56s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1542.02 ms /     6 tokens (  257.00 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2775.56 ms /     3 runs   (  925.19 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    4319.77 ms /     9 tokens\n",
      " 41%|████      | 1424/3487 [4:32:41<4:34:41,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4254.98 ms /    21 tokens (  202.62 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.77 ms /     3 runs   (  874.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6882.27 ms /    24 tokens\n",
      " 41%|████      | 1425/3487 [4:32:48<4:23:14,  7.66s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4702.08 ms /    24 tokens (  195.92 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.22 ms /     3 runs   (  878.41 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7339.55 ms /    27 tokens\n",
      " 41%|████      | 1426/3487 [4:32:55<4:19:54,  7.57s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4221.19 ms /    21 tokens (  201.01 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.16 ms /     3 runs   (  877.05 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6855.22 ms /    24 tokens\n",
      " 41%|████      | 1427/3487 [4:33:02<4:12:31,  7.36s/it]Llama.generate: 314 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1336.02 ms /     4 tokens (  334.00 ms per token,     2.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2784.72 ms /     3 runs   (  928.24 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    4123.38 ms /     7 tokens\n",
      " 41%|████      | 1428/3487 [4:33:06<3:39:13,  6.39s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6136.26 ms /    31 tokens (  197.94 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.37 ms /     3 runs   (  895.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8825.89 ms /    34 tokens\n",
      " 41%|████      | 1429/3487 [4:33:15<4:04:17,  7.12s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2055.57 ms /     8 tokens (  256.95 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.63 ms /     3 runs   (  881.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4702.80 ms /    11 tokens\n",
      " 41%|████      | 1430/3487 [4:33:19<3:39:23,  6.40s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4186.06 ms /    20 tokens (  209.30 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.07 ms /     3 runs   (  881.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6833.44 ms /    23 tokens\n",
      " 41%|████      | 1431/3487 [4:33:26<3:43:49,  6.53s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5166.11 ms /    26 tokens (  198.70 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.50 ms /     3 runs   (  879.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7808.05 ms /    29 tokens\n",
      " 41%|████      | 1432/3487 [4:33:34<3:56:54,  6.92s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5224.74 ms /    27 tokens (  193.51 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.70 ms /     3 runs   (  882.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7875.04 ms /    30 tokens\n",
      " 41%|████      | 1433/3487 [4:33:42<4:06:43,  7.21s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4161.04 ms /    21 tokens (  198.14 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.92 ms /     3 runs   (  879.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6802.21 ms /    24 tokens\n",
      " 41%|████      | 1434/3487 [4:33:49<4:02:50,  7.10s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2028.96 ms /     8 tokens (  253.62 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.67 ms /     3 runs   (  887.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4694.02 ms /    11 tokens\n",
      " 41%|████      | 1435/3487 [4:33:54<3:38:10,  6.38s/it]Llama.generate: 306 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11289.79 ms /    61 tokens (  185.08 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.16 ms /     3 runs   (  882.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13940.41 ms /    64 tokens\n",
      " 41%|████      | 1436/3487 [4:34:07<4:55:39,  8.65s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4429.46 ms /    22 tokens (  201.34 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.51 ms /     3 runs   (  884.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7085.44 ms /    25 tokens\n",
      " 41%|████      | 1437/3487 [4:34:15<4:39:35,  8.18s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4426.52 ms /    19 tokens (  232.97 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.64 ms /     3 runs   (  907.55 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7151.51 ms /    22 tokens\n",
      " 41%|████      | 1438/3487 [4:34:22<4:28:58,  7.88s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5854.33 ms /    29 tokens (  201.87 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.93 ms /     3 runs   (  882.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8504.38 ms /    32 tokens\n",
      " 41%|████▏     | 1439/3487 [4:34:30<4:35:20,  8.07s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4386.20 ms /    21 tokens (  208.87 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2827.27 ms /     3 runs   (  942.42 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7216.03 ms /    24 tokens\n",
      " 41%|████▏     | 1440/3487 [4:34:37<4:26:35,  7.81s/it]Llama.generate: 307 prefix-match hit, remaining 126 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23104.46 ms /   126 tokens (  183.37 ms per token,     5.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.70 ms /     3 runs   (  880.23 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   25748.27 ms /   129 tokens\n",
      " 41%|████▏     | 1441/3487 [4:35:03<7:30:21, 13.21s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9034.21 ms /    48 tokens (  188.21 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.74 ms /     3 runs   (  875.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11662.59 ms /    51 tokens\n",
      " 41%|████▏     | 1442/3487 [4:35:15<7:14:24, 12.75s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1992.99 ms /     7 tokens (  284.71 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2826.56 ms /     3 runs   (  942.19 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4821.86 ms /    10 tokens\n",
      " 41%|████▏     | 1443/3487 [4:35:20<5:53:18, 10.37s/it]Llama.generate: 306 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13141.22 ms /    70 tokens (  187.73 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.07 ms /     3 runs   (  880.69 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15785.87 ms /    73 tokens\n",
      " 41%|████▏     | 1444/3487 [4:35:36<6:48:31, 12.00s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4788.01 ms /    22 tokens (  217.64 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.31 ms /     3 runs   (  908.10 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7514.93 ms /    25 tokens\n",
      " 41%|████▏     | 1445/3487 [4:35:43<6:02:37, 10.66s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7075.41 ms /    33 tokens (  214.41 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.74 ms /     3 runs   (  884.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9731.22 ms /    36 tokens\n",
      " 41%|████▏     | 1446/3487 [4:35:53<5:53:05, 10.38s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2949.18 ms /    13 tokens (  226.86 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.00 ms /     3 runs   (  883.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5602.45 ms /    16 tokens\n",
      " 41%|████▏     | 1447/3487 [4:35:58<5:04:16,  8.95s/it]Llama.generate: 306 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13424.12 ms /    71 tokens (  189.07 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.44 ms /     3 runs   (  880.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16068.59 ms /    74 tokens\n",
      " 42%|████▏     | 1448/3487 [4:36:15<6:16:47, 11.09s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10507.24 ms /    56 tokens (  187.63 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2834.26 ms /     3 runs   (  944.75 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   13344.32 ms /    59 tokens\n",
      " 42%|████▏     | 1449/3487 [4:36:28<6:39:42, 11.77s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11425.60 ms /    62 tokens (  184.28 ms per token,     5.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.59 ms /     3 runs   (  874.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14052.60 ms /    65 tokens\n",
      " 42%|████▏     | 1450/3487 [4:36:42<7:02:52, 12.46s/it]Llama.generate: 308 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14705.48 ms /    80 tokens (  183.82 ms per token,     5.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.91 ms /     3 runs   (  883.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17358.22 ms /    83 tokens\n",
      " 42%|████▏     | 1451/3487 [4:36:59<7:52:39, 13.93s/it]Llama.generate: 308 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8256.45 ms /    43 tokens (  192.01 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.21 ms /     3 runs   (  876.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10888.17 ms /    46 tokens\n",
      " 42%|████▏     | 1452/3487 [4:37:10<7:21:34, 13.02s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7876.73 ms /    41 tokens (  192.12 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.38 ms /     3 runs   (  875.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10505.48 ms /    44 tokens\n",
      " 42%|████▏     | 1453/3487 [4:37:21<6:55:51, 12.27s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2809.24 ms /    10 tokens (  280.92 ms per token,     3.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.60 ms /     3 runs   (  896.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5500.40 ms /    13 tokens\n",
      " 42%|████▏     | 1454/3487 [4:37:26<5:46:57, 10.24s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8234.06 ms /    43 tokens (  191.49 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.50 ms /     3 runs   (  873.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10857.83 ms /    46 tokens\n",
      " 42%|████▏     | 1455/3487 [4:37:37<5:53:09, 10.43s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8213.52 ms /    43 tokens (  191.01 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.20 ms /     3 runs   (  897.73 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10908.91 ms /    46 tokens\n",
      " 42%|████▏     | 1456/3487 [4:37:48<5:57:56, 10.57s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1910.63 ms /     7 tokens (  272.95 ms per token,     3.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.88 ms /     3 runs   (  898.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4609.70 ms /    10 tokens\n",
      " 42%|████▏     | 1457/3487 [4:37:53<4:57:18,  8.79s/it]Llama.generate: 307 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14321.93 ms /    75 tokens (  190.96 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2621.22 ms /     3 runs   (  873.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16945.49 ms /    78 tokens\n",
      " 42%|████▏     | 1458/3487 [4:38:10<6:20:01, 11.24s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8245.89 ms /    43 tokens (  191.76 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.70 ms /     3 runs   (  885.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10905.92 ms /    46 tokens\n",
      " 42%|████▏     | 1459/3487 [4:38:20<6:16:33, 11.14s/it]Llama.generate: 308 prefix-match hit, remaining 170 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   31021.77 ms /   170 tokens (  182.48 ms per token,     5.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.00 ms /     3 runs   (  889.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   33693.17 ms /   173 tokens\n",
      " 42%|████▏     | 1460/3487 [4:38:54<10:05:02, 17.91s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6152.07 ms /    32 tokens (  192.25 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.45 ms /     3 runs   (  881.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8797.98 ms /    35 tokens\n",
      " 42%|████▏     | 1461/3487 [4:39:03<8:32:31, 15.18s/it] Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9696.49 ms /    51 tokens (  190.13 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.35 ms /     3 runs   (  882.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12347.86 ms /    54 tokens\n",
      " 42%|████▏     | 1462/3487 [4:39:15<8:03:40, 14.33s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8658.48 ms /    46 tokens (  188.23 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3511.42 ms /     4 runs   (  877.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12204.21 ms /    50 tokens\n",
      " 42%|████▏     | 1463/3487 [4:39:28<7:41:58, 13.70s/it]Llama.generate: 307 prefix-match hit, remaining 117 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21411.65 ms /   117 tokens (  183.01 ms per token,     5.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.95 ms /     3 runs   (  883.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   24065.84 ms /   120 tokens\n",
      " 42%|████▏     | 1464/3487 [4:39:52<9:26:43, 16.81s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7602.45 ms /    39 tokens (  194.93 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.55 ms /     3 runs   (  881.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10249.60 ms /    42 tokens\n",
      " 42%|████▏     | 1465/3487 [4:40:02<8:20:13, 14.84s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5019.08 ms /    25 tokens (  200.76 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.47 ms /     3 runs   (  882.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7670.73 ms /    28 tokens\n",
      " 42%|████▏     | 1466/3487 [4:40:10<7:07:35, 12.69s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4214.45 ms /    21 tokens (  200.69 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.35 ms /     3 runs   (  887.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6877.92 ms /    24 tokens\n",
      " 42%|████▏     | 1467/3487 [4:40:16<6:08:42, 10.95s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5111.36 ms /    24 tokens (  212.97 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.01 ms /     3 runs   (  892.34 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7790.56 ms /    27 tokens\n",
      " 42%|████▏     | 1468/3487 [4:40:24<5:36:42, 10.01s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3980.68 ms /    18 tokens (  221.15 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.14 ms /     3 runs   (  907.38 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6705.55 ms /    21 tokens\n",
      " 42%|████▏     | 1469/3487 [4:40:31<5:03:20,  9.02s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4631.88 ms /    23 tokens (  201.39 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.93 ms /     3 runs   (  903.31 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7343.59 ms /    26 tokens\n",
      " 42%|████▏     | 1470/3487 [4:40:38<4:46:22,  8.52s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5293.88 ms /    25 tokens (  211.76 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.24 ms /     3 runs   (  888.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7962.37 ms /    28 tokens\n",
      " 42%|████▏     | 1471/3487 [4:40:46<4:40:42,  8.35s/it]Llama.generate: 306 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16704.60 ms /    90 tokens (  185.61 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.69 ms /     3 runs   (  892.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   19386.21 ms /    93 tokens\n",
      " 42%|████▏     | 1472/3487 [4:41:06<6:31:47, 11.67s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7186.84 ms /    36 tokens (  199.63 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.49 ms /     3 runs   (  878.50 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9824.82 ms /    39 tokens\n",
      " 42%|████▏     | 1473/3487 [4:41:16<6:13:08, 11.12s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7034.37 ms /    35 tokens (  200.98 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.76 ms /     3 runs   (  880.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9679.95 ms /    38 tokens\n",
      " 42%|████▏     | 1474/3487 [4:41:25<5:58:34, 10.69s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2670.48 ms /    12 tokens (  222.54 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.99 ms /     3 runs   (  888.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5337.11 ms /    15 tokens\n",
      " 42%|████▏     | 1475/3487 [4:41:31<5:04:38,  9.08s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4061.23 ms /    19 tokens (  213.75 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.29 ms /     3 runs   (  886.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6722.21 ms /    22 tokens\n",
      " 42%|████▏     | 1476/3487 [4:41:37<4:40:50,  8.38s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8010.07 ms /    41 tokens (  195.37 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.60 ms /     3 runs   (  902.87 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10722.06 ms /    44 tokens\n",
      " 42%|████▏     | 1477/3487 [4:41:48<5:04:21,  9.09s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4826.90 ms /    23 tokens (  209.87 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2759.21 ms /     3 runs   (  919.74 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7588.72 ms /    26 tokens\n",
      " 42%|████▏     | 1478/3487 [4:41:56<4:49:16,  8.64s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3995.02 ms /    19 tokens (  210.26 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.91 ms /     3 runs   (  880.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6638.47 ms /    22 tokens\n",
      " 42%|████▏     | 1479/3487 [4:42:02<4:29:07,  8.04s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7917.17 ms /    40 tokens (  197.93 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.81 ms /     3 runs   (  880.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10560.33 ms /    43 tokens\n",
      " 42%|████▏     | 1480/3487 [4:42:13<4:54:21,  8.80s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3098.84 ms /    14 tokens (  221.35 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.32 ms /     3 runs   (  876.11 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5729.68 ms /    17 tokens\n",
      " 42%|████▏     | 1481/3487 [4:42:19<4:23:30,  7.88s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7585.05 ms /    37 tokens (  205.00 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2615.08 ms /     3 runs   (  871.69 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10202.43 ms /    40 tokens\n",
      " 43%|████▎     | 1482/3487 [4:42:29<4:46:43,  8.58s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7268.86 ms /    37 tokens (  196.46 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.45 ms /     3 runs   (  883.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9921.11 ms /    40 tokens\n",
      " 43%|████▎     | 1483/3487 [4:42:39<5:00:05,  8.98s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6957.93 ms /    33 tokens (  210.85 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.73 ms /     3 runs   (  884.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9615.71 ms /    36 tokens\n",
      " 43%|████▎     | 1484/3487 [4:42:48<5:06:21,  9.18s/it]Llama.generate: 306 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12680.68 ms /    67 tokens (  189.26 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.48 ms /     3 runs   (  883.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15332.59 ms /    70 tokens\n",
      " 43%|████▎     | 1485/3487 [4:43:04<6:07:53, 11.03s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8756.33 ms /    47 tokens (  186.30 ms per token,     5.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.90 ms /     3 runs   (  882.97 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11407.68 ms /    50 tokens\n",
      " 43%|████▎     | 1486/3487 [4:43:15<6:11:36, 11.14s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7174.47 ms /    37 tokens (  193.90 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.25 ms /     3 runs   (  880.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9817.19 ms /    40 tokens\n",
      " 43%|████▎     | 1487/3487 [4:43:25<5:58:16, 10.75s/it]Llama.generate: 311 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13911.69 ms /    75 tokens (  185.49 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2620.94 ms /     3 runs   (  873.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16534.96 ms /    78 tokens\n",
      " 43%|████▎     | 1488/3487 [4:43:41<6:56:00, 12.49s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8680.81 ms /    47 tokens (  184.70 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.85 ms /     3 runs   (  883.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11334.06 ms /    50 tokens\n",
      " 43%|████▎     | 1489/3487 [4:43:53<6:44:22, 12.14s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4440.64 ms /    22 tokens (  201.85 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.68 ms /     3 runs   (  899.56 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7141.61 ms /    25 tokens\n",
      " 43%|████▎     | 1490/3487 [4:44:00<5:54:18, 10.65s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7010.47 ms /    35 tokens (  200.30 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.89 ms /     3 runs   (  877.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9645.36 ms /    38 tokens\n",
      " 43%|████▎     | 1491/3487 [4:44:10<5:44:13, 10.35s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10375.88 ms /    50 tokens (  207.52 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.61 ms /     3 runs   (  884.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13032.50 ms /    53 tokens\n",
      " 43%|████▎     | 1492/3487 [4:44:23<6:10:53, 11.15s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7793.44 ms /    36 tokens (  216.48 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.86 ms /     3 runs   (  901.62 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10500.76 ms /    39 tokens\n",
      " 43%|████▎     | 1493/3487 [4:44:33<6:04:15, 10.96s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11027.02 ms /    56 tokens (  196.91 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.87 ms /     3 runs   (  886.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13689.35 ms /    59 tokens\n",
      " 43%|████▎     | 1494/3487 [4:44:47<6:31:20, 11.78s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9231.84 ms /    49 tokens (  188.40 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.24 ms /     3 runs   (  884.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11887.38 ms /    52 tokens\n",
      " 43%|████▎     | 1495/3487 [4:44:59<6:32:17, 11.82s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5169.92 ms /    24 tokens (  215.41 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2734.03 ms /     3 runs   (  911.34 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7906.21 ms /    27 tokens\n",
      " 43%|████▎     | 1496/3487 [4:45:07<5:53:15, 10.65s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4863.06 ms /    24 tokens (  202.63 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.73 ms /     3 runs   (  903.91 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7576.70 ms /    27 tokens\n",
      " 43%|████▎     | 1497/3487 [4:45:14<5:22:37,  9.73s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18597.64 ms /    74 tokens (  251.32 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3043.19 ms /     3 runs   ( 1014.40 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   21643.29 ms /    77 tokens\n",
      " 43%|████▎     | 1498/3487 [4:45:36<7:21:02, 13.30s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13613.45 ms /    67 tokens (  203.19 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.05 ms /     3 runs   (  880.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16259.45 ms /    70 tokens\n",
      " 43%|████▎     | 1499/3487 [4:45:52<7:50:17, 14.19s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13181.10 ms /    69 tokens (  191.03 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.80 ms /     3 runs   (  886.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15843.57 ms /    72 tokens\n",
      " 43%|████▎     | 1500/3487 [4:46:08<8:06:32, 14.69s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7072.74 ms /    35 tokens (  202.08 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.60 ms /     3 runs   (  876.20 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9703.69 ms /    38 tokens\n",
      " 43%|████▎     | 1501/3487 [4:46:18<7:16:50, 13.20s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10710.75 ms /    57 tokens (  187.91 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.44 ms /     3 runs   (  915.81 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   13462.12 ms /    60 tokens\n",
      " 43%|████▎     | 1502/3487 [4:46:31<7:19:19, 13.28s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6156.70 ms /    29 tokens (  212.30 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2901.58 ms /     3 runs   (  967.19 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    9061.87 ms /    32 tokens\n",
      " 43%|████▎     | 1503/3487 [4:46:40<6:37:23, 12.02s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5234.56 ms /    24 tokens (  218.11 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2851.72 ms /     3 runs   (  950.57 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    8088.84 ms /    27 tokens\n",
      " 43%|████▎     | 1504/3487 [4:46:48<5:58:19, 10.84s/it]Llama.generate: 308 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6188.50 ms /    29 tokens (  213.40 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2738.69 ms /     3 runs   (  912.90 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8929.56 ms /    32 tokens\n",
      " 43%|████▎     | 1505/3487 [4:46:57<5:39:18, 10.27s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7846.66 ms /    39 tokens (  201.20 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.80 ms /     3 runs   (  882.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10501.70 ms /    42 tokens\n",
      " 43%|████▎     | 1506/3487 [4:47:08<5:41:40, 10.35s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2546.82 ms /    11 tokens (  231.53 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.20 ms /     3 runs   (  894.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5232.15 ms /    14 tokens\n",
      " 43%|████▎     | 1507/3487 [4:47:13<4:50:56,  8.82s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4204.46 ms /    21 tokens (  200.21 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.31 ms /     3 runs   (  891.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6880.79 ms /    24 tokens\n",
      " 43%|████▎     | 1508/3487 [4:47:20<4:31:42,  8.24s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9757.23 ms /    51 tokens (  191.32 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.23 ms /     3 runs   (  886.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12419.57 ms /    54 tokens\n",
      " 43%|████▎     | 1509/3487 [4:47:32<5:13:00,  9.49s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9521.40 ms /    47 tokens (  202.58 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.01 ms /     3 runs   (  881.00 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12167.09 ms /    50 tokens\n",
      " 43%|████▎     | 1510/3487 [4:47:45<5:39:21, 10.30s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2190.19 ms /     9 tokens (  243.35 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.45 ms /     3 runs   (  889.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4860.03 ms /    12 tokens\n",
      " 43%|████▎     | 1511/3487 [4:47:49<4:45:31,  8.67s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8868.40 ms /    46 tokens (  192.79 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.16 ms /     3 runs   (  894.72 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11555.53 ms /    49 tokens\n",
      " 43%|████▎     | 1512/3487 [4:48:01<5:13:57,  9.54s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8306.72 ms /    41 tokens (  202.60 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3453.51 ms /     3 runs   ( 1151.17 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =   11762.85 ms /    44 tokens\n",
      " 43%|████▎     | 1513/3487 [4:48:13<5:35:51, 10.21s/it]Llama.generate: 307 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18061.24 ms /    73 tokens (  247.41 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2751.51 ms /     3 runs   (  917.17 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   20815.46 ms /    76 tokens\n",
      " 43%|████▎     | 1514/3487 [4:48:34<7:20:25, 13.39s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9438.59 ms /    48 tokens (  196.64 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.03 ms /     3 runs   (  896.01 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12129.80 ms /    51 tokens\n",
      " 43%|████▎     | 1515/3487 [4:48:46<7:07:48, 13.02s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7456.23 ms /    36 tokens (  207.12 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.74 ms /     3 runs   (  885.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10116.77 ms /    39 tokens\n",
      " 43%|████▎     | 1516/3487 [4:48:56<6:39:04, 12.15s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3284.73 ms /    15 tokens (  218.98 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.67 ms /     3 runs   (  895.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5972.68 ms /    18 tokens\n",
      " 44%|████▎     | 1517/3487 [4:49:02<5:38:08, 10.30s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7479.22 ms /    36 tokens (  207.76 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.72 ms /     3 runs   (  884.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10134.40 ms /    39 tokens\n",
      " 44%|████▎     | 1518/3487 [4:49:12<5:36:26, 10.25s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7294.24 ms /    37 tokens (  197.14 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4395.36 ms /     3 runs   ( 1465.12 ms per token,     0.68 tokens per second)\n",
      "llama_perf_context_print:       total time =   11692.48 ms /    40 tokens\n",
      " 44%|████▎     | 1519/3487 [4:49:24<5:50:32, 10.69s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9230.19 ms /    38 tokens (  242.90 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2940.26 ms /     3 runs   (  980.09 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =   12174.50 ms /    41 tokens\n",
      " 44%|████▎     | 1520/3487 [4:49:36<6:05:06, 11.14s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6147.87 ms /    28 tokens (  219.57 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2785.77 ms /     3 runs   (  928.59 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8936.16 ms /    31 tokens\n",
      " 44%|████▎     | 1521/3487 [4:49:45<5:43:22, 10.48s/it]Llama.generate: 307 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13515.13 ms /    68 tokens (  198.75 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.55 ms /     3 runs   (  886.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16178.18 ms /    71 tokens\n",
      " 44%|████▎     | 1522/3487 [4:50:01<6:39:16, 12.19s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9366.64 ms /    45 tokens (  208.15 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2760.32 ms /     3 runs   (  920.11 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   12129.11 ms /    48 tokens\n",
      " 44%|████▎     | 1523/3487 [4:50:13<6:38:32, 12.18s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7179.39 ms /    33 tokens (  217.56 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.92 ms /     3 runs   (  899.31 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9879.88 ms /    36 tokens\n",
      " 44%|████▎     | 1524/3487 [4:50:23<6:15:53, 11.49s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2507.92 ms /     8 tokens (  313.49 ms per token,     3.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.95 ms /     3 runs   (  891.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5186.68 ms /    11 tokens\n",
      " 44%|████▎     | 1525/3487 [4:50:28<5:13:56,  9.60s/it]Llama.generate: 307 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13270.64 ms /    68 tokens (  195.16 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.80 ms /     3 runs   (  886.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15933.29 ms /    71 tokens\n",
      " 44%|████▍     | 1526/3487 [4:50:44<6:15:57, 11.50s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9619.42 ms /    50 tokens (  192.39 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.78 ms /     3 runs   (  886.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12281.54 ms /    53 tokens\n",
      " 44%|████▍     | 1527/3487 [4:50:56<6:23:29, 11.74s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8931.84 ms /    45 tokens (  198.49 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.31 ms /     3 runs   (  885.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11589.34 ms /    48 tokens\n",
      " 44%|████▍     | 1528/3487 [4:51:08<6:21:53, 11.70s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5220.72 ms /    27 tokens (  193.36 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.70 ms /     3 runs   (  895.23 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7908.78 ms /    30 tokens\n",
      " 44%|████▍     | 1529/3487 [4:51:16<5:44:41, 10.56s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7279.37 ms /    35 tokens (  207.98 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.16 ms /     3 runs   (  895.39 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9968.72 ms /    38 tokens\n",
      " 44%|████▍     | 1530/3487 [4:51:26<5:38:48, 10.39s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13044.25 ms /    65 tokens (  200.68 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2787.99 ms /     3 runs   (  929.33 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   15835.18 ms /    68 tokens\n",
      " 44%|████▍     | 1531/3487 [4:51:42<6:31:59, 12.02s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4635.12 ms /    21 tokens (  220.72 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.09 ms /     3 runs   (  899.36 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7335.82 ms /    24 tokens\n",
      " 44%|████▍     | 1532/3487 [4:51:49<5:46:02, 10.62s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8998.02 ms /    46 tokens (  195.61 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2880.51 ms /     3 runs   (  960.17 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   11881.84 ms /    49 tokens\n",
      " 44%|████▍     | 1533/3487 [4:52:01<5:58:16, 11.00s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3979.90 ms /    19 tokens (  209.47 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2758.99 ms /     3 runs   (  919.66 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6741.57 ms /    22 tokens\n",
      " 44%|████▍     | 1534/3487 [4:52:08<5:16:35,  9.73s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11338.99 ms /    60 tokens (  188.98 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.33 ms /     3 runs   (  881.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13986.16 ms /    63 tokens\n",
      " 44%|████▍     | 1535/3487 [4:52:22<5:58:04, 11.01s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7123.18 ms /    34 tokens (  209.51 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.39 ms /     3 runs   (  890.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9797.14 ms /    37 tokens\n",
      " 44%|████▍     | 1536/3487 [4:52:32<5:46:10, 10.65s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3716.97 ms /    18 tokens (  206.50 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.95 ms /     3 runs   (  887.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6383.38 ms /    21 tokens\n",
      " 44%|████▍     | 1537/3487 [4:52:38<5:04:32,  9.37s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7449.58 ms /    38 tokens (  196.04 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.95 ms /     3 runs   (  881.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10097.03 ms /    41 tokens\n",
      " 44%|████▍     | 1538/3487 [4:52:48<5:11:31,  9.59s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5787.93 ms /    30 tokens (  192.93 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.26 ms /     3 runs   (  887.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8453.48 ms /    33 tokens\n",
      " 44%|████▍     | 1539/3487 [4:52:57<5:00:21,  9.25s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4487.35 ms /    19 tokens (  236.18 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.97 ms /     3 runs   (  902.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7198.67 ms /    22 tokens\n",
      " 44%|████▍     | 1540/3487 [4:53:04<4:40:17,  8.64s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3483.00 ms /    16 tokens (  217.69 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2741.72 ms /     3 runs   (  913.91 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6226.84 ms /    19 tokens\n",
      " 44%|████▍     | 1541/3487 [4:53:10<4:16:45,  7.92s/it]Llama.generate: 308 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7546.71 ms /    38 tokens (  198.60 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.00 ms /     3 runs   (  883.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10199.72 ms /    41 tokens\n",
      " 44%|████▍     | 1542/3487 [4:53:20<4:38:54,  8.60s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9012.97 ms /    47 tokens (  191.77 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.88 ms /     3 runs   (  894.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11699.88 ms /    50 tokens\n",
      " 44%|████▍     | 1543/3487 [4:53:32<5:08:56,  9.54s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3471.91 ms /    16 tokens (  216.99 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.74 ms /     3 runs   (  895.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6161.37 ms /    19 tokens\n",
      " 44%|████▍     | 1544/3487 [4:53:38<4:36:04,  8.53s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5558.03 ms /    28 tokens (  198.50 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.62 ms /     3 runs   (  903.88 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8272.15 ms /    31 tokens\n",
      " 44%|████▍     | 1545/3487 [4:53:46<4:33:32,  8.45s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4877.00 ms /    24 tokens (  203.21 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.95 ms /     3 runs   (  906.98 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7600.18 ms /    27 tokens\n",
      " 44%|████▍     | 1546/3487 [4:53:54<4:25:13,  8.20s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7074.98 ms /    34 tokens (  208.09 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.46 ms /     3 runs   (  889.82 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9747.00 ms /    37 tokens\n",
      " 44%|████▍     | 1547/3487 [4:54:04<4:40:12,  8.67s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3274.64 ms /    15 tokens (  218.31 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.28 ms /     3 runs   (  880.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5918.82 ms /    18 tokens\n",
      " 44%|████▍     | 1548/3487 [4:54:10<4:13:30,  7.84s/it]Llama.generate: 314 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4244.21 ms /    21 tokens (  202.11 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.98 ms /     3 runs   (  887.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6910.79 ms /    24 tokens\n",
      " 44%|████▍     | 1549/3487 [4:54:17<4:04:24,  7.57s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12926.32 ms /    67 tokens (  192.93 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.53 ms /     3 runs   (  889.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15598.51 ms /    70 tokens\n",
      " 44%|████▍     | 1550/3487 [4:54:32<5:22:08,  9.98s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5956.48 ms /    30 tokens (  198.55 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.99 ms /     3 runs   (  902.00 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8664.84 ms /    33 tokens\n",
      " 44%|████▍     | 1551/3487 [4:54:41<5:09:19,  9.59s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8236.36 ms /    42 tokens (  196.10 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.44 ms /     3 runs   (  882.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10886.89 ms /    45 tokens\n",
      " 45%|████▍     | 1552/3487 [4:54:52<5:21:50,  9.98s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5338.38 ms /    27 tokens (  197.72 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.68 ms /     3 runs   (  888.23 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8005.69 ms /    30 tokens\n",
      " 45%|████▍     | 1553/3487 [4:55:00<5:02:39,  9.39s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7431.31 ms /    35 tokens (  212.32 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.41 ms /     3 runs   (  893.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10112.80 ms /    38 tokens\n",
      " 45%|████▍     | 1554/3487 [4:55:10<5:09:33,  9.61s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3530.58 ms /    16 tokens (  220.66 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.20 ms /     3 runs   (  894.07 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6215.25 ms /    19 tokens\n",
      " 45%|████▍     | 1555/3487 [4:55:16<4:36:41,  8.59s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4172.38 ms /    20 tokens (  208.62 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.18 ms /     3 runs   (  884.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6829.45 ms /    23 tokens\n",
      " 45%|████▍     | 1556/3487 [4:55:23<4:19:37,  8.07s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7510.12 ms /    38 tokens (  197.63 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.24 ms /     3 runs   (  889.75 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10181.56 ms /    41 tokens\n",
      " 45%|████▍     | 1557/3487 [4:55:33<4:40:17,  8.71s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2513.49 ms /    10 tokens (  251.35 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.60 ms /     3 runs   (  891.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5190.60 ms /    13 tokens\n",
      " 45%|████▍     | 1558/3487 [4:55:38<4:06:14,  7.66s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4737.40 ms /    23 tokens (  205.97 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.84 ms /     3 runs   (  898.28 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7434.98 ms /    26 tokens\n",
      " 45%|████▍     | 1559/3487 [4:55:46<4:04:01,  7.59s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5881.81 ms /    30 tokens (  196.06 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.89 ms /     3 runs   (  897.63 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8576.89 ms /    33 tokens\n",
      " 45%|████▍     | 1560/3487 [4:55:54<4:13:26,  7.89s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7368.88 ms /    36 tokens (  204.69 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.85 ms /     3 runs   (  888.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10036.98 ms /    39 tokens\n",
      " 45%|████▍     | 1561/3487 [4:56:04<4:34:03,  8.54s/it]Llama.generate: 307 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17571.21 ms /    93 tokens (  188.94 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.29 ms /     3 runs   (  899.76 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   20273.14 ms /    96 tokens\n",
      " 45%|████▍     | 1562/3487 [4:56:25<6:26:56, 12.06s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7166.57 ms /    34 tokens (  210.78 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.46 ms /     3 runs   (  884.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9823.97 ms /    37 tokens\n",
      " 45%|████▍     | 1563/3487 [4:56:35<6:05:18, 11.39s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8966.21 ms /    47 tokens (  190.77 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.79 ms /     3 runs   (  880.60 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11610.63 ms /    50 tokens\n",
      " 45%|████▍     | 1564/3487 [4:56:46<6:07:18, 11.46s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5599.78 ms /    28 tokens (  199.99 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.86 ms /     3 runs   (  889.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8270.71 ms /    31 tokens\n",
      " 45%|████▍     | 1565/3487 [4:56:54<5:36:32, 10.51s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3172.69 ms /    15 tokens (  211.51 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.00 ms /     3 runs   (  902.33 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5881.64 ms /    18 tokens\n",
      " 45%|████▍     | 1566/3487 [4:57:00<4:52:01,  9.12s/it]Llama.generate: 310 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2769.78 ms /    10 tokens (  276.98 ms per token,     3.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.79 ms /     3 runs   (  887.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5435.38 ms /    13 tokens\n",
      " 45%|████▍     | 1567/3487 [4:57:06<4:16:33,  8.02s/it]Llama.generate: 310 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2558.55 ms /    11 tokens (  232.60 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2918.35 ms /     3 runs   (  972.78 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    5479.83 ms /    14 tokens\n",
      " 45%|████▍     | 1568/3487 [4:57:11<3:52:08,  7.26s/it]Llama.generate: 309 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2827.64 ms /    13 tokens (  217.51 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.57 ms /     3 runs   (  896.19 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5519.05 ms /    16 tokens\n",
      " 45%|████▍     | 1569/3487 [4:57:17<3:35:25,  6.74s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3096.68 ms /    14 tokens (  221.19 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.49 ms /     3 runs   (  890.16 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5768.75 ms /    17 tokens\n",
      " 45%|████▌     | 1570/3487 [4:57:23<3:26:05,  6.45s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9090.50 ms /    47 tokens (  193.41 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2789.37 ms /     3 runs   (  929.79 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   11882.04 ms /    50 tokens\n",
      " 45%|████▌     | 1571/3487 [4:57:34<4:18:05,  8.08s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4904.69 ms /    22 tokens (  222.94 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2749.58 ms /     3 runs   (  916.53 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7657.09 ms /    25 tokens\n",
      " 45%|████▌     | 1572/3487 [4:57:42<4:13:58,  7.96s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5849.95 ms /    30 tokens (  195.00 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.14 ms /     3 runs   (  887.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8515.48 ms /    33 tokens\n",
      " 45%|████▌     | 1573/3487 [4:57:51<4:19:17,  8.13s/it]Llama.generate: 314 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3731.43 ms /    18 tokens (  207.30 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.80 ms /     3 runs   (  895.27 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6418.80 ms /    21 tokens\n",
      " 45%|████▌     | 1574/3487 [4:57:57<4:02:53,  7.62s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4248.95 ms /    21 tokens (  202.33 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.34 ms /     3 runs   (  887.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6912.59 ms /    24 tokens\n",
      " 45%|████▌     | 1575/3487 [4:58:04<3:56:05,  7.41s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5635.40 ms /    28 tokens (  201.26 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.90 ms /     3 runs   (  891.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8314.06 ms /    31 tokens\n",
      " 45%|████▌     | 1576/3487 [4:58:12<4:04:42,  7.68s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2418.12 ms /    10 tokens (  241.81 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.51 ms /     3 runs   (  887.17 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5081.96 ms /    13 tokens\n",
      " 45%|████▌     | 1577/3487 [4:58:17<3:39:47,  6.90s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3084.79 ms /    14 tokens (  220.34 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.48 ms /     3 runs   (  881.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5732.86 ms /    17 tokens\n",
      " 45%|████▌     | 1578/3487 [4:58:23<3:28:36,  6.56s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4153.10 ms /    20 tokens (  207.65 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.07 ms /     3 runs   (  883.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6805.59 ms /    23 tokens\n",
      " 45%|████▌     | 1579/3487 [4:58:30<3:30:57,  6.63s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3963.93 ms /    19 tokens (  208.63 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.90 ms /     3 runs   (  890.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6639.47 ms /    22 tokens\n",
      " 45%|████▌     | 1580/3487 [4:58:37<3:30:59,  6.64s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2159.05 ms /     9 tokens (  239.89 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.62 ms /     3 runs   (  884.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4814.22 ms /    12 tokens\n",
      " 45%|████▌     | 1581/3487 [4:58:41<3:13:34,  6.09s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5432.85 ms /    25 tokens (  217.31 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.22 ms /     3 runs   (  881.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8079.69 ms /    28 tokens\n",
      " 45%|████▌     | 1582/3487 [4:58:50<3:32:27,  6.69s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9178.42 ms /    45 tokens (  203.96 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2996.46 ms /     3 runs   (  998.82 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =   12177.42 ms /    48 tokens\n",
      " 45%|████▌     | 1583/3487 [4:59:02<4:24:39,  8.34s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10038.73 ms /    51 tokens (  196.84 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.23 ms /     3 runs   (  878.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12678.28 ms /    54 tokens\n",
      " 45%|████▌     | 1584/3487 [4:59:14<5:05:52,  9.64s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12994.90 ms /    66 tokens (  196.89 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.91 ms /     3 runs   (  874.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15622.69 ms /    69 tokens\n",
      " 45%|████▌     | 1585/3487 [4:59:30<6:02:38, 11.44s/it]Llama.generate: 306 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13501.59 ms /    72 tokens (  187.52 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.51 ms /     3 runs   (  878.84 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16141.11 ms /    75 tokens\n",
      " 45%|████▌     | 1586/3487 [4:59:46<6:47:13, 12.85s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7584.67 ms /    39 tokens (  194.48 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.62 ms /     3 runs   (  878.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10222.62 ms /    42 tokens\n",
      " 46%|████▌     | 1587/3487 [4:59:56<6:22:05, 12.07s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2064.23 ms /     8 tokens (  258.03 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.78 ms /     3 runs   (  898.59 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4762.87 ms /    11 tokens\n",
      " 46%|████▌     | 1588/3487 [5:00:01<5:12:37,  9.88s/it]Llama.generate: 307 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14311.78 ms /    76 tokens (  188.31 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.72 ms /     3 runs   (  893.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16994.06 ms /    79 tokens\n",
      " 46%|████▌     | 1589/3487 [5:00:18<6:20:03, 12.01s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9477.32 ms /    49 tokens (  193.41 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.94 ms /     3 runs   (  875.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12105.36 ms /    52 tokens\n",
      " 46%|████▌     | 1590/3487 [5:00:30<6:20:48, 12.04s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4616.39 ms /    23 tokens (  200.71 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.31 ms /     3 runs   (  880.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7261.38 ms /    26 tokens\n",
      " 46%|████▌     | 1591/3487 [5:00:38<5:35:20, 10.61s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9852.99 ms /    52 tokens (  189.48 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.82 ms /     3 runs   (  882.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12503.36 ms /    55 tokens\n",
      " 46%|████▌     | 1592/3487 [5:00:50<5:53:09, 11.18s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7352.81 ms /    37 tokens (  198.72 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.80 ms /     3 runs   (  886.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10014.09 ms /    40 tokens\n",
      " 46%|████▌     | 1593/3487 [5:01:00<5:41:58, 10.83s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6085.17 ms /    31 tokens (  196.30 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.44 ms /     3 runs   (  892.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8766.22 ms /    34 tokens\n",
      " 46%|████▌     | 1594/3487 [5:01:09<5:22:18, 10.22s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4456.02 ms /    20 tokens (  222.80 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.23 ms /     3 runs   (  877.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7089.39 ms /    23 tokens\n",
      " 46%|████▌     | 1595/3487 [5:01:16<4:52:37,  9.28s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5628.48 ms /    29 tokens (  194.09 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.36 ms /     3 runs   (  883.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8282.76 ms /    32 tokens\n",
      " 46%|████▌     | 1596/3487 [5:01:24<4:43:07,  8.98s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5595.00 ms /    27 tokens (  207.22 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.58 ms /     3 runs   (  883.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8249.31 ms /    30 tokens\n",
      " 46%|████▌     | 1597/3487 [5:01:33<4:36:07,  8.77s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3307.59 ms /    16 tokens (  206.72 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.85 ms /     3 runs   (  886.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5970.07 ms /    19 tokens\n",
      " 46%|████▌     | 1598/3487 [5:01:38<4:09:39,  7.93s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2529.99 ms /    11 tokens (  230.00 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.27 ms /     3 runs   (  888.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5198.78 ms /    14 tokens\n",
      " 46%|████▌     | 1599/3487 [5:01:44<3:43:49,  7.11s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7878.15 ms /    40 tokens (  196.95 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.39 ms /     3 runs   (  881.80 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10525.69 ms /    43 tokens\n",
      " 46%|████▌     | 1600/3487 [5:01:54<4:15:59,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4103.87 ms /    20 tokens (  205.19 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.33 ms /     3 runs   (  897.44 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6799.19 ms /    23 tokens\n",
      " 46%|████▌     | 1601/3487 [5:02:01<4:03:16,  7.74s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2635.82 ms /    11 tokens (  239.62 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.02 ms /     3 runs   (  898.01 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5332.63 ms /    14 tokens\n",
      " 46%|████▌     | 1602/3487 [5:02:06<3:40:32,  7.02s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1666.95 ms /     6 tokens (  277.82 ms per token,     3.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.73 ms /     3 runs   (  881.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4314.94 ms /     9 tokens\n",
      " 46%|████▌     | 1603/3487 [5:02:11<3:15:01,  6.21s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2681.94 ms /    12 tokens (  223.49 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.66 ms /     3 runs   (  891.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5359.18 ms /    15 tokens\n",
      " 46%|████▌     | 1604/3487 [5:02:16<3:06:58,  5.96s/it]Llama.generate: 306 prefix-match hit, remaining 119 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   22273.48 ms /   119 tokens (  187.17 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.32 ms /     3 runs   (  878.11 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   24910.89 ms /   122 tokens\n",
      " 46%|████▌     | 1605/3487 [5:02:41<6:05:18, 11.65s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7618.88 ms /    38 tokens (  200.50 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.57 ms /     3 runs   (  882.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10269.82 ms /    41 tokens\n",
      " 46%|████▌     | 1606/3487 [5:02:51<5:52:15, 11.24s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4126.36 ms /    20 tokens (  206.32 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.39 ms /     3 runs   (  895.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6816.50 ms /    23 tokens\n",
      " 46%|████▌     | 1607/3487 [5:02:58<5:10:35,  9.91s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5833.61 ms /    29 tokens (  201.16 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.99 ms /     3 runs   (  881.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8480.33 ms /    32 tokens\n",
      " 46%|████▌     | 1608/3487 [5:03:07<4:57:02,  9.49s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2145.02 ms /     6 tokens (  357.50 ms per token,     2.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.31 ms /     3 runs   (  890.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4819.62 ms /     9 tokens\n",
      " 46%|████▌     | 1609/3487 [5:03:11<4:13:08,  8.09s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2066.13 ms /     8 tokens (  258.27 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.67 ms /     3 runs   (  885.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4725.05 ms /    11 tokens\n",
      " 46%|████▌     | 1610/3487 [5:03:16<3:41:31,  7.08s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2640.57 ms /    12 tokens (  220.05 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.84 ms /     3 runs   (  888.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5308.95 ms /    15 tokens\n",
      " 46%|████▌     | 1611/3487 [5:03:21<3:24:51,  6.55s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7141.02 ms /    34 tokens (  210.03 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.57 ms /     3 runs   (  881.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9788.08 ms /    37 tokens\n",
      " 46%|████▌     | 1612/3487 [5:03:31<3:55:27,  7.53s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4174.52 ms /    21 tokens (  198.79 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.33 ms /     3 runs   (  882.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6825.12 ms /    24 tokens\n",
      " 46%|████▋     | 1613/3487 [5:03:38<3:48:46,  7.32s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2161.14 ms /     9 tokens (  240.13 ms per token,     4.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.50 ms /     3 runs   (  897.83 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4856.62 ms /    12 tokens\n",
      " 46%|████▋     | 1614/3487 [5:03:43<3:25:36,  6.59s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4312.59 ms /    21 tokens (  205.36 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.04 ms /     3 runs   (  893.68 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6995.74 ms /    24 tokens\n",
      " 46%|████▋     | 1615/3487 [5:03:50<3:29:41,  6.72s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1683.42 ms /     6 tokens (  280.57 ms per token,     3.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2742.65 ms /     3 runs   (  914.22 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4428.35 ms /     9 tokens\n",
      " 46%|████▋     | 1616/3487 [5:03:54<3:08:13,  6.04s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8115.60 ms /    41 tokens (  197.94 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.93 ms /     3 runs   (  876.98 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10749.39 ms /    44 tokens\n",
      " 46%|████▋     | 1617/3487 [5:04:05<3:52:16,  7.45s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3480.30 ms /    16 tokens (  217.52 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.36 ms /     3 runs   (  881.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6128.37 ms /    19 tokens\n",
      " 46%|████▋     | 1618/3487 [5:04:11<3:39:50,  7.06s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3071.10 ms /    14 tokens (  219.36 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.57 ms /     3 runs   (  882.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5722.78 ms /    17 tokens\n",
      " 46%|████▋     | 1619/3487 [5:04:17<3:27:20,  6.66s/it]Llama.generate: 307 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12196.64 ms /    64 tokens (  190.57 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2899.85 ms /     3 runs   (  966.62 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   15099.19 ms /    67 tokens\n",
      " 46%|████▋     | 1620/3487 [5:04:32<4:46:05,  9.19s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4516.32 ms /    21 tokens (  215.06 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.10 ms /     3 runs   (  908.37 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7243.93 ms /    24 tokens\n",
      " 46%|████▋     | 1621/3487 [5:04:39<4:27:49,  8.61s/it]Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8979.15 ms /    44 tokens (  204.07 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.82 ms /     3 runs   (  895.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11669.23 ms /    47 tokens\n",
      " 47%|████▋     | 1622/3487 [5:04:51<4:56:16,  9.53s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3953.31 ms /    16 tokens (  247.08 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.44 ms /     3 runs   (  905.81 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6673.31 ms /    19 tokens\n",
      " 47%|████▋     | 1623/3487 [5:04:58<4:29:32,  8.68s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3511.25 ms /    16 tokens (  219.45 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.28 ms /     3 runs   (  896.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6202.04 ms /    19 tokens\n",
      " 47%|████▋     | 1624/3487 [5:05:04<4:06:26,  7.94s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8904.85 ms /    47 tokens (  189.46 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.34 ms /     3 runs   (  874.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11531.97 ms /    50 tokens\n",
      " 47%|████▋     | 1625/3487 [5:05:16<4:39:51,  9.02s/it]Llama.generate: 314 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2916.17 ms /    13 tokens (  224.32 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.38 ms /     3 runs   (  878.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5552.94 ms /    16 tokens\n",
      " 47%|████▋     | 1626/3487 [5:05:21<4:07:32,  7.98s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3159.89 ms /    15 tokens (  210.66 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.06 ms /     3 runs   (  883.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5811.14 ms /    18 tokens\n",
      " 47%|████▋     | 1627/3487 [5:05:27<3:47:18,  7.33s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2726.94 ms /    12 tokens (  227.24 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.06 ms /     3 runs   (  883.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5379.82 ms /    15 tokens\n",
      " 47%|████▋     | 1628/3487 [5:05:32<3:29:05,  6.75s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3251.86 ms /    15 tokens (  216.79 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.93 ms /     3 runs   (  892.31 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5931.54 ms /    18 tokens\n",
      " 47%|████▋     | 1629/3487 [5:05:38<3:21:28,  6.51s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3493.87 ms /    16 tokens (  218.37 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.97 ms /     3 runs   (  903.32 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6206.57 ms /    19 tokens\n",
      " 47%|████▋     | 1630/3487 [5:05:44<3:18:40,  6.42s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8942.13 ms /    46 tokens (  194.39 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.97 ms /     3 runs   (  902.66 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11652.90 ms /    49 tokens\n",
      " 47%|████▋     | 1631/3487 [5:05:56<4:07:14,  7.99s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2807.35 ms /    12 tokens (  233.95 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2741.24 ms /     3 runs   (  913.75 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5551.15 ms /    15 tokens\n",
      " 47%|████▋     | 1632/3487 [5:06:02<3:44:31,  7.26s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3322.17 ms /    15 tokens (  221.48 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.60 ms /     3 runs   (  892.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6001.41 ms /    18 tokens\n",
      " 47%|████▋     | 1633/3487 [5:06:08<3:32:47,  6.89s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4849.34 ms /    23 tokens (  210.84 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2740.28 ms /     3 runs   (  913.43 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7592.00 ms /    26 tokens\n",
      " 47%|████▋     | 1634/3487 [5:06:15<3:39:17,  7.10s/it]Llama.generate: 314 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1468.85 ms /     4 tokens (  367.21 ms per token,     2.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.54 ms /     3 runs   (  889.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4139.54 ms /     7 tokens\n",
      " 47%|████▋     | 1635/3487 [5:06:19<3:11:50,  6.21s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8366.05 ms /    43 tokens (  194.56 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.76 ms /     3 runs   (  885.92 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11025.99 ms /    46 tokens\n",
      " 47%|████▋     | 1636/3487 [5:06:30<3:56:19,  7.66s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2468.98 ms /     8 tokens (  308.62 ms per token,     3.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.28 ms /     3 runs   (  882.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5118.85 ms /    11 tokens\n",
      " 47%|████▋     | 1637/3487 [5:06:36<3:32:45,  6.90s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3160.23 ms /    13 tokens (  243.09 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.56 ms /     3 runs   (  900.19 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5862.60 ms /    16 tokens\n",
      " 47%|████▋     | 1638/3487 [5:06:41<3:23:07,  6.59s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4244.89 ms /    21 tokens (  202.14 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.94 ms /     3 runs   (  880.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6889.93 ms /    24 tokens\n",
      " 47%|████▋     | 1639/3487 [5:06:48<3:25:50,  6.68s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3645.19 ms /    16 tokens (  227.82 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.60 ms /     3 runs   (  894.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6331.30 ms /    19 tokens\n",
      " 47%|████▋     | 1640/3487 [5:06:55<3:22:33,  6.58s/it]Llama.generate: 306 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9986.33 ms /    53 tokens (  188.42 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.11 ms /     3 runs   (  882.37 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12636.31 ms /    56 tokens\n",
      " 47%|████▋     | 1641/3487 [5:07:07<4:18:24,  8.40s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4035.13 ms /    19 tokens (  212.38 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.75 ms /     3 runs   (  907.92 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6761.06 ms /    22 tokens\n",
      " 47%|████▋     | 1642/3487 [5:07:14<4:03:12,  7.91s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7314.92 ms /    37 tokens (  197.70 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.60 ms /     3 runs   (  883.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9966.79 ms /    40 tokens\n",
      " 47%|████▋     | 1643/3487 [5:07:24<4:22:07,  8.53s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7538.88 ms /    34 tokens (  221.73 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2862.56 ms /     3 runs   (  954.19 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   10404.51 ms /    37 tokens\n",
      " 47%|████▋     | 1644/3487 [5:07:35<4:39:20,  9.09s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7243.30 ms /    36 tokens (  201.20 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.73 ms /     3 runs   (  879.58 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9884.45 ms /    39 tokens\n",
      " 47%|████▋     | 1645/3487 [5:07:44<4:46:32,  9.33s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3447.18 ms /    16 tokens (  215.45 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.02 ms /     3 runs   (  891.01 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6122.14 ms /    19 tokens\n",
      " 47%|████▋     | 1646/3487 [5:07:51<4:16:53,  8.37s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4971.57 ms /    25 tokens (  198.86 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.38 ms /     3 runs   (  884.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7626.51 ms /    28 tokens\n",
      " 47%|████▋     | 1647/3487 [5:07:58<4:09:58,  8.15s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7223.55 ms /    34 tokens (  212.46 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.75 ms /     3 runs   (  883.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9877.04 ms /    37 tokens\n",
      " 47%|████▋     | 1648/3487 [5:08:08<4:25:47,  8.67s/it]Llama.generate: 307 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11877.84 ms /    64 tokens (  185.59 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.99 ms /     3 runs   (  879.00 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14517.13 ms /    67 tokens\n",
      " 47%|████▋     | 1649/3487 [5:08:23<5:19:25, 10.43s/it]Llama.generate: 307 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10631.01 ms /    55 tokens (  193.29 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.89 ms /     3 runs   (  876.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13264.64 ms /    58 tokens\n",
      " 47%|████▋     | 1650/3487 [5:08:36<5:45:23, 11.28s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10896.12 ms /    59 tokens (  184.68 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.30 ms /     3 runs   (  879.10 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13536.10 ms /    62 tokens\n",
      " 47%|████▋     | 1651/3487 [5:08:49<6:05:59, 11.96s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9468.52 ms /    50 tokens (  189.37 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2771.52 ms /     3 runs   (  923.84 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   12242.81 ms /    53 tokens\n",
      " 47%|████▋     | 1652/3487 [5:09:02<6:08:26, 12.05s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4906.11 ms /    24 tokens (  204.42 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.01 ms /     3 runs   (  880.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7550.31 ms /    27 tokens\n",
      " 47%|████▋     | 1653/3487 [5:09:09<5:27:05, 10.70s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2071.13 ms /     8 tokens (  258.89 ms per token,     3.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.27 ms /     3 runs   (  888.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4738.64 ms /    11 tokens\n",
      " 47%|████▋     | 1654/3487 [5:09:14<4:32:20,  8.91s/it]Llama.generate: 308 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3035.64 ms /    13 tokens (  233.51 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.88 ms /     3 runs   (  880.63 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5680.11 ms /    16 tokens\n",
      " 47%|████▋     | 1655/3487 [5:09:20<4:02:38,  7.95s/it]Llama.generate: 307 prefix-match hit, remaining 175 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   32071.91 ms /   175 tokens (  183.27 ms per token,     5.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2764.95 ms /     3 runs   (  921.65 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   34840.00 ms /   178 tokens\n",
      " 47%|████▋     | 1656/3487 [5:09:55<8:08:47, 16.02s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8395.73 ms /    42 tokens (  199.90 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.87 ms /     3 runs   (  877.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11030.87 ms /    45 tokens\n",
      " 48%|████▊     | 1657/3487 [5:10:06<7:22:58, 14.52s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2778.07 ms /    12 tokens (  231.51 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2749.78 ms /     3 runs   (  916.59 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5530.51 ms /    15 tokens\n",
      " 48%|████▊     | 1658/3487 [5:10:11<6:00:34, 11.83s/it]Llama.generate: 314 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3044.48 ms /    13 tokens (  234.19 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.16 ms /     3 runs   (  884.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5700.84 ms /    16 tokens\n",
      " 48%|████▊     | 1659/3487 [5:10:17<5:04:26,  9.99s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4274.59 ms /    21 tokens (  203.55 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.37 ms /     3 runs   (  881.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6920.41 ms /    24 tokens\n",
      " 48%|████▊     | 1660/3487 [5:10:24<4:36:16,  9.07s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2757.08 ms /    12 tokens (  229.76 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.16 ms /     3 runs   (  902.39 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5467.12 ms /    15 tokens\n",
      " 48%|████▊     | 1661/3487 [5:10:29<4:03:17,  7.99s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10324.08 ms /    51 tokens (  202.43 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.23 ms /     3 runs   (  891.08 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12999.27 ms /    54 tokens\n",
      " 48%|████▊     | 1662/3487 [5:10:42<4:48:55,  9.50s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2904.22 ms /    13 tokens (  223.40 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.73 ms /     3 runs   (  884.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5560.98 ms /    16 tokens\n",
      " 48%|████▊     | 1663/3487 [5:10:48<4:12:55,  8.32s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2721.72 ms /    12 tokens (  226.81 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.98 ms /     3 runs   (  888.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5389.33 ms /    15 tokens\n",
      " 48%|████▊     | 1664/3487 [5:10:53<3:46:07,  7.44s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2224.74 ms /     9 tokens (  247.19 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.49 ms /     3 runs   (  888.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4893.61 ms /    12 tokens\n",
      " 48%|████▊     | 1665/3487 [5:10:58<3:22:51,  6.68s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3252.71 ms /    15 tokens (  216.85 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.12 ms /     3 runs   (  889.04 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5922.28 ms /    18 tokens\n",
      " 48%|████▊     | 1666/3487 [5:11:04<3:15:56,  6.46s/it]Llama.generate: 308 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4794.29 ms /    24 tokens (  199.76 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.51 ms /     3 runs   (  887.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7460.17 ms /    27 tokens\n",
      " 48%|████▊     | 1667/3487 [5:11:11<3:25:02,  6.76s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1757.51 ms /     6 tokens (  292.92 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2746.66 ms /     3 runs   (  915.55 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4506.41 ms /     9 tokens\n",
      " 48%|████▊     | 1668/3487 [5:11:16<3:04:29,  6.09s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2783.22 ms /    12 tokens (  231.94 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.70 ms /     3 runs   (  892.23 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5462.25 ms /    15 tokens\n",
      " 48%|████▊     | 1669/3487 [5:11:21<2:58:48,  5.90s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2788.57 ms /    11 tokens (  253.51 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2815.66 ms /     3 runs   (  938.55 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5607.15 ms /    14 tokens\n",
      " 48%|████▊     | 1670/3487 [5:11:27<2:56:07,  5.82s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2761.01 ms /    12 tokens (  230.08 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2797.30 ms /     3 runs   (  932.43 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5560.26 ms /    15 tokens\n",
      " 48%|████▊     | 1671/3487 [5:11:33<2:53:46,  5.74s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2344.78 ms /     8 tokens (  293.10 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2995.74 ms /     3 runs   (  998.58 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    5344.21 ms /    11 tokens\n",
      " 48%|████▊     | 1672/3487 [5:11:38<2:50:09,  5.62s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3224.55 ms /    13 tokens (  248.04 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2714.86 ms /     3 runs   (  904.95 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5942.84 ms /    16 tokens\n",
      " 48%|████▊     | 1673/3487 [5:11:44<2:53:02,  5.72s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2970.68 ms /    12 tokens (  247.56 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.66 ms /     3 runs   (  894.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5655.90 ms /    15 tokens\n",
      " 48%|████▊     | 1674/3487 [5:11:50<2:52:24,  5.71s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3740.64 ms /    15 tokens (  249.38 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.25 ms /     3 runs   (  899.75 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6442.24 ms /    18 tokens\n",
      " 48%|████▊     | 1675/3487 [5:11:56<2:59:03,  5.93s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2718.48 ms /    12 tokens (  226.54 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.53 ms /     3 runs   (  891.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5395.65 ms /    15 tokens\n",
      " 48%|████▊     | 1676/3487 [5:12:01<2:54:13,  5.77s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6132.07 ms /    31 tokens (  197.81 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.22 ms /     3 runs   (  883.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8784.86 ms /    34 tokens\n",
      " 48%|████▊     | 1677/3487 [5:12:10<3:21:27,  6.68s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9324.83 ms /    49 tokens (  190.30 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.99 ms /     3 runs   (  882.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11975.63 ms /    52 tokens\n",
      " 48%|████▊     | 1678/3487 [5:12:22<4:09:19,  8.27s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3956.39 ms /    19 tokens (  208.23 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.54 ms /     3 runs   (  889.18 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6626.47 ms /    22 tokens\n",
      " 48%|████▊     | 1679/3487 [5:12:29<3:54:24,  7.78s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3724.73 ms /    18 tokens (  206.93 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.96 ms /     3 runs   (  896.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6417.84 ms /    21 tokens\n",
      " 48%|████▊     | 1680/3487 [5:12:35<3:42:03,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3482.06 ms /    16 tokens (  217.63 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2852.15 ms /     3 runs   (  950.72 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    6336.67 ms /    19 tokens\n",
      " 48%|████▊     | 1681/3487 [5:12:42<3:32:38,  7.06s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3191.57 ms /    14 tokens (  227.97 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.37 ms /     3 runs   (  908.12 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5918.41 ms /    17 tokens\n",
      " 48%|████▊     | 1682/3487 [5:12:48<3:22:16,  6.72s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3127.05 ms /    14 tokens (  223.36 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.31 ms /     3 runs   (  887.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5790.80 ms /    17 tokens\n",
      " 48%|████▊     | 1683/3487 [5:12:53<3:13:48,  6.45s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3510.51 ms /    16 tokens (  219.41 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.53 ms /     3 runs   (  893.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6194.10 ms /    19 tokens\n",
      " 48%|████▊     | 1684/3487 [5:13:00<3:11:30,  6.37s/it]Llama.generate: 310 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2543.24 ms /    10 tokens (  254.32 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2768.11 ms /     3 runs   (  922.70 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5314.25 ms /    13 tokens\n",
      " 48%|████▊     | 1685/3487 [5:13:05<3:01:56,  6.06s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7404.91 ms /    34 tokens (  217.79 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.33 ms /     3 runs   (  883.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10058.24 ms /    37 tokens\n",
      " 48%|████▊     | 1686/3487 [5:13:15<3:37:56,  7.26s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4315.91 ms /    21 tokens (  205.52 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.18 ms /     3 runs   (  890.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6988.55 ms /    24 tokens\n",
      " 48%|████▊     | 1687/3487 [5:13:22<3:35:27,  7.18s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3222.62 ms /    15 tokens (  214.84 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.68 ms /     3 runs   (  894.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5908.73 ms /    18 tokens\n",
      " 48%|████▊     | 1688/3487 [5:13:28<3:23:57,  6.80s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3142.39 ms /    12 tokens (  261.87 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3269.78 ms /     3 runs   ( 1089.93 ms per token,     0.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    6414.71 ms /    15 tokens\n",
      " 48%|████▊     | 1689/3487 [5:13:34<3:20:26,  6.69s/it]Llama.generate: 306 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17433.26 ms /    80 tokens (  217.92 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2973.54 ms /     3 runs   (  991.18 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   20409.26 ms /    83 tokens\n",
      " 48%|████▊     | 1690/3487 [5:13:55<5:23:41, 10.81s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6072.13 ms /    27 tokens (  224.89 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2788.72 ms /     3 runs   (  929.57 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8863.55 ms /    30 tokens\n",
      " 48%|████▊     | 1691/3487 [5:14:04<5:06:09, 10.23s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5809.07 ms /    29 tokens (  200.31 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.53 ms /     3 runs   (  889.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8481.09 ms /    32 tokens\n",
      " 49%|████▊     | 1692/3487 [5:14:12<4:50:22,  9.71s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4302.46 ms /    21 tokens (  204.88 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.94 ms /     3 runs   (  891.31 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6978.91 ms /    24 tokens\n",
      " 49%|████▊     | 1693/3487 [5:14:19<4:25:49,  8.89s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7482.73 ms /    36 tokens (  207.85 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.11 ms /     3 runs   (  896.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10176.21 ms /    39 tokens\n",
      " 49%|████▊     | 1694/3487 [5:14:29<4:37:16,  9.28s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2558.85 ms /    11 tokens (  232.62 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2774.35 ms /     3 runs   (  924.78 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5336.11 ms /    14 tokens\n",
      " 49%|████▊     | 1695/3487 [5:14:35<4:01:54,  8.10s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5760.51 ms /    26 tokens (  221.56 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2757.33 ms /     3 runs   (  919.11 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8521.13 ms /    29 tokens\n",
      " 49%|████▊     | 1696/3487 [5:14:43<4:05:37,  8.23s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3615.30 ms /    17 tokens (  212.66 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.76 ms /     3 runs   (  892.92 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6297.08 ms /    20 tokens\n",
      " 49%|████▊     | 1697/3487 [5:14:49<3:48:17,  7.65s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6305.67 ms /    32 tokens (  197.05 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.12 ms /     3 runs   (  899.04 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9005.46 ms /    35 tokens\n",
      " 49%|████▊     | 1698/3487 [5:14:58<4:00:20,  8.06s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7957.53 ms /    41 tokens (  194.09 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.68 ms /     3 runs   (  886.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10619.88 ms /    44 tokens\n",
      " 49%|████▊     | 1699/3487 [5:15:09<4:23:09,  8.83s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2140.95 ms /     9 tokens (  237.88 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.73 ms /     3 runs   (  887.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4805.10 ms /    12 tokens\n",
      " 49%|████▉     | 1700/3487 [5:15:14<3:47:07,  7.63s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4410.93 ms /    19 tokens (  232.15 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.90 ms /     3 runs   (  897.30 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7105.29 ms /    22 tokens\n",
      " 49%|████▉     | 1701/3487 [5:15:21<3:42:23,  7.47s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2100.08 ms /     8 tokens (  262.51 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.44 ms /     3 runs   (  892.48 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4780.22 ms /    11 tokens\n",
      " 49%|████▉     | 1702/3487 [5:15:26<3:18:19,  6.67s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3506.03 ms /    16 tokens (  219.13 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.25 ms /     3 runs   (  885.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6164.67 ms /    19 tokens\n",
      " 49%|████▉     | 1703/3487 [5:15:32<3:13:49,  6.52s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5351.63 ms /    27 tokens (  198.21 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.74 ms /     3 runs   (  888.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8021.02 ms /    30 tokens\n",
      " 49%|████▉     | 1704/3487 [5:15:40<3:27:11,  6.97s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1933.42 ms /     7 tokens (  276.20 ms per token,     3.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.39 ms /     3 runs   (  886.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4594.74 ms /    10 tokens\n",
      " 49%|████▉     | 1705/3487 [5:15:45<3:05:57,  6.26s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2210.99 ms /     9 tokens (  245.67 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.36 ms /     3 runs   (  892.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4891.30 ms /    12 tokens\n",
      " 49%|████▉     | 1706/3487 [5:15:50<2:53:43,  5.85s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4102.45 ms /    20 tokens (  205.12 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.38 ms /     3 runs   (  890.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6776.94 ms /    23 tokens\n",
      " 49%|████▉     | 1707/3487 [5:15:56<3:01:54,  6.13s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2193.48 ms /     9 tokens (  243.72 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.39 ms /     3 runs   (  889.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4864.92 ms /    12 tokens\n",
      " 49%|████▉     | 1708/3487 [5:16:01<2:50:36,  5.75s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3761.52 ms /    18 tokens (  208.97 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.16 ms /     3 runs   (  889.72 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6433.25 ms /    21 tokens\n",
      " 49%|████▉     | 1709/3487 [5:16:08<2:56:36,  5.96s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2948.31 ms /    13 tokens (  226.79 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.66 ms /     3 runs   (  886.89 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5611.58 ms /    16 tokens\n",
      " 49%|████▉     | 1710/3487 [5:16:13<2:53:29,  5.86s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4741.61 ms /    24 tokens (  197.57 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.52 ms /     3 runs   (  883.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7395.65 ms /    27 tokens\n",
      " 49%|████▉     | 1711/3487 [5:16:21<3:07:08,  6.32s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7444.04 ms /    38 tokens (  195.90 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.30 ms /     3 runs   (  888.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10112.65 ms /    41 tokens\n",
      " 49%|████▉     | 1712/3487 [5:16:31<3:40:44,  7.46s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13147.83 ms /    70 tokens (  187.83 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.97 ms /     3 runs   (  882.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15796.96 ms /    73 tokens\n",
      " 49%|████▉     | 1713/3487 [5:16:47<4:54:37,  9.96s/it]Llama.generate: 307 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16930.51 ms /    86 tokens (  196.87 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2732.48 ms /     3 runs   (  910.83 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   19665.38 ms /    89 tokens\n",
      " 49%|████▉     | 1714/3487 [5:17:06<6:20:30, 12.88s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4920.97 ms /    24 tokens (  205.04 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2733.78 ms /     3 runs   (  911.26 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7657.36 ms /    27 tokens\n",
      " 49%|████▉     | 1715/3487 [5:17:14<5:34:07, 11.31s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3231.13 ms /    15 tokens (  215.41 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.32 ms /     3 runs   (  882.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5879.68 ms /    18 tokens\n",
      " 49%|████▉     | 1716/3487 [5:17:20<4:45:54,  9.69s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2926.02 ms /    13 tokens (  225.08 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.36 ms /     3 runs   (  890.45 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5600.50 ms /    16 tokens\n",
      " 49%|████▉     | 1717/3487 [5:17:25<4:09:39,  8.46s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11863.51 ms /    63 tokens (  188.31 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.95 ms /     3 runs   (  882.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14515.33 ms /    66 tokens\n",
      " 49%|████▉     | 1718/3487 [5:17:40<5:03:07, 10.28s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4577.25 ms /    21 tokens (  217.96 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.37 ms /     3 runs   (  891.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7253.04 ms /    24 tokens\n",
      " 49%|████▉     | 1719/3487 [5:17:47<4:36:14,  9.37s/it]Llama.generate: 315 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3002.39 ms /    13 tokens (  230.95 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.73 ms /     3 runs   (  888.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5670.73 ms /    16 tokens\n",
      " 49%|████▉     | 1720/3487 [5:17:53<4:03:25,  8.27s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5580.71 ms /    28 tokens (  199.31 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.89 ms /     3 runs   (  896.30 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8272.37 ms /    31 tokens\n",
      " 49%|████▉     | 1721/3487 [5:18:01<4:03:24,  8.27s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4151.68 ms /    20 tokens (  207.58 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.76 ms /     3 runs   (  904.59 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6867.97 ms /    23 tokens\n",
      " 49%|████▉     | 1722/3487 [5:18:08<3:50:58,  7.85s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2993.90 ms /    13 tokens (  230.30 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.08 ms /     3 runs   (  889.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5664.45 ms /    16 tokens\n",
      " 49%|████▉     | 1723/3487 [5:18:14<3:31:37,  7.20s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4351.22 ms /    21 tokens (  207.20 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.28 ms /     3 runs   (  891.76 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7029.32 ms /    24 tokens\n",
      " 49%|████▉     | 1724/3487 [5:18:21<3:30:05,  7.15s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12967.18 ms /    67 tokens (  193.54 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.72 ms /     3 runs   (  885.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15626.68 ms /    70 tokens\n",
      " 49%|████▉     | 1725/3487 [5:18:36<4:44:43,  9.70s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9573.69 ms /    50 tokens (  191.47 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.61 ms /     3 runs   (  886.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12237.34 ms /    53 tokens\n",
      " 49%|████▉     | 1726/3487 [5:18:49<5:07:03, 10.46s/it]Llama.generate: 315 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4032.35 ms /    17 tokens (  237.20 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.85 ms /     3 runs   (  889.95 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6705.53 ms /    20 tokens\n",
      " 50%|████▉     | 1727/3487 [5:18:55<4:33:54,  9.34s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2984.55 ms /    13 tokens (  229.58 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.76 ms /     3 runs   (  906.59 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5707.24 ms /    16 tokens\n",
      " 50%|████▉     | 1728/3487 [5:19:01<4:01:54,  8.25s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4186.17 ms /    20 tokens (  209.31 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.74 ms /     3 runs   (  890.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6860.27 ms /    23 tokens\n",
      " 50%|████▉     | 1729/3487 [5:19:08<3:49:36,  7.84s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5018.36 ms /    25 tokens (  200.73 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.27 ms /     3 runs   (  895.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7706.71 ms /    28 tokens\n",
      " 50%|████▉     | 1730/3487 [5:19:16<3:48:24,  7.80s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2943.42 ms /    13 tokens (  226.42 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.73 ms /     3 runs   (  889.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5615.18 ms /    16 tokens\n",
      " 50%|████▉     | 1731/3487 [5:19:21<3:29:08,  7.15s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1971.14 ms /     7 tokens (  281.59 ms per token,     3.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.91 ms /     3 runs   (  891.30 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4647.01 ms /    10 tokens\n",
      " 50%|████▉     | 1732/3487 [5:19:26<3:07:10,  6.40s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5393.41 ms /    27 tokens (  199.76 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.72 ms /     3 runs   (  903.57 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8106.42 ms /    30 tokens\n",
      " 50%|████▉     | 1733/3487 [5:19:34<3:22:06,  6.91s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3096.49 ms /    14 tokens (  221.18 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.91 ms /     3 runs   (  893.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5780.83 ms /    17 tokens\n",
      " 50%|████▉     | 1734/3487 [5:19:40<3:12:08,  6.58s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8001.94 ms /    41 tokens (  195.17 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2824.61 ms /     3 runs   (  941.54 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   10829.20 ms /    44 tokens\n",
      " 50%|████▉     | 1735/3487 [5:19:51<3:49:21,  7.85s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2669.16 ms /    10 tokens (  266.92 ms per token,     3.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2738.22 ms /     3 runs   (  912.74 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5409.48 ms /    13 tokens\n",
      " 50%|████▉     | 1736/3487 [5:19:56<3:27:54,  7.12s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4210.96 ms /    20 tokens (  210.55 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2726.98 ms /     3 runs   (  908.99 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6940.05 ms /    23 tokens\n",
      " 50%|████▉     | 1737/3487 [5:20:03<3:26:15,  7.07s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4603.35 ms /    22 tokens (  209.24 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.50 ms /     3 runs   (  894.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7289.91 ms /    25 tokens\n",
      " 50%|████▉     | 1738/3487 [5:20:10<3:28:07,  7.14s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5026.89 ms /    25 tokens (  201.08 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.66 ms /     3 runs   (  890.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7700.32 ms /    28 tokens\n",
      " 50%|████▉     | 1739/3487 [5:20:18<3:32:58,  7.31s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3196.77 ms /    12 tokens (  266.40 ms per token,     3.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.01 ms /     3 runs   (  894.00 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5881.49 ms /    15 tokens\n",
      " 50%|████▉     | 1740/3487 [5:20:24<3:20:26,  6.88s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14091.09 ms /    74 tokens (  190.42 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.11 ms /     3 runs   (  882.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16742.03 ms /    77 tokens\n",
      " 50%|████▉     | 1741/3487 [5:20:41<4:46:27,  9.84s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3011.02 ms /    13 tokens (  231.62 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2714.36 ms /     3 runs   (  904.79 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5728.02 ms /    16 tokens\n",
      " 50%|████▉     | 1742/3487 [5:20:46<4:10:28,  8.61s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2694.32 ms /    12 tokens (  224.53 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.15 ms /     3 runs   (  883.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5346.12 ms /    15 tokens\n",
      " 50%|████▉     | 1743/3487 [5:20:52<3:41:55,  7.64s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1728.94 ms /     6 tokens (  288.16 ms per token,     3.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.89 ms /     3 runs   (  904.63 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4445.28 ms /     9 tokens\n",
      " 50%|█████     | 1744/3487 [5:20:56<3:14:03,  6.68s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5302.12 ms /    26 tokens (  203.93 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.95 ms /     3 runs   (  887.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7967.61 ms /    29 tokens\n",
      " 50%|█████     | 1745/3487 [5:21:04<3:25:14,  7.07s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2703.48 ms /    12 tokens (  225.29 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.30 ms /     3 runs   (  899.10 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5403.29 ms /    15 tokens\n",
      " 50%|█████     | 1746/3487 [5:21:10<3:10:40,  6.57s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7118.24 ms /    33 tokens (  215.70 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.41 ms /     3 runs   (  879.80 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9760.00 ms /    36 tokens\n",
      " 50%|█████     | 1747/3487 [5:21:19<3:38:23,  7.53s/it]Llama.generate: 308 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6058.66 ms /    30 tokens (  201.96 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2789.46 ms /     3 runs   (  929.82 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8850.43 ms /    33 tokens\n",
      " 50%|█████     | 1748/3487 [5:21:28<3:49:49,  7.93s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2713.90 ms /    12 tokens (  226.16 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.72 ms /     3 runs   (  893.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5395.59 ms /    15 tokens\n",
      " 50%|█████     | 1749/3487 [5:21:34<3:27:45,  7.17s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3013.96 ms /    13 tokens (  231.84 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.35 ms /     3 runs   (  896.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5705.10 ms /    16 tokens\n",
      " 50%|█████     | 1750/3487 [5:21:39<3:14:57,  6.73s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7227.42 ms /    35 tokens (  206.50 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.37 ms /     3 runs   (  885.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9886.81 ms /    38 tokens\n",
      " 50%|█████     | 1751/3487 [5:21:49<3:42:16,  7.68s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5095.51 ms /    25 tokens (  203.82 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.67 ms /     3 runs   (  889.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7767.60 ms /    28 tokens\n",
      " 50%|█████     | 1752/3487 [5:21:57<3:42:56,  7.71s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7722.89 ms /    33 tokens (  234.03 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.92 ms /     3 runs   (  886.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10385.06 ms /    36 tokens\n",
      " 50%|█████     | 1753/3487 [5:22:07<4:06:04,  8.51s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4182.36 ms /    20 tokens (  209.12 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.67 ms /     3 runs   (  896.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6875.86 ms /    23 tokens\n",
      " 50%|█████     | 1754/3487 [5:22:14<3:51:48,  8.03s/it]Llama.generate: 308 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5617.17 ms /    28 tokens (  200.61 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.46 ms /     3 runs   (  887.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8280.67 ms /    31 tokens\n",
      " 50%|█████     | 1755/3487 [5:22:23<3:53:57,  8.10s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5247.27 ms /    27 tokens (  194.34 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.35 ms /     3 runs   (  893.45 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7930.96 ms /    30 tokens\n",
      " 50%|█████     | 1756/3487 [5:22:31<3:52:24,  8.06s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3067.01 ms /    14 tokens (  219.07 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.32 ms /     3 runs   (  888.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5735.80 ms /    17 tokens\n",
      " 50%|█████     | 1757/3487 [5:22:36<3:32:16,  7.36s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2950.33 ms /    13 tokens (  226.95 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.74 ms /     3 runs   (  892.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5630.25 ms /    16 tokens\n",
      " 50%|█████     | 1758/3487 [5:22:42<3:17:15,  6.85s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3087.06 ms /    14 tokens (  220.50 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.63 ms /     3 runs   (  880.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5729.88 ms /    17 tokens\n",
      " 50%|█████     | 1759/3487 [5:22:48<3:07:34,  6.51s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9772.38 ms /    50 tokens (  195.45 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2894.49 ms /     3 runs   (  964.83 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   12668.90 ms /    53 tokens\n",
      " 50%|█████     | 1760/3487 [5:23:00<4:00:41,  8.36s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4540.83 ms /    22 tokens (  206.40 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.15 ms /     3 runs   (  884.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7197.59 ms /    25 tokens\n",
      " 51%|█████     | 1761/3487 [5:23:08<3:50:34,  8.02s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8885.51 ms /    47 tokens (  189.05 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.86 ms /     3 runs   (  882.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11536.74 ms /    50 tokens\n",
      " 51%|█████     | 1762/3487 [5:23:19<4:20:53,  9.07s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4749.28 ms /    24 tokens (  197.89 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.89 ms /     3 runs   (  886.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7410.93 ms /    27 tokens\n",
      " 51%|█████     | 1763/3487 [5:23:26<4:06:27,  8.58s/it]Llama.generate: 306 prefix-match hit, remaining 111 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20903.62 ms /   111 tokens (  188.32 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.24 ms /     3 runs   (  883.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23557.35 ms /   114 tokens\n",
      " 51%|█████     | 1764/3487 [5:23:50<6:15:26, 13.07s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11405.43 ms /    60 tokens (  190.09 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.91 ms /     3 runs   (  894.64 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14091.61 ms /    63 tokens\n",
      " 51%|█████     | 1765/3487 [5:24:04<6:24:02, 13.38s/it]Llama.generate: 307 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15245.47 ms /    79 tokens (  192.98 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.02 ms /     3 runs   (  903.01 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   17957.64 ms /    82 tokens\n",
      " 51%|█████     | 1766/3487 [5:24:22<7:03:16, 14.76s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4719.99 ms /    21 tokens (  224.76 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2746.80 ms /     3 runs   (  915.60 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7469.53 ms /    24 tokens\n",
      " 51%|█████     | 1767/3487 [5:24:30<6:00:25, 12.57s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5077.84 ms /    24 tokens (  211.58 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3672.31 ms /     4 runs   (  918.08 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8753.61 ms /    28 tokens\n",
      " 51%|█████     | 1768/3487 [5:24:38<5:27:28, 11.43s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3026.08 ms /    13 tokens (  232.78 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.71 ms /     3 runs   (  894.57 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5712.37 ms /    16 tokens\n",
      " 51%|█████     | 1769/3487 [5:24:44<4:38:13,  9.72s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5528.60 ms /    27 tokens (  204.76 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2744.33 ms /     3 runs   (  914.78 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8275.32 ms /    30 tokens\n",
      " 51%|█████     | 1770/3487 [5:24:52<4:25:45,  9.29s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9500.57 ms /    49 tokens (  193.89 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.21 ms /     3 runs   (  879.07 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12140.62 ms /    52 tokens\n",
      " 51%|█████     | 1771/3487 [5:25:04<4:50:10, 10.15s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8899.11 ms /    47 tokens (  189.34 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.88 ms /     3 runs   (  878.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11536.62 ms /    50 tokens\n",
      " 51%|█████     | 1772/3487 [5:25:16<5:01:59, 10.57s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4168.71 ms /    20 tokens (  208.44 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.37 ms /     3 runs   (  887.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6832.43 ms /    23 tokens\n",
      " 51%|█████     | 1773/3487 [5:25:23<4:29:53,  9.45s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9689.27 ms /    50 tokens (  193.79 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.75 ms /     3 runs   (  879.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12330.13 ms /    53 tokens\n",
      " 51%|█████     | 1774/3487 [5:25:35<4:54:30, 10.32s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3174.14 ms /    15 tokens (  211.61 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.90 ms /     3 runs   (  891.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5852.62 ms /    18 tokens\n",
      " 51%|█████     | 1775/3487 [5:25:41<4:16:13,  8.98s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4169.32 ms /    21 tokens (  198.54 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.29 ms /     3 runs   (  877.76 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6807.97 ms /    24 tokens\n",
      " 51%|█████     | 1776/3487 [5:25:48<3:57:34,  8.33s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4429.76 ms /    19 tokens (  233.15 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.35 ms /     3 runs   (  879.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7070.19 ms /    22 tokens\n",
      " 51%|█████     | 1777/3487 [5:25:55<3:46:42,  7.95s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4080.95 ms /    19 tokens (  214.79 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.98 ms /     3 runs   (  889.33 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6751.50 ms /    22 tokens\n",
      " 51%|█████     | 1778/3487 [5:26:02<3:36:21,  7.60s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7176.84 ms /    35 tokens (  205.05 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.44 ms /     3 runs   (  884.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9833.00 ms /    38 tokens\n",
      " 51%|█████     | 1779/3487 [5:26:12<3:55:23,  8.27s/it]Llama.generate: 306 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14207.67 ms /    75 tokens (  189.44 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.39 ms /     3 runs   (  879.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16847.62 ms /    78 tokens\n",
      " 51%|█████     | 1780/3487 [5:26:28<5:08:32, 10.85s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10121.82 ms /    54 tokens (  187.44 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.03 ms /     3 runs   (  885.68 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12781.64 ms /    57 tokens\n",
      " 51%|█████     | 1781/3487 [5:26:41<5:24:57, 11.43s/it]Llama.generate: 306 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13199.07 ms /    70 tokens (  188.56 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.46 ms /     3 runs   (  882.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15850.00 ms /    73 tokens\n",
      " 51%|█████     | 1782/3487 [5:26:57<6:02:31, 12.76s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7257.43 ms /    36 tokens (  201.60 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.99 ms /     3 runs   (  878.66 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9895.54 ms /    39 tokens\n",
      " 51%|█████     | 1783/3487 [5:27:07<5:38:00, 11.90s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9777.61 ms /    48 tokens (  203.70 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.22 ms /     3 runs   (  894.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12463.09 ms /    51 tokens\n",
      " 51%|█████     | 1784/3487 [5:27:19<5:42:39, 12.07s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7805.37 ms /    40 tokens (  195.13 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.20 ms /     3 runs   (  885.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10463.30 ms /    43 tokens\n",
      " 51%|█████     | 1785/3487 [5:27:30<5:28:50, 11.59s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4488.92 ms /    19 tokens (  236.26 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2812.95 ms /     3 runs   (  937.65 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7304.66 ms /    22 tokens\n",
      " 51%|█████     | 1786/3487 [5:27:37<4:52:15, 10.31s/it]Llama.generate: 307 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16097.79 ms /    84 tokens (  191.64 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.66 ms /     3 runs   (  885.89 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18758.25 ms /    87 tokens\n",
      " 51%|█████     | 1787/3487 [5:27:56<6:03:59, 12.85s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3085.87 ms /    13 tokens (  237.37 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.60 ms /     3 runs   (  904.20 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5801.25 ms /    16 tokens\n",
      " 51%|█████▏    | 1788/3487 [5:28:02<5:04:00, 10.74s/it]Llama.generate: 307 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13700.76 ms /    71 tokens (  192.97 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.83 ms /     3 runs   (  877.28 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16335.55 ms /    74 tokens\n",
      " 51%|█████▏    | 1789/3487 [5:28:18<5:51:41, 12.43s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2406.59 ms /     7 tokens (  343.80 ms per token,     2.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.59 ms /     3 runs   (  880.53 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5050.76 ms /    10 tokens\n",
      " 51%|█████▏    | 1790/3487 [5:28:23<4:48:58, 10.22s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3961.26 ms /    19 tokens (  208.49 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.49 ms /     3 runs   (  894.16 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6646.47 ms /    22 tokens\n",
      " 51%|█████▏    | 1791/3487 [5:28:30<4:18:35,  9.15s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3730.40 ms /    18 tokens (  207.24 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.77 ms /     3 runs   (  884.26 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6385.51 ms /    21 tokens\n",
      " 51%|█████▏    | 1792/3487 [5:28:36<3:55:06,  8.32s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1759.08 ms /     6 tokens (  293.18 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.90 ms /     3 runs   (  881.97 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4407.21 ms /     9 tokens\n",
      " 51%|█████▏    | 1793/3487 [5:28:41<3:21:53,  7.15s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4541.05 ms /    22 tokens (  206.41 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.01 ms /     3 runs   (  884.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7195.34 ms /    25 tokens\n",
      " 51%|█████▏    | 1794/3487 [5:28:48<3:22:12,  7.17s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6043.53 ms /    31 tokens (  194.95 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.95 ms /     3 runs   (  885.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8701.89 ms /    34 tokens\n",
      " 51%|█████▏    | 1795/3487 [5:28:57<3:35:08,  7.63s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6072.62 ms /    30 tokens (  202.42 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.38 ms /     3 runs   (  889.13 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8742.73 ms /    33 tokens\n",
      " 52%|█████▏    | 1796/3487 [5:29:05<3:44:45,  7.97s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5831.75 ms /    30 tokens (  194.39 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.93 ms /     3 runs   (  895.31 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8520.74 ms /    33 tokens\n",
      " 52%|█████▏    | 1797/3487 [5:29:14<3:49:18,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1954.53 ms /     7 tokens (  279.22 ms per token,     3.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.04 ms /     3 runs   (  898.68 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4653.05 ms /    10 tokens\n",
      " 52%|█████▏    | 1798/3487 [5:29:19<3:19:46,  7.10s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3256.02 ms /    14 tokens (  232.57 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.29 ms /     3 runs   (  906.43 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5978.04 ms /    17 tokens\n",
      " 52%|█████▏    | 1799/3487 [5:29:25<3:10:15,  6.76s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5759.16 ms /    29 tokens (  198.59 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.22 ms /     3 runs   (  884.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8414.65 ms /    32 tokens\n",
      " 52%|█████▏    | 1800/3487 [5:29:33<3:24:09,  7.26s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3021.98 ms /    13 tokens (  232.46 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.41 ms /     3 runs   (  890.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5695.46 ms /    16 tokens\n",
      " 52%|█████▏    | 1801/3487 [5:29:39<3:10:54,  6.79s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4071.37 ms /    17 tokens (  239.49 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.89 ms /     3 runs   (  880.30 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6715.46 ms /    20 tokens\n",
      " 52%|█████▏    | 1802/3487 [5:29:45<3:10:12,  6.77s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7105.17 ms /    33 tokens (  215.31 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2732.11 ms /     3 runs   (  910.70 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    9840.12 ms /    36 tokens\n",
      " 52%|█████▏    | 1803/3487 [5:29:55<3:35:58,  7.70s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4088.72 ms /    19 tokens (  215.20 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2726.95 ms /     3 runs   (  908.98 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6818.67 ms /    22 tokens\n",
      " 52%|█████▏    | 1804/3487 [5:30:02<3:28:32,  7.43s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3330.90 ms /    15 tokens (  222.06 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2761.74 ms /     3 runs   (  920.58 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6095.55 ms /    18 tokens\n",
      " 52%|█████▏    | 1805/3487 [5:30:08<3:17:14,  7.04s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9448.81 ms /    49 tokens (  192.83 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3363.88 ms /     3 runs   ( 1121.29 ms per token,     0.89 tokens per second)\n",
      "llama_perf_context_print:       total time =   12815.32 ms /    52 tokens\n",
      " 52%|█████▏    | 1806/3487 [5:30:21<4:05:48,  8.77s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5977.95 ms /    23 tokens (  259.91 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3055.32 ms /     3 runs   ( 1018.44 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    9036.63 ms /    26 tokens\n",
      " 52%|█████▏    | 1807/3487 [5:30:30<4:07:56,  8.86s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3887.06 ms /    18 tokens (  215.95 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.64 ms /     3 runs   (  886.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6549.29 ms /    21 tokens\n",
      " 52%|█████▏    | 1808/3487 [5:30:37<3:48:30,  8.17s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5802.61 ms /    29 tokens (  200.09 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.93 ms /     3 runs   (  889.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8474.92 ms /    32 tokens\n",
      " 52%|█████▏    | 1809/3487 [5:30:45<3:51:02,  8.26s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9423.70 ms /    49 tokens (  192.32 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2746.42 ms /     3 runs   (  915.47 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   12172.55 ms /    52 tokens\n",
      " 52%|█████▏    | 1810/3487 [5:30:57<4:23:45,  9.44s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3045.67 ms /    13 tokens (  234.28 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.19 ms /     3 runs   (  880.06 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5688.61 ms /    16 tokens\n",
      " 52%|█████▏    | 1811/3487 [5:31:03<3:52:15,  8.31s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7291.09 ms /    36 tokens (  202.53 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.68 ms /     3 runs   (  883.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9944.01 ms /    39 tokens\n",
      " 52%|█████▏    | 1812/3487 [5:31:13<4:05:49,  8.81s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5631.12 ms /    29 tokens (  194.18 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.60 ms /     3 runs   (  898.87 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8329.96 ms /    32 tokens\n",
      " 52%|█████▏    | 1813/3487 [5:31:21<4:01:46,  8.67s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3058.19 ms /    12 tokens (  254.85 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.95 ms /     3 runs   (  878.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5696.44 ms /    15 tokens\n",
      " 52%|█████▏    | 1814/3487 [5:31:27<3:36:51,  7.78s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3631.18 ms /    17 tokens (  213.60 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.19 ms /     3 runs   (  891.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6307.58 ms /    20 tokens\n",
      " 52%|█████▏    | 1815/3487 [5:31:33<3:24:30,  7.34s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1759.16 ms /     6 tokens (  293.19 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.48 ms /     3 runs   (  877.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4393.73 ms /     9 tokens\n",
      " 52%|█████▏    | 1816/3487 [5:31:38<2:59:51,  6.46s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2719.10 ms /    12 tokens (  226.59 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.42 ms /     3 runs   (  890.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5394.31 ms /    15 tokens\n",
      " 52%|█████▏    | 1817/3487 [5:31:43<2:50:56,  6.14s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7464.47 ms /    38 tokens (  196.43 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.34 ms /     3 runs   (  883.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10116.66 ms /    41 tokens\n",
      " 52%|█████▏    | 1818/3487 [5:31:53<3:24:04,  7.34s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11026.44 ms /    59 tokens (  186.89 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.93 ms /     3 runs   (  876.31 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13657.73 ms /    62 tokens\n",
      " 52%|█████▏    | 1819/3487 [5:32:07<4:16:43,  9.23s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3216.80 ms /    15 tokens (  214.45 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.14 ms /     3 runs   (  883.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5868.36 ms /    18 tokens\n",
      " 52%|█████▏    | 1820/3487 [5:32:13<3:48:35,  8.23s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1485.01 ms /     5 tokens (  297.00 ms per token,     3.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2773.57 ms /     3 runs   (  924.52 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    4261.37 ms /     8 tokens\n",
      " 52%|█████▏    | 1821/3487 [5:32:17<3:15:29,  7.04s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5664.68 ms /    29 tokens (  195.33 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.68 ms /     3 runs   (  878.56 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8302.76 ms /    32 tokens\n",
      " 52%|█████▏    | 1822/3487 [5:32:25<3:25:56,  7.42s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7553.31 ms /    37 tokens (  204.14 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.21 ms /     3 runs   (  872.40 ms per token,     1.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   10172.76 ms /    40 tokens\n",
      " 52%|█████▏    | 1823/3487 [5:32:36<3:48:47,  8.25s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8930.07 ms /    47 tokens (  190.00 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.01 ms /     3 runs   (  883.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11583.54 ms /    50 tokens\n",
      " 52%|█████▏    | 1824/3487 [5:32:47<4:16:26,  9.25s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3906.61 ms /    18 tokens (  217.03 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.91 ms /     3 runs   (  913.30 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6648.92 ms /    21 tokens\n",
      " 52%|█████▏    | 1825/3487 [5:32:54<3:54:42,  8.47s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9088.14 ms /    47 tokens (  193.36 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.12 ms /     3 runs   (  893.04 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11769.28 ms /    50 tokens\n",
      " 52%|█████▏    | 1826/3487 [5:33:06<4:22:00,  9.46s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3861.41 ms /    16 tokens (  241.34 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.99 ms /     3 runs   (  892.00 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6540.02 ms /    19 tokens\n",
      " 52%|█████▏    | 1827/3487 [5:33:12<3:57:39,  8.59s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1730.46 ms /     6 tokens (  288.41 ms per token,     3.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2742.20 ms /     3 runs   (  914.07 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4474.81 ms /     9 tokens\n",
      " 52%|█████▏    | 1828/3487 [5:33:17<3:23:27,  7.36s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3046.07 ms /    13 tokens (  234.31 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.26 ms /     3 runs   (  886.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5709.11 ms /    16 tokens\n",
      " 52%|█████▏    | 1829/3487 [5:33:22<3:09:44,  6.87s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4125.00 ms /    20 tokens (  206.25 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.61 ms /     3 runs   (  881.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6771.08 ms /    23 tokens\n",
      " 52%|█████▏    | 1830/3487 [5:33:29<3:08:55,  6.84s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2465.69 ms /    10 tokens (  246.57 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.74 ms /     3 runs   (  887.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5130.92 ms /    13 tokens\n",
      " 53%|█████▎    | 1831/3487 [5:33:34<2:54:42,  6.33s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15878.57 ms /    86 tokens (  184.63 ms per token,     5.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.29 ms /     3 runs   (  885.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18538.11 ms /    89 tokens\n",
      " 53%|█████▎    | 1832/3487 [5:33:53<4:35:41,  9.99s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4511.53 ms /    22 tokens (  205.07 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.74 ms /     3 runs   (  899.25 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7211.20 ms /    25 tokens\n",
      " 53%|█████▎    | 1833/3487 [5:34:00<4:12:33,  9.16s/it]Llama.generate: 308 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3930.20 ms /    18 tokens (  218.34 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.59 ms /     3 runs   (  893.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6613.10 ms /    21 tokens\n",
      " 53%|█████▎    | 1834/3487 [5:34:07<3:51:24,  8.40s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2538.44 ms /    10 tokens (  253.84 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.59 ms /     3 runs   (  883.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5190.82 ms /    13 tokens\n",
      " 53%|█████▎    | 1835/3487 [5:34:12<3:24:49,  7.44s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9209.69 ms /    48 tokens (  191.87 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.74 ms /     3 runs   (  885.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11868.06 ms /    51 tokens\n",
      " 53%|█████▎    | 1836/3487 [5:34:24<4:01:20,  8.77s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1999.99 ms /     8 tokens (  250.00 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.90 ms /     3 runs   (  886.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4661.42 ms /    11 tokens\n",
      " 53%|█████▎    | 1837/3487 [5:34:28<3:27:20,  7.54s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2989.41 ms /    13 tokens (  229.95 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.81 ms /     3 runs   (  905.60 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5708.91 ms /    16 tokens\n",
      " 53%|█████▎    | 1838/3487 [5:34:34<3:12:11,  6.99s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2408.33 ms /     8 tokens (  301.04 ms per token,     3.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.30 ms /     3 runs   (  883.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5060.54 ms /    11 tokens\n",
      " 53%|█████▎    | 1839/3487 [5:34:39<2:56:14,  6.42s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2725.62 ms /    12 tokens (  227.13 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.38 ms /     3 runs   (  879.46 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5366.30 ms /    15 tokens\n",
      " 53%|█████▎    | 1840/3487 [5:34:45<2:47:33,  6.10s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7214.36 ms /    35 tokens (  206.12 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2814.91 ms /     3 runs   (  938.30 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   10031.17 ms /    38 tokens\n",
      " 53%|█████▎    | 1841/3487 [5:34:55<3:19:51,  7.29s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4885.87 ms /    24 tokens (  203.58 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2803.81 ms /     3 runs   (  934.60 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7692.44 ms /    27 tokens\n",
      " 53%|█████▎    | 1842/3487 [5:35:02<3:23:09,  7.41s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5238.10 ms /    26 tokens (  201.47 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2770.19 ms /     3 runs   (  923.40 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8011.75 ms /    29 tokens\n",
      " 53%|█████▎    | 1843/3487 [5:35:10<3:28:02,  7.59s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3027.61 ms /    13 tokens (  232.89 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.42 ms /     3 runs   (  886.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5688.68 ms /    16 tokens\n",
      " 53%|█████▎    | 1844/3487 [5:35:16<3:12:20,  7.02s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4036.74 ms /    19 tokens (  212.46 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.16 ms /     3 runs   (  880.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6680.96 ms /    22 tokens\n",
      " 53%|█████▎    | 1845/3487 [5:35:23<3:09:44,  6.93s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2988.50 ms /    13 tokens (  229.88 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.03 ms /     3 runs   (  876.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5621.69 ms /    16 tokens\n",
      " 53%|█████▎    | 1846/3487 [5:35:28<2:58:56,  6.54s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5525.89 ms /    28 tokens (  197.35 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.76 ms /     3 runs   (  877.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8160.38 ms /    31 tokens\n",
      " 53%|█████▎    | 1847/3487 [5:35:37<3:12:10,  7.03s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7421.46 ms /    36 tokens (  206.15 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.55 ms /     3 runs   (  879.85 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10063.04 ms /    39 tokens\n",
      " 53%|█████▎    | 1848/3487 [5:35:47<3:36:59,  7.94s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3714.03 ms /    18 tokens (  206.34 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.44 ms /     3 runs   (  890.48 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6388.64 ms /    21 tokens\n",
      " 53%|█████▎    | 1849/3487 [5:35:53<3:24:12,  7.48s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3634.05 ms /    17 tokens (  213.77 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.32 ms /     3 runs   (  886.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6295.52 ms /    20 tokens\n",
      " 53%|█████▎    | 1850/3487 [5:35:59<3:14:27,  7.13s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2325.82 ms /     7 tokens (  332.26 ms per token,     3.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.89 ms /     3 runs   (  883.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4979.33 ms /    10 tokens\n",
      " 53%|█████▎    | 1851/3487 [5:36:04<2:56:50,  6.49s/it]Llama.generate: 306 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11746.11 ms /    63 tokens (  186.45 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.45 ms /     3 runs   (  874.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14373.30 ms /    66 tokens\n",
      " 53%|█████▎    | 1852/3487 [5:36:19<4:01:16,  8.85s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2151.43 ms /     9 tokens (  239.05 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.18 ms /     3 runs   (  884.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4805.47 ms /    12 tokens\n",
      " 53%|█████▎    | 1853/3487 [5:36:24<3:28:22,  7.65s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2242.95 ms /     9 tokens (  249.22 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.88 ms /     3 runs   (  890.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4917.14 ms /    12 tokens\n",
      " 53%|█████▎    | 1854/3487 [5:36:28<3:05:59,  6.83s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2064.40 ms /     8 tokens (  258.05 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.44 ms /     3 runs   (  886.81 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4727.43 ms /    11 tokens\n",
      " 53%|█████▎    | 1855/3487 [5:36:33<2:48:44,  6.20s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2669.78 ms /    11 tokens (  242.71 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.57 ms /     3 runs   (  893.52 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5352.89 ms /    14 tokens\n",
      " 53%|█████▎    | 1856/3487 [5:36:39<2:41:46,  5.95s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1623.08 ms /     5 tokens (  324.62 ms per token,     3.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.94 ms /     3 runs   (  891.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4302.32 ms /     8 tokens\n",
      " 53%|█████▎    | 1857/3487 [5:36:43<2:28:18,  5.46s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1646.55 ms /     5 tokens (  329.31 ms per token,     3.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.11 ms /     3 runs   (  882.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4296.82 ms /     8 tokens\n",
      " 53%|█████▎    | 1858/3487 [5:36:47<2:18:48,  5.11s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3524.51 ms /    16 tokens (  220.28 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.20 ms /     3 runs   (  905.73 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6244.25 ms /    19 tokens\n",
      " 53%|█████▎    | 1859/3487 [5:36:53<2:28:00,  5.46s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5541.94 ms /    28 tokens (  197.93 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.37 ms /     3 runs   (  900.79 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8247.18 ms /    31 tokens\n",
      " 53%|█████▎    | 1860/3487 [5:37:02<2:50:42,  6.30s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7859.24 ms /    40 tokens (  196.48 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.64 ms /     3 runs   (  882.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10509.08 ms /    43 tokens\n",
      " 53%|█████▎    | 1861/3487 [5:37:12<3:24:55,  7.56s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3131.78 ms /    14 tokens (  223.70 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.54 ms /     3 runs   (  892.18 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5810.84 ms /    17 tokens\n",
      " 53%|█████▎    | 1862/3487 [5:37:18<3:10:38,  7.04s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4931.64 ms /    22 tokens (  224.17 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.43 ms /     3 runs   (  882.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7581.33 ms /    25 tokens\n",
      " 53%|█████▎    | 1863/3487 [5:37:26<3:14:59,  7.20s/it]Llama.generate: 327 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3833.98 ms /     4 runs   (  958.49 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    3837.32 ms /     5 tokens\n",
      " 53%|█████▎    | 1864/3487 [5:37:29<2:47:36,  6.20s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4120.36 ms /    19 tokens (  216.86 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.28 ms /     3 runs   (  881.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6766.15 ms /    22 tokens\n",
      " 53%|█████▎    | 1865/3487 [5:37:36<2:52:12,  6.37s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2680.68 ms /    12 tokens (  223.39 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.13 ms /     3 runs   (  884.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5336.87 ms /    15 tokens\n",
      " 54%|█████▎    | 1866/3487 [5:37:42<2:43:48,  6.06s/it]Llama.generate: 310 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2535.12 ms /    10 tokens (  253.51 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.73 ms /     3 runs   (  888.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5203.57 ms /    13 tokens\n",
      " 54%|█████▎    | 1867/3487 [5:37:47<2:36:48,  5.81s/it]Llama.generate: 306 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16337.35 ms /    83 tokens (  196.84 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.91 ms /     3 runs   (  880.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18983.05 ms /    86 tokens\n",
      " 54%|█████▎    | 1868/3487 [5:38:06<4:23:26,  9.76s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5091.33 ms /    25 tokens (  203.65 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.04 ms /     3 runs   (  882.01 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7740.02 ms /    28 tokens\n",
      " 54%|█████▎    | 1869/3487 [5:38:14<4:06:59,  9.16s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2484.33 ms /    10 tokens (  248.43 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.91 ms /     3 runs   (  882.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5133.24 ms /    13 tokens\n",
      " 54%|█████▎    | 1870/3487 [5:38:19<3:34:21,  7.95s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3562.04 ms /    16 tokens (  222.63 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2877.76 ms /     3 runs   (  959.25 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    6442.33 ms /    19 tokens\n",
      " 54%|█████▎    | 1871/3487 [5:38:25<3:22:04,  7.50s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2686.83 ms /    12 tokens (  223.90 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.45 ms /     3 runs   (  880.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5331.71 ms /    15 tokens\n",
      " 54%|█████▎    | 1872/3487 [5:38:30<3:04:28,  6.85s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2497.41 ms /    10 tokens (  249.74 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.84 ms /     3 runs   (  885.28 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5155.84 ms /    13 tokens\n",
      " 54%|█████▎    | 1873/3487 [5:38:36<2:50:44,  6.35s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7743.71 ms /    39 tokens (  198.56 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.90 ms /     3 runs   (  880.63 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10388.40 ms /    42 tokens\n",
      " 54%|█████▎    | 1874/3487 [5:38:46<3:23:17,  7.56s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3304.12 ms /    13 tokens (  254.16 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.53 ms /     3 runs   (  883.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5958.01 ms /    16 tokens\n",
      " 54%|█████▍    | 1875/3487 [5:38:52<3:10:19,  7.08s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3225.08 ms /    15 tokens (  215.01 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.68 ms /     3 runs   (  888.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5894.30 ms /    18 tokens\n",
      " 54%|█████▍    | 1876/3487 [5:38:58<3:00:41,  6.73s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9149.76 ms /    47 tokens (  194.68 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.64 ms /     3 runs   (  877.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11784.12 ms /    50 tokens\n",
      " 54%|█████▍    | 1877/3487 [5:39:10<3:41:19,  8.25s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3177.59 ms /    14 tokens (  226.97 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.83 ms /     3 runs   (  895.61 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5866.91 ms /    17 tokens\n",
      " 54%|█████▍    | 1878/3487 [5:39:16<3:22:05,  7.54s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8772.39 ms /    45 tokens (  194.94 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.40 ms /     3 runs   (  882.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11421.32 ms /    48 tokens\n",
      " 54%|█████▍    | 1879/3487 [5:39:27<3:53:17,  8.71s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2569.96 ms /    11 tokens (  233.63 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2703.72 ms /     3 runs   (  901.24 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5275.84 ms /    14 tokens\n",
      " 54%|█████▍    | 1880/3487 [5:39:32<3:25:40,  7.68s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1985.20 ms /     7 tokens (  283.60 ms per token,     3.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.61 ms /     3 runs   (  887.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4650.23 ms /    10 tokens\n",
      " 54%|█████▍    | 1881/3487 [5:39:37<3:01:18,  6.77s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1957.42 ms /     7 tokens (  279.63 ms per token,     3.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.86 ms /     3 runs   (  884.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4613.98 ms /    10 tokens\n",
      " 54%|█████▍    | 1882/3487 [5:39:42<2:43:56,  6.13s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3663.91 ms /    17 tokens (  215.52 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.13 ms /     3 runs   (  880.71 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6308.64 ms /    20 tokens\n",
      " 54%|█████▍    | 1883/3487 [5:39:48<2:45:20,  6.18s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2737.26 ms /    12 tokens (  228.10 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.05 ms /     3 runs   (  881.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5382.51 ms /    15 tokens\n",
      " 54%|█████▍    | 1884/3487 [5:39:53<2:38:51,  5.95s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9358.65 ms /    39 tokens (  239.97 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2755.03 ms /     3 runs   (  918.34 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   12116.88 ms /    42 tokens\n",
      " 54%|█████▍    | 1885/3487 [5:40:05<3:28:17,  7.80s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12550.10 ms /    62 tokens (  202.42 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.19 ms /     3 runs   (  883.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15203.23 ms /    65 tokens\n",
      " 54%|█████▍    | 1886/3487 [5:40:21<4:27:29, 10.02s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4656.72 ms /    21 tokens (  221.75 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.70 ms /     3 runs   (  896.57 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7349.36 ms /    24 tokens\n",
      " 54%|█████▍    | 1887/3487 [5:40:28<4:05:58,  9.22s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2784.19 ms /    12 tokens (  232.02 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.96 ms /     3 runs   (  901.65 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5491.40 ms /    15 tokens\n",
      " 54%|█████▍    | 1888/3487 [5:40:33<3:36:02,  8.11s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5893.28 ms /    30 tokens (  196.44 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.40 ms /     3 runs   (  884.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8547.94 ms /    33 tokens\n",
      " 54%|█████▍    | 1889/3487 [5:40:42<3:39:30,  8.24s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10209.33 ms /    54 tokens (  189.06 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.66 ms /     3 runs   (  892.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12890.86 ms /    57 tokens\n",
      " 54%|█████▍    | 1890/3487 [5:40:55<4:16:32,  9.64s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7259.87 ms /    36 tokens (  201.66 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4781.01 ms /     3 runs   ( 1593.67 ms per token,     0.63 tokens per second)\n",
      "llama_perf_context_print:       total time =   12043.38 ms /    39 tokens\n",
      " 54%|█████▍    | 1891/3487 [5:41:07<4:35:39, 10.36s/it]Llama.generate: 308 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10372.43 ms /    42 tokens (  246.96 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2885.98 ms /     3 runs   (  961.99 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   13261.51 ms /    45 tokens\n",
      " 54%|█████▍    | 1892/3487 [5:41:20<4:58:40, 11.24s/it]Llama.generate: 307 prefix-match hit, remaining 136 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25472.31 ms /   136 tokens (  187.30 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.80 ms /     3 runs   (  881.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   28118.87 ms /   139 tokens\n",
      " 54%|█████▍    | 1893/3487 [5:41:48<7:13:07, 16.30s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9588.52 ms /    50 tokens (  191.77 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.64 ms /     3 runs   (  886.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12250.96 ms /    53 tokens\n",
      " 54%|█████▍    | 1894/3487 [5:42:01<6:40:39, 15.09s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3996.08 ms /    19 tokens (  210.32 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.06 ms /     3 runs   (  890.35 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6669.64 ms /    22 tokens\n",
      " 54%|█████▍    | 1895/3487 [5:42:07<5:33:27, 12.57s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3712.15 ms /    17 tokens (  218.36 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.30 ms /     3 runs   (  902.77 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6422.73 ms /    20 tokens\n",
      " 54%|█████▍    | 1896/3487 [5:42:14<4:44:25, 10.73s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3198.87 ms /    12 tokens (  266.57 ms per token,     3.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.41 ms /     3 runs   (  883.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5852.22 ms /    15 tokens\n",
      " 54%|█████▍    | 1897/3487 [5:42:20<4:05:33,  9.27s/it]Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8561.35 ms /    44 tokens (  194.58 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.29 ms /     3 runs   (  881.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11207.22 ms /    47 tokens\n",
      " 54%|█████▍    | 1898/3487 [5:42:31<4:20:52,  9.85s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2739.61 ms /    12 tokens (  228.30 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.83 ms /     3 runs   (  897.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5435.25 ms /    15 tokens\n",
      " 54%|█████▍    | 1899/3487 [5:42:36<3:45:43,  8.53s/it]Llama.generate: 306 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11013.22 ms /    58 tokens (  189.88 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.45 ms /     3 runs   (  879.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13653.94 ms /    61 tokens\n",
      " 54%|█████▍    | 1900/3487 [5:42:50<4:26:19, 10.07s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4762.63 ms /    23 tokens (  207.07 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.72 ms /     3 runs   (  902.57 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7472.57 ms /    26 tokens\n",
      " 55%|█████▍    | 1901/3487 [5:42:57<4:05:37,  9.29s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7837.89 ms /    40 tokens (  195.95 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.75 ms /     3 runs   (  889.92 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10510.26 ms /    43 tokens\n",
      " 55%|█████▍    | 1902/3487 [5:43:08<4:15:11,  9.66s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7188.85 ms /    35 tokens (  205.40 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.34 ms /     3 runs   (  877.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9825.32 ms /    38 tokens\n",
      " 55%|█████▍    | 1903/3487 [5:43:18<4:16:23,  9.71s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4253.88 ms /    20 tokens (  212.69 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.28 ms /     3 runs   (  896.76 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6947.07 ms /    23 tokens\n",
      " 55%|█████▍    | 1904/3487 [5:43:25<3:54:26,  8.89s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8887.62 ms /    44 tokens (  201.99 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.73 ms /     3 runs   (  882.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11537.48 ms /    47 tokens\n",
      " 55%|█████▍    | 1905/3487 [5:43:36<4:15:21,  9.68s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7188.97 ms /    34 tokens (  211.44 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.41 ms /     3 runs   (  887.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9853.84 ms /    37 tokens\n",
      " 55%|█████▍    | 1906/3487 [5:43:46<4:16:34,  9.74s/it]Llama.generate: 308 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2562.77 ms /    11 tokens (  232.98 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.33 ms /     3 runs   (  887.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5227.74 ms /    14 tokens\n",
      " 55%|█████▍    | 1907/3487 [5:43:51<3:40:51,  8.39s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7917.04 ms /    40 tokens (  197.93 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.49 ms /     3 runs   (  879.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10559.48 ms /    43 tokens\n",
      " 55%|█████▍    | 1908/3487 [5:44:02<3:57:56,  9.04s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2644.32 ms /     9 tokens (  293.81 ms per token,     3.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.21 ms /     3 runs   (  886.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5304.46 ms /    12 tokens\n",
      " 55%|█████▍    | 1909/3487 [5:44:07<3:28:22,  7.92s/it]Llama.generate: 307 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13934.48 ms /    73 tokens (  190.88 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.46 ms /     3 runs   (  876.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16568.23 ms /    76 tokens\n",
      " 55%|█████▍    | 1910/3487 [5:44:24<4:36:27, 10.52s/it]Llama.generate: 307 prefix-match hit, remaining 180 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   33128.06 ms /   180 tokens (  184.04 ms per token,     5.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.64 ms /     3 runs   (  883.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   35782.32 ms /   183 tokens\n",
      " 55%|█████▍    | 1911/3487 [5:45:00<7:55:28, 18.10s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12989.36 ms /    65 tokens (  199.84 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.65 ms /     3 runs   (  880.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15633.93 ms /    68 tokens\n",
      " 55%|█████▍    | 1912/3487 [5:45:15<7:35:48, 17.36s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9217.15 ms /    48 tokens (  192.02 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.38 ms /     3 runs   (  883.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11871.45 ms /    51 tokens\n",
      " 55%|█████▍    | 1913/3487 [5:45:27<6:52:21, 15.72s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4278.28 ms /    21 tokens (  203.73 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.97 ms /     3 runs   (  890.32 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6951.96 ms /    24 tokens\n",
      " 55%|█████▍    | 1914/3487 [5:45:34<5:43:12, 13.09s/it]Llama.generate: 306 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13164.96 ms /    70 tokens (  188.07 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.33 ms /     3 runs   (  884.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15821.58 ms /    73 tokens\n",
      " 55%|█████▍    | 1915/3487 [5:45:50<6:04:30, 13.91s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5157.17 ms /    26 tokens (  198.35 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.08 ms /     3 runs   (  900.03 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7860.00 ms /    29 tokens\n",
      " 55%|█████▍    | 1916/3487 [5:45:58<5:16:48, 12.10s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9026.67 ms /    46 tokens (  196.23 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.50 ms /     3 runs   (  898.83 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11726.09 ms /    49 tokens\n",
      " 55%|█████▍    | 1917/3487 [5:46:10<5:13:44, 11.99s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3370.69 ms /    15 tokens (  224.71 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.61 ms /     3 runs   (  905.87 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6090.91 ms /    18 tokens\n",
      " 55%|█████▌    | 1918/3487 [5:46:16<4:27:18, 10.22s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8709.93 ms /    45 tokens (  193.55 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.09 ms /     3 runs   (  891.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11386.44 ms /    48 tokens\n",
      " 55%|█████▌    | 1919/3487 [5:46:27<4:36:20, 10.57s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5100.84 ms /    25 tokens (  204.03 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.49 ms /     3 runs   (  905.83 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7821.23 ms /    28 tokens\n",
      " 55%|█████▌    | 1920/3487 [5:46:35<4:14:39,  9.75s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4426.11 ms /    19 tokens (  232.95 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2762.48 ms /     3 runs   (  920.83 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7191.73 ms /    22 tokens\n",
      " 55%|█████▌    | 1921/3487 [5:46:42<3:54:31,  8.99s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3574.77 ms /    16 tokens (  223.42 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.59 ms /     3 runs   (  889.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6245.73 ms /    19 tokens\n",
      " 55%|█████▌    | 1922/3487 [5:46:48<3:33:00,  8.17s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1785.66 ms /     6 tokens (  297.61 ms per token,     3.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.27 ms /     3 runs   (  893.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4467.72 ms /     9 tokens\n",
      " 55%|█████▌    | 1923/3487 [5:46:53<3:04:00,  7.06s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3606.71 ms /    16 tokens (  225.42 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.40 ms /     3 runs   (  902.47 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6316.25 ms /    19 tokens\n",
      " 55%|█████▌    | 1924/3487 [5:46:59<2:58:08,  6.84s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4679.16 ms /    23 tokens (  203.44 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.17 ms /     3 runs   (  881.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7330.69 ms /    26 tokens\n",
      " 55%|█████▌    | 1925/3487 [5:47:06<3:01:57,  6.99s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3997.47 ms /    19 tokens (  210.39 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.66 ms /     3 runs   (  906.89 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6720.79 ms /    22 tokens\n",
      " 55%|█████▌    | 1926/3487 [5:47:13<2:59:48,  6.91s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3153.87 ms /    14 tokens (  225.28 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.28 ms /     3 runs   (  893.43 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5836.73 ms /    17 tokens\n",
      " 55%|█████▌    | 1927/3487 [5:47:19<2:51:23,  6.59s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15986.93 ms /    86 tokens (  185.89 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.08 ms /     3 runs   (  897.36 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   18681.98 ms /    89 tokens\n",
      " 55%|█████▌    | 1928/3487 [5:47:38<4:25:35, 10.22s/it]Llama.generate: 311 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2733.37 ms /    12 tokens (  227.78 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.81 ms /     3 runs   (  899.27 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5433.71 ms /    15 tokens\n",
      " 55%|█████▌    | 1929/3487 [5:47:43<3:48:11,  8.79s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6328.49 ms /    31 tokens (  204.14 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.24 ms /     3 runs   (  898.75 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9028.00 ms /    34 tokens\n",
      " 55%|█████▌    | 1930/3487 [5:47:52<3:49:59,  8.86s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8596.74 ms /    43 tokens (  199.92 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.09 ms /     3 runs   (  883.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11248.34 ms /    46 tokens\n",
      " 55%|█████▌    | 1931/3487 [5:48:03<4:08:27,  9.58s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5078.08 ms /    25 tokens (  203.12 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2763.74 ms /     3 runs   (  921.25 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7845.14 ms /    28 tokens\n",
      " 55%|█████▌    | 1932/3487 [5:48:11<3:54:53,  9.06s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7491.40 ms /    33 tokens (  227.01 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2762.54 ms /     3 runs   (  920.85 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10256.64 ms /    36 tokens\n",
      " 55%|█████▌    | 1933/3487 [5:48:22<4:04:04,  9.42s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7780.82 ms /    36 tokens (  216.13 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.59 ms /     3 runs   (  888.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10448.73 ms /    39 tokens\n",
      " 55%|█████▌    | 1934/3487 [5:48:32<4:11:55,  9.73s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4333.37 ms /    21 tokens (  206.35 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.57 ms /     3 runs   (  893.86 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7017.65 ms /    24 tokens\n",
      " 55%|█████▌    | 1935/3487 [5:48:39<3:50:45,  8.92s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5097.76 ms /    24 tokens (  212.41 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2728.63 ms /     3 runs   (  909.54 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7829.44 ms /    27 tokens\n",
      " 56%|█████▌    | 1936/3487 [5:48:47<3:42:14,  8.60s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3505.14 ms /    16 tokens (  219.07 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.15 ms /     3 runs   (  900.38 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6208.71 ms /    19 tokens\n",
      " 56%|█████▌    | 1937/3487 [5:48:53<3:23:38,  7.88s/it]Llama.generate: 306 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11109.76 ms /    58 tokens (  191.55 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.51 ms /     3 runs   (  890.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13785.68 ms /    61 tokens\n",
      " 56%|█████▌    | 1938/3487 [5:49:07<4:09:17,  9.66s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3159.94 ms /    14 tokens (  225.71 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2727.64 ms /     3 runs   (  909.21 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5889.95 ms /    17 tokens\n",
      " 56%|█████▌    | 1939/3487 [5:49:13<3:40:03,  8.53s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13217.11 ms /    69 tokens (  191.55 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.35 ms /     3 runs   (  890.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15889.68 ms /    72 tokens\n",
      " 56%|█████▌    | 1940/3487 [5:49:29<4:36:54, 10.74s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2041.42 ms /     8 tokens (  255.18 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.94 ms /     3 runs   (  896.65 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4734.10 ms /    11 tokens\n",
      " 56%|█████▌    | 1941/3487 [5:49:33<3:50:22,  8.94s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7486.32 ms /    37 tokens (  202.33 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.49 ms /     3 runs   (  891.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10164.13 ms /    40 tokens\n",
      " 56%|█████▌    | 1942/3487 [5:49:44<3:59:44,  9.31s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2034.68 ms /     7 tokens (  290.67 ms per token,     3.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.00 ms /     3 runs   (  905.67 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4753.98 ms /    10 tokens\n",
      " 56%|█████▌    | 1943/3487 [5:49:48<3:24:28,  7.95s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8497.73 ms /    44 tokens (  193.13 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.63 ms /     3 runs   (  885.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11156.80 ms /    47 tokens\n",
      " 56%|█████▌    | 1944/3487 [5:50:00<3:49:09,  8.91s/it]Llama.generate: 310 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4319.71 ms /    18 tokens (  239.98 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2875.98 ms /     3 runs   (  958.66 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    7198.32 ms /    21 tokens\n",
      " 56%|█████▌    | 1945/3487 [5:50:07<3:35:52,  8.40s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2630.58 ms /    11 tokens (  239.14 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2703.99 ms /     3 runs   (  901.33 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5337.36 ms /    14 tokens\n",
      " 56%|█████▌    | 1946/3487 [5:50:12<3:12:12,  7.48s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4969.42 ms /    23 tokens (  216.06 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.44 ms /     3 runs   (  893.48 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7652.82 ms /    26 tokens\n",
      " 56%|█████▌    | 1947/3487 [5:50:20<3:13:26,  7.54s/it]Llama.generate: 307 prefix-match hit, remaining 104 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19627.98 ms /   104 tokens (  188.73 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.99 ms /     3 runs   (  886.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   22291.92 ms /   107 tokens\n",
      " 56%|█████▌    | 1948/3487 [5:50:42<5:06:55, 11.97s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3696.41 ms /    17 tokens (  217.44 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.46 ms /     3 runs   (  893.49 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6379.42 ms /    20 tokens\n",
      " 56%|█████▌    | 1949/3487 [5:50:48<4:23:50, 10.29s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5168.34 ms /    26 tokens (  198.78 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.34 ms /     3 runs   (  895.45 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7857.54 ms /    29 tokens\n",
      " 56%|█████▌    | 1950/3487 [5:50:56<4:05:01,  9.57s/it]Llama.generate: 310 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4718.46 ms /    22 tokens (  214.48 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.77 ms /     3 runs   (  900.59 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7422.90 ms /    25 tokens\n",
      " 56%|█████▌    | 1951/3487 [5:51:04<3:48:29,  8.93s/it]Llama.generate: 321 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2792.52 ms /    12 tokens (  232.71 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.92 ms /     3 runs   (  901.64 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5500.18 ms /    15 tokens\n",
      " 56%|█████▌    | 1952/3487 [5:51:09<3:22:06,  7.90s/it]Llama.generate: 306 prefix-match hit, remaining 89 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16700.03 ms /    89 tokens (  187.64 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.36 ms /     3 runs   (  894.45 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   19386.22 ms /    92 tokens\n",
      " 56%|█████▌    | 1953/3487 [5:51:29<4:50:08, 11.35s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7542.63 ms /    37 tokens (  203.85 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.00 ms /     3 runs   (  883.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10195.25 ms /    40 tokens\n",
      " 56%|█████▌    | 1954/3487 [5:51:39<4:41:11, 11.01s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5204.66 ms /    26 tokens (  200.18 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.65 ms /     3 runs   (  890.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7879.28 ms /    29 tokens\n",
      " 56%|█████▌    | 1955/3487 [5:51:47<4:17:06, 10.07s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7283.26 ms /    34 tokens (  214.21 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2753.67 ms /     3 runs   (  917.89 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10040.08 ms /    37 tokens\n",
      " 56%|█████▌    | 1956/3487 [5:51:57<4:17:02, 10.07s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2862.91 ms /     9 tokens (  318.10 ms per token,     3.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2809.57 ms /     3 runs   (  936.52 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5675.22 ms /    12 tokens\n",
      " 56%|█████▌    | 1957/3487 [5:52:02<3:43:16,  8.76s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8385.91 ms /    42 tokens (  199.66 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.72 ms /     3 runs   (  896.57 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11077.77 ms /    45 tokens\n",
      " 56%|█████▌    | 1958/3487 [5:52:14<4:00:56,  9.45s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1944.34 ms /     7 tokens (  277.76 ms per token,     3.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.72 ms /     3 runs   (  894.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4631.40 ms /    10 tokens\n",
      " 56%|█████▌    | 1959/3487 [5:52:18<3:23:59,  8.01s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3999.28 ms /    19 tokens (  210.49 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.32 ms /     3 runs   (  892.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6678.54 ms /    22 tokens\n",
      " 56%|█████▌    | 1960/3487 [5:52:25<3:13:45,  7.61s/it]Llama.generate: 309 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2069.56 ms /     8 tokens (  258.70 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.25 ms /     3 runs   (  886.08 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4730.38 ms /    11 tokens\n",
      " 56%|█████▌    | 1961/3487 [5:52:30<2:51:41,  6.75s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3660.91 ms /    17 tokens (  215.35 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.71 ms /     3 runs   (  886.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6323.08 ms /    20 tokens\n",
      " 56%|█████▋    | 1962/3487 [5:52:36<2:48:22,  6.62s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2722.49 ms /    12 tokens (  226.87 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.37 ms /     3 runs   (  887.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5387.06 ms /    15 tokens\n",
      " 56%|█████▋    | 1963/3487 [5:52:41<2:38:53,  6.26s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2489.90 ms /    10 tokens (  248.99 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.13 ms /     3 runs   (  891.71 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5167.63 ms /    13 tokens\n",
      " 56%|█████▋    | 1964/3487 [5:52:47<2:30:34,  5.93s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2218.93 ms /     9 tokens (  246.55 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.83 ms /     3 runs   (  894.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4904.11 ms /    12 tokens\n",
      " 56%|█████▋    | 1965/3487 [5:52:51<2:22:43,  5.63s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3231.34 ms /    15 tokens (  215.42 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2768.80 ms /     3 runs   (  922.93 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6002.30 ms /    18 tokens\n",
      " 56%|█████▋    | 1966/3487 [5:52:57<2:25:33,  5.74s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4250.41 ms /    19 tokens (  223.71 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.99 ms /     3 runs   (  903.66 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6964.28 ms /    22 tokens\n",
      " 56%|█████▋    | 1967/3487 [5:53:04<2:34:48,  6.11s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2191.54 ms /     9 tokens (  243.50 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.37 ms /     3 runs   (  885.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4851.70 ms /    12 tokens\n",
      " 56%|█████▋    | 1968/3487 [5:53:09<2:25:12,  5.74s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2981.04 ms /    10 tokens (  298.10 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.85 ms /     3 runs   (  889.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5651.33 ms /    13 tokens\n",
      " 56%|█████▋    | 1969/3487 [5:53:15<2:24:31,  5.71s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4228.72 ms /    20 tokens (  211.44 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.72 ms /     3 runs   (  888.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6898.35 ms /    23 tokens\n",
      " 56%|█████▋    | 1970/3487 [5:53:22<2:33:29,  6.07s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4595.45 ms /    22 tokens (  208.88 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.18 ms /     3 runs   (  880.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7239.97 ms /    25 tokens\n",
      " 57%|█████▋    | 1971/3487 [5:53:29<2:42:18,  6.42s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2585.20 ms /    10 tokens (  258.52 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2959.00 ms /     3 runs   (  986.33 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    5547.16 ms /    13 tokens\n",
      " 57%|█████▋    | 1972/3487 [5:53:35<2:35:38,  6.16s/it]Llama.generate: 306 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16147.89 ms /    84 tokens (  192.24 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.25 ms /     3 runs   (  886.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18811.25 ms /    87 tokens\n",
      " 57%|█████▋    | 1973/3487 [5:53:53<4:11:20,  9.96s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2612.02 ms /    10 tokens (  261.20 ms per token,     3.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.52 ms /     3 runs   (  894.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5298.87 ms /    13 tokens\n",
      " 57%|█████▋    | 1974/3487 [5:53:59<3:35:57,  8.56s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2774.95 ms /    12 tokens (  231.25 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2732.12 ms /     3 runs   (  910.71 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5509.91 ms /    15 tokens\n",
      " 57%|█████▋    | 1975/3487 [5:54:04<3:12:48,  7.65s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2217.60 ms /     9 tokens (  246.40 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.55 ms /     3 runs   (  889.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4889.33 ms /    12 tokens\n",
      " 57%|█████▋    | 1976/3487 [5:54:09<2:51:51,  6.82s/it]Llama.generate: 308 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2104.90 ms /     8 tokens (  263.11 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.96 ms /     3 runs   (  885.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4764.07 ms /    11 tokens\n",
      " 57%|█████▋    | 1977/3487 [5:54:14<2:36:14,  6.21s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3721.59 ms /    17 tokens (  218.92 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.60 ms /     3 runs   (  890.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6395.84 ms /    20 tokens\n",
      " 57%|█████▋    | 1978/3487 [5:54:20<2:37:37,  6.27s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1734.82 ms /     6 tokens (  289.14 ms per token,     3.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.88 ms /     3 runs   (  890.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4407.97 ms /     9 tokens\n",
      " 57%|█████▋    | 1979/3487 [5:54:25<2:23:33,  5.71s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5377.04 ms /    27 tokens (  199.15 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.39 ms /     3 runs   (  905.13 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8095.63 ms /    30 tokens\n",
      " 57%|█████▋    | 1980/3487 [5:54:33<2:41:29,  6.43s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7786.26 ms /    35 tokens (  222.46 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.74 ms /     3 runs   (  886.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10447.45 ms /    38 tokens\n",
      " 57%|█████▋    | 1981/3487 [5:54:43<3:11:41,  7.64s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2673.16 ms /    10 tokens (  267.32 ms per token,     3.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3192.53 ms /     3 runs   ( 1064.18 ms per token,     0.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    5868.58 ms /    13 tokens\n",
      " 57%|█████▋    | 1982/3487 [5:54:49<2:58:18,  7.11s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12635.77 ms /    30 tokens (  421.19 ms per token,     2.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11490.00 ms /     3 runs   ( 3830.00 ms per token,     0.26 tokens per second)\n",
      "llama_perf_context_print:       total time =   24132.04 ms /    33 tokens\n",
      " 57%|█████▋    | 1983/3487 [5:55:13<5:06:25, 12.22s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4104.23 ms /    11 tokens (  373.11 ms per token,     2.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3459.25 ms /     3 runs   ( 1153.08 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =    7568.31 ms /    14 tokens\n",
      " 57%|█████▋    | 1984/3487 [5:55:21<4:31:26, 10.84s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2909.62 ms /    10 tokens (  290.96 ms per token,     3.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3246.38 ms /     3 runs   ( 1082.13 ms per token,     0.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    6159.38 ms /    13 tokens\n",
      " 57%|█████▋    | 1985/3487 [5:55:27<3:56:13,  9.44s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2894.87 ms /    10 tokens (  289.49 ms per token,     3.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.99 ms /     3 runs   (  890.33 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5568.85 ms /    13 tokens\n",
      " 57%|█████▋    | 1986/3487 [5:55:33<3:27:07,  8.28s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9667.90 ms /    50 tokens (  193.36 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.52 ms /     3 runs   (  888.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12337.22 ms /    53 tokens\n",
      " 57%|█████▋    | 1987/3487 [5:55:45<3:57:28,  9.50s/it]Llama.generate: 307 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11448.12 ms /    60 tokens (  190.80 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.32 ms /     3 runs   (  897.44 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   14143.21 ms /    63 tokens\n",
      " 57%|█████▋    | 1988/3487 [5:55:59<4:32:12, 10.90s/it]Llama.generate: 307 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19072.05 ms /   102 tokens (  186.98 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.14 ms /     3 runs   (  884.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   21766.66 ms /   105 tokens\n",
      " 57%|█████▋    | 1989/3487 [5:56:21<5:53:30, 14.16s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2700.48 ms /    12 tokens (  225.04 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.28 ms /     3 runs   (  890.43 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5374.51 ms /    15 tokens\n",
      " 57%|█████▋    | 1990/3487 [5:56:26<4:47:35, 11.53s/it]Llama.generate: 308 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9084.08 ms /    37 tokens (  245.52 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2857.95 ms /     3 runs   (  952.65 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   11944.30 ms /    40 tokens\n",
      " 57%|█████▋    | 1991/3487 [5:56:38<4:50:34, 11.65s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8343.23 ms /    42 tokens (  198.65 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.33 ms /     3 runs   (  883.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10997.29 ms /    45 tokens\n",
      " 57%|█████▋    | 1992/3487 [5:56:49<4:45:31, 11.46s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2553.72 ms /    10 tokens (  255.37 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.42 ms /     3 runs   (  889.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5224.78 ms /    13 tokens\n",
      " 57%|█████▋    | 1993/3487 [5:56:55<3:58:50,  9.59s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5146.09 ms /    25 tokens (  205.84 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.33 ms /     3 runs   (  901.44 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7853.20 ms /    28 tokens\n",
      " 57%|█████▋    | 1994/3487 [5:57:02<3:45:44,  9.07s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3001.32 ms /    13 tokens (  230.87 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.95 ms /     3 runs   (  888.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5669.52 ms /    16 tokens\n",
      " 57%|█████▋    | 1995/3487 [5:57:08<3:20:16,  8.05s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4149.12 ms /    19 tokens (  218.37 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.10 ms /     3 runs   (  899.37 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6849.72 ms /    22 tokens\n",
      " 57%|█████▋    | 1996/3487 [5:57:15<3:11:14,  7.70s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8320.18 ms /    42 tokens (  198.10 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.09 ms /     3 runs   (  890.03 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10993.45 ms /    45 tokens\n",
      " 57%|█████▋    | 1997/3487 [5:57:26<3:35:43,  8.69s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5265.49 ms /    27 tokens (  195.02 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.23 ms /     3 runs   (  893.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7949.31 ms /    30 tokens\n",
      " 57%|█████▋    | 1998/3487 [5:57:34<3:30:09,  8.47s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4122.52 ms /    20 tokens (  206.13 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.69 ms /     3 runs   (  888.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6790.58 ms /    23 tokens\n",
      " 57%|█████▋    | 1999/3487 [5:57:41<3:17:36,  7.97s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5077.04 ms /    25 tokens (  203.08 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.30 ms /     3 runs   (  881.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7724.49 ms /    28 tokens\n",
      " 57%|█████▋    | 2000/3487 [5:57:48<3:15:43,  7.90s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2280.38 ms /     9 tokens (  253.38 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.79 ms /     3 runs   (  889.93 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4952.67 ms /    12 tokens\n",
      " 57%|█████▋    | 2001/3487 [5:57:53<2:53:47,  7.02s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4443.41 ms /    19 tokens (  233.86 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.97 ms /     3 runs   (  879.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7086.51 ms /    22 tokens\n",
      " 57%|█████▋    | 2002/3487 [5:58:01<2:54:15,  7.04s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6237.69 ms /    32 tokens (  194.93 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.64 ms /     3 runs   (  880.88 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8883.34 ms /    35 tokens\n",
      " 57%|█████▋    | 2003/3487 [5:58:09<3:07:51,  7.60s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2937.45 ms /    13 tokens (  225.96 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.38 ms /     3 runs   (  878.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5574.38 ms /    16 tokens\n",
      " 57%|█████▋    | 2004/3487 [5:58:15<2:52:49,  6.99s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2598.21 ms /    11 tokens (  236.20 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.58 ms /     3 runs   (  880.86 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5243.00 ms /    14 tokens\n",
      " 57%|█████▋    | 2005/3487 [5:58:20<2:39:48,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2732.87 ms /    12 tokens (  227.74 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.40 ms /     3 runs   (  883.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5384.73 ms /    15 tokens\n",
      " 58%|█████▊    | 2006/3487 [5:58:26<2:31:42,  6.15s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5928.72 ms /    30 tokens (  197.62 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.78 ms /     3 runs   (  895.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8617.82 ms /    33 tokens\n",
      " 58%|█████▊    | 2007/3487 [5:58:34<2:49:58,  6.89s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2413.27 ms /     8 tokens (  301.66 ms per token,     3.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.82 ms /     3 runs   (  889.61 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5084.78 ms /    11 tokens\n",
      " 58%|█████▊    | 2008/3487 [5:58:39<2:36:33,  6.35s/it]Llama.generate: 307 prefix-match hit, remaining 113 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21157.55 ms /   113 tokens (  187.23 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.55 ms /     3 runs   (  883.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23810.83 ms /   116 tokens\n",
      " 58%|█████▊    | 2009/3487 [5:59:03<4:45:32, 11.59s/it]Llama.generate: 307 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14466.30 ms /    75 tokens (  192.88 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.72 ms /     3 runs   (  885.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17125.11 ms /    78 tokens\n",
      " 58%|█████▊    | 2010/3487 [5:59:20<5:26:17, 13.25s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7453.56 ms /    37 tokens (  201.45 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.57 ms /     3 runs   (  880.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10096.89 ms /    40 tokens\n",
      " 58%|█████▊    | 2011/3487 [5:59:30<5:02:49, 12.31s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3089.16 ms /    14 tokens (  220.65 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.31 ms /     3 runs   (  880.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5733.69 ms /    17 tokens\n",
      " 58%|█████▊    | 2012/3487 [5:59:36<4:14:10, 10.34s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9369.19 ms /    46 tokens (  203.68 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2749.38 ms /     3 runs   (  916.46 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   12121.11 ms /    49 tokens\n",
      " 58%|█████▊    | 2013/3487 [5:59:48<4:27:12, 10.88s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2276.55 ms /     9 tokens (  252.95 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.48 ms /     3 runs   (  887.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4942.73 ms /    12 tokens\n",
      " 58%|█████▊    | 2014/3487 [5:59:53<3:43:22,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2479.67 ms /    10 tokens (  247.97 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.97 ms /     3 runs   (  889.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5152.27 ms /    13 tokens\n",
      " 58%|█████▊    | 2015/3487 [5:59:58<3:14:14,  7.92s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4880.37 ms /    24 tokens (  203.35 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.52 ms /     3 runs   (  879.84 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7522.37 ms /    27 tokens\n",
      " 58%|█████▊    | 2016/3487 [6:00:06<3:11:16,  7.80s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4643.68 ms /    23 tokens (  201.90 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.98 ms /     3 runs   (  892.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7325.59 ms /    26 tokens\n",
      " 58%|█████▊    | 2017/3487 [6:00:13<3:07:41,  7.66s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2282.74 ms /     9 tokens (  253.64 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2860.05 ms /     3 runs   (  953.35 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    5144.83 ms /    12 tokens\n",
      " 58%|█████▊    | 2018/3487 [6:00:18<2:49:08,  6.91s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11617.20 ms /    59 tokens (  196.90 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.44 ms /     3 runs   (  913.15 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   14358.55 ms /    62 tokens\n",
      " 58%|█████▊    | 2019/3487 [6:00:33<3:43:47,  9.15s/it]Llama.generate: 306 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13178.04 ms /    68 tokens (  193.79 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.36 ms /     3 runs   (  883.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15831.54 ms /    71 tokens\n",
      " 58%|█████▊    | 2020/3487 [6:00:49<4:32:43, 11.15s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2608.75 ms /    11 tokens (  237.16 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.72 ms /     3 runs   (  878.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5246.44 ms /    14 tokens\n",
      " 58%|█████▊    | 2021/3487 [6:00:54<3:49:17,  9.38s/it]Llama.generate: 306 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11970.38 ms /    63 tokens (  190.01 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.89 ms /     3 runs   (  888.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14639.36 ms /    66 tokens\n",
      " 58%|█████▊    | 2022/3487 [6:01:09<4:27:42, 10.96s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8374.53 ms /    43 tokens (  194.76 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.78 ms /     3 runs   (  877.59 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11009.50 ms /    46 tokens\n",
      " 58%|█████▊    | 2023/3487 [6:01:20<4:27:54, 10.98s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3241.58 ms /    13 tokens (  249.35 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.51 ms /     3 runs   (  880.17 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5884.45 ms /    16 tokens\n",
      " 58%|█████▊    | 2024/3487 [6:01:25<3:50:31,  9.45s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5676.48 ms /    29 tokens (  195.74 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.01 ms /     3 runs   (  885.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8334.61 ms /    32 tokens\n",
      " 58%|█████▊    | 2025/3487 [6:01:34<3:42:14,  9.12s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3762.41 ms /    18 tokens (  209.02 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.80 ms /     3 runs   (  882.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6412.94 ms /    21 tokens\n",
      " 58%|█████▊    | 2026/3487 [6:01:40<3:22:21,  8.31s/it]Llama.generate: 307 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13565.66 ms /    73 tokens (  185.83 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.01 ms /     3 runs   (  878.34 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16204.01 ms /    76 tokens\n",
      " 58%|█████▊    | 2027/3487 [6:01:56<4:19:53, 10.68s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1569.28 ms /     5 tokens (  313.86 ms per token,     3.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.15 ms /     3 runs   (  887.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4234.01 ms /     8 tokens\n",
      " 58%|█████▊    | 2028/3487 [6:02:01<3:32:45,  8.75s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11738.15 ms /    62 tokens (  189.32 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.18 ms /     3 runs   (  886.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14400.05 ms /    65 tokens\n",
      " 58%|█████▊    | 2029/3487 [6:02:15<4:13:51, 10.45s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2532.78 ms /    11 tokens (  230.25 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.45 ms /     3 runs   (  881.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5180.19 ms /    14 tokens\n",
      " 58%|█████▊    | 2030/3487 [6:02:20<3:35:22,  8.87s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2457.51 ms /    10 tokens (  245.75 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.49 ms /     3 runs   (  887.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5122.05 ms /    13 tokens\n",
      " 58%|█████▊    | 2031/3487 [6:02:25<3:08:00,  7.75s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2682.13 ms /    12 tokens (  223.51 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.46 ms /     3 runs   (  884.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5336.95 ms /    15 tokens\n",
      " 58%|█████▊    | 2032/3487 [6:02:31<2:50:23,  7.03s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2951.42 ms /    13 tokens (  227.03 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.88 ms /     3 runs   (  891.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5629.50 ms /    16 tokens\n",
      " 58%|█████▊    | 2033/3487 [6:02:36<2:40:11,  6.61s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2972.59 ms /    13 tokens (  228.66 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.28 ms /     3 runs   (  880.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5617.54 ms /    16 tokens\n",
      " 58%|█████▊    | 2034/3487 [6:02:42<2:32:55,  6.32s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2976.78 ms /    13 tokens (  228.98 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.47 ms /     3 runs   (  879.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5618.83 ms /    16 tokens\n",
      " 58%|█████▊    | 2035/3487 [6:02:48<2:27:50,  6.11s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5221.80 ms /    24 tokens (  217.57 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.43 ms /     3 runs   (  881.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7870.63 ms /    27 tokens\n",
      " 58%|█████▊    | 2036/3487 [6:02:56<2:40:33,  6.64s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4578.27 ms /    22 tokens (  208.10 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.44 ms /     3 runs   (  883.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7229.97 ms /    25 tokens\n",
      " 58%|█████▊    | 2037/3487 [6:03:03<2:44:47,  6.82s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3490.32 ms /    16 tokens (  218.15 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.38 ms /     3 runs   (  885.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6150.08 ms /    19 tokens\n",
      " 58%|█████▊    | 2038/3487 [6:03:09<2:39:54,  6.62s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2574.64 ms /    11 tokens (  234.06 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.67 ms /     3 runs   (  883.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5226.77 ms /    14 tokens\n",
      " 58%|█████▊    | 2039/3487 [6:03:14<2:29:44,  6.21s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3716.36 ms /    18 tokens (  206.46 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.79 ms /     3 runs   (  883.26 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6368.62 ms /    21 tokens\n",
      " 59%|█████▊    | 2040/3487 [6:03:21<2:30:52,  6.26s/it]Llama.generate: 306 prefix-match hit, remaining 140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26001.67 ms /   140 tokens (  185.73 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.00 ms /     3 runs   (  887.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   28666.31 ms /   143 tokens\n",
      " 59%|█████▊    | 2041/3487 [6:03:49<5:12:51, 12.98s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5658.62 ms /    30 tokens (  188.62 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.33 ms /     3 runs   (  892.11 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8337.45 ms /    33 tokens\n",
      " 59%|█████▊    | 2042/3487 [6:03:58<4:39:10, 11.59s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5163.20 ms /    26 tokens (  198.58 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.17 ms /     3 runs   (  881.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7809.81 ms /    29 tokens\n",
      " 59%|█████▊    | 2043/3487 [6:04:05<4:11:44, 10.46s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10210.60 ms /    54 tokens (  189.09 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.16 ms /     3 runs   (  884.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12866.61 ms /    57 tokens\n",
      " 59%|█████▊    | 2044/3487 [6:04:18<4:28:59, 11.18s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8835.47 ms /    46 tokens (  192.08 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.01 ms /     3 runs   (  882.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11484.53 ms /    49 tokens\n",
      " 59%|█████▊    | 2045/3487 [6:04:30<4:31:14, 11.29s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13382.56 ms /    70 tokens (  191.18 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.16 ms /     3 runs   (  886.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16044.36 ms /    73 tokens\n",
      " 59%|█████▊    | 2046/3487 [6:04:46<5:05:23, 12.72s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3175.55 ms /    15 tokens (  211.70 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.82 ms /     3 runs   (  888.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5846.07 ms /    18 tokens\n",
      " 59%|█████▊    | 2047/3487 [6:04:52<4:15:46, 10.66s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3040.72 ms /    11 tokens (  276.43 ms per token,     3.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.65 ms /     3 runs   (  887.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5706.64 ms /    14 tokens\n",
      " 59%|█████▊    | 2048/3487 [6:04:57<3:40:01,  9.17s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8442.22 ms /    43 tokens (  196.33 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2887.75 ms /     3 runs   (  962.58 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   11332.77 ms /    46 tokens\n",
      " 59%|█████▉    | 2049/3487 [6:05:09<3:55:27,  9.82s/it]Llama.generate: 307 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20455.91 ms /   107 tokens (  191.18 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.58 ms /     3 runs   (  881.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23104.24 ms /   110 tokens\n",
      " 59%|█████▉    | 2050/3487 [6:05:32<5:30:46, 13.81s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1687.18 ms /     6 tokens (  281.20 ms per token,     3.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.13 ms /     3 runs   (  890.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4360.72 ms /     9 tokens\n",
      " 59%|█████▉    | 2051/3487 [6:05:36<4:22:45, 10.98s/it]Llama.generate: 312 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3843.12 ms /     4 runs   (  960.78 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    3845.20 ms /     5 tokens\n",
      " 59%|█████▉    | 2052/3487 [6:05:40<3:31:27,  8.84s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3551.48 ms /    16 tokens (  221.97 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.57 ms /     3 runs   (  884.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6207.75 ms /    19 tokens\n",
      " 59%|█████▉    | 2053/3487 [6:05:46<3:12:29,  8.05s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1735.47 ms /     6 tokens (  289.25 ms per token,     3.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.26 ms /     3 runs   (  887.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4399.59 ms /     9 tokens\n",
      " 59%|█████▉    | 2054/3487 [6:05:51<2:46:13,  6.96s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5724.85 ms /    29 tokens (  197.41 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.79 ms /     3 runs   (  882.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8376.64 ms /    32 tokens\n",
      " 59%|█████▉    | 2055/3487 [6:05:59<2:56:19,  7.39s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8960.16 ms /    46 tokens (  194.79 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2624.11 ms /     3 runs   (  874.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11586.97 ms /    49 tokens\n",
      " 59%|█████▉    | 2056/3487 [6:06:11<3:26:16,  8.65s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7123.37 ms /    34 tokens (  209.51 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.29 ms /     3 runs   (  876.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9755.36 ms /    37 tokens\n",
      " 59%|█████▉    | 2057/3487 [6:06:20<3:34:07,  8.98s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3092.20 ms /    14 tokens (  220.87 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.60 ms /     3 runs   (  879.87 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5734.48 ms /    17 tokens\n",
      " 59%|█████▉    | 2058/3487 [6:06:26<3:10:48,  8.01s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4517.77 ms /    20 tokens (  225.89 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.84 ms /     3 runs   (  879.95 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7160.20 ms /    23 tokens\n",
      " 59%|█████▉    | 2059/3487 [6:06:33<3:04:38,  7.76s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7530.05 ms /    38 tokens (  198.16 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.90 ms /     3 runs   (  877.63 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10166.31 ms /    41 tokens\n",
      " 59%|█████▉    | 2060/3487 [6:06:44<3:21:45,  8.48s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4986.08 ms /    25 tokens (  199.44 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.99 ms /     3 runs   (  886.33 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7647.33 ms /    28 tokens\n",
      " 59%|█████▉    | 2061/3487 [6:06:51<3:15:42,  8.23s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7136.33 ms /    33 tokens (  216.25 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.63 ms /     3 runs   (  879.54 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9777.70 ms /    36 tokens\n",
      " 59%|█████▉    | 2062/3487 [6:07:01<3:26:36,  8.70s/it]Llama.generate: 308 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8470.35 ms /    44 tokens (  192.51 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.51 ms /     3 runs   (  897.17 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11164.60 ms /    47 tokens\n",
      " 59%|█████▉    | 2063/3487 [6:07:12<3:44:05,  9.44s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1682.61 ms /     6 tokens (  280.43 ms per token,     3.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.56 ms /     3 runs   (  886.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4345.43 ms /     9 tokens\n",
      " 59%|█████▉    | 2064/3487 [6:07:16<3:07:44,  7.92s/it]Llama.generate: 308 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1737.35 ms /     6 tokens (  289.56 ms per token,     3.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.61 ms /     3 runs   (  881.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4385.43 ms /     9 tokens\n",
      " 59%|█████▉    | 2065/3487 [6:07:21<2:42:34,  6.86s/it]Llama.generate: 308 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1604.05 ms /     5 tokens (  320.81 ms per token,     3.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.08 ms /     3 runs   (  882.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4254.59 ms /     8 tokens\n",
      " 59%|█████▉    | 2066/3487 [6:07:25<2:24:00,  6.08s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3766.05 ms /    18 tokens (  209.22 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.48 ms /     3 runs   (  883.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6420.33 ms /    21 tokens\n",
      " 59%|█████▉    | 2067/3487 [6:07:32<2:26:21,  6.18s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1937.58 ms /     7 tokens (  276.80 ms per token,     3.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.87 ms /     3 runs   (  885.96 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4598.32 ms /    10 tokens\n",
      " 59%|█████▉    | 2068/3487 [6:07:36<2:15:03,  5.71s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1621.74 ms /     5 tokens (  324.35 ms per token,     3.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.66 ms /     3 runs   (  886.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4284.09 ms /     8 tokens\n",
      " 59%|█████▉    | 2069/3487 [6:07:40<2:05:07,  5.29s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10809.47 ms /    54 tokens (  200.18 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.72 ms /     3 runs   (  879.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13450.32 ms /    57 tokens\n",
      " 59%|█████▉    | 2070/3487 [6:07:54<3:02:52,  7.74s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4050.77 ms /    19 tokens (  213.20 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.00 ms /     3 runs   (  897.33 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6745.76 ms /    22 tokens\n",
      " 59%|█████▉    | 2071/3487 [6:08:01<2:55:57,  7.46s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1675.56 ms /     5 tokens (  335.11 ms per token,     2.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.99 ms /     3 runs   (  884.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4330.28 ms /     8 tokens\n",
      " 59%|█████▉    | 2072/3487 [6:08:05<2:33:47,  6.52s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6025.56 ms /    31 tokens (  194.37 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.35 ms /     3 runs   (  886.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8687.55 ms /    34 tokens\n",
      " 59%|█████▉    | 2073/3487 [6:08:14<2:49:02,  7.17s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15962.41 ms /    86 tokens (  185.61 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.89 ms /     3 runs   (  884.96 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18620.41 ms /    89 tokens\n",
      " 59%|█████▉    | 2074/3487 [6:08:32<4:09:51, 10.61s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2445.36 ms /    10 tokens (  244.54 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.57 ms /     3 runs   (  885.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5104.14 ms /    13 tokens\n",
      " 60%|█████▉    | 2075/3487 [6:08:38<3:30:52,  8.96s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2847.53 ms /    12 tokens (  237.29 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.93 ms /     3 runs   (  887.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5512.68 ms /    15 tokens\n",
      " 60%|█████▉    | 2076/3487 [6:08:43<3:06:27,  7.93s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3140.45 ms /    14 tokens (  224.32 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.28 ms /     3 runs   (  887.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5804.03 ms /    17 tokens\n",
      " 60%|█████▉    | 2077/3487 [6:08:49<2:51:23,  7.29s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2706.13 ms /    12 tokens (  225.51 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.92 ms /     3 runs   (  888.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5375.24 ms /    15 tokens\n",
      " 60%|█████▉    | 2078/3487 [6:08:54<2:37:49,  6.72s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3766.94 ms /    18 tokens (  209.27 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2718.04 ms /     3 runs   (  906.01 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6487.81 ms /    21 tokens\n",
      " 60%|█████▉    | 2079/3487 [6:09:01<2:36:07,  6.65s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2988.73 ms /    13 tokens (  229.90 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.35 ms /     3 runs   (  879.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5629.61 ms /    16 tokens\n",
      " 60%|█████▉    | 2080/3487 [6:09:06<2:28:52,  6.35s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2065.40 ms /     6 tokens (  344.23 ms per token,     2.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.16 ms /     3 runs   (  881.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4712.48 ms /     9 tokens\n",
      " 60%|█████▉    | 2081/3487 [6:09:11<2:17:18,  5.86s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3119.04 ms /    14 tokens (  222.79 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.51 ms /     3 runs   (  885.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5778.81 ms /    17 tokens\n",
      " 60%|█████▉    | 2082/3487 [6:09:17<2:16:41,  5.84s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3770.24 ms /    18 tokens (  209.46 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.82 ms /     3 runs   (  888.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6439.76 ms /    21 tokens\n",
      " 60%|█████▉    | 2083/3487 [6:09:23<2:20:52,  6.02s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5778.94 ms /    30 tokens (  192.63 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.86 ms /     3 runs   (  879.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8419.48 ms /    33 tokens\n",
      " 60%|█████▉    | 2084/3487 [6:09:32<2:37:40,  6.74s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4560.64 ms /    22 tokens (  207.30 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.29 ms /     3 runs   (  885.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7218.26 ms /    25 tokens\n",
      " 60%|█████▉    | 2085/3487 [6:09:39<2:40:57,  6.89s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3701.57 ms /    18 tokens (  205.64 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.63 ms /     3 runs   (  885.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6360.95 ms /    21 tokens\n",
      " 60%|█████▉    | 2086/3487 [6:09:45<2:37:12,  6.73s/it]Llama.generate: 308 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1503.58 ms /     5 tokens (  300.72 ms per token,     3.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.54 ms /     3 runs   (  887.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4169.69 ms /     8 tokens\n",
      " 60%|█████▉    | 2087/3487 [6:09:50<2:19:12,  5.97s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2026.74 ms /     8 tokens (  253.34 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.68 ms /     3 runs   (  896.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4719.47 ms /    11 tokens\n",
      " 60%|█████▉    | 2088/3487 [6:09:54<2:10:27,  5.60s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9929.58 ms /    50 tokens (  198.59 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.35 ms /     3 runs   (  913.12 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   12672.41 ms /    53 tokens\n",
      " 60%|█████▉    | 2089/3487 [6:10:07<2:59:54,  7.72s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3885.86 ms /    18 tokens (  215.88 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.76 ms /     3 runs   (  891.92 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6564.62 ms /    21 tokens\n",
      " 60%|█████▉    | 2090/3487 [6:10:14<2:51:45,  7.38s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5047.70 ms /    23 tokens (  219.47 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.60 ms /     3 runs   (  904.53 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7763.54 ms /    26 tokens\n",
      " 60%|█████▉    | 2091/3487 [6:10:21<2:54:24,  7.50s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5415.05 ms /    27 tokens (  200.56 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2911.23 ms /     3 runs   (  970.41 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    8329.02 ms /    30 tokens\n",
      " 60%|█████▉    | 2092/3487 [6:10:30<3:00:08,  7.75s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5798.91 ms /    29 tokens (  199.96 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2703.72 ms /     3 runs   (  901.24 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8505.00 ms /    32 tokens\n",
      " 60%|██████    | 2093/3487 [6:10:38<3:05:20,  7.98s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2148.27 ms /     8 tokens (  268.53 ms per token,     3.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.70 ms /     3 runs   (  907.90 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4874.38 ms /    11 tokens\n",
      " 60%|██████    | 2094/3487 [6:10:43<2:43:38,  7.05s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1919.42 ms /     7 tokens (  274.20 ms per token,     3.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.78 ms /     3 runs   (  905.59 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4638.30 ms /    10 tokens\n",
      " 60%|██████    | 2095/3487 [6:10:48<2:26:48,  6.33s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3627.34 ms /    16 tokens (  226.71 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.19 ms /     3 runs   (  896.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6317.91 ms /    19 tokens\n",
      " 60%|██████    | 2096/3487 [6:10:54<2:26:41,  6.33s/it]Llama.generate: 307 prefix-match hit, remaining 200 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   36939.84 ms /   200 tokens (  184.70 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.82 ms /     3 runs   (  894.27 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   39624.90 ms /   203 tokens\n",
      " 60%|██████    | 2097/3487 [6:11:34<6:18:04, 16.32s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5928.81 ms /    30 tokens (  197.63 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.07 ms /     3 runs   (  893.69 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8612.33 ms /    33 tokens\n",
      " 60%|██████    | 2098/3487 [6:11:42<5:24:19, 14.01s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1680.55 ms /     6 tokens (  280.09 ms per token,     3.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.09 ms /     3 runs   (  892.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4361.25 ms /     9 tokens\n",
      " 60%|██████    | 2099/3487 [6:11:47<4:17:10, 11.12s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4024.78 ms /    19 tokens (  211.83 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.59 ms /     3 runs   (  893.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6707.68 ms /    22 tokens\n",
      " 60%|██████    | 2100/3487 [6:11:53<3:46:28,  9.80s/it]Llama.generate: 307 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16601.47 ms /    87 tokens (  190.82 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.30 ms /     3 runs   (  888.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19268.43 ms /    90 tokens\n",
      " 60%|██████    | 2101/3487 [6:12:13<4:52:00, 12.64s/it]Llama.generate: 307 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9245.10 ms /    48 tokens (  192.61 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.70 ms /     3 runs   (  886.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11908.60 ms /    51 tokens\n",
      " 60%|██████    | 2102/3487 [6:12:25<4:46:47, 12.42s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4455.40 ms /    22 tokens (  202.52 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.96 ms /     3 runs   (  884.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7112.48 ms /    25 tokens\n",
      " 60%|██████    | 2103/3487 [6:12:32<4:09:53, 10.83s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3730.50 ms /    18 tokens (  207.25 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.41 ms /     3 runs   (  891.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6407.73 ms /    21 tokens\n",
      " 60%|██████    | 2104/3487 [6:12:38<3:39:10,  9.51s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4767.81 ms /    24 tokens (  198.66 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2732.64 ms /     3 runs   (  910.88 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7503.21 ms /    27 tokens\n",
      " 60%|██████    | 2105/3487 [6:12:46<3:25:12,  8.91s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9489.84 ms /    49 tokens (  193.67 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.16 ms /     3 runs   (  881.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12137.51 ms /    52 tokens\n",
      " 60%|██████    | 2106/3487 [6:12:58<3:47:24,  9.88s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1742.43 ms /     6 tokens (  290.41 ms per token,     3.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.75 ms /     3 runs   (  886.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4404.71 ms /     9 tokens\n",
      " 60%|██████    | 2107/3487 [6:13:02<3:09:31,  8.24s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3996.77 ms /    19 tokens (  210.36 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.89 ms /     3 runs   (  887.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6662.33 ms /    22 tokens\n",
      " 60%|██████    | 2108/3487 [6:13:09<2:58:33,  7.77s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4705.07 ms /    23 tokens (  204.57 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.98 ms /     3 runs   (  886.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7367.58 ms /    26 tokens\n",
      " 60%|██████    | 2109/3487 [6:13:16<2:55:43,  7.65s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2603.58 ms /    11 tokens (  236.69 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.99 ms /     3 runs   (  888.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5269.78 ms /    14 tokens\n",
      " 61%|██████    | 2110/3487 [6:13:21<2:39:15,  6.94s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2069.46 ms /     8 tokens (  258.68 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.53 ms /     3 runs   (  890.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4743.69 ms /    11 tokens\n",
      " 61%|██████    | 2111/3487 [6:13:26<2:24:05,  6.28s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8760.24 ms /    43 tokens (  203.73 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.12 ms /     3 runs   (  889.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11431.13 ms /    46 tokens\n",
      " 61%|██████    | 2112/3487 [6:13:38<2:59:26,  7.83s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2518.06 ms /    10 tokens (  251.81 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.95 ms /     3 runs   (  903.32 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5231.18 ms /    13 tokens\n",
      " 61%|██████    | 2113/3487 [6:13:43<2:41:30,  7.05s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2869.81 ms /    11 tokens (  260.89 ms per token,     3.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.67 ms /     3 runs   (  889.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5541.06 ms /    14 tokens\n",
      " 61%|██████    | 2114/3487 [6:13:48<2:31:03,  6.60s/it]Llama.generate: 306 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19363.03 ms /   103 tokens (  187.99 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.63 ms /     3 runs   (  892.54 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   22043.33 ms /   106 tokens\n",
      " 61%|██████    | 2115/3487 [6:14:10<4:16:57, 11.24s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2529.48 ms /    10 tokens (  252.95 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.16 ms /     3 runs   (  886.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5191.97 ms /    13 tokens\n",
      " 61%|██████    | 2116/3487 [6:14:16<3:35:23,  9.43s/it]Llama.generate: 306 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15143.76 ms /    80 tokens (  189.30 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.59 ms /     3 runs   (  888.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17813.21 ms /    83 tokens\n",
      " 61%|██████    | 2117/3487 [6:14:34<4:32:43, 11.94s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5246.04 ms /    24 tokens (  218.59 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3073.46 ms /     3 runs   ( 1024.49 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    8322.85 ms /    27 tokens\n",
      " 61%|██████    | 2118/3487 [6:14:42<4:07:48, 10.86s/it]Llama.generate: 311 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7715.21 ms /    28 tokens (  275.54 ms per token,     3.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2872.99 ms /     3 runs   (  957.66 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   10591.31 ms /    31 tokens\n",
      " 61%|██████    | 2119/3487 [6:14:52<4:05:50, 10.78s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2255.66 ms /     8 tokens (  281.96 ms per token,     3.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2730.27 ms /     3 runs   (  910.09 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4988.75 ms /    11 tokens\n",
      " 61%|██████    | 2120/3487 [6:14:57<3:26:07,  9.05s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2855.88 ms /    11 tokens (  259.63 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4653.75 ms /     3 runs   ( 1551.25 ms per token,     0.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    7512.18 ms /    14 tokens\n",
      " 61%|██████    | 2121/3487 [6:15:05<3:15:33,  8.59s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2933.12 ms /    12 tokens (  244.43 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2750.88 ms /     3 runs   (  916.96 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5687.08 ms /    15 tokens\n",
      " 61%|██████    | 2122/3487 [6:15:11<2:55:40,  7.72s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4393.55 ms /    21 tokens (  209.22 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.98 ms /     3 runs   (  896.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7086.99 ms /    24 tokens\n",
      " 61%|██████    | 2123/3487 [6:15:18<2:51:17,  7.53s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2951.45 ms /    12 tokens (  245.95 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.25 ms /     3 runs   (  901.42 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5658.11 ms /    15 tokens\n",
      " 61%|██████    | 2124/3487 [6:15:23<2:38:25,  6.97s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3190.92 ms /    14 tokens (  227.92 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2842.73 ms /     3 runs   (  947.58 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    6036.21 ms /    17 tokens\n",
      " 61%|██████    | 2125/3487 [6:15:29<2:31:58,  6.70s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7427.67 ms /    35 tokens (  212.22 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.74 ms /     3 runs   (  893.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10111.23 ms /    38 tokens\n",
      " 61%|██████    | 2126/3487 [6:15:40<2:55:11,  7.72s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5418.55 ms /    27 tokens (  200.69 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.67 ms /     3 runs   (  889.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8090.83 ms /    30 tokens\n",
      " 61%|██████    | 2127/3487 [6:15:48<2:57:37,  7.84s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5659.95 ms /    28 tokens (  202.14 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.26 ms /     3 runs   (  897.09 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8353.92 ms /    31 tokens\n",
      " 61%|██████    | 2128/3487 [6:15:56<3:01:03,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12972.59 ms /    65 tokens (  199.58 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.03 ms /     3 runs   (  887.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15636.71 ms /    68 tokens\n",
      " 61%|██████    | 2129/3487 [6:16:12<3:52:52, 10.29s/it]Llama.generate: 308 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4070.01 ms /    19 tokens (  214.21 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.16 ms /     3 runs   (  900.39 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6773.31 ms /    22 tokens\n",
      " 61%|██████    | 2130/3487 [6:16:18<3:28:54,  9.24s/it]Llama.generate: 318 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2004.92 ms /     4 tokens (  501.23 ms per token,     2.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.44 ms /     3 runs   (  903.81 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4718.57 ms /     7 tokens\n",
      " 61%|██████    | 2131/3487 [6:16:23<2:58:10,  7.88s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3558.21 ms /    16 tokens (  222.39 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.07 ms /     3 runs   (  896.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6249.35 ms /    19 tokens\n",
      " 61%|██████    | 2132/3487 [6:16:29<2:47:02,  7.40s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8954.42 ms /    43 tokens (  208.24 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.25 ms /     3 runs   (  898.42 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11652.39 ms /    46 tokens\n",
      " 61%|██████    | 2133/3487 [6:16:41<3:15:47,  8.68s/it]Llama.generate: 307 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16426.67 ms /    82 tokens (  200.33 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3010.98 ms /     3 runs   ( 1003.66 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =   19440.17 ms /    85 tokens\n",
      " 61%|██████    | 2134/3487 [6:17:01<4:28:31, 11.91s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5613.81 ms /    25 tokens (  224.55 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2718.14 ms /     3 runs   (  906.05 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8334.43 ms /    28 tokens\n",
      " 61%|██████    | 2135/3487 [6:17:09<4:04:13, 10.84s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4195.99 ms /    20 tokens (  209.80 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.10 ms /     3 runs   (  895.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6884.94 ms /    23 tokens\n",
      " 61%|██████▏   | 2136/3487 [6:17:16<3:37:23,  9.65s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4242.98 ms /    20 tokens (  212.15 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.44 ms /     3 runs   (  900.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6946.53 ms /    23 tokens\n",
      " 61%|██████▏   | 2137/3487 [6:17:23<3:19:00,  8.84s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9005.19 ms /    46 tokens (  195.76 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2764.57 ms /     3 runs   (  921.52 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   11771.31 ms /    49 tokens\n",
      " 61%|██████▏   | 2138/3487 [6:17:35<3:38:39,  9.73s/it]Llama.generate: 307 prefix-match hit, remaining 208 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   38731.00 ms /   208 tokens (  186.21 ms per token,     5.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3315.95 ms /     3 runs   ( 1105.32 ms per token,     0.90 tokens per second)\n",
      "llama_perf_context_print:       total time =   42049.58 ms /   211 tokens\n",
      " 61%|██████▏   | 2139/3487 [6:18:17<7:16:25, 19.43s/it]Llama.generate: 307 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21269.09 ms /   100 tokens (  212.69 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3099.48 ms /     3 runs   ( 1033.16 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =   24371.33 ms /   103 tokens\n",
      " 61%|██████▏   | 2140/3487 [6:18:41<7:49:29, 20.91s/it]Llama.generate: 307 prefix-match hit, remaining 198 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   39077.91 ms /   198 tokens (  197.36 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2799.37 ms /     3 runs   (  933.12 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   41879.78 ms /   201 tokens\n",
      " 61%|██████▏   | 2141/3487 [6:19:23<10:10:20, 27.21s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4684.55 ms /    19 tokens (  246.56 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2749.12 ms /     3 runs   (  916.37 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7437.43 ms /    22 tokens\n",
      " 61%|██████▏   | 2142/3487 [6:19:30<7:56:59, 21.28s/it] Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5880.44 ms /    28 tokens (  210.02 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2788.54 ms /     3 runs   (  929.51 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8671.86 ms /    31 tokens\n",
      " 61%|██████▏   | 2143/3487 [6:19:39<6:31:59, 17.50s/it]Llama.generate: 307 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11147.07 ms /    58 tokens (  192.19 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.10 ms /     3 runs   (  889.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13818.68 ms /    61 tokens\n",
      " 61%|██████▏   | 2144/3487 [6:19:53<6:07:02, 16.40s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7137.59 ms /    34 tokens (  209.93 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.06 ms /     3 runs   (  886.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9799.79 ms /    37 tokens\n",
      " 62%|██████▏   | 2145/3487 [6:20:03<5:22:33, 14.42s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5622.49 ms /    28 tokens (  200.80 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.85 ms /     3 runs   (  895.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8311.13 ms /    31 tokens\n",
      " 62%|██████▏   | 2146/3487 [6:20:11<4:41:49, 12.61s/it]Llama.generate: 306 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13132.49 ms /    68 tokens (  193.12 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.51 ms /     3 runs   (  885.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15791.99 ms /    71 tokens\n",
      " 62%|██████▏   | 2147/3487 [6:20:27<5:02:59, 13.57s/it]Llama.generate: 308 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2937.26 ms /    13 tokens (  225.94 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2809.92 ms /     3 runs   (  936.64 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5749.63 ms /    16 tokens\n",
      " 62%|██████▏   | 2148/3487 [6:20:33<4:10:28, 11.22s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3070.33 ms /    13 tokens (  236.18 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.33 ms /     3 runs   (  907.11 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5794.06 ms /    16 tokens\n",
      " 62%|██████▏   | 2149/3487 [6:20:38<3:34:01,  9.60s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13399.84 ms /    69 tokens (  194.20 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2770.62 ms /     3 runs   (  923.54 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   16173.24 ms /    72 tokens\n",
      " 62%|██████▏   | 2150/3487 [6:20:55<4:17:53, 11.57s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2003.74 ms /     7 tokens (  286.25 ms per token,     3.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.40 ms /     3 runs   (  895.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4692.79 ms /    10 tokens\n",
      " 62%|██████▏   | 2151/3487 [6:20:59<3:31:47,  9.51s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2220.37 ms /     9 tokens (  246.71 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.96 ms /     3 runs   (  897.65 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4915.47 ms /    12 tokens\n",
      " 62%|██████▏   | 2152/3487 [6:21:04<3:01:00,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3580.27 ms /    14 tokens (  255.73 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2905.05 ms /     3 runs   (  968.35 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6487.88 ms /    17 tokens\n",
      " 62%|██████▏   | 2153/3487 [6:21:11<2:49:56,  7.64s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7558.40 ms /    36 tokens (  209.96 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.03 ms /     3 runs   (  885.01 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10215.79 ms /    39 tokens\n",
      " 62%|██████▏   | 2154/3487 [6:21:21<3:07:00,  8.42s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2214.97 ms /     9 tokens (  246.11 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.01 ms /     3 runs   (  900.00 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4917.74 ms /    12 tokens\n",
      " 62%|██████▏   | 2155/3487 [6:21:26<2:43:37,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13246.41 ms /    69 tokens (  191.98 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.17 ms /     3 runs   (  890.39 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15920.25 ms /    72 tokens\n",
      " 62%|██████▏   | 2156/3487 [6:21:42<3:40:27,  9.94s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5227.62 ms /    26 tokens (  201.06 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.53 ms /     3 runs   (  896.18 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7918.54 ms /    29 tokens\n",
      " 62%|██████▏   | 2157/3487 [6:21:50<3:26:54,  9.33s/it]Llama.generate: 312 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13195.71 ms /    70 tokens (  188.51 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.09 ms /     3 runs   (  881.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15843.27 ms /    73 tokens\n",
      " 62%|██████▏   | 2158/3487 [6:22:06<4:10:03, 11.29s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5041.54 ms /    25 tokens (  201.66 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.92 ms /     3 runs   (  885.97 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7702.70 ms /    28 tokens\n",
      " 62%|██████▏   | 2159/3487 [6:22:13<3:46:06, 10.22s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2175.99 ms /     9 tokens (  241.78 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.93 ms /     3 runs   (  886.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4836.85 ms /    12 tokens\n",
      " 62%|██████▏   | 2160/3487 [6:22:18<3:10:18,  8.60s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4141.04 ms /    20 tokens (  207.05 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.95 ms /     3 runs   (  886.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6805.21 ms /    23 tokens\n",
      " 62%|██████▏   | 2161/3487 [6:22:25<2:58:16,  8.07s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4726.81 ms /    24 tokens (  196.95 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.75 ms /     3 runs   (  885.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7385.75 ms /    27 tokens\n",
      " 62%|██████▏   | 2162/3487 [6:22:32<2:53:40,  7.86s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3162.35 ms /    15 tokens (  210.82 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.08 ms /     3 runs   (  881.03 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5807.40 ms /    18 tokens\n",
      " 62%|██████▏   | 2163/3487 [6:22:38<2:39:59,  7.25s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3590.33 ms /    14 tokens (  256.45 ms per token,     3.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.09 ms /     3 runs   (  886.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6253.21 ms /    17 tokens\n",
      " 62%|██████▏   | 2164/3487 [6:22:44<2:33:19,  6.95s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2508.09 ms /    10 tokens (  250.81 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.82 ms /     3 runs   (  898.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5206.08 ms /    13 tokens\n",
      " 62%|██████▏   | 2165/3487 [6:22:50<2:21:42,  6.43s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7474.94 ms /    37 tokens (  202.03 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.87 ms /     3 runs   (  879.29 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10115.56 ms /    40 tokens\n",
      " 62%|██████▏   | 2166/3487 [6:23:00<2:45:59,  7.54s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2700.49 ms /    12 tokens (  225.04 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.09 ms /     3 runs   (  892.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5381.01 ms /    15 tokens\n",
      " 62%|██████▏   | 2167/3487 [6:23:05<2:31:41,  6.89s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2187.56 ms /     9 tokens (  243.06 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.64 ms /     3 runs   (  885.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4845.52 ms /    12 tokens\n",
      " 62%|██████▏   | 2168/3487 [6:23:10<2:18:07,  6.28s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2447.52 ms /    10 tokens (  244.75 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.46 ms /     3 runs   (  897.82 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5143.09 ms /    13 tokens\n",
      " 62%|██████▏   | 2169/3487 [6:23:15<2:10:32,  5.94s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2691.50 ms /    12 tokens (  224.29 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.32 ms /     3 runs   (  888.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5359.63 ms /    15 tokens\n",
      " 62%|██████▏   | 2170/3487 [6:23:20<2:06:39,  5.77s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2176.37 ms /     9 tokens (  241.82 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.06 ms /     3 runs   (  886.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4837.21 ms /    12 tokens\n",
      " 62%|██████▏   | 2171/3487 [6:23:25<2:00:28,  5.49s/it]Llama.generate: 311 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2969.69 ms /    13 tokens (  228.44 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.06 ms /     3 runs   (  886.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5630.04 ms /    16 tokens\n",
      " 62%|██████▏   | 2172/3487 [6:23:31<2:01:19,  5.54s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2570.30 ms /    11 tokens (  233.66 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.50 ms /     3 runs   (  887.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5235.28 ms /    14 tokens\n",
      " 62%|██████▏   | 2173/3487 [6:23:36<1:59:19,  5.45s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2496.76 ms /     9 tokens (  277.42 ms per token,     3.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.86 ms /     3 runs   (  884.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5153.64 ms /    12 tokens\n",
      " 62%|██████▏   | 2174/3487 [6:23:41<1:57:20,  5.36s/it]Llama.generate: 314 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3903.88 ms /     4 runs   (  975.97 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    3907.14 ms /     5 tokens\n",
      " 62%|██████▏   | 2175/3487 [6:23:45<1:47:45,  4.93s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2152.48 ms /     8 tokens (  269.06 ms per token,     3.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.93 ms /     3 runs   (  894.64 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4838.96 ms /    11 tokens\n",
      " 62%|██████▏   | 2176/3487 [6:23:50<1:47:08,  4.90s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1603.98 ms /     5 tokens (  320.80 ms per token,     3.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2703.42 ms /     3 runs   (  901.14 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4310.14 ms /     8 tokens\n",
      " 62%|██████▏   | 2177/3487 [6:23:54<1:43:14,  4.73s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7835.74 ms /    35 tokens (  223.88 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.76 ms /     3 runs   (  881.92 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10484.15 ms /    38 tokens\n",
      " 62%|██████▏   | 2178/3487 [6:24:05<2:20:53,  6.46s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4613.02 ms /    22 tokens (  209.68 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.27 ms /     3 runs   (  888.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7281.30 ms /    25 tokens\n",
      " 62%|██████▏   | 2179/3487 [6:24:12<2:26:12,  6.71s/it]Llama.generate: 306 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14420.61 ms /    61 tokens (  236.40 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4336.59 ms /     3 runs   ( 1445.53 ms per token,     0.69 tokens per second)\n",
      "llama_perf_context_print:       total time =   18760.40 ms /    64 tokens\n",
      " 63%|██████▎   | 2180/3487 [6:24:31<3:44:56, 10.33s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6194.24 ms /    25 tokens (  247.77 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3856.00 ms /     3 runs   ( 1285.33 ms per token,     0.78 tokens per second)\n",
      "llama_perf_context_print:       total time =   10053.71 ms /    28 tokens\n",
      " 63%|██████▎   | 2181/3487 [6:24:41<3:43:03, 10.25s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7065.92 ms /    32 tokens (  220.81 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3513.95 ms /     3 runs   ( 1171.32 ms per token,     0.85 tokens per second)\n",
      "llama_perf_context_print:       total time =   10583.12 ms /    35 tokens\n",
      " 63%|██████▎   | 2182/3487 [6:24:52<3:45:08, 10.35s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2882.83 ms /     9 tokens (  320.31 ms per token,     3.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.44 ms /     3 runs   (  905.48 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5601.56 ms /    12 tokens\n",
      " 63%|██████▎   | 2183/3487 [6:24:57<3:14:03,  8.93s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2385.48 ms /     5 tokens (  477.10 ms per token,     2.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2799.53 ms /     3 runs   (  933.18 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5187.47 ms /     8 tokens\n",
      " 63%|██████▎   | 2184/3487 [6:25:02<2:49:36,  7.81s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4030.14 ms /    18 tokens (  223.90 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.22 ms /     3 runs   (  896.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6722.86 ms /    21 tokens\n",
      " 63%|██████▎   | 2185/3487 [6:25:09<2:42:28,  7.49s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9613.59 ms /    49 tokens (  196.20 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.64 ms /     3 runs   (  895.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12302.35 ms /    52 tokens\n",
      " 63%|██████▎   | 2186/3487 [6:25:22<3:13:43,  8.93s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11206.26 ms /    57 tokens (  196.60 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3104.82 ms /     3 runs   ( 1034.94 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =   14314.04 ms /    60 tokens\n",
      " 63%|██████▎   | 2187/3487 [6:25:36<3:48:35, 10.55s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3484.45 ms /    14 tokens (  248.89 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2823.78 ms /     3 runs   (  941.26 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    6311.01 ms /    17 tokens\n",
      " 63%|██████▎   | 2188/3487 [6:25:42<3:20:56,  9.28s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11101.32 ms /    57 tokens (  194.76 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.11 ms /     3 runs   (  876.37 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13733.27 ms /    60 tokens\n",
      " 63%|██████▎   | 2189/3487 [6:25:56<3:49:44, 10.62s/it]Llama.generate: 307 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19537.79 ms /   103 tokens (  189.69 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.99 ms /     3 runs   (  897.33 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   22232.34 ms /   106 tokens\n",
      " 63%|██████▎   | 2190/3487 [6:26:18<5:04:56, 14.11s/it]Llama.generate: 307 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19061.16 ms /    98 tokens (  194.50 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.92 ms /     3 runs   (  903.97 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   21775.77 ms /   101 tokens\n",
      " 63%|██████▎   | 2191/3487 [6:26:40<5:54:27, 16.41s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12820.20 ms /    65 tokens (  197.23 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.82 ms /     3 runs   (  880.61 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15464.22 ms /    68 tokens\n",
      " 63%|██████▎   | 2192/3487 [6:26:55<5:48:07, 16.13s/it]Llama.generate: 308 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4661.25 ms /    21 tokens (  221.96 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.43 ms /     3 runs   (  879.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7301.05 ms /    24 tokens\n",
      " 63%|██████▎   | 2193/3487 [6:27:03<4:50:47, 13.48s/it]Llama.generate: 307 prefix-match hit, remaining 81 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15220.87 ms /    81 tokens (  187.91 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.15 ms /     3 runs   (  892.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   17900.78 ms /    84 tokens\n",
      " 63%|██████▎   | 2194/3487 [6:27:21<5:19:10, 14.81s/it]Llama.generate: 307 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13094.12 ms /    69 tokens (  189.77 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.37 ms /     3 runs   (  882.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15743.03 ms /    72 tokens\n",
      " 63%|██████▎   | 2195/3487 [6:27:36<5:25:00, 15.09s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2671.96 ms /    12 tokens (  222.66 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.78 ms /     3 runs   (  894.93 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5359.03 ms /    15 tokens\n",
      " 63%|██████▎   | 2196/3487 [6:27:42<4:21:58, 12.18s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4741.57 ms /    23 tokens (  206.16 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.83 ms /     3 runs   (  885.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7402.25 ms /    26 tokens\n",
      " 63%|██████▎   | 2197/3487 [6:27:49<3:51:01, 10.75s/it]Llama.generate: 307 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11408.27 ms /    61 tokens (  187.02 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.34 ms /     3 runs   (  884.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14064.23 ms /    64 tokens\n",
      " 63%|██████▎   | 2198/3487 [6:28:03<4:12:18, 11.74s/it]Llama.generate: 307 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14380.07 ms /    77 tokens (  186.75 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.09 ms /     3 runs   (  889.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   17051.28 ms /    80 tokens\n",
      " 63%|██████▎   | 2199/3487 [6:28:20<4:46:20, 13.34s/it]Llama.generate: 307 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26751.16 ms /   107 tokens (  250.01 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3533.83 ms /     3 runs   ( 1177.94 ms per token,     0.85 tokens per second)\n",
      "llama_perf_context_print:       total time =   30287.46 ms /   110 tokens\n",
      " 63%|██████▎   | 2200/3487 [6:28:51<6:35:14, 18.43s/it]Llama.generate: 307 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21091.30 ms /    82 tokens (  257.21 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2919.89 ms /     3 runs   (  973.30 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   24015.13 ms /    85 tokens\n",
      " 63%|██████▎   | 2201/3487 [6:29:15<7:10:56, 20.11s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2364.87 ms /     9 tokens (  262.76 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2742.72 ms /     3 runs   (  914.24 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5110.95 ms /    12 tokens\n",
      " 63%|██████▎   | 2202/3487 [6:29:20<5:34:20, 15.61s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5762.82 ms /    25 tokens (  230.51 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.64 ms /     3 runs   (  896.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8454.99 ms /    28 tokens\n",
      " 63%|██████▎   | 2203/3487 [6:29:28<4:48:11, 13.47s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2254.50 ms /     9 tokens (  250.50 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2781.52 ms /     3 runs   (  927.17 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5038.51 ms /    12 tokens\n",
      " 63%|██████▎   | 2204/3487 [6:29:33<3:53:57, 10.94s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3767.03 ms /    17 tokens (  221.59 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.08 ms /     3 runs   (  882.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6418.14 ms /    20 tokens\n",
      " 63%|██████▎   | 2205/3487 [6:29:40<3:24:50,  9.59s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5015.90 ms /    24 tokens (  209.00 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2727.51 ms /     3 runs   (  909.17 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7746.05 ms /    27 tokens\n",
      " 63%|██████▎   | 2206/3487 [6:29:47<3:12:56,  9.04s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8153.16 ms /    40 tokens (  203.83 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.18 ms /     3 runs   (  884.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10809.68 ms /    43 tokens\n",
      " 63%|██████▎   | 2207/3487 [6:29:58<3:24:12,  9.57s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2740.62 ms /    12 tokens (  228.38 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.88 ms /     3 runs   (  899.29 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5440.76 ms /    15 tokens\n",
      " 63%|██████▎   | 2208/3487 [6:30:04<2:57:40,  8.34s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6187.07 ms /    31 tokens (  199.58 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.02 ms /     3 runs   (  883.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8840.33 ms /    34 tokens\n",
      " 63%|██████▎   | 2209/3487 [6:30:13<3:00:48,  8.49s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7457.73 ms /    37 tokens (  201.56 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.07 ms /     3 runs   (  884.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10112.73 ms /    40 tokens\n",
      " 63%|██████▎   | 2210/3487 [6:30:23<3:11:05,  8.98s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2347.11 ms /     9 tokens (  260.79 ms per token,     3.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.21 ms /     3 runs   (  891.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5023.44 ms /    12 tokens\n",
      " 63%|██████▎   | 2211/3487 [6:30:28<2:45:46,  7.79s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2619.23 ms /    11 tokens (  238.11 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.66 ms /     3 runs   (  897.22 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5316.09 ms /    14 tokens\n",
      " 63%|██████▎   | 2212/3487 [6:30:33<2:29:53,  7.05s/it]Llama.generate: 316 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4321.42 ms /     4 runs   ( 1080.35 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    4324.26 ms /     5 tokens\n",
      " 63%|██████▎   | 2213/3487 [6:30:37<2:12:26,  6.24s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3946.62 ms /    13 tokens (  303.59 ms per token,     3.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2805.41 ms /     3 runs   (  935.14 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6754.54 ms /    16 tokens\n",
      " 63%|██████▎   | 2214/3487 [6:30:44<2:15:40,  6.39s/it]Llama.generate: 306 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16322.97 ms /    83 tokens (  196.66 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.71 ms /     3 runs   (  907.90 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   19048.93 ms /    86 tokens\n",
      " 64%|██████▎   | 2215/3487 [6:31:03<3:36:05, 10.19s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7962.50 ms /    40 tokens (  199.06 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.29 ms /     3 runs   (  880.43 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10606.22 ms /    43 tokens\n",
      " 64%|██████▎   | 2216/3487 [6:31:14<3:38:36, 10.32s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3032.84 ms /    13 tokens (  233.30 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.60 ms /     3 runs   (  894.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5719.60 ms /    16 tokens\n",
      " 64%|██████▎   | 2217/3487 [6:31:20<3:09:16,  8.94s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6165.33 ms /    31 tokens (  198.88 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.11 ms /     3 runs   (  889.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8837.30 ms /    34 tokens\n",
      " 64%|██████▎   | 2218/3487 [6:31:28<3:08:30,  8.91s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2548.93 ms /    10 tokens (  254.89 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.36 ms /     3 runs   (  895.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5236.65 ms /    13 tokens\n",
      " 64%|██████▎   | 2219/3487 [6:31:34<2:45:06,  7.81s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2611.38 ms /    11 tokens (  237.40 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.54 ms /     3 runs   (  897.51 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5306.28 ms /    14 tokens\n",
      " 64%|██████▎   | 2220/3487 [6:31:39<2:29:08,  7.06s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2693.85 ms /    11 tokens (  244.90 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2753.08 ms /     3 runs   (  917.69 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5449.03 ms /    14 tokens\n",
      " 64%|██████▎   | 2221/3487 [6:31:44<2:18:52,  6.58s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5965.62 ms /    30 tokens (  198.85 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4047.74 ms /     3 runs   ( 1349.25 ms per token,     0.74 tokens per second)\n",
      "llama_perf_context_print:       total time =   10015.66 ms /    33 tokens\n",
      " 64%|██████▎   | 2222/3487 [6:31:54<2:40:33,  7.62s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5804.78 ms /    18 tokens (  322.49 ms per token,     3.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3031.40 ms /     3 runs   ( 1010.47 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    8839.08 ms /    21 tokens\n",
      " 64%|██████▍   | 2223/3487 [6:32:03<2:48:13,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3530.59 ms /    15 tokens (  235.37 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2802.81 ms /     3 runs   (  934.27 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6336.42 ms /    18 tokens\n",
      " 64%|██████▍   | 2224/3487 [6:32:10<2:37:44,  7.49s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3684.28 ms /    16 tokens (  230.27 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.64 ms /     3 runs   (  895.21 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6372.33 ms /    19 tokens\n",
      " 64%|██████▍   | 2225/3487 [6:32:16<2:30:35,  7.16s/it]Llama.generate: 310 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3764.18 ms /    18 tokens (  209.12 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.67 ms /     3 runs   (  905.89 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6484.32 ms /    21 tokens\n",
      " 64%|██████▍   | 2226/3487 [6:32:22<2:26:16,  6.96s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5912.34 ms /    29 tokens (  203.87 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.97 ms /     3 runs   (  902.32 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8621.99 ms /    32 tokens\n",
      " 64%|██████▍   | 2227/3487 [6:32:31<2:36:41,  7.46s/it]Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8774.14 ms /    44 tokens (  199.41 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.46 ms /     3 runs   (  896.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11465.24 ms /    47 tokens\n",
      " 64%|██████▍   | 2228/3487 [6:32:43<3:01:49,  8.67s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7006.98 ms /    28 tokens (  250.25 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2840.63 ms /     3 runs   (  946.88 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    9850.43 ms /    31 tokens\n",
      " 64%|██████▍   | 2229/3487 [6:32:52<3:09:11,  9.02s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3121.81 ms /     7 tokens (  445.97 ms per token,     2.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3501.24 ms /     3 runs   ( 1167.08 ms per token,     0.86 tokens per second)\n",
      "llama_perf_context_print:       total time =    6625.99 ms /    10 tokens\n",
      " 64%|██████▍   | 2230/3487 [6:32:59<2:54:02,  8.31s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4708.68 ms /    22 tokens (  214.03 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.94 ms /     3 runs   (  888.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7378.26 ms /    25 tokens\n",
      " 64%|██████▍   | 2231/3487 [6:33:06<2:48:07,  8.03s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7130.99 ms /    33 tokens (  216.09 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.88 ms /     3 runs   (  893.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9814.00 ms /    36 tokens\n",
      " 64%|██████▍   | 2232/3487 [6:33:16<2:59:13,  8.57s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2207.05 ms /     6 tokens (  367.84 ms per token,     2.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.24 ms /     3 runs   (  882.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4858.50 ms /     9 tokens\n",
      " 64%|██████▍   | 2233/3487 [6:33:21<2:35:52,  7.46s/it]Llama.generate: 306 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14130.31 ms /    75 tokens (  188.40 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.76 ms /     3 runs   (  880.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16776.01 ms /    78 tokens\n",
      " 64%|██████▍   | 2234/3487 [6:33:38<3:34:10, 10.26s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4494.28 ms /    22 tokens (  204.29 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.69 ms /     3 runs   (  890.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7169.50 ms /    25 tokens\n",
      " 64%|██████▍   | 2235/3487 [6:33:45<3:14:44,  9.33s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3439.26 ms /    16 tokens (  214.95 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.13 ms /     3 runs   (  895.71 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6128.96 ms /    19 tokens\n",
      " 64%|██████▍   | 2236/3487 [6:33:51<2:54:35,  8.37s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4104.59 ms /    19 tokens (  216.03 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.16 ms /     3 runs   (  904.05 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6819.86 ms /    22 tokens\n",
      " 64%|██████▍   | 2237/3487 [6:33:58<2:44:48,  7.91s/it]Llama.generate: 306 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14029.20 ms /    72 tokens (  194.85 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.39 ms /     3 runs   (  889.13 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16699.42 ms /    75 tokens\n",
      " 64%|██████▍   | 2238/3487 [6:34:15<3:39:37, 10.55s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4207.44 ms /    20 tokens (  210.37 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.39 ms /     3 runs   (  909.80 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6939.99 ms /    23 tokens\n",
      " 64%|██████▍   | 2239/3487 [6:34:22<3:16:58,  9.47s/it]Llama.generate: 306 prefix-match hit, remaining 106 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19916.13 ms /   106 tokens (  187.89 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.13 ms /     3 runs   (  891.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   22592.59 ms /   109 tokens\n",
      " 64%|██████▍   | 2240/3487 [6:34:44<4:38:40, 13.41s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2182.52 ms /     8 tokens (  272.81 ms per token,     3.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2783.76 ms /     3 runs   (  927.92 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    4968.50 ms /    11 tokens\n",
      " 64%|██████▍   | 2241/3487 [6:34:49<3:45:56, 10.88s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7343.76 ms /    34 tokens (  215.99 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.26 ms /     3 runs   (  880.75 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9988.66 ms /    37 tokens\n",
      " 64%|██████▍   | 2242/3487 [6:34:59<3:40:15, 10.61s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2164.19 ms /     6 tokens (  360.70 ms per token,     2.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.24 ms /     3 runs   (  883.08 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4815.88 ms /     9 tokens\n",
      " 64%|██████▍   | 2243/3487 [6:35:04<3:04:03,  8.88s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3257.47 ms /    15 tokens (  217.16 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.66 ms /     3 runs   (  885.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5915.50 ms /    18 tokens\n",
      " 64%|██████▍   | 2244/3487 [6:35:10<2:45:33,  7.99s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2657.60 ms /    11 tokens (  241.60 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.90 ms /     3 runs   (  887.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5322.91 ms /    14 tokens\n",
      " 64%|██████▍   | 2245/3487 [6:35:15<2:28:54,  7.19s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3233.89 ms /    14 tokens (  230.99 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2748.31 ms /     3 runs   (  916.10 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5985.00 ms /    17 tokens\n",
      " 64%|██████▍   | 2246/3487 [6:35:21<2:21:20,  6.83s/it]Llama.generate: 308 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4286.46 ms /    20 tokens (  214.32 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.33 ms /     3 runs   (  879.44 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6927.21 ms /    23 tokens\n",
      " 64%|██████▍   | 2247/3487 [6:35:28<2:21:51,  6.86s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2626.69 ms /    11 tokens (  238.79 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.77 ms /     3 runs   (  901.92 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5334.81 ms /    14 tokens\n",
      " 64%|██████▍   | 2248/3487 [6:35:34<2:12:19,  6.41s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2269.54 ms /     9 tokens (  252.17 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.58 ms /     3 runs   (  885.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4929.17 ms /    12 tokens\n",
      " 64%|██████▍   | 2249/3487 [6:35:39<2:03:06,  5.97s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3408.45 ms /    14 tokens (  243.46 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.24 ms /     3 runs   (  908.41 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6136.95 ms /    17 tokens\n",
      " 65%|██████▍   | 2250/3487 [6:35:45<2:04:07,  6.02s/it]Llama.generate: 307 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10642.38 ms /    56 tokens (  190.04 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.00 ms /     3 runs   (  889.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13314.45 ms /    59 tokens\n",
      " 65%|██████▍   | 2251/3487 [6:35:58<2:49:08,  8.21s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3255.51 ms /    15 tokens (  217.03 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.32 ms /     3 runs   (  898.11 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5952.16 ms /    18 tokens\n",
      " 65%|██████▍   | 2252/3487 [6:36:04<2:35:06,  7.54s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11368.81 ms /    57 tokens (  199.45 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2752.61 ms /     3 runs   (  917.54 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   14123.82 ms /    60 tokens\n",
      " 65%|██████▍   | 2253/3487 [6:36:18<3:15:40,  9.51s/it]Llama.generate: 306 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13721.68 ms /    71 tokens (  193.26 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.45 ms /     3 runs   (  880.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16366.38 ms /    74 tokens\n",
      " 65%|██████▍   | 2254/3487 [6:36:35<3:57:48, 11.57s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8436.31 ms /    43 tokens (  196.19 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.42 ms /     3 runs   (  879.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11076.21 ms /    46 tokens\n",
      " 65%|██████▍   | 2255/3487 [6:36:46<3:54:37, 11.43s/it]Llama.generate: 308 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10901.97 ms /    59 tokens (  184.78 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.38 ms /     3 runs   (  882.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13553.35 ms /    62 tokens\n",
      " 65%|██████▍   | 2256/3487 [6:36:59<4:07:34, 12.07s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4174.92 ms /    20 tokens (  208.75 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.89 ms /     3 runs   (  894.63 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6861.79 ms /    23 tokens\n",
      " 65%|██████▍   | 2257/3487 [6:37:06<3:35:24, 10.51s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7234.60 ms /    36 tokens (  200.96 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.41 ms /     3 runs   (  882.80 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9885.84 ms /    39 tokens\n",
      " 65%|██████▍   | 2258/3487 [6:37:16<3:31:28, 10.32s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3492.22 ms /    16 tokens (  218.26 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.53 ms /     3 runs   (  891.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6170.32 ms /    19 tokens\n",
      " 65%|██████▍   | 2259/3487 [6:37:22<3:05:50,  9.08s/it]Llama.generate: 306 prefix-match hit, remaining 89 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16490.06 ms /    89 tokens (  185.28 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.09 ms /     3 runs   (  881.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19136.79 ms /    92 tokens\n",
      " 65%|██████▍   | 2260/3487 [6:37:41<4:07:26, 12.10s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4691.93 ms /    23 tokens (  204.00 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.94 ms /     3 runs   (  890.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7367.46 ms /    26 tokens\n",
      " 65%|██████▍   | 2261/3487 [6:37:49<3:38:17, 10.68s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2627.63 ms /    11 tokens (  238.88 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.55 ms /     3 runs   (  890.18 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5301.27 ms /    14 tokens\n",
      " 65%|██████▍   | 2262/3487 [6:37:54<3:05:11,  9.07s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7625.81 ms /    34 tokens (  224.29 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.46 ms /     3 runs   (  896.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10316.55 ms /    37 tokens\n",
      " 65%|██████▍   | 2263/3487 [6:38:04<3:12:43,  9.45s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5450.34 ms /    27 tokens (  201.86 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.91 ms /     3 runs   (  879.64 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8091.54 ms /    30 tokens\n",
      " 65%|██████▍   | 2264/3487 [6:38:12<3:04:19,  9.04s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6280.94 ms /    32 tokens (  196.28 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.49 ms /     3 runs   (  897.83 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8977.33 ms /    35 tokens\n",
      " 65%|██████▍   | 2265/3487 [6:38:21<3:03:49,  9.03s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3215.85 ms /    15 tokens (  214.39 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.78 ms /     3 runs   (  886.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5878.52 ms /    18 tokens\n",
      " 65%|██████▍   | 2266/3487 [6:38:27<2:44:30,  8.08s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5260.36 ms /    27 tokens (  194.83 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.21 ms /     3 runs   (  883.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7912.96 ms /    30 tokens\n",
      " 65%|██████▌   | 2267/3487 [6:38:35<2:43:23,  8.04s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7165.40 ms /    33 tokens (  217.13 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.46 ms /     3 runs   (  877.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9800.90 ms /    36 tokens\n",
      " 65%|██████▌   | 2268/3487 [6:38:45<2:54:03,  8.57s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5279.79 ms /    27 tokens (  195.55 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.99 ms /     3 runs   (  890.66 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7954.23 ms /    30 tokens\n",
      " 65%|██████▌   | 2269/3487 [6:38:53<2:50:14,  8.39s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4035.31 ms /    19 tokens (  212.38 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2733.95 ms /     3 runs   (  911.32 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6771.55 ms /    22 tokens\n",
      " 65%|██████▌   | 2270/3487 [6:39:00<2:40:19,  7.90s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3372.86 ms /    15 tokens (  224.86 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2738.31 ms /     3 runs   (  912.77 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6113.65 ms /    18 tokens\n",
      " 65%|██████▌   | 2271/3487 [6:39:06<2:29:20,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5501.42 ms /    26 tokens (  211.59 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.97 ms /     3 runs   (  881.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8147.61 ms /    29 tokens\n",
      " 65%|██████▌   | 2272/3487 [6:39:14<2:33:59,  7.60s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2683.17 ms /     9 tokens (  298.13 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.85 ms /     3 runs   (  884.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5339.83 ms /    12 tokens\n",
      " 65%|██████▌   | 2273/3487 [6:39:19<2:20:11,  6.93s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2129.70 ms /     8 tokens (  266.21 ms per token,     3.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.94 ms /     3 runs   (  890.31 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4803.11 ms /    11 tokens\n",
      " 65%|██████▌   | 2274/3487 [6:39:24<2:07:13,  6.29s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5244.04 ms /    26 tokens (  201.69 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.10 ms /     3 runs   (  890.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7917.91 ms /    29 tokens\n",
      " 65%|██████▌   | 2275/3487 [6:39:32<2:17:01,  6.78s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4342.11 ms /    21 tokens (  206.77 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.38 ms /     3 runs   (  895.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7031.09 ms /    24 tokens\n",
      " 65%|██████▌   | 2276/3487 [6:39:39<2:18:27,  6.86s/it]Llama.generate: 306 prefix-match hit, remaining 232 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   42247.84 ms /   232 tokens (  182.10 ms per token,     5.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.49 ms /     3 runs   (  889.16 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   44918.13 ms /   235 tokens\n",
      " 65%|██████▌   | 2277/3487 [6:40:24<6:08:38, 18.28s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5435.50 ms /    27 tokens (  201.31 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.07 ms /     3 runs   (  893.69 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8118.83 ms /    30 tokens\n",
      " 65%|██████▌   | 2278/3487 [6:40:32<5:06:58, 15.23s/it]Llama.generate: 307 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13239.13 ms /    67 tokens (  197.60 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.71 ms /     3 runs   (  896.90 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   15932.31 ms /    70 tokens\n",
      " 65%|██████▌   | 2279/3487 [6:40:48<5:10:58, 15.45s/it]Llama.generate: 307 prefix-match hit, remaining 129 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24387.29 ms /   129 tokens (  189.05 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.72 ms /     3 runs   (  880.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27032.64 ms /   132 tokens\n",
      " 65%|██████▌   | 2280/3487 [6:41:15<6:20:42, 18.93s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8826.61 ms /    46 tokens (  191.88 ms per token,     5.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.86 ms /     3 runs   (  885.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11486.07 ms /    49 tokens\n",
      " 65%|██████▌   | 2281/3487 [6:41:27<5:35:35, 16.70s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9226.80 ms /    45 tokens (  205.04 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.94 ms /     3 runs   (  890.65 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11901.03 ms /    48 tokens\n",
      " 65%|██████▌   | 2282/3487 [6:41:39<5:06:27, 15.26s/it]Llama.generate: 307 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14031.96 ms /    74 tokens (  189.62 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.81 ms /     3 runs   (  894.60 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16718.47 ms /    77 tokens\n",
      " 65%|██████▌   | 2283/3487 [6:41:55<5:15:02, 15.70s/it]Llama.generate: 307 prefix-match hit, remaining 120 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23787.31 ms /   120 tokens (  198.23 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.36 ms /     3 runs   (  896.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   26478.40 ms /   123 tokens\n",
      " 66%|██████▌   | 2284/3487 [6:42:22<6:19:39, 18.94s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3578.02 ms /    14 tokens (  255.57 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2882.80 ms /     3 runs   (  960.93 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    6463.18 ms /    17 tokens\n",
      " 66%|██████▌   | 2285/3487 [6:42:28<5:04:27, 15.20s/it]Llama.generate: 306 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15527.11 ms /    82 tokens (  189.36 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.76 ms /     3 runs   (  894.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   18213.23 ms /    85 tokens\n",
      " 66%|██████▌   | 2286/3487 [6:42:46<5:22:21, 16.10s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4262.56 ms /    21 tokens (  202.98 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.87 ms /     3 runs   (  905.62 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6981.80 ms /    24 tokens\n",
      " 66%|██████▌   | 2287/3487 [6:42:53<4:27:24, 13.37s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6228.39 ms /    32 tokens (  194.64 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.60 ms /     3 runs   (  884.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8885.73 ms /    35 tokens\n",
      " 66%|██████▌   | 2288/3487 [6:43:02<4:00:20, 12.03s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8864.94 ms /    30 tokens (  295.50 ms per token,     3.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3700.34 ms /     3 runs   ( 1233.45 ms per token,     0.81 tokens per second)\n",
      "llama_perf_context_print:       total time =   12568.36 ms /    33 tokens\n",
      " 66%|██████▌   | 2289/3487 [6:43:15<4:03:26, 12.19s/it]Llama.generate: 308 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5735.41 ms /    23 tokens (  249.37 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3308.69 ms /     3 runs   ( 1102.90 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =    9047.68 ms /    26 tokens\n",
      " 66%|██████▌   | 2290/3487 [6:43:24<3:44:28, 11.25s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5640.25 ms /    24 tokens (  235.01 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2877.04 ms /     3 runs   (  959.01 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    8520.31 ms /    27 tokens\n",
      " 66%|██████▌   | 2291/3487 [6:43:33<3:28:01, 10.44s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4156.05 ms /    16 tokens (  259.75 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2832.35 ms /     3 runs   (  944.12 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    6991.01 ms /    19 tokens\n",
      " 66%|██████▌   | 2292/3487 [6:43:40<3:07:19,  9.41s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5388.90 ms /    25 tokens (  215.56 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2812.64 ms /     3 runs   (  937.55 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    8204.05 ms /    28 tokens\n",
      " 66%|██████▌   | 2293/3487 [6:43:48<3:00:03,  9.05s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3508.00 ms /    15 tokens (  233.87 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2803.59 ms /     3 runs   (  934.53 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6314.76 ms /    18 tokens\n",
      " 66%|██████▌   | 2294/3487 [6:43:54<2:43:39,  8.23s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5280.91 ms /    24 tokens (  220.04 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.74 ms /     3 runs   (  909.91 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8012.50 ms /    27 tokens\n",
      " 66%|██████▌   | 2295/3487 [6:44:02<2:42:15,  8.17s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7479.68 ms /    35 tokens (  213.71 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2784.18 ms /     3 runs   (  928.06 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   10266.55 ms /    38 tokens\n",
      " 66%|██████▌   | 2296/3487 [6:44:12<2:54:40,  8.80s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5081.75 ms /    21 tokens (  241.99 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2868.85 ms /     3 runs   (  956.28 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    7953.38 ms /    24 tokens\n",
      " 66%|██████▌   | 2297/3487 [6:44:20<2:49:33,  8.55s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3545.25 ms /    16 tokens (  221.58 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.77 ms /     3 runs   (  890.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6219.93 ms /    19 tokens\n",
      " 66%|██████▌   | 2298/3487 [6:44:27<2:35:36,  7.85s/it]Llama.generate: 307 prefix-match hit, remaining 151 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28106.48 ms /   151 tokens (  186.14 ms per token,     5.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.80 ms /     3 runs   (  896.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   30800.13 ms /   154 tokens\n",
      " 66%|██████▌   | 2299/3487 [6:44:57<4:51:50, 14.74s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4253.85 ms /    21 tokens (  202.56 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.46 ms /     3 runs   (  893.49 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6936.65 ms /    24 tokens\n",
      " 66%|██████▌   | 2300/3487 [6:45:04<4:05:21, 12.40s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2085.39 ms /     8 tokens (  260.67 ms per token,     3.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.02 ms /     3 runs   (  907.01 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4807.99 ms /    11 tokens\n",
      " 66%|██████▌   | 2301/3487 [6:45:09<3:20:09, 10.13s/it]Llama.generate: 307 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15089.26 ms /    78 tokens (  193.45 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.73 ms /     3 runs   (  876.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17722.93 ms /    81 tokens\n",
      " 66%|██████▌   | 2302/3487 [6:45:27<4:05:03, 12.41s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4385.60 ms /    20 tokens (  219.28 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2792.96 ms /     3 runs   (  930.99 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7180.62 ms /    23 tokens\n",
      " 66%|██████▌   | 2303/3487 [6:45:34<3:33:57, 10.84s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7445.19 ms /    34 tokens (  218.98 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.57 ms /     3 runs   (  897.86 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10141.28 ms /    37 tokens\n",
      " 66%|██████▌   | 2304/3487 [6:45:44<3:29:40, 10.63s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6184.32 ms /    28 tokens (  220.87 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.52 ms /     3 runs   (  891.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8862.60 ms /    31 tokens\n",
      " 66%|██████▌   | 2305/3487 [6:45:53<3:19:04, 10.11s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7194.87 ms /    34 tokens (  211.61 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.25 ms /     3 runs   (  896.08 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9885.48 ms /    37 tokens\n",
      " 66%|██████▌   | 2306/3487 [6:46:03<3:17:38, 10.04s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5031.50 ms /    23 tokens (  218.76 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.37 ms /     3 runs   (  897.12 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7725.75 ms /    26 tokens\n",
      " 66%|██████▌   | 2307/3487 [6:46:11<3:03:51,  9.35s/it]Llama.generate: 314 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3571.03 ms /    16 tokens (  223.19 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2714.48 ms /     3 runs   (  904.83 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6287.59 ms /    19 tokens\n",
      " 66%|██████▌   | 2308/3487 [6:46:17<2:45:41,  8.43s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5839.70 ms /    29 tokens (  201.37 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.25 ms /     3 runs   (  896.08 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8530.58 ms /    32 tokens\n",
      " 66%|██████▌   | 2309/3487 [6:46:26<2:46:11,  8.47s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4051.24 ms /    19 tokens (  213.22 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.67 ms /     3 runs   (  887.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6716.07 ms /    22 tokens\n",
      " 66%|██████▌   | 2310/3487 [6:46:32<2:35:48,  7.94s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2501.66 ms /    10 tokens (  250.17 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2870.07 ms /     3 runs   (  956.69 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    5373.92 ms /    13 tokens\n",
      " 66%|██████▋   | 2311/3487 [6:46:38<2:20:36,  7.17s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2846.37 ms /    12 tokens (  237.20 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2754.08 ms /     3 runs   (  918.03 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5603.92 ms /    15 tokens\n",
      " 66%|██████▋   | 2312/3487 [6:46:43<2:11:20,  6.71s/it]Llama.generate: 307 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15992.17 ms /    84 tokens (  190.38 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.29 ms /     3 runs   (  883.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18644.29 ms /    87 tokens\n",
      " 66%|██████▋   | 2313/3487 [6:47:02<3:21:21, 10.29s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2597.83 ms /    10 tokens (  259.78 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2766.12 ms /     3 runs   (  922.04 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5366.75 ms /    13 tokens\n",
      " 66%|██████▋   | 2314/3487 [6:47:07<2:52:22,  8.82s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5822.61 ms /    29 tokens (  200.78 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.56 ms /     3 runs   (  904.52 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8539.13 ms /    32 tokens\n",
      " 66%|██████▋   | 2315/3487 [6:47:16<2:50:38,  8.74s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3705.28 ms /    16 tokens (  231.58 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.98 ms /     3 runs   (  898.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6405.00 ms /    19 tokens\n",
      " 66%|██████▋   | 2316/3487 [6:47:22<2:36:53,  8.04s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3227.86 ms /    14 tokens (  230.56 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.00 ms /     3 runs   (  896.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5920.16 ms /    17 tokens\n",
      " 66%|██████▋   | 2317/3487 [6:47:28<2:24:24,  7.41s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12451.62 ms /    64 tokens (  194.56 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.70 ms /     3 runs   (  893.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15135.40 ms /    67 tokens\n",
      " 66%|██████▋   | 2318/3487 [6:47:43<3:09:31,  9.73s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3315.77 ms /    15 tokens (  221.05 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2736.98 ms /     3 runs   (  912.33 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6055.51 ms /    18 tokens\n",
      " 67%|██████▋   | 2319/3487 [6:47:49<2:47:58,  8.63s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3375.67 ms /    15 tokens (  225.04 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.52 ms /     3 runs   (  900.51 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6079.68 ms /    18 tokens\n",
      " 67%|██████▋   | 2320/3487 [6:47:55<2:33:00,  7.87s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6135.00 ms /    28 tokens (  219.11 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.09 ms /     3 runs   (  894.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8821.92 ms /    31 tokens\n",
      " 67%|██████▋   | 2321/3487 [6:48:04<2:38:29,  8.16s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3209.55 ms /    14 tokens (  229.25 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.41 ms /     3 runs   (  897.14 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5903.76 ms /    17 tokens\n",
      " 67%|██████▋   | 2322/3487 [6:48:10<2:25:16,  7.48s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8301.98 ms /    41 tokens (  202.49 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.38 ms /     3 runs   (  879.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10941.87 ms /    44 tokens\n",
      " 67%|██████▋   | 2323/3487 [6:48:21<2:45:20,  8.52s/it]Llama.generate: 307 prefix-match hit, remaining 141 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26424.67 ms /   141 tokens (  187.41 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.52 ms /     3 runs   (  893.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   29108.82 ms /   144 tokens\n",
      " 67%|██████▋   | 2324/3487 [6:48:50<4:44:57, 14.70s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3068.94 ms /    12 tokens (  255.74 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3241.10 ms /     3 runs   ( 1080.37 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    6313.34 ms /    15 tokens\n",
      " 67%|██████▋   | 2325/3487 [6:48:57<3:56:02, 12.19s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5179.89 ms /    24 tokens (  215.83 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.53 ms /     3 runs   (  889.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7850.94 ms /    27 tokens\n",
      " 67%|██████▋   | 2326/3487 [6:49:04<3:30:42, 10.89s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2022.22 ms /     7 tokens (  288.89 ms per token,     3.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.89 ms /     3 runs   (  890.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4697.75 ms /    10 tokens\n",
      " 67%|██████▋   | 2327/3487 [6:49:09<2:54:39,  9.03s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2273.78 ms /     9 tokens (  252.64 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.46 ms /     3 runs   (  904.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4988.47 ms /    12 tokens\n",
      " 67%|██████▋   | 2328/3487 [6:49:14<2:31:07,  7.82s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1653.28 ms /     5 tokens (  330.66 ms per token,     3.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2727.20 ms /     3 runs   (  909.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4383.33 ms /     8 tokens\n",
      " 67%|██████▋   | 2329/3487 [6:49:19<2:11:07,  6.79s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2258.58 ms /     8 tokens (  282.32 ms per token,     3.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2734.71 ms /     3 runs   (  911.57 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4995.85 ms /    11 tokens\n",
      " 67%|██████▋   | 2330/3487 [6:49:24<2:00:39,  6.26s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2510.21 ms /     7 tokens (  358.60 ms per token,     2.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.06 ms /     3 runs   (  888.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5176.88 ms /    10 tokens\n",
      " 67%|██████▋   | 2331/3487 [6:49:29<1:54:21,  5.94s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1983.62 ms /     7 tokens (  283.38 ms per token,     3.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.56 ms /     3 runs   (  887.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4649.08 ms /    10 tokens\n",
      " 67%|██████▋   | 2332/3487 [6:49:33<1:46:52,  5.55s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2248.93 ms /     9 tokens (  249.88 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.39 ms /     3 runs   (  894.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4936.22 ms /    12 tokens\n",
      " 67%|██████▋   | 2333/3487 [6:49:38<1:43:16,  5.37s/it]Llama.generate: 311 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4124.41 ms /    19 tokens (  217.07 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.32 ms /     3 runs   (  899.11 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6823.63 ms /    22 tokens\n",
      " 67%|██████▋   | 2334/3487 [6:49:45<1:51:37,  5.81s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7277.11 ms /    35 tokens (  207.92 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.35 ms /     3 runs   (  889.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9949.05 ms /    38 tokens\n",
      " 67%|██████▋   | 2335/3487 [6:49:55<2:15:25,  7.05s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2623.00 ms /    11 tokens (  238.45 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.57 ms /     3 runs   (  907.52 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5348.28 ms /    14 tokens\n",
      " 67%|██████▋   | 2336/3487 [6:50:00<2:05:32,  6.54s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3699.32 ms /    17 tokens (  217.61 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2714.38 ms /     3 runs   (  904.79 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6416.83 ms /    20 tokens\n",
      " 67%|██████▋   | 2337/3487 [6:50:07<2:04:44,  6.51s/it]Llama.generate: 313 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2465.23 ms /    10 tokens (  246.52 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2733.09 ms /     3 runs   (  911.03 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5201.44 ms /    13 tokens\n",
      " 67%|██████▋   | 2338/3487 [6:50:12<1:57:10,  6.12s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3482.67 ms /    15 tokens (  232.18 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2885.30 ms /     3 runs   (  961.77 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    6370.20 ms /    18 tokens\n",
      " 67%|██████▋   | 2339/3487 [6:50:19<1:58:33,  6.20s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6159.60 ms /    29 tokens (  212.40 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2855.56 ms /     3 runs   (  951.85 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    9018.07 ms /    32 tokens\n",
      " 67%|██████▋   | 2340/3487 [6:50:28<2:14:41,  7.05s/it]Llama.generate: 306 prefix-match hit, remaining 208 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   39384.41 ms /   208 tokens (  189.35 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.73 ms /     3 runs   (  890.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   42070.18 ms /   211 tokens\n",
      " 67%|██████▋   | 2341/3487 [6:51:10<5:35:28, 17.56s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4315.21 ms /    20 tokens (  215.76 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.00 ms /     3 runs   (  903.00 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7026.46 ms /    23 tokens\n",
      " 67%|██████▋   | 2342/3487 [6:51:17<4:34:54, 14.41s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5687.71 ms /    24 tokens (  236.99 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2880.17 ms /     3 runs   (  960.06 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    8570.71 ms /    27 tokens\n",
      " 67%|██████▋   | 2343/3487 [6:51:25<4:01:20, 12.66s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8119.07 ms /    39 tokens (  208.18 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.95 ms /     3 runs   (  891.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10798.65 ms /    42 tokens\n",
      " 67%|██████▋   | 2344/3487 [6:51:36<3:50:33, 12.10s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8714.46 ms /    45 tokens (  193.65 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.12 ms /     3 runs   (  893.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11397.34 ms /    48 tokens\n",
      " 67%|██████▋   | 2345/3487 [6:51:47<3:46:23, 11.89s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3108.62 ms /    14 tokens (  222.04 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2746.69 ms /     3 runs   (  915.56 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5857.95 ms /    17 tokens\n",
      " 67%|██████▋   | 2346/3487 [6:51:53<3:11:47, 10.09s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4131.25 ms /    19 tokens (  217.43 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.98 ms /     3 runs   (  893.66 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6814.26 ms /    22 tokens\n",
      " 67%|██████▋   | 2347/3487 [6:52:00<2:53:01,  9.11s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10775.28 ms /    54 tokens (  199.54 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2888.69 ms /     3 runs   (  962.90 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   13666.95 ms /    57 tokens\n",
      " 67%|██████▋   | 2348/3487 [6:52:14<3:18:54, 10.48s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4260.30 ms /    19 tokens (  224.23 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2752.06 ms /     3 runs   (  917.35 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7015.24 ms /    22 tokens\n",
      " 67%|██████▋   | 2349/3487 [6:52:21<2:59:05,  9.44s/it]Llama.generate: 306 prefix-match hit, remaining 115 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21455.95 ms /   115 tokens (  186.57 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.18 ms /     3 runs   (  892.73 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   24137.66 ms /   118 tokens\n",
      " 67%|██████▋   | 2350/3487 [6:52:45<4:22:30, 13.85s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3604.39 ms /    14 tokens (  257.46 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.19 ms /     3 runs   (  897.40 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6299.37 ms /    17 tokens\n",
      " 67%|██████▋   | 2351/3487 [6:52:51<3:39:26, 11.59s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2677.77 ms /    11 tokens (  243.43 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.17 ms /     3 runs   (  896.72 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5370.42 ms /    14 tokens\n",
      " 67%|██████▋   | 2352/3487 [6:52:57<3:04:00,  9.73s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1783.93 ms /     6 tokens (  297.32 ms per token,     3.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.54 ms /     3 runs   (  894.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4472.19 ms /     9 tokens\n",
      " 67%|██████▋   | 2353/3487 [6:53:01<2:34:05,  8.15s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2267.61 ms /     9 tokens (  251.96 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.11 ms /     3 runs   (  899.37 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4967.65 ms /    12 tokens\n",
      " 68%|██████▊   | 2354/3487 [6:53:06<2:15:57,  7.20s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2011.45 ms /     7 tokens (  287.35 ms per token,     3.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.19 ms /     3 runs   (  892.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4690.80 ms /    10 tokens\n",
      " 68%|██████▊   | 2355/3487 [6:53:11<2:01:41,  6.45s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4248.99 ms /    20 tokens (  212.45 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.55 ms /     3 runs   (  894.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6935.62 ms /    23 tokens\n",
      " 68%|██████▊   | 2356/3487 [6:53:18<2:04:22,  6.60s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8256.06 ms /    41 tokens (  201.37 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.27 ms /     3 runs   (  884.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10912.94 ms /    44 tokens\n",
      " 68%|██████▊   | 2357/3487 [6:53:29<2:28:41,  7.89s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7937.11 ms /    40 tokens (  198.43 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.46 ms /     3 runs   (  887.15 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10600.91 ms /    43 tokens\n",
      " 68%|██████▊   | 2358/3487 [6:53:39<2:43:52,  8.71s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12874.71 ms /    66 tokens (  195.07 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.72 ms /     3 runs   (  883.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15527.79 ms /    69 tokens\n",
      " 68%|██████▊   | 2359/3487 [6:53:55<3:22:14, 10.76s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4411.65 ms /    20 tokens (  220.58 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.74 ms /     3 runs   (  906.58 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7134.07 ms /    23 tokens\n",
      " 68%|██████▊   | 2360/3487 [6:54:02<3:01:41,  9.67s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4216.02 ms /    18 tokens (  234.22 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.18 ms /     3 runs   (  884.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6873.55 ms /    21 tokens\n",
      " 68%|██████▊   | 2361/3487 [6:54:09<2:45:49,  8.84s/it]Llama.generate: 308 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5285.74 ms /    26 tokens (  203.30 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.23 ms /     3 runs   (  893.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7968.24 ms /    29 tokens\n",
      " 68%|██████▊   | 2362/3487 [6:54:17<2:40:50,  8.58s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5515.26 ms /    25 tokens (  220.61 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.75 ms /     3 runs   (  900.58 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8219.60 ms /    28 tokens\n",
      " 68%|██████▊   | 2363/3487 [6:54:25<2:38:43,  8.47s/it]Llama.generate: 306 prefix-match hit, remaining 158 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   29297.79 ms /   158 tokens (  185.43 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.76 ms /     3 runs   (  894.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   31983.72 ms /   161 tokens\n",
      " 68%|██████▊   | 2364/3487 [6:54:57<4:50:38, 15.53s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3761.90 ms /    17 tokens (  221.29 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2796.89 ms /     3 runs   (  932.30 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6561.23 ms /    20 tokens\n",
      " 68%|██████▊   | 2365/3487 [6:55:04<4:00:07, 12.84s/it]Llama.generate: 306 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18941.32 ms /   100 tokens (  189.41 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.97 ms /     3 runs   (  888.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   21610.50 ms /   103 tokens\n",
      " 68%|██████▊   | 2366/3487 [6:55:25<4:49:06, 15.47s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7212.54 ms /    35 tokens (  206.07 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.38 ms /     3 runs   (  891.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9889.00 ms /    38 tokens\n",
      " 68%|██████▊   | 2367/3487 [6:55:35<4:17:36, 13.80s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11427.96 ms /    60 tokens (  190.47 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.34 ms /     3 runs   (  899.45 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   14129.54 ms /    63 tokens\n",
      " 68%|██████▊   | 2368/3487 [6:55:49<4:19:16, 13.90s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5906.78 ms /    28 tokens (  210.96 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2808.25 ms /     3 runs   (  936.08 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    8717.68 ms /    31 tokens\n",
      " 68%|██████▊   | 2369/3487 [6:55:58<3:50:06, 12.35s/it]Llama.generate: 307 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1663.07 ms /     5 tokens (  332.61 ms per token,     3.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.11 ms /     3 runs   (  909.70 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4394.69 ms /     8 tokens\n",
      " 68%|██████▊   | 2370/3487 [6:56:02<3:05:31,  9.97s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3627.74 ms /    16 tokens (  226.73 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.09 ms /     3 runs   (  911.70 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6365.52 ms /    19 tokens\n",
      " 68%|██████▊   | 2371/3487 [6:56:09<2:45:18,  8.89s/it]Llama.generate: 306 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19661.76 ms /   105 tokens (  187.25 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2785.94 ms /     3 runs   (  928.65 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   22451.63 ms /   108 tokens\n",
      " 68%|██████▊   | 2372/3487 [6:56:31<4:00:49, 12.96s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5728.65 ms /    29 tokens (  197.54 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.10 ms /     3 runs   (  891.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8405.25 ms /    32 tokens\n",
      " 68%|██████▊   | 2373/3487 [6:56:40<3:35:17, 11.60s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4320.64 ms /    21 tokens (  205.74 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2711.67 ms /     3 runs   (  903.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7034.81 ms /    24 tokens\n",
      " 68%|██████▊   | 2374/3487 [6:56:47<3:09:45, 10.23s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2106.63 ms /     8 tokens (  263.33 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.75 ms /     3 runs   (  902.92 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4817.88 ms /    11 tokens\n",
      " 68%|██████▊   | 2375/3487 [6:56:52<2:39:33,  8.61s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5397.77 ms /    27 tokens (  199.92 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.00 ms /     3 runs   (  902.33 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8107.02 ms /    30 tokens\n",
      " 68%|██████▊   | 2376/3487 [6:57:00<2:36:40,  8.46s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1695.84 ms /     5 tokens (  339.17 ms per token,     2.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.35 ms /     3 runs   (  902.45 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4405.73 ms /     8 tokens\n",
      " 68%|██████▊   | 2377/3487 [6:57:04<2:14:04,  7.25s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3680.32 ms /    14 tokens (  262.88 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.58 ms /     3 runs   (  898.86 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6379.42 ms /    17 tokens\n",
      " 68%|██████▊   | 2378/3487 [6:57:10<2:09:11,  6.99s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5477.18 ms /    27 tokens (  202.86 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2728.80 ms /     3 runs   (  909.60 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8208.62 ms /    30 tokens\n",
      " 68%|██████▊   | 2379/3487 [6:57:19<2:15:52,  7.36s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3623.97 ms /    16 tokens (  226.50 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.38 ms /     3 runs   (  885.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6282.68 ms /    19 tokens\n",
      " 68%|██████▊   | 2380/3487 [6:57:25<2:09:51,  7.04s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2498.82 ms /    10 tokens (  249.88 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.69 ms /     3 runs   (  887.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5163.59 ms /    13 tokens\n",
      " 68%|██████▊   | 2381/3487 [6:57:30<1:59:24,  6.48s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9934.59 ms /    52 tokens (  191.05 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.48 ms /     3 runs   (  882.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12583.61 ms /    55 tokens\n",
      " 68%|██████▊   | 2382/3487 [6:57:43<2:33:05,  8.31s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11157.96 ms /    59 tokens (  189.12 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.54 ms /     3 runs   (  878.85 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   13797.13 ms /    62 tokens\n",
      " 68%|██████▊   | 2383/3487 [6:57:57<3:03:16,  9.96s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2436.67 ms /    10 tokens (  243.67 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.89 ms /     3 runs   (  892.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5118.38 ms /    13 tokens\n",
      " 68%|██████▊   | 2384/3487 [6:58:02<2:36:26,  8.51s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3308.38 ms /    15 tokens (  220.56 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.31 ms /     3 runs   (  884.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5963.47 ms /    18 tokens\n",
      " 68%|██████▊   | 2385/3487 [6:58:08<2:22:19,  7.75s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4330.65 ms /    21 tokens (  206.22 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.69 ms /     3 runs   (  882.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6981.73 ms /    24 tokens\n",
      " 68%|██████▊   | 2386/3487 [6:58:15<2:18:11,  7.53s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3151.57 ms /    14 tokens (  225.11 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.54 ms /     3 runs   (  902.18 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5860.91 ms /    17 tokens\n",
      " 68%|██████▊   | 2387/3487 [6:58:21<2:08:55,  7.03s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2547.11 ms /     7 tokens (  363.87 ms per token,     2.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.40 ms /     3 runs   (  890.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5220.70 ms /    10 tokens\n",
      " 68%|██████▊   | 2388/3487 [6:58:26<1:58:53,  6.49s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8426.40 ms /    42 tokens (  200.63 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2629.86 ms /     3 runs   (  876.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11058.81 ms /    45 tokens\n",
      " 69%|██████▊   | 2389/3487 [6:58:37<2:23:54,  7.86s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1997.41 ms /     7 tokens (  285.34 ms per token,     3.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.65 ms /     3 runs   (  887.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4661.96 ms /    10 tokens\n",
      " 69%|██████▊   | 2390/3487 [6:58:42<2:06:15,  6.91s/it]Llama.generate: 313 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3951.66 ms /     4 runs   (  987.92 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    3954.90 ms /     5 tokens\n",
      " 69%|██████▊   | 2391/3487 [6:58:45<1:50:01,  6.02s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2093.25 ms /     8 tokens (  261.66 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.22 ms /     3 runs   (  906.41 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4815.61 ms /    11 tokens\n",
      " 69%|██████▊   | 2392/3487 [6:58:50<1:43:21,  5.66s/it]Llama.generate: 306 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13262.01 ms /    65 tokens (  204.03 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.16 ms /     3 runs   (  882.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15910.32 ms /    68 tokens\n",
      " 69%|██████▊   | 2393/3487 [6:59:06<2:39:22,  8.74s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5196.69 ms /    25 tokens (  207.87 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.97 ms /     3 runs   (  898.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7896.27 ms /    28 tokens\n",
      " 69%|██████▊   | 2394/3487 [6:59:14<2:34:38,  8.49s/it]Llama.generate: 307 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15646.85 ms /    79 tokens (  198.06 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.81 ms /     3 runs   (  888.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18315.17 ms /    82 tokens\n",
      " 69%|██████▊   | 2395/3487 [6:59:32<3:28:11, 11.44s/it]Llama.generate: 307 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11940.52 ms /    64 tokens (  186.57 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.60 ms /     3 runs   (  885.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14598.68 ms /    67 tokens\n",
      " 69%|██████▊   | 2396/3487 [6:59:47<3:45:17, 12.39s/it]Llama.generate: 307 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19355.23 ms /   100 tokens (  193.55 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.18 ms /     3 runs   (  883.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   22007.80 ms /   103 tokens\n",
      " 69%|██████▊   | 2397/3487 [7:00:09<4:37:33, 15.28s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6530.59 ms /    32 tokens (  204.08 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.46 ms /     3 runs   (  902.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9239.55 ms /    35 tokens\n",
      " 69%|██████▉   | 2398/3487 [7:00:18<4:04:27, 13.47s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1832.87 ms /     6 tokens (  305.48 ms per token,     3.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.35 ms /     3 runs   (  896.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4524.17 ms /     9 tokens\n",
      " 69%|██████▉   | 2399/3487 [7:00:23<3:15:36, 10.79s/it]Llama.generate: 306 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15298.79 ms /    80 tokens (  191.23 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.39 ms /     3 runs   (  885.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17957.54 ms /    83 tokens\n",
      " 69%|██████▉   | 2400/3487 [7:00:41<3:54:26, 12.94s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1694.78 ms /     6 tokens (  282.46 ms per token,     3.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2795.07 ms /     3 runs   (  931.69 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4492.70 ms /     9 tokens\n",
      " 69%|██████▉   | 2401/3487 [7:00:45<3:08:24, 10.41s/it]Llama.generate: 312 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3979.57 ms /     4 runs   (  994.89 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    3982.20 ms /     5 tokens\n",
      " 69%|██████▉   | 2402/3487 [7:00:49<2:33:25,  8.48s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3563.59 ms /    16 tokens (  222.72 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.24 ms /     3 runs   (  879.75 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6206.67 ms /    19 tokens\n",
      " 69%|██████▉   | 2403/3487 [7:00:56<2:20:59,  7.80s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9961.42 ms /    49 tokens (  203.29 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.42 ms /     3 runs   (  902.14 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   12670.13 ms /    52 tokens\n",
      " 69%|██████▉   | 2404/3487 [7:01:08<2:47:25,  9.28s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2763.07 ms /    11 tokens (  251.19 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.00 ms /     3 runs   (  891.33 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5439.89 ms /    14 tokens\n",
      " 69%|██████▉   | 2405/3487 [7:01:14<2:26:34,  8.13s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2933.48 ms /    10 tokens (  293.35 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.61 ms /     3 runs   (  889.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5605.72 ms /    13 tokens\n",
      " 69%|██████▉   | 2406/3487 [7:01:19<2:12:51,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7522.38 ms /    38 tokens (  197.96 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.00 ms /     3 runs   (  879.00 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10162.38 ms /    41 tokens\n",
      " 69%|██████▉   | 2407/3487 [7:01:29<2:27:50,  8.21s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2612.40 ms /    11 tokens (  237.49 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.25 ms /     3 runs   (  896.42 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5304.15 ms /    14 tokens\n",
      " 69%|██████▉   | 2408/3487 [7:01:35<2:12:03,  7.34s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7328.23 ms /    33 tokens (  222.07 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.96 ms /     3 runs   (  885.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9986.98 ms /    36 tokens\n",
      " 69%|██████▉   | 2409/3487 [7:01:45<2:26:13,  8.14s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5243.64 ms /    26 tokens (  201.68 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.22 ms /     3 runs   (  905.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7962.03 ms /    29 tokens\n",
      " 69%|██████▉   | 2410/3487 [7:01:53<2:25:11,  8.09s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3496.01 ms /    15 tokens (  233.07 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.71 ms /     3 runs   (  894.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6180.70 ms /    18 tokens\n",
      " 69%|██████▉   | 2411/3487 [7:01:59<2:14:49,  7.52s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1777.16 ms /     6 tokens (  296.19 ms per token,     3.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.86 ms /     3 runs   (  889.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4446.85 ms /     9 tokens\n",
      " 69%|██████▉   | 2412/3487 [7:02:03<1:58:13,  6.60s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3621.12 ms /    16 tokens (  226.32 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.47 ms /     3 runs   (  887.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6286.63 ms /    19 tokens\n",
      " 69%|██████▉   | 2413/3487 [7:02:10<1:56:29,  6.51s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7511.17 ms /    38 tokens (  197.66 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.18 ms /     3 runs   (  878.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10149.85 ms /    41 tokens\n",
      " 69%|██████▉   | 2414/3487 [7:02:20<2:15:57,  7.60s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6234.08 ms /    32 tokens (  194.82 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.73 ms /     3 runs   (  888.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8901.50 ms /    35 tokens\n",
      " 69%|██████▉   | 2415/3487 [7:02:29<2:22:50,  7.99s/it]Llama.generate: 307 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13372.06 ms /    68 tokens (  196.65 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.53 ms /     3 runs   (  879.18 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16012.72 ms /    71 tokens\n",
      " 69%|██████▉   | 2416/3487 [7:02:45<3:05:41, 10.40s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1790.43 ms /     6 tokens (  298.41 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2727.34 ms /     3 runs   (  909.11 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4519.98 ms /     9 tokens\n",
      " 69%|██████▉   | 2417/3487 [7:02:49<2:34:05,  8.64s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3625.72 ms /    16 tokens (  226.61 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.14 ms /     3 runs   (  900.38 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6329.82 ms /    19 tokens\n",
      " 69%|██████▉   | 2418/3487 [7:02:56<2:21:38,  7.95s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1384.80 ms /     4 tokens (  346.20 ms per token,     2.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2878.61 ms /     3 runs   (  959.54 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4265.87 ms /     7 tokens\n",
      " 69%|██████▉   | 2419/3487 [7:03:00<2:01:53,  6.85s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6403.02 ms /    32 tokens (  200.09 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.64 ms /     3 runs   (  899.21 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9103.37 ms /    35 tokens\n",
      " 69%|██████▉   | 2420/3487 [7:03:09<2:13:51,  7.53s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3556.26 ms /    16 tokens (  222.27 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.09 ms /     3 runs   (  892.03 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6234.96 ms /    19 tokens\n",
      " 69%|██████▉   | 2421/3487 [7:03:15<2:06:53,  7.14s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11806.82 ms /    62 tokens (  190.43 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.33 ms /     3 runs   (  878.11 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14443.82 ms /    65 tokens\n",
      " 69%|██████▉   | 2422/3487 [7:03:30<2:45:41,  9.33s/it]Llama.generate: 306 prefix-match hit, remaining 132 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24412.74 ms /   132 tokens (  184.95 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.58 ms /     3 runs   (  884.19 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   27067.89 ms /   135 tokens\n",
      " 69%|██████▉   | 2423/3487 [7:03:57<4:19:55, 14.66s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5882.88 ms /    28 tokens (  210.10 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.49 ms /     3 runs   (  893.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8567.38 ms /    31 tokens\n",
      " 70%|██████▉   | 2424/3487 [7:04:05<3:47:21, 12.83s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2550.09 ms /     8 tokens (  318.76 ms per token,     3.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.55 ms /     3 runs   (  883.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5203.64 ms /    11 tokens\n",
      " 70%|██████▉   | 2425/3487 [7:04:11<3:06:40, 10.55s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4441.95 ms /    21 tokens (  211.52 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.05 ms /     3 runs   (  894.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7126.25 ms /    24 tokens\n",
      " 70%|██████▉   | 2426/3487 [7:04:18<2:48:23,  9.52s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3588.33 ms /    16 tokens (  224.27 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.51 ms /     3 runs   (  892.17 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6267.10 ms /    19 tokens\n",
      " 70%|██████▉   | 2427/3487 [7:04:24<2:31:01,  8.55s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4476.53 ms /    19 tokens (  235.61 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.48 ms /     3 runs   (  878.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7114.86 ms /    22 tokens\n",
      " 70%|██████▉   | 2428/3487 [7:04:31<2:23:20,  8.12s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2712.80 ms /    12 tokens (  226.07 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.88 ms /     3 runs   (  896.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5406.04 ms /    15 tokens\n",
      " 70%|██████▉   | 2429/3487 [7:04:37<2:08:53,  7.31s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3906.00 ms /    18 tokens (  217.00 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.99 ms /     3 runs   (  888.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6571.46 ms /    21 tokens\n",
      " 70%|██████▉   | 2430/3487 [7:04:43<2:04:54,  7.09s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3311.94 ms /    15 tokens (  220.80 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.93 ms /     3 runs   (  883.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5965.37 ms /    18 tokens\n",
      " 70%|██████▉   | 2431/3487 [7:04:49<1:58:53,  6.76s/it]Llama.generate: 307 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13408.65 ms /    70 tokens (  191.55 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.73 ms /     3 runs   (  886.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16069.56 ms /    73 tokens\n",
      " 70%|██████▉   | 2432/3487 [7:05:05<2:47:57,  9.55s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5798.79 ms /    29 tokens (  199.96 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.98 ms /     3 runs   (  887.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8464.13 ms /    32 tokens\n",
      " 70%|██████▉   | 2433/3487 [7:05:14<2:42:05,  9.23s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5616.24 ms /    26 tokens (  216.01 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.51 ms /     3 runs   (  891.17 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8292.25 ms /    29 tokens\n",
      " 70%|██████▉   | 2434/3487 [7:05:22<2:37:03,  8.95s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8470.46 ms /    42 tokens (  201.68 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.68 ms /     3 runs   (  878.56 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11108.46 ms /    45 tokens\n",
      " 70%|██████▉   | 2435/3487 [7:05:33<2:48:17,  9.60s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5248.24 ms /    26 tokens (  201.86 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.69 ms /     3 runs   (  895.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7939.10 ms /    29 tokens\n",
      " 70%|██████▉   | 2436/3487 [7:05:41<2:39:27,  9.10s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5862.73 ms /    30 tokens (  195.42 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.51 ms /     3 runs   (  888.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8531.89 ms /    33 tokens\n",
      " 70%|██████▉   | 2437/3487 [7:05:50<2:36:20,  8.93s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8966.56 ms /    47 tokens (  190.78 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.39 ms /     3 runs   (  888.80 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11635.59 ms /    50 tokens\n",
      " 70%|██████▉   | 2438/3487 [7:06:01<2:50:24,  9.75s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13064.10 ms /    66 tokens (  197.94 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.22 ms /     3 runs   (  880.41 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15708.31 ms /    69 tokens\n",
      " 70%|██████▉   | 2439/3487 [7:06:17<3:21:31, 11.54s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8246.54 ms /    41 tokens (  201.14 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2842.82 ms /     3 runs   (  947.61 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   11091.80 ms /    44 tokens\n",
      " 70%|██████▉   | 2440/3487 [7:06:28<3:19:02, 11.41s/it]Llama.generate: 307 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15267.15 ms /    80 tokens (  190.84 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.25 ms /     3 runs   (  880.08 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17910.80 ms /    83 tokens\n",
      " 70%|███████   | 2441/3487 [7:06:46<3:52:55, 13.36s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4143.62 ms /    20 tokens (  207.18 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.13 ms /     3 runs   (  887.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6809.18 ms /    23 tokens\n",
      " 70%|███████   | 2442/3487 [7:06:53<3:18:30, 11.40s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2048.74 ms /     5 tokens (  409.75 ms per token,     2.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2778.59 ms /     3 runs   (  926.20 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    4829.98 ms /     8 tokens\n",
      " 70%|███████   | 2443/3487 [7:06:58<2:44:04,  9.43s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3722.42 ms /    17 tokens (  218.97 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.16 ms /     3 runs   (  890.05 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6394.54 ms /    20 tokens\n",
      " 70%|███████   | 2444/3487 [7:07:04<2:28:07,  8.52s/it]Llama.generate: 306 prefix-match hit, remaining 158 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28799.60 ms /   158 tokens (  182.28 ms per token,     5.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.12 ms /     3 runs   (  878.37 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   31437.28 ms /   161 tokens\n",
      " 70%|███████   | 2445/3487 [7:07:35<4:27:25, 15.40s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7433.55 ms /    38 tokens (  195.62 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.67 ms /     3 runs   (  878.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10070.50 ms /    41 tokens\n",
      " 70%|███████   | 2446/3487 [7:07:45<3:59:28, 13.80s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3512.86 ms /    16 tokens (  219.55 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.17 ms /     3 runs   (  903.39 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6225.23 ms /    19 tokens\n",
      " 70%|███████   | 2447/3487 [7:07:52<3:19:52, 11.53s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3653.89 ms /    16 tokens (  228.37 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.02 ms /     3 runs   (  889.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6325.69 ms /    19 tokens\n",
      " 70%|███████   | 2448/3487 [7:07:58<2:52:40,  9.97s/it]Llama.generate: 307 prefix-match hit, remaining 130 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   24464.02 ms /   130 tokens (  188.18 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.95 ms /     3 runs   (  880.65 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   27108.96 ms /   133 tokens\n",
      " 70%|███████   | 2449/3487 [7:08:25<4:21:29, 15.12s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5372.31 ms /    26 tokens (  206.63 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2733.70 ms /     3 runs   (  911.23 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8108.08 ms /    29 tokens\n",
      " 70%|███████   | 2450/3487 [7:08:33<3:44:56, 13.02s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4740.09 ms /    23 tokens (  206.09 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.00 ms /     3 runs   (  879.33 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7380.54 ms /    26 tokens\n",
      " 70%|███████   | 2451/3487 [7:08:41<3:15:35, 11.33s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4649.63 ms /    20 tokens (  232.48 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2765.79 ms /     3 runs   (  921.93 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7418.27 ms /    23 tokens\n",
      " 70%|███████   | 2452/3487 [7:08:48<2:55:12, 10.16s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7286.01 ms /    33 tokens (  220.79 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.90 ms /     3 runs   (  884.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9941.97 ms /    36 tokens\n",
      " 70%|███████   | 2453/3487 [7:08:58<2:53:57, 10.09s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2274.17 ms /     9 tokens (  252.69 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.00 ms /     3 runs   (  915.67 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5023.96 ms /    12 tokens\n",
      " 70%|███████   | 2454/3487 [7:09:03<2:27:39,  8.58s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7426.91 ms /    37 tokens (  200.73 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.66 ms /     3 runs   (  884.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10083.85 ms /    40 tokens\n",
      " 70%|███████   | 2455/3487 [7:09:13<2:35:20,  9.03s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2198.52 ms /     9 tokens (  244.28 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.67 ms /     3 runs   (  898.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4897.21 ms /    12 tokens\n",
      " 70%|███████   | 2456/3487 [7:09:18<2:13:55,  7.79s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3285.19 ms /    15 tokens (  219.01 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.60 ms /     3 runs   (  888.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5953.04 ms /    18 tokens\n",
      " 70%|███████   | 2457/3487 [7:09:24<2:04:21,  7.24s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14309.10 ms /    74 tokens (  193.37 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.03 ms /     3 runs   (  888.68 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16977.99 ms /    77 tokens\n",
      " 70%|███████   | 2458/3487 [7:09:41<2:54:21, 10.17s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3011.68 ms /    13 tokens (  231.67 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2763.62 ms /     3 runs   (  921.21 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5777.90 ms /    16 tokens\n",
      " 71%|███████   | 2459/3487 [7:09:47<2:31:40,  8.85s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12694.82 ms /    64 tokens (  198.36 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.95 ms /     3 runs   (  906.65 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   15417.71 ms /    67 tokens\n",
      " 71%|███████   | 2460/3487 [7:10:02<3:05:17, 10.83s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9929.39 ms /    49 tokens (  202.64 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.09 ms /     3 runs   (  896.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12622.47 ms /    52 tokens\n",
      " 71%|███████   | 2461/3487 [7:10:15<3:14:22, 11.37s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3210.12 ms /    14 tokens (  229.29 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.93 ms /     3 runs   (  905.98 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5931.04 ms /    17 tokens\n",
      " 71%|███████   | 2462/3487 [7:10:21<2:46:21,  9.74s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4681.43 ms /    22 tokens (  212.79 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.46 ms /     3 runs   (  891.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7357.40 ms /    25 tokens\n",
      " 71%|███████   | 2463/3487 [7:10:28<2:34:02,  9.03s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2133.41 ms /     8 tokens (  266.68 ms per token,     3.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.07 ms /     3 runs   (  895.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4822.07 ms /    11 tokens\n",
      " 71%|███████   | 2464/3487 [7:10:33<2:12:26,  7.77s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3222.07 ms /    14 tokens (  230.15 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.02 ms /     3 runs   (  906.34 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5944.11 ms /    17 tokens\n",
      " 71%|███████   | 2465/3487 [7:10:39<2:03:02,  7.22s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3167.29 ms /    13 tokens (  243.64 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2750.21 ms /     3 runs   (  916.74 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5920.01 ms /    16 tokens\n",
      " 71%|███████   | 2466/3487 [7:10:45<1:56:18,  6.83s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3108.46 ms /    13 tokens (  239.11 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3435.80 ms /     3 runs   ( 1145.27 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =    6547.34 ms /    16 tokens\n",
      " 71%|███████   | 2467/3487 [7:10:51<1:54:46,  6.75s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8408.92 ms /    29 tokens (  289.96 ms per token,     3.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12769.33 ms /     3 runs   ( 4256.44 ms per token,     0.23 tokens per second)\n",
      "llama_perf_context_print:       total time =   21183.78 ms /    32 tokens\n",
      " 71%|███████   | 2468/3487 [7:11:13<3:08:17, 11.09s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10505.75 ms /    14 tokens (  750.41 ms per token,     1.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9897.34 ms /     3 runs   ( 3299.11 ms per token,     0.30 tokens per second)\n",
      "llama_perf_context_print:       total time =   20409.13 ms /    17 tokens\n",
      " 71%|███████   | 2469/3487 [7:11:33<3:55:42, 13.89s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4837.74 ms /    13 tokens (  372.13 ms per token,     2.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3422.57 ms /     3 runs   ( 1140.86 ms per token,     0.88 tokens per second)\n",
      "llama_perf_context_print:       total time =    8265.52 ms /    16 tokens\n",
      " 71%|███████   | 2470/3487 [7:11:41<3:27:02, 12.22s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3589.87 ms /    11 tokens (  326.35 ms per token,     3.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3117.83 ms /     3 runs   ( 1039.28 ms per token,     0.96 tokens per second)\n",
      "llama_perf_context_print:       total time =    6712.21 ms /    14 tokens\n",
      " 71%|███████   | 2471/3487 [7:11:48<2:58:56, 10.57s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3508.04 ms /    15 tokens (  233.87 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2777.68 ms /     3 runs   (  925.89 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6288.64 ms /    18 tokens\n",
      " 71%|███████   | 2472/3487 [7:11:54<2:37:06,  9.29s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2892.00 ms /    12 tokens (  241.00 ms per token,     4.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.74 ms /     3 runs   (  905.25 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5610.03 ms /    15 tokens\n",
      " 71%|███████   | 2473/3487 [7:12:00<2:18:20,  8.19s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2183.56 ms /     9 tokens (  242.62 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.21 ms /     3 runs   (  892.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4864.42 ms /    12 tokens\n",
      " 71%|███████   | 2474/3487 [7:12:05<2:01:25,  7.19s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3088.16 ms /    14 tokens (  220.58 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.67 ms /     3 runs   (  892.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5769.70 ms /    17 tokens\n",
      " 71%|███████   | 2475/3487 [7:12:11<1:54:09,  6.77s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2677.95 ms /    11 tokens (  243.45 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.09 ms /     3 runs   (  899.70 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5378.96 ms /    14 tokens\n",
      " 71%|███████   | 2476/3487 [7:12:16<1:47:02,  6.35s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2138.92 ms /     9 tokens (  237.66 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.33 ms /     3 runs   (  893.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4821.61 ms /    12 tokens\n",
      " 71%|███████   | 2477/3487 [7:12:21<1:39:15,  5.90s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3817.02 ms /    11 tokens (  347.00 ms per token,     2.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2918.11 ms /     3 runs   (  972.70 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6737.28 ms /    14 tokens\n",
      " 71%|███████   | 2478/3487 [7:12:28<1:43:25,  6.15s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3188.01 ms /    13 tokens (  245.23 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.65 ms /     3 runs   (  888.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5856.20 ms /    16 tokens\n",
      " 71%|███████   | 2479/3487 [7:12:34<1:41:53,  6.07s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2560.17 ms /    11 tokens (  232.74 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.68 ms /     3 runs   (  890.23 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5233.05 ms /    14 tokens\n",
      " 71%|███████   | 2480/3487 [7:12:39<1:37:38,  5.82s/it]Llama.generate: 313 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4139.79 ms /    20 tokens (  206.99 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.70 ms /     3 runs   (  894.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6827.35 ms /    23 tokens\n",
      " 71%|███████   | 2481/3487 [7:12:46<1:42:39,  6.12s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2330.85 ms /     9 tokens (  258.98 ms per token,     3.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.90 ms /     3 runs   (  883.97 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4985.46 ms /    12 tokens\n",
      " 71%|███████   | 2482/3487 [7:12:51<1:36:53,  5.78s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5051.27 ms /    25 tokens (  202.05 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2891.46 ms /     3 runs   (  963.82 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    7944.90 ms /    28 tokens\n",
      " 71%|███████   | 2483/3487 [7:12:59<1:47:40,  6.43s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5988.77 ms /    30 tokens (  199.63 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.14 ms /     3 runs   (  900.05 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8691.56 ms /    33 tokens\n",
      " 71%|███████   | 2484/3487 [7:13:07<1:58:55,  7.11s/it]Llama.generate: 315 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1766.27 ms /     6 tokens (  294.38 ms per token,     3.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.39 ms /     3 runs   (  893.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4450.20 ms /     9 tokens\n",
      " 71%|███████▏  | 2485/3487 [7:13:12<1:45:30,  6.32s/it]Llama.generate: 306 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25018.36 ms /   133 tokens (  188.11 ms per token,     5.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.61 ms /     3 runs   (  888.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   27685.93 ms /   136 tokens\n",
      " 71%|███████▏  | 2486/3487 [7:13:39<3:32:23, 12.73s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7905.44 ms /    38 tokens (  208.04 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.47 ms /     3 runs   (  884.49 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10561.79 ms /    41 tokens\n",
      " 71%|███████▏  | 2487/3487 [7:13:50<3:21:22, 12.08s/it]Llama.generate: 306 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15473.98 ms /    82 tokens (  188.71 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2748.47 ms /     3 runs   (  916.16 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   18225.16 ms /    85 tokens\n",
      " 71%|███████▏  | 2488/3487 [7:14:08<3:51:53, 13.93s/it]Llama.generate: 308 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7728.93 ms /    38 tokens (  203.39 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3345.67 ms /     3 runs   ( 1115.22 ms per token,     0.90 tokens per second)\n",
      "llama_perf_context_print:       total time =   11077.26 ms /    41 tokens\n",
      " 71%|███████▏  | 2489/3487 [7:14:19<3:37:28, 13.07s/it]Llama.generate: 307 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   22577.87 ms /   100 tokens (  225.78 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3016.51 ms /     3 runs   ( 1005.50 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   25598.69 ms /   103 tokens\n",
      " 71%|███████▏  | 2490/3487 [7:14:45<4:39:45, 16.84s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4889.51 ms /    22 tokens (  222.25 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.56 ms /     3 runs   (  909.85 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7621.97 ms /    25 tokens\n",
      " 71%|███████▏  | 2491/3487 [7:14:53<3:53:38, 14.07s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5222.20 ms /    25 tokens (  208.89 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.92 ms /     3 runs   (  897.64 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7917.75 ms /    28 tokens\n",
      " 71%|███████▏  | 2492/3487 [7:15:00<3:22:48, 12.23s/it]Llama.generate: 306 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17545.05 ms /    94 tokens (  186.65 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.57 ms /     3 runs   (  887.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20209.97 ms /    97 tokens\n",
      " 71%|███████▏  | 2493/3487 [7:15:21<4:02:18, 14.63s/it]Llama.generate: 307 prefix-match hit, remaining 120 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23088.68 ms /   120 tokens (  192.41 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.34 ms /     3 runs   (  889.11 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   25758.52 ms /   123 tokens\n",
      " 72%|███████▏  | 2494/3487 [7:15:46<4:57:23, 17.97s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4679.49 ms /    21 tokens (  222.83 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.32 ms /     3 runs   (  884.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7336.09 ms /    24 tokens\n",
      " 72%|███████▏  | 2495/3487 [7:15:54<4:04:23, 14.78s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5190.55 ms /    25 tokens (  207.62 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.42 ms /     3 runs   (  889.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7861.02 ms /    28 tokens\n",
      " 72%|███████▏  | 2496/3487 [7:16:02<3:29:53, 12.71s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4295.00 ms /    21 tokens (  204.52 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.74 ms /     3 runs   (  886.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6958.33 ms /    24 tokens\n",
      " 72%|███████▏  | 2497/3487 [7:16:09<3:01:14, 10.98s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8334.37 ms /    42 tokens (  198.44 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.84 ms /     3 runs   (  890.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11008.31 ms /    45 tokens\n",
      " 72%|███████▏  | 2498/3487 [7:16:20<3:01:13, 10.99s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9439.95 ms /    49 tokens (  192.65 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.22 ms /     3 runs   (  886.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12100.78 ms /    52 tokens\n",
      " 72%|███████▏  | 2499/3487 [7:16:32<3:06:33, 11.33s/it]Llama.generate: 307 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14032.45 ms /    71 tokens (  197.64 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.72 ms /     3 runs   (  888.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16702.17 ms /    74 tokens\n",
      " 72%|███████▏  | 2500/3487 [7:16:48<3:32:55, 12.94s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3718.11 ms /    17 tokens (  218.71 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.34 ms /     3 runs   (  892.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6398.54 ms /    20 tokens\n",
      " 72%|███████▏  | 2501/3487 [7:16:55<3:00:29, 10.98s/it]Llama.generate: 306 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17401.41 ms /    93 tokens (  187.11 ms per token,     5.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.00 ms /     3 runs   (  888.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20067.85 ms /    96 tokens\n",
      " 72%|███████▏  | 2502/3487 [7:17:15<3:45:05, 13.71s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9881.66 ms /    52 tokens (  190.03 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.41 ms /     3 runs   (  885.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12540.89 ms /    55 tokens\n",
      " 72%|███████▏  | 2503/3487 [7:17:27<3:39:08, 13.36s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5165.67 ms /    23 tokens (  224.59 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.53 ms /     3 runs   (  905.18 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7883.97 ms /    26 tokens\n",
      " 72%|███████▏  | 2504/3487 [7:17:35<3:12:02, 11.72s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12202.36 ms /    64 tokens (  190.66 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.12 ms /     3 runs   (  886.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14863.68 ms /    67 tokens\n",
      " 72%|███████▏  | 2505/3487 [7:17:50<3:27:18, 12.67s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5167.05 ms /    26 tokens (  198.73 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.88 ms /     3 runs   (  892.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7846.82 ms /    29 tokens\n",
      " 72%|███████▏  | 2506/3487 [7:17:58<3:03:30, 11.22s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5758.01 ms /    29 tokens (  198.55 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.69 ms /     3 runs   (  891.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8436.20 ms /    32 tokens\n",
      " 72%|███████▏  | 2507/3487 [7:18:07<2:49:42, 10.39s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5289.19 ms /    26 tokens (  203.43 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.93 ms /     3 runs   (  886.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7953.58 ms /    29 tokens\n",
      " 72%|███████▏  | 2508/3487 [7:18:15<2:37:38,  9.66s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5201.80 ms /    26 tokens (  200.07 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.05 ms /     3 runs   (  900.68 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7905.85 ms /    29 tokens\n",
      " 72%|███████▏  | 2509/3487 [7:18:22<2:28:56,  9.14s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6090.65 ms /    31 tokens (  196.47 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.39 ms /     3 runs   (  888.13 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8757.61 ms /    34 tokens\n",
      " 72%|███████▏  | 2510/3487 [7:18:31<2:26:58,  9.03s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9615.70 ms /    49 tokens (  196.24 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.64 ms /     3 runs   (  899.21 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   12315.84 ms /    52 tokens\n",
      " 72%|███████▏  | 2511/3487 [7:18:44<2:42:55, 10.02s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5255.07 ms /    11 tokens (  477.73 ms per token,     2.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3718.62 ms /     3 runs   ( 1239.54 ms per token,     0.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    8976.93 ms /    14 tokens\n",
      " 72%|███████▏  | 2512/3487 [7:18:53<2:37:45,  9.71s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3452.88 ms /     9 tokens (  383.65 ms per token,     2.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2920.05 ms /     3 runs   (  973.35 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6375.71 ms /    12 tokens\n",
      " 72%|███████▏  | 2513/3487 [7:18:59<2:21:24,  8.71s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12554.63 ms /    51 tokens (  246.17 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3134.83 ms /     3 runs   ( 1044.94 ms per token,     0.96 tokens per second)\n",
      "llama_perf_context_print:       total time =   15723.99 ms /    54 tokens\n",
      " 72%|███████▏  | 2514/3487 [7:19:15<2:55:25, 10.82s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6364.97 ms /    25 tokens (  254.60 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3287.93 ms /     3 runs   ( 1095.98 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =    9656.21 ms /    28 tokens\n",
      " 72%|███████▏  | 2515/3487 [7:19:24<2:49:38, 10.47s/it]Llama.generate: 308 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6007.78 ms /    22 tokens (  273.08 ms per token,     3.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2832.91 ms /     3 runs   (  944.30 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    8843.49 ms /    25 tokens\n",
      " 72%|███████▏  | 2516/3487 [7:19:33<2:41:45, 10.00s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2206.06 ms /     7 tokens (  315.15 ms per token,     3.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2911.21 ms /     3 runs   (  970.40 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    5120.17 ms /    10 tokens\n",
      " 72%|███████▏  | 2517/3487 [7:19:38<2:18:00,  8.54s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3965.36 ms /    16 tokens (  247.83 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2918.59 ms /     3 runs   (  972.86 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    6887.03 ms /    19 tokens\n",
      " 72%|███████▏  | 2518/3487 [7:19:45<2:09:55,  8.05s/it]Llama.generate: 307 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25564.62 ms /   133 tokens (  192.22 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.97 ms /     3 runs   (  886.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   28227.26 ms /   136 tokens\n",
      " 72%|███████▏  | 2519/3487 [7:20:13<3:47:30, 14.10s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9535.74 ms /    49 tokens (  194.61 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2811.66 ms /     3 runs   (  937.22 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12350.49 ms /    52 tokens\n",
      " 72%|███████▏  | 2520/3487 [7:20:26<3:38:51, 13.58s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7436.00 ms /    33 tokens (  225.33 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.46 ms /     3 runs   (  885.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10095.76 ms /    36 tokens\n",
      " 72%|███████▏  | 2521/3487 [7:20:36<3:21:50, 12.54s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3753.93 ms /    15 tokens (  250.26 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2801.21 ms /     3 runs   (  933.74 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    6557.20 ms /    18 tokens\n",
      " 72%|███████▏  | 2522/3487 [7:20:42<2:52:49, 10.75s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4263.90 ms /    21 tokens (  203.04 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.68 ms /     3 runs   (  906.89 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6987.01 ms /    24 tokens\n",
      " 72%|███████▏  | 2523/3487 [7:20:49<2:34:34,  9.62s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3849.03 ms /    18 tokens (  213.84 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.27 ms /     3 runs   (  907.76 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6575.06 ms /    21 tokens\n",
      " 72%|███████▏  | 2524/3487 [7:20:56<2:19:47,  8.71s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2715.11 ms /    10 tokens (  271.51 ms per token,     3.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2812.08 ms /     3 runs   (  937.36 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5529.61 ms /    13 tokens\n",
      " 72%|███████▏  | 2525/3487 [7:21:02<2:04:23,  7.76s/it]Llama.generate: 316 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3949.43 ms /     4 runs   (  987.36 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    3952.14 ms /     5 tokens\n",
      " 72%|███████▏  | 2526/3487 [7:21:06<1:46:00,  6.62s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4007.36 ms /    18 tokens (  222.63 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.20 ms /     3 runs   (  915.73 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6757.32 ms /    21 tokens\n",
      " 72%|███████▏  | 2527/3487 [7:21:12<1:46:35,  6.66s/it]Llama.generate: 316 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2300.67 ms /     9 tokens (  255.63 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.15 ms /     3 runs   (  895.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4989.72 ms /    12 tokens\n",
      " 72%|███████▏  | 2528/3487 [7:21:17<1:38:30,  6.16s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6227.83 ms /    31 tokens (  200.90 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.85 ms /     3 runs   (  889.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8898.34 ms /    34 tokens\n",
      " 73%|███████▎  | 2529/3487 [7:21:26<1:51:33,  6.99s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2290.17 ms /     9 tokens (  254.46 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2957.47 ms /     3 runs   (  985.82 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    5250.29 ms /    12 tokens\n",
      " 73%|███████▎  | 2530/3487 [7:21:31<1:43:10,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3685.14 ms /    13 tokens (  283.47 ms per token,     3.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.44 ms /     3 runs   (  905.81 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6405.09 ms /    16 tokens\n",
      " 73%|███████▎  | 2531/3487 [7:21:38<1:42:47,  6.45s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3220.66 ms /    13 tokens (  247.74 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2734.69 ms /     3 runs   (  911.56 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5958.52 ms /    16 tokens\n",
      " 73%|███████▎  | 2532/3487 [7:21:44<1:40:22,  6.31s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2329.14 ms /     7 tokens (  332.73 ms per token,     3.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.86 ms /     3 runs   (  893.95 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5014.23 ms /    10 tokens\n",
      " 73%|███████▎  | 2533/3487 [7:21:49<1:34:09,  5.92s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2673.33 ms /    11 tokens (  243.03 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.07 ms /     3 runs   (  901.69 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5380.95 ms /    14 tokens\n",
      " 73%|███████▎  | 2534/3487 [7:21:54<1:31:30,  5.76s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4869.95 ms /    24 tokens (  202.91 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.13 ms /     3 runs   (  882.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7518.89 ms /    27 tokens\n",
      " 73%|███████▎  | 2535/3487 [7:22:02<1:39:49,  6.29s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4740.22 ms /    23 tokens (  206.10 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.39 ms /     3 runs   (  893.13 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7421.86 ms /    26 tokens\n",
      " 73%|███████▎  | 2536/3487 [7:22:09<1:45:07,  6.63s/it]Llama.generate: 308 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3727.88 ms /    17 tokens (  219.29 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.02 ms /     3 runs   (  884.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6384.53 ms /    20 tokens\n",
      " 73%|███████▎  | 2537/3487 [7:22:16<1:43:52,  6.56s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3033.73 ms /    13 tokens (  233.36 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.16 ms /     3 runs   (  885.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5691.18 ms /    16 tokens\n",
      " 73%|███████▎  | 2538/3487 [7:22:21<1:39:40,  6.30s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3776.05 ms /    18 tokens (  209.78 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.97 ms /     3 runs   (  886.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6440.00 ms /    21 tokens\n",
      " 73%|███████▎  | 2539/3487 [7:22:28<1:40:16,  6.35s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4447.13 ms /    19 tokens (  234.06 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.07 ms /     3 runs   (  884.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7101.93 ms /    22 tokens\n",
      " 73%|███████▎  | 2540/3487 [7:22:35<1:43:47,  6.58s/it]Llama.generate: 307 prefix-match hit, remaining 101 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19068.01 ms /   101 tokens (  188.79 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.71 ms /     3 runs   (  879.24 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21708.00 ms /   104 tokens\n",
      " 73%|███████▎  | 2541/3487 [7:22:57<2:55:17, 11.12s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1994.96 ms /     7 tokens (  284.99 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.76 ms /     3 runs   (  901.59 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4702.41 ms /    10 tokens\n",
      " 73%|███████▎  | 2542/3487 [7:23:01<2:24:49,  9.20s/it]Llama.generate: 306 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10066.52 ms /    53 tokens (  189.93 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.57 ms /     3 runs   (  877.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12701.19 ms /    56 tokens\n",
      " 73%|███████▎  | 2543/3487 [7:23:14<2:41:15, 10.25s/it]Llama.generate: 307 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10367.73 ms /    55 tokens (  188.50 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.92 ms /     3 runs   (  881.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13014.53 ms /    58 tokens\n",
      " 73%|███████▎  | 2544/3487 [7:23:27<2:54:09, 11.08s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3065.31 ms /    13 tokens (  235.79 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.56 ms /     3 runs   (  897.85 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5761.89 ms /    16 tokens\n",
      " 73%|███████▎  | 2545/3487 [7:23:33<2:28:57,  9.49s/it]Llama.generate: 306 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14548.33 ms /    77 tokens (  188.94 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.81 ms /     3 runs   (  879.94 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   17191.52 ms /    80 tokens\n",
      " 73%|███████▎  | 2546/3487 [7:23:50<3:05:05, 11.80s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7800.71 ms /    39 tokens (  200.02 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.55 ms /     3 runs   (  884.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10456.61 ms /    42 tokens\n",
      " 73%|███████▎  | 2547/3487 [7:24:00<2:58:36, 11.40s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9689.54 ms /    51 tokens (  189.99 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2625.63 ms /     3 runs   (  875.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12318.37 ms /    54 tokens\n",
      " 73%|███████▎  | 2548/3487 [7:24:13<3:02:46, 11.68s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5463.40 ms /    25 tokens (  218.54 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.48 ms /     3 runs   (  886.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8126.06 ms /    28 tokens\n",
      " 73%|███████▎  | 2549/3487 [7:24:21<2:45:57, 10.62s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2657.29 ms /    11 tokens (  241.57 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.45 ms /     3 runs   (  898.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5354.46 ms /    14 tokens\n",
      " 73%|███████▎  | 2550/3487 [7:24:26<2:21:10,  9.04s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4233.87 ms /    19 tokens (  222.84 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.60 ms /     3 runs   (  884.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6891.55 ms /    22 tokens\n",
      " 73%|███████▎  | 2551/3487 [7:24:33<2:11:00,  8.40s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3289.57 ms /    15 tokens (  219.30 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2743.41 ms /     3 runs   (  914.47 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6035.73 ms /    18 tokens\n",
      " 73%|███████▎  | 2552/3487 [7:24:39<1:59:51,  7.69s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4283.79 ms /    18 tokens (  237.99 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.66 ms /     3 runs   (  885.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6942.15 ms /    21 tokens\n",
      " 73%|███████▎  | 2553/3487 [7:24:46<1:56:16,  7.47s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3749.93 ms /    17 tokens (  220.58 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.21 ms /     3 runs   (  885.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6407.38 ms /    20 tokens\n",
      " 73%|███████▎  | 2554/3487 [7:24:53<1:51:14,  7.15s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4880.29 ms /    24 tokens (  203.35 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.39 ms /     3 runs   (  893.13 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7562.45 ms /    27 tokens\n",
      " 73%|███████▎  | 2555/3487 [7:25:00<1:53:03,  7.28s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1987.85 ms /     7 tokens (  283.98 ms per token,     3.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.32 ms /     3 runs   (  883.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4642.29 ms /    10 tokens\n",
      " 73%|███████▎  | 2556/3487 [7:25:05<1:40:43,  6.49s/it]Llama.generate: 306 prefix-match hit, remaining 125 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23723.89 ms /   125 tokens (  189.79 ms per token,     5.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.79 ms /     3 runs   (  894.26 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   26409.83 ms /   128 tokens\n",
      " 73%|███████▎  | 2557/3487 [7:25:31<3:13:16, 12.47s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9104.40 ms /    46 tokens (  197.92 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.81 ms /     3 runs   (  885.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11763.25 ms /    49 tokens\n",
      " 73%|███████▎  | 2558/3487 [7:25:43<3:09:49, 12.26s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7247.11 ms /    35 tokens (  207.06 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.05 ms /     3 runs   (  890.35 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9920.26 ms /    38 tokens\n",
      " 73%|███████▎  | 2559/3487 [7:25:53<2:58:47, 11.56s/it]Llama.generate: 308 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19250.13 ms /   102 tokens (  188.73 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.66 ms /     3 runs   (  880.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21894.19 ms /   105 tokens\n",
      " 73%|███████▎  | 2560/3487 [7:26:15<3:46:32, 14.66s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5897.06 ms /    30 tokens (  196.57 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.38 ms /     3 runs   (  899.46 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8597.76 ms /    33 tokens\n",
      " 73%|███████▎  | 2561/3487 [7:26:23<3:18:15, 12.85s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10149.18 ms /    52 tokens (  195.18 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.18 ms /     3 runs   (  894.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12833.38 ms /    55 tokens\n",
      " 73%|███████▎  | 2562/3487 [7:26:36<3:18:01, 12.84s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5948.92 ms /    29 tokens (  205.14 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2778.32 ms /     3 runs   (  926.11 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8730.16 ms /    32 tokens\n",
      " 74%|███████▎  | 2563/3487 [7:26:45<2:58:49, 11.61s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6848.82 ms /    31 tokens (  220.93 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.94 ms /     3 runs   (  892.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9530.29 ms /    34 tokens\n",
      " 74%|███████▎  | 2564/3487 [7:26:55<2:49:04, 10.99s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4769.18 ms /    23 tokens (  207.36 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.81 ms /     3 runs   (  895.27 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7457.46 ms /    26 tokens\n",
      " 74%|███████▎  | 2565/3487 [7:27:02<2:32:38,  9.93s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8054.70 ms /    41 tokens (  196.46 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2825.29 ms /     3 runs   (  941.76 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   10882.72 ms /    44 tokens\n",
      " 74%|███████▎  | 2566/3487 [7:27:13<2:36:52, 10.22s/it]Llama.generate: 307 prefix-match hit, remaining 140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   25862.72 ms /   140 tokens (  184.73 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2798.07 ms /     3 runs   (  932.69 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   28664.04 ms /   143 tokens\n",
      " 74%|███████▎  | 2567/3487 [7:27:42<4:01:35, 15.76s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6382.76 ms /    31 tokens (  205.90 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.22 ms /     3 runs   (  879.41 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9023.41 ms /    34 tokens\n",
      " 74%|███████▎  | 2568/3487 [7:27:51<3:30:25, 13.74s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3093.53 ms /    14 tokens (  220.97 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.68 ms /     3 runs   (  883.23 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5745.59 ms /    17 tokens\n",
      " 74%|███████▎  | 2569/3487 [7:27:56<2:53:33, 11.34s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8403.72 ms /    43 tokens (  195.44 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2808.11 ms /     3 runs   (  936.03 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   11214.49 ms /    46 tokens\n",
      " 74%|███████▎  | 2570/3487 [7:28:08<2:52:48, 11.31s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6158.29 ms /    31 tokens (  198.65 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.30 ms /     3 runs   (  888.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8826.34 ms /    34 tokens\n",
      " 74%|███████▎  | 2571/3487 [7:28:16<2:41:17, 10.56s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6165.49 ms /    31 tokens (  198.89 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.19 ms /     3 runs   (  897.73 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8861.57 ms /    34 tokens\n",
      " 74%|███████▍  | 2572/3487 [7:28:25<2:33:21, 10.06s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6020.37 ms /    28 tokens (  215.01 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.64 ms /     3 runs   (  878.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8658.31 ms /    31 tokens\n",
      " 74%|███████▍  | 2573/3487 [7:28:34<2:26:50,  9.64s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9810.99 ms /    51 tokens (  192.37 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.80 ms /     3 runs   (  878.27 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12448.14 ms /    54 tokens\n",
      " 74%|███████▍  | 2574/3487 [7:28:46<2:39:32, 10.48s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9515.72 ms /    49 tokens (  194.20 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2809.91 ms /     3 runs   (  936.64 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12328.36 ms /    52 tokens\n",
      " 74%|███████▍  | 2575/3487 [7:28:59<2:47:49, 11.04s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9037.48 ms /    45 tokens (  200.83 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.66 ms /     3 runs   (  878.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11676.04 ms /    48 tokens\n",
      " 74%|███████▍  | 2576/3487 [7:29:10<2:50:34, 11.23s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6036.85 ms /    30 tokens (  201.23 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.28 ms /     3 runs   (  887.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8702.40 ms /    33 tokens\n",
      " 74%|███████▍  | 2577/3487 [7:29:19<2:38:54, 10.48s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7977.77 ms /    41 tokens (  194.58 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.27 ms /     3 runs   (  878.09 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10615.57 ms /    44 tokens\n",
      " 74%|███████▍  | 2578/3487 [7:29:30<2:39:23, 10.52s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2975.48 ms /    13 tokens (  228.88 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.10 ms /     3 runs   (  895.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5664.13 ms /    16 tokens\n",
      " 74%|███████▍  | 2579/3487 [7:29:35<2:17:12,  9.07s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3085.31 ms /    13 tokens (  237.33 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.20 ms /     3 runs   (  885.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5744.83 ms /    16 tokens\n",
      " 74%|███████▍  | 2580/3487 [7:29:41<2:02:02,  8.07s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3365.49 ms /    15 tokens (  224.37 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.37 ms /     3 runs   (  904.12 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6080.28 ms /    18 tokens\n",
      " 74%|███████▍  | 2581/3487 [7:29:47<1:53:03,  7.49s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5001.64 ms /    22 tokens (  227.35 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2858.82 ms /     3 runs   (  952.94 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    7863.10 ms /    25 tokens\n",
      " 74%|███████▍  | 2582/3487 [7:29:55<1:54:40,  7.60s/it]Llama.generate: 312 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1363.18 ms /     4 tokens (  340.80 ms per token,     2.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2831.69 ms /     3 runs   (  943.90 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4197.67 ms /     7 tokens\n",
      " 74%|███████▍  | 2583/3487 [7:29:59<1:39:11,  6.58s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3537.59 ms /    16 tokens (  221.10 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.52 ms /     3 runs   (  883.17 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6189.18 ms /    19 tokens\n",
      " 74%|███████▍  | 2584/3487 [7:30:06<1:37:20,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3199.47 ms /    15 tokens (  213.30 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.63 ms /     3 runs   (  899.54 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5900.45 ms /    18 tokens\n",
      " 74%|███████▍  | 2585/3487 [7:30:12<1:34:42,  6.30s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4345.87 ms /    21 tokens (  206.95 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.84 ms /     3 runs   (  887.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7012.21 ms /    24 tokens\n",
      " 74%|███████▍  | 2586/3487 [7:30:19<1:37:51,  6.52s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4807.97 ms /    22 tokens (  218.54 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2768.13 ms /     3 runs   (  922.71 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7578.37 ms /    25 tokens\n",
      " 74%|███████▍  | 2587/3487 [7:30:26<1:42:33,  6.84s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4769.45 ms /    23 tokens (  207.37 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.92 ms /     3 runs   (  883.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7423.34 ms /    26 tokens\n",
      " 74%|███████▍  | 2588/3487 [7:30:34<1:45:06,  7.01s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3139.57 ms /    14 tokens (  224.25 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.80 ms /     3 runs   (  898.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5838.93 ms /    17 tokens\n",
      " 74%|███████▍  | 2589/3487 [7:30:39<1:39:44,  6.66s/it]Llama.generate: 319 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4261.51 ms /     4 runs   ( 1065.38 ms per token,     0.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    4264.07 ms /     5 tokens\n",
      " 74%|███████▍  | 2590/3487 [7:30:44<1:28:54,  5.95s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3212.06 ms /    14 tokens (  229.43 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.22 ms /     3 runs   (  883.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5866.45 ms /    17 tokens\n",
      " 74%|███████▍  | 2591/3487 [7:30:50<1:28:29,  5.93s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2795.68 ms /    12 tokens (  232.97 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.16 ms /     3 runs   (  886.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5458.32 ms /    15 tokens\n",
      " 74%|███████▍  | 2592/3487 [7:30:55<1:26:19,  5.79s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2336.72 ms /     9 tokens (  259.63 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.28 ms /     3 runs   (  886.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4999.62 ms /    12 tokens\n",
      " 74%|███████▍  | 2593/3487 [7:31:00<1:22:44,  5.55s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3185.17 ms /    14 tokens (  227.51 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.34 ms /     3 runs   (  886.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5848.51 ms /    17 tokens\n",
      " 74%|███████▍  | 2594/3487 [7:31:06<1:24:01,  5.65s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2174.89 ms /     8 tokens (  271.86 ms per token,     3.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.80 ms /     3 runs   (  898.60 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4873.17 ms /    11 tokens\n",
      " 74%|███████▍  | 2595/3487 [7:31:11<1:20:31,  5.42s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8477.31 ms /    43 tokens (  197.15 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.35 ms /     3 runs   (  880.78 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11122.68 ms /    46 tokens\n",
      " 74%|███████▍  | 2596/3487 [7:31:22<1:45:53,  7.13s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3017.75 ms /    13 tokens (  232.13 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.13 ms /     3 runs   (  897.04 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5712.00 ms /    16 tokens\n",
      " 74%|███████▍  | 2597/3487 [7:31:28<1:39:29,  6.71s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9105.07 ms /    45 tokens (  202.33 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.78 ms /     3 runs   (  888.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11773.08 ms /    48 tokens\n",
      " 75%|███████▍  | 2598/3487 [7:31:39<2:01:56,  8.23s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4664.45 ms /    22 tokens (  212.02 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.92 ms /     3 runs   (  906.97 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7388.61 ms /    25 tokens\n",
      " 75%|███████▍  | 2599/3487 [7:31:47<1:58:05,  7.98s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5038.93 ms /    23 tokens (  219.08 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2765.79 ms /     3 runs   (  921.93 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7806.58 ms /    26 tokens\n",
      " 75%|███████▍  | 2600/3487 [7:31:55<1:57:14,  7.93s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3470.78 ms /    15 tokens (  231.39 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.44 ms /     3 runs   (  889.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6142.91 ms /    18 tokens\n",
      " 75%|███████▍  | 2601/3487 [7:32:01<1:49:13,  7.40s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7568.39 ms /    37 tokens (  204.55 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.53 ms /     3 runs   (  885.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10228.87 ms /    40 tokens\n",
      " 75%|███████▍  | 2602/3487 [7:32:11<2:01:40,  8.25s/it]Llama.generate: 315 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1348.33 ms /     4 tokens (  337.08 ms per token,     2.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2836.39 ms /     3 runs   (  945.47 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4187.17 ms /     7 tokens\n",
      " 75%|███████▍  | 2603/3487 [7:32:15<1:43:36,  7.03s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3131.81 ms /    14 tokens (  223.70 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.29 ms /     3 runs   (  886.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5793.94 ms /    17 tokens\n",
      " 75%|███████▍  | 2604/3487 [7:32:21<1:38:04,  6.66s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5755.62 ms /    29 tokens (  198.47 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.59 ms /     3 runs   (  900.20 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8459.34 ms /    32 tokens\n",
      " 75%|███████▍  | 2605/3487 [7:32:29<1:45:54,  7.21s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1344.47 ms /     4 tokens (  336.12 ms per token,     2.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2940.80 ms /     3 runs   (  980.27 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    4287.75 ms /     7 tokens\n",
      " 75%|███████▍  | 2606/3487 [7:32:34<1:32:59,  6.33s/it]Llama.generate: 311 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4873.24 ms /    24 tokens (  203.05 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.21 ms /     3 runs   (  880.40 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7517.41 ms /    27 tokens\n",
      " 75%|███████▍  | 2607/3487 [7:32:41<1:38:07,  6.69s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3222.41 ms /    15 tokens (  214.83 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.96 ms /     3 runs   (  885.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5880.70 ms /    18 tokens\n",
      " 75%|███████▍  | 2608/3487 [7:32:47<1:34:29,  6.45s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1753.61 ms /     6 tokens (  292.27 ms per token,     3.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.96 ms /     3 runs   (  886.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4417.00 ms /     9 tokens\n",
      " 75%|███████▍  | 2609/3487 [7:32:52<1:25:30,  5.84s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3811.94 ms /    18 tokens (  211.77 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.81 ms /     3 runs   (  880.60 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6456.84 ms /    21 tokens\n",
      " 75%|███████▍  | 2610/3487 [7:32:58<1:28:08,  6.03s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7423.20 ms /    37 tokens (  200.63 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.83 ms /     3 runs   (  885.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10082.55 ms /    40 tokens\n",
      " 75%|███████▍  | 2611/3487 [7:33:08<1:45:49,  7.25s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4124.70 ms /    20 tokens (  206.24 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.03 ms /     3 runs   (  896.68 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6816.94 ms /    23 tokens\n",
      " 75%|███████▍  | 2612/3487 [7:33:15<1:43:51,  7.12s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2970.37 ms /    13 tokens (  228.49 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.07 ms /     3 runs   (  890.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5643.04 ms /    16 tokens\n",
      " 75%|███████▍  | 2613/3487 [7:33:21<1:37:18,  6.68s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6248.92 ms /    30 tokens (  208.30 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.80 ms /     3 runs   (  883.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8903.81 ms /    33 tokens\n",
      " 75%|███████▍  | 2614/3487 [7:33:30<1:46:56,  7.35s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3299.18 ms /    15 tokens (  219.95 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.08 ms /     3 runs   (  887.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5964.71 ms /    18 tokens\n",
      " 75%|███████▍  | 2615/3487 [7:33:36<1:40:48,  6.94s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7167.50 ms /    33 tokens (  217.20 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.64 ms /     3 runs   (  880.55 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9811.69 ms /    36 tokens\n",
      " 75%|███████▌  | 2616/3487 [7:33:45<1:53:15,  7.80s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2058.32 ms /     7 tokens (  294.05 ms per token,     3.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2982.09 ms /     3 runs   (  994.03 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    5043.23 ms /    10 tokens\n",
      " 75%|███████▌  | 2617/3487 [7:33:50<1:41:10,  6.98s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5341.17 ms /    24 tokens (  222.55 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.17 ms /     3 runs   (  887.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8005.73 ms /    27 tokens\n",
      " 75%|███████▌  | 2618/3487 [7:33:58<1:45:33,  7.29s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5080.17 ms /    25 tokens (  203.21 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.06 ms /     3 runs   (  880.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7722.78 ms /    28 tokens\n",
      " 75%|███████▌  | 2619/3487 [7:34:06<1:47:21,  7.42s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10001.52 ms /    52 tokens (  192.34 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.25 ms /     3 runs   (  877.75 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12637.58 ms /    55 tokens\n",
      " 75%|███████▌  | 2620/3487 [7:34:19<2:09:52,  8.99s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4007.95 ms /    19 tokens (  210.94 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.50 ms /     3 runs   (  890.50 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6682.24 ms /    22 tokens\n",
      " 75%|███████▌  | 2621/3487 [7:34:25<1:59:46,  8.30s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7574.29 ms /    36 tokens (  210.40 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.21 ms /     3 runs   (  881.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10220.79 ms /    39 tokens\n",
      " 75%|███████▌  | 2622/3487 [7:34:36<2:07:59,  8.88s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10205.12 ms /    52 tokens (  196.25 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.27 ms /     3 runs   (  879.76 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12847.08 ms /    55 tokens\n",
      " 75%|███████▌  | 2623/3487 [7:34:49<2:25:01, 10.07s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7474.56 ms /    38 tokens (  196.70 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.05 ms /     3 runs   (  878.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10113.43 ms /    41 tokens\n",
      " 75%|███████▌  | 2624/3487 [7:34:59<2:25:04, 10.09s/it]Llama.generate: 307 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13890.30 ms /    71 tokens (  195.64 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.86 ms /     3 runs   (  878.62 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16528.95 ms /    74 tokens\n",
      " 75%|███████▌  | 2625/3487 [7:35:15<2:52:42, 12.02s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4835.30 ms /    24 tokens (  201.47 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.87 ms /     3 runs   (  905.96 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7555.23 ms /    27 tokens\n",
      " 75%|███████▌  | 2626/3487 [7:35:23<2:33:19, 10.68s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1497.48 ms /     5 tokens (  299.50 ms per token,     3.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2782.28 ms /     3 runs   (  927.43 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    4282.53 ms /     8 tokens\n",
      " 75%|███████▌  | 2627/3487 [7:35:27<2:05:38,  8.77s/it]Llama.generate: 306 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13563.97 ms /    72 tokens (  188.39 ms per token,     5.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.19 ms /     3 runs   (  882.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16212.48 ms /    75 tokens\n",
      " 75%|███████▌  | 2628/3487 [7:35:43<2:37:30, 11.00s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5085.41 ms /    25 tokens (  203.42 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.69 ms /     3 runs   (  883.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7738.69 ms /    28 tokens\n",
      " 75%|███████▌  | 2629/3487 [7:35:51<2:23:21, 10.03s/it]Llama.generate: 308 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2621.67 ms /    11 tokens (  238.33 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.69 ms /     3 runs   (  888.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5289.84 ms /    14 tokens\n",
      " 75%|███████▌  | 2630/3487 [7:35:56<2:02:56,  8.61s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8350.88 ms /    41 tokens (  203.68 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.06 ms /     3 runs   (  879.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10991.49 ms /    44 tokens\n",
      " 75%|███████▌  | 2631/3487 [7:36:07<2:13:02,  9.33s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1725.47 ms /     6 tokens (  287.58 ms per token,     3.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.74 ms /     3 runs   (  880.25 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4368.77 ms /     9 tokens\n",
      " 75%|███████▌  | 2632/3487 [7:36:12<1:51:44,  7.84s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4664.40 ms /    23 tokens (  202.80 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.11 ms /     3 runs   (  888.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7333.57 ms /    26 tokens\n",
      " 76%|███████▌  | 2633/3487 [7:36:19<1:49:27,  7.69s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5307.60 ms /    27 tokens (  196.58 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.61 ms /     3 runs   (  885.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7968.37 ms /    30 tokens\n",
      " 76%|███████▌  | 2634/3487 [7:36:27<1:50:33,  7.78s/it]Llama.generate: 315 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1362.03 ms /     4 tokens (  340.51 ms per token,     2.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2912.96 ms /     3 runs   (  970.99 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    4277.73 ms /     7 tokens\n",
      " 76%|███████▌  | 2635/3487 [7:36:31<1:35:33,  6.73s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6612.87 ms /    32 tokens (  206.65 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.29 ms /     3 runs   (  909.76 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    9345.13 ms /    35 tokens\n",
      " 76%|███████▌  | 2636/3487 [7:36:41<1:46:37,  7.52s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2781.32 ms /    12 tokens (  231.78 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.13 ms /     3 runs   (  903.04 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5493.27 ms /    15 tokens\n",
      " 76%|███████▌  | 2637/3487 [7:36:46<1:37:55,  6.91s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2256.10 ms /     9 tokens (  250.68 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.18 ms /     3 runs   (  883.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4907.67 ms /    12 tokens\n",
      " 76%|███████▌  | 2638/3487 [7:36:51<1:29:19,  6.31s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2782.60 ms /    12 tokens (  231.88 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2820.70 ms /     3 runs   (  940.23 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5606.18 ms /    15 tokens\n",
      " 76%|███████▌  | 2639/3487 [7:36:57<1:26:15,  6.10s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3686.44 ms /    13 tokens (  283.57 ms per token,     3.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2719.98 ms /     3 runs   (  906.66 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6408.61 ms /    16 tokens\n",
      " 76%|███████▌  | 2640/3487 [7:37:03<1:27:29,  6.20s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8257.12 ms /    41 tokens (  201.39 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.89 ms /     3 runs   (  877.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10893.54 ms /    44 tokens\n",
      " 76%|███████▌  | 2641/3487 [7:37:14<1:47:17,  7.61s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2191.34 ms /     9 tokens (  243.48 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.09 ms /     3 runs   (  886.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4851.30 ms /    12 tokens\n",
      " 76%|███████▌  | 2642/3487 [7:37:19<1:35:32,  6.78s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6180.76 ms /    31 tokens (  199.38 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.93 ms /     3 runs   (  884.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8836.78 ms /    34 tokens\n",
      " 76%|███████▌  | 2643/3487 [7:37:28<1:44:07,  7.40s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8744.88 ms /    45 tokens (  194.33 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.77 ms /     3 runs   (  880.26 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11388.00 ms /    48 tokens\n",
      " 76%|███████▌  | 2644/3487 [7:37:39<2:00:50,  8.60s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2237.34 ms /     9 tokens (  248.59 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.59 ms /     3 runs   (  892.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4916.99 ms /    12 tokens\n",
      " 76%|███████▌  | 2645/3487 [7:37:44<1:45:13,  7.50s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4288.43 ms /    21 tokens (  204.21 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.66 ms /     3 runs   (  886.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6950.15 ms /    24 tokens\n",
      " 76%|███████▌  | 2646/3487 [7:37:51<1:42:49,  7.34s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4643.29 ms /    23 tokens (  201.88 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.99 ms /     3 runs   (  891.00 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7318.31 ms /    26 tokens\n",
      " 76%|███████▌  | 2647/3487 [7:37:58<1:42:39,  7.33s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4168.48 ms /    19 tokens (  219.39 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2835.74 ms /     3 runs   (  945.25 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7006.42 ms /    22 tokens\n",
      " 76%|███████▌  | 2648/3487 [7:38:05<1:41:12,  7.24s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4909.57 ms /    24 tokens (  204.57 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.16 ms /     3 runs   (  886.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7571.81 ms /    27 tokens\n",
      " 76%|███████▌  | 2649/3487 [7:38:13<1:42:31,  7.34s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4654.75 ms /    23 tokens (  202.38 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.19 ms /     3 runs   (  885.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7312.23 ms /    26 tokens\n",
      " 76%|███████▌  | 2650/3487 [7:38:20<1:42:19,  7.34s/it]Llama.generate: 308 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4656.48 ms /    22 tokens (  211.66 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.39 ms /     3 runs   (  879.13 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7295.87 ms /    25 tokens\n",
      " 76%|███████▌  | 2651/3487 [7:38:28<1:42:04,  7.33s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2642.71 ms /    11 tokens (  240.25 ms per token,     4.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.67 ms /     3 runs   (  889.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5314.94 ms /    14 tokens\n",
      " 76%|███████▌  | 2652/3487 [7:38:33<1:33:35,  6.72s/it]Llama.generate: 313 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2618.02 ms /    11 tokens (  238.00 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.68 ms /     3 runs   (  888.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5286.99 ms /    14 tokens\n",
      " 76%|███████▌  | 2653/3487 [7:38:38<1:27:30,  6.30s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4660.74 ms /    22 tokens (  211.85 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.06 ms /     3 runs   (  888.02 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7328.13 ms /    25 tokens\n",
      " 76%|███████▌  | 2654/3487 [7:38:46<1:31:45,  6.61s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2704.29 ms /    12 tokens (  225.36 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.03 ms /     3 runs   (  877.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5339.83 ms /    15 tokens\n",
      " 76%|███████▌  | 2655/3487 [7:38:51<1:26:23,  6.23s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6503.62 ms /    31 tokens (  209.79 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2737.61 ms /     3 runs   (  912.53 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    9243.85 ms /    34 tokens\n",
      " 76%|███████▌  | 2656/3487 [7:39:00<1:38:50,  7.14s/it]Llama.generate: 313 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3187.37 ms /    14 tokens (  227.67 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2633.89 ms /     3 runs   (  877.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5823.79 ms /    17 tokens\n",
      " 76%|███████▌  | 2657/3487 [7:39:06<1:33:18,  6.75s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2010.38 ms /     7 tokens (  287.20 ms per token,     3.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.84 ms /     3 runs   (  893.95 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4694.57 ms /    10 tokens\n",
      " 76%|███████▌  | 2658/3487 [7:39:11<1:24:44,  6.13s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2542.15 ms /    10 tokens (  254.22 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.34 ms /     3 runs   (  889.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5214.21 ms /    13 tokens\n",
      " 76%|███████▋  | 2659/3487 [7:39:16<1:20:52,  5.86s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9472.42 ms /    49 tokens (  193.31 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.34 ms /     3 runs   (  886.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12134.70 ms /    52 tokens\n",
      " 76%|███████▋  | 2660/3487 [7:39:28<1:46:44,  7.74s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2227.78 ms /     9 tokens (  247.53 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.98 ms /     3 runs   (  883.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4881.80 ms /    12 tokens\n",
      " 76%|███████▋  | 2661/3487 [7:39:33<1:34:49,  6.89s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2719.79 ms /    11 tokens (  247.25 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.51 ms /     3 runs   (  885.50 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5379.48 ms /    14 tokens\n",
      " 76%|███████▋  | 2662/3487 [7:39:38<1:28:30,  6.44s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1756.11 ms /     6 tokens (  292.69 ms per token,     3.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.79 ms /     3 runs   (  889.93 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4428.83 ms /     9 tokens\n",
      " 76%|███████▋  | 2663/3487 [7:39:43<1:20:10,  5.84s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4918.29 ms /    24 tokens (  204.93 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2820.33 ms /     3 runs   (  940.11 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7741.65 ms /    27 tokens\n",
      " 76%|███████▋  | 2664/3487 [7:39:50<1:27:56,  6.41s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5152.09 ms /    25 tokens (  206.08 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.11 ms /     3 runs   (  888.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7820.97 ms /    28 tokens\n",
      " 76%|███████▋  | 2665/3487 [7:39:58<1:33:39,  6.84s/it]Llama.generate: 311 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4995.16 ms /    24 tokens (  208.13 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.90 ms /     3 runs   (  887.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7659.32 ms /    27 tokens\n",
      " 76%|███████▋  | 2666/3487 [7:40:06<1:36:57,  7.09s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2636.83 ms /    11 tokens (  239.71 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2896.37 ms /     3 runs   (  965.46 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    5534.72 ms /    14 tokens\n",
      " 76%|███████▋  | 2667/3487 [7:40:12<1:30:30,  6.62s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2244.00 ms /     9 tokens (  249.33 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.37 ms /     3 runs   (  889.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4916.16 ms /    12 tokens\n",
      " 77%|███████▋  | 2668/3487 [7:40:16<1:23:26,  6.11s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3345.23 ms /    15 tokens (  223.02 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.60 ms /     3 runs   (  887.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6009.63 ms /    18 tokens\n",
      " 77%|███████▋  | 2669/3487 [7:40:22<1:22:57,  6.08s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7674.82 ms /    37 tokens (  207.43 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.70 ms /     3 runs   (  881.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10323.21 ms /    40 tokens\n",
      " 77%|███████▋  | 2670/3487 [7:40:33<1:40:12,  7.36s/it]Llama.generate: 342 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3997.11 ms /     4 runs   (  999.28 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    3999.85 ms /     5 tokens\n",
      " 77%|███████▋  | 2671/3487 [7:40:37<1:26:24,  6.35s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4228.20 ms /    20 tokens (  211.41 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.13 ms /     3 runs   (  877.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6863.12 ms /    23 tokens\n",
      " 77%|███████▋  | 2672/3487 [7:40:44<1:28:24,  6.51s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3020.10 ms /    13 tokens (  232.32 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.30 ms /     3 runs   (  895.10 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5708.20 ms /    16 tokens\n",
      " 77%|███████▋  | 2673/3487 [7:40:49<1:25:04,  6.27s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2339.33 ms /     9 tokens (  259.93 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.78 ms /     3 runs   (  891.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5016.81 ms /    12 tokens\n",
      " 77%|███████▋  | 2674/3487 [7:40:54<1:19:54,  5.90s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10524.12 ms /    54 tokens (  194.89 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.23 ms /     3 runs   (  886.08 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13185.56 ms /    57 tokens\n",
      " 77%|███████▋  | 2675/3487 [7:41:08<1:49:26,  8.09s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2707.28 ms /    12 tokens (  225.61 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.27 ms /     3 runs   (  880.76 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5352.29 ms /    15 tokens\n",
      " 77%|███████▋  | 2676/3487 [7:41:13<1:38:14,  7.27s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15525.08 ms /    37 tokens (  419.60 ms per token,     2.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7462.94 ms /     3 runs   ( 2487.64 ms per token,     0.40 tokens per second)\n",
      "llama_perf_context_print:       total time =   22993.00 ms /    40 tokens\n",
      " 77%|███████▋  | 2677/3487 [7:41:36<2:41:55, 11.99s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3409.13 ms /    11 tokens (  309.92 ms per token,     3.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3474.57 ms /     3 runs   ( 1158.19 ms per token,     0.86 tokens per second)\n",
      "llama_perf_context_print:       total time =    6889.03 ms /    14 tokens\n",
      " 77%|███████▋  | 2678/3487 [7:41:43<2:21:11, 10.47s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9627.25 ms /    37 tokens (  260.20 ms per token,     3.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2940.07 ms /     3 runs   (  980.02 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =   12570.08 ms /    40 tokens\n",
      " 77%|███████▋  | 2679/3487 [7:41:55<2:29:32, 11.10s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4465.89 ms /    21 tokens (  212.66 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2788.06 ms /     3 runs   (  929.35 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7257.01 ms /    24 tokens\n",
      " 77%|███████▋  | 2680/3487 [7:42:03<2:13:52,  9.95s/it]Llama.generate: 307 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11878.42 ms /    62 tokens (  191.59 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.65 ms /     3 runs   (  880.22 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14521.60 ms /    65 tokens\n",
      " 77%|███████▋  | 2681/3487 [7:42:17<2:32:08, 11.33s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7887.90 ms /    40 tokens (  197.20 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3522.11 ms /     4 runs   (  880.53 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11413.45 ms /    44 tokens\n",
      " 77%|███████▋  | 2682/3487 [7:42:29<2:32:20, 11.35s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7378.57 ms /    37 tokens (  199.42 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.61 ms /     3 runs   (  882.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10029.63 ms /    40 tokens\n",
      " 77%|███████▋  | 2683/3487 [7:42:39<2:26:51, 10.96s/it]Llama.generate: 314 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4556.01 ms /    22 tokens (  207.09 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.71 ms /     3 runs   (  882.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7205.17 ms /    25 tokens\n",
      " 77%|███████▋  | 2684/3487 [7:42:46<2:11:37,  9.84s/it]Llama.generate: 306 prefix-match hit, remaining 109 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20163.18 ms /   109 tokens (  184.98 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.28 ms /     3 runs   (  881.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   22810.13 ms /   112 tokens\n",
      " 77%|███████▋  | 2685/3487 [7:43:09<3:03:31, 13.73s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7921.42 ms /    41 tokens (  193.21 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.72 ms /     3 runs   (  880.57 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10566.70 ms /    44 tokens\n",
      " 77%|███████▋  | 2686/3487 [7:43:19<2:50:39, 12.78s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7937.53 ms /    38 tokens (  208.88 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.43 ms /     3 runs   (  888.81 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10606.59 ms /    41 tokens\n",
      " 77%|███████▋  | 2687/3487 [7:43:30<2:41:46, 12.13s/it]Llama.generate: 306 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   18634.57 ms /    98 tokens (  190.15 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.02 ms /     3 runs   (  876.67 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   21266.55 ms /   101 tokens\n",
      " 77%|███████▋  | 2688/3487 [7:43:51<3:18:12, 14.88s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7481.38 ms /    38 tokens (  196.88 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.08 ms /     3 runs   (  897.03 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10175.47 ms /    41 tokens\n",
      " 77%|███████▋  | 2689/3487 [7:44:01<2:59:12, 13.47s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5049.17 ms /    25 tokens (  201.97 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.45 ms /     3 runs   (  891.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7725.41 ms /    28 tokens\n",
      " 77%|███████▋  | 2690/3487 [7:44:09<2:36:06, 11.75s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2269.42 ms /     9 tokens (  252.16 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.62 ms /     3 runs   (  891.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4947.29 ms /    12 tokens\n",
      " 77%|███████▋  | 2691/3487 [7:44:14<2:08:51,  9.71s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2094.93 ms /     8 tokens (  261.87 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.75 ms /     3 runs   (  885.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4752.99 ms /    11 tokens\n",
      " 77%|███████▋  | 2692/3487 [7:44:19<1:49:01,  8.23s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5743.82 ms /    29 tokens (  198.06 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.90 ms /     3 runs   (  881.97 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8392.07 ms /    32 tokens\n",
      " 77%|███████▋  | 2693/3487 [7:44:27<1:49:34,  8.28s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3712.42 ms /    15 tokens (  247.49 ms per token,     4.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2867.10 ms /     3 runs   (  955.70 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    6582.23 ms /    18 tokens\n",
      " 77%|███████▋  | 2694/3487 [7:44:34<1:42:43,  7.77s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6429.63 ms /    30 tokens (  214.32 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.45 ms /     3 runs   (  897.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9124.18 ms /    33 tokens\n",
      " 77%|███████▋  | 2695/3487 [7:44:43<1:47:59,  8.18s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2720.92 ms /    12 tokens (  226.74 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.21 ms /     3 runs   (  889.07 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5391.15 ms /    15 tokens\n",
      " 77%|███████▋  | 2696/3487 [7:44:48<1:36:50,  7.35s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11622.45 ms /    60 tokens (  193.71 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.47 ms /     3 runs   (  887.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14286.46 ms /    63 tokens\n",
      " 77%|███████▋  | 2697/3487 [7:45:03<2:04:10,  9.43s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1953.78 ms /     7 tokens (  279.11 ms per token,     3.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2793.07 ms /     3 runs   (  931.02 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4749.29 ms /    10 tokens\n",
      " 77%|███████▋  | 2698/3487 [7:45:07<1:45:34,  8.03s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5729.58 ms /    26 tokens (  220.37 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2759.31 ms /     3 runs   (  919.77 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8491.07 ms /    29 tokens\n",
      " 77%|███████▋  | 2699/3487 [7:45:16<1:47:17,  8.17s/it]Llama.generate: 308 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7430.98 ms /    34 tokens (  218.56 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.29 ms /     3 runs   (  907.10 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   10155.06 ms /    37 tokens\n",
      " 77%|███████▋  | 2700/3487 [7:45:26<1:55:00,  8.77s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4547.96 ms /    20 tokens (  227.40 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.37 ms /     3 runs   (  894.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7234.90 ms /    23 tokens\n",
      " 77%|███████▋  | 2701/3487 [7:45:33<1:48:52,  8.31s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13557.94 ms /    47 tokens (  288.47 ms per token,     3.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3012.56 ms /     3 runs   ( 1004.19 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =   16573.06 ms /    50 tokens\n",
      " 77%|███████▋  | 2702/3487 [7:45:50<2:21:12, 10.79s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7872.19 ms /    34 tokens (  231.53 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3062.60 ms /     3 runs   ( 1020.87 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =   10937.35 ms /    37 tokens\n",
      " 78%|███████▊  | 2703/3487 [7:46:01<2:21:37, 10.84s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2302.55 ms /     9 tokens (  255.84 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.19 ms /     3 runs   (  905.40 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5021.16 ms /    12 tokens\n",
      " 78%|███████▊  | 2704/3487 [7:46:06<1:58:41,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4269.33 ms /    14 tokens (  304.95 ms per token,     3.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4140.44 ms /     3 runs   ( 1380.15 ms per token,     0.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    8411.87 ms /    17 tokens\n",
      " 78%|███████▊  | 2705/3487 [7:46:14<1:55:54,  8.89s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5376.92 ms /    18 tokens (  298.72 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3069.63 ms /     3 runs   ( 1023.21 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    8449.73 ms /    21 tokens\n",
      " 78%|███████▊  | 2706/3487 [7:46:23<1:54:03,  8.76s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4480.52 ms /    19 tokens (  235.82 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2762.48 ms /     3 runs   (  920.83 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7246.56 ms /    22 tokens\n",
      " 78%|███████▊  | 2707/3487 [7:46:30<1:48:02,  8.31s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10029.18 ms /    49 tokens (  204.68 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.58 ms /     3 runs   (  899.86 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   12731.76 ms /    52 tokens\n",
      " 78%|███████▊  | 2708/3487 [7:46:43<2:05:09,  9.64s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11965.78 ms /    62 tokens (  193.00 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.02 ms /     3 runs   (  896.67 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14658.30 ms /    65 tokens\n",
      " 78%|███████▊  | 2709/3487 [7:46:57<2:24:32, 11.15s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7923.58 ms /    37 tokens (  214.15 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.01 ms /     3 runs   (  902.67 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10634.00 ms /    40 tokens\n",
      " 78%|███████▊  | 2710/3487 [7:47:08<2:22:23, 11.00s/it]Llama.generate: 315 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3286.78 ms /    15 tokens (  219.12 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.24 ms /     3 runs   (  892.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5966.81 ms /    18 tokens\n",
      " 78%|███████▊  | 2711/3487 [7:47:14<2:02:44,  9.49s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4645.69 ms /    22 tokens (  211.17 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.90 ms /     3 runs   (  902.30 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7355.15 ms /    25 tokens\n",
      " 78%|███████▊  | 2712/3487 [7:47:21<1:54:20,  8.85s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2267.11 ms /     9 tokens (  251.90 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.84 ms /     3 runs   (  899.28 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4968.09 ms /    12 tokens\n",
      " 78%|███████▊  | 2713/3487 [7:47:26<1:39:11,  7.69s/it]Llama.generate: 311 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3304.48 ms /    15 tokens (  220.30 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.70 ms /     3 runs   (  886.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5968.26 ms /    18 tokens\n",
      " 78%|███████▊  | 2714/3487 [7:47:32<1:32:26,  7.18s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9124.62 ms /    47 tokens (  194.14 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.28 ms /     3 runs   (  886.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11787.14 ms /    50 tokens\n",
      " 78%|███████▊  | 2715/3487 [7:47:44<1:50:09,  8.56s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2586.76 ms /    11 tokens (  235.16 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.95 ms /     3 runs   (  903.65 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5300.17 ms /    14 tokens\n",
      " 78%|███████▊  | 2716/3487 [7:47:50<1:37:28,  7.59s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2369.51 ms /     9 tokens (  263.28 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.45 ms /     3 runs   (  887.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5035.64 ms /    12 tokens\n",
      " 78%|███████▊  | 2717/3487 [7:47:55<1:27:33,  6.82s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3610.29 ms /    14 tokens (  257.88 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2960.12 ms /     3 runs   (  986.71 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    6572.88 ms /    17 tokens\n",
      " 78%|███████▊  | 2718/3487 [7:48:01<1:26:31,  6.75s/it]Llama.generate: 311 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2278.07 ms /     9 tokens (  253.12 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.83 ms /     3 runs   (  902.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4988.57 ms /    12 tokens\n",
      " 78%|███████▊  | 2719/3487 [7:48:06<1:19:40,  6.22s/it]Llama.generate: 307 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1857.59 ms /     6 tokens (  309.60 ms per token,     3.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2763.12 ms /     3 runs   (  921.04 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4623.37 ms /     9 tokens\n",
      " 78%|███████▊  | 2720/3487 [7:48:11<1:13:27,  5.75s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3144.30 ms /    13 tokens (  241.87 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.82 ms /     3 runs   (  893.61 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5828.21 ms /    16 tokens\n",
      " 78%|███████▊  | 2721/3487 [7:48:17<1:13:42,  5.77s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5392.94 ms /    27 tokens (  199.74 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.85 ms /     3 runs   (  885.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8053.36 ms /    30 tokens\n",
      " 78%|███████▊  | 2722/3487 [7:48:25<1:22:21,  6.46s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5245.74 ms /    26 tokens (  201.76 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.24 ms /     3 runs   (  895.08 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7933.47 ms /    29 tokens\n",
      " 78%|███████▊  | 2723/3487 [7:48:33<1:27:55,  6.91s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3663.29 ms /    17 tokens (  215.49 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.42 ms /     3 runs   (  893.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6345.89 ms /    20 tokens\n",
      " 78%|███████▊  | 2724/3487 [7:48:39<1:25:42,  6.74s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3327.31 ms /    15 tokens (  221.82 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.93 ms /     3 runs   (  889.31 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5997.86 ms /    18 tokens\n",
      " 78%|███████▊  | 2725/3487 [7:48:45<1:22:48,  6.52s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8315.31 ms /    39 tokens (  213.21 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2729.13 ms /     3 runs   (  909.71 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   11047.44 ms /    42 tokens\n",
      " 78%|███████▊  | 2726/3487 [7:48:56<1:39:57,  7.88s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3794.12 ms /    17 tokens (  223.18 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.38 ms /     3 runs   (  892.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6474.64 ms /    20 tokens\n",
      " 78%|███████▊  | 2727/3487 [7:49:03<1:34:30,  7.46s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2288.66 ms /     9 tokens (  254.30 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.97 ms /     3 runs   (  897.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4984.80 ms /    12 tokens\n",
      " 78%|███████▊  | 2728/3487 [7:49:08<1:25:01,  6.72s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3616.65 ms /    16 tokens (  226.04 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.20 ms /     3 runs   (  888.07 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6283.16 ms /    19 tokens\n",
      " 78%|███████▊  | 2729/3487 [7:49:14<1:23:17,  6.59s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2531.36 ms /    10 tokens (  253.14 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.44 ms /     3 runs   (  892.81 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5212.82 ms /    13 tokens\n",
      " 78%|███████▊  | 2730/3487 [7:49:19<1:17:59,  6.18s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4299.99 ms /    21 tokens (  204.76 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.25 ms /     3 runs   (  891.75 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6978.19 ms /    24 tokens\n",
      " 78%|███████▊  | 2731/3487 [7:49:26<1:20:55,  6.42s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2624.34 ms /    11 tokens (  238.58 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.06 ms /     3 runs   (  883.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5277.59 ms /    14 tokens\n",
      " 78%|███████▊  | 2732/3487 [7:49:31<1:16:31,  6.08s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4688.25 ms /    23 tokens (  203.84 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.98 ms /     3 runs   (  890.33 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7362.50 ms /    26 tokens\n",
      " 78%|███████▊  | 2733/3487 [7:49:39<1:21:17,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3731.37 ms /    15 tokens (  248.76 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.86 ms /     3 runs   (  883.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6386.18 ms /    18 tokens\n",
      " 78%|███████▊  | 2734/3487 [7:49:45<1:20:54,  6.45s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5839.61 ms /    30 tokens (  194.65 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.32 ms /     3 runs   (  891.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8516.08 ms /    33 tokens\n",
      " 78%|███████▊  | 2735/3487 [7:49:54<1:28:36,  7.07s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2090.40 ms /     7 tokens (  298.63 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.87 ms /     3 runs   (  894.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4777.66 ms /    10 tokens\n",
      " 78%|███████▊  | 2736/3487 [7:49:58<1:19:55,  6.39s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7622.42 ms /    38 tokens (  200.59 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.20 ms /     3 runs   (  884.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10279.66 ms /    41 tokens\n",
      " 78%|███████▊  | 2737/3487 [7:50:09<1:34:26,  7.56s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2784.97 ms /    12 tokens (  232.08 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.57 ms /     3 runs   (  884.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5441.72 ms /    15 tokens\n",
      " 79%|███████▊  | 2738/3487 [7:50:14<1:26:25,  6.92s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4190.19 ms /    20 tokens (  209.51 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.83 ms /     3 runs   (  895.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6880.87 ms /    23 tokens\n",
      " 79%|███████▊  | 2739/3487 [7:50:21<1:26:10,  6.91s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1715.74 ms /     6 tokens (  285.96 ms per token,     3.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.80 ms /     3 runs   (  891.27 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4391.94 ms /     9 tokens\n",
      " 79%|███████▊  | 2740/3487 [7:50:25<1:16:40,  6.16s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7325.77 ms /    36 tokens (  203.49 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.47 ms /     3 runs   (  884.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9982.77 ms /    39 tokens\n",
      " 79%|███████▊  | 2741/3487 [7:50:35<1:30:52,  7.31s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8857.24 ms /    40 tokens (  221.43 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2743.97 ms /     3 runs   (  914.66 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   11604.00 ms /    43 tokens\n",
      " 79%|███████▊  | 2742/3487 [7:50:47<1:46:46,  8.60s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10340.98 ms /    54 tokens (  191.50 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.97 ms /     3 runs   (  886.32 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13002.94 ms /    57 tokens\n",
      " 79%|███████▊  | 2743/3487 [7:51:00<2:03:02,  9.92s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3220.29 ms /    15 tokens (  214.69 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.63 ms /     3 runs   (  886.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5883.13 ms /    18 tokens\n",
      " 79%|███████▊  | 2744/3487 [7:51:06<1:47:54,  8.71s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7334.17 ms /    35 tokens (  209.55 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.92 ms /     3 runs   (  889.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10006.88 ms /    38 tokens\n",
      " 79%|███████▊  | 2745/3487 [7:51:16<1:52:35,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1723.26 ms /     6 tokens (  287.21 ms per token,     3.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.74 ms /     3 runs   (  889.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4394.55 ms /     9 tokens\n",
      " 79%|███████▊  | 2746/3487 [7:51:20<1:35:01,  7.69s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8819.10 ms /    45 tokens (  195.98 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.13 ms /     3 runs   (  896.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11510.80 ms /    48 tokens\n",
      " 79%|███████▉  | 2747/3487 [7:51:32<1:49:02,  8.84s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7870.60 ms /    38 tokens (  207.12 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2892.49 ms /     3 runs   (  964.16 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   10765.25 ms /    41 tokens\n",
      " 79%|███████▉  | 2748/3487 [7:51:43<1:56:02,  9.42s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3469.10 ms /    15 tokens (  231.27 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.80 ms /     3 runs   (  889.93 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6141.43 ms /    18 tokens\n",
      " 79%|███████▉  | 2749/3487 [7:51:49<1:43:48,  8.44s/it]Llama.generate: 307 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11066.20 ms /    56 tokens (  197.61 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.27 ms /     3 runs   (  893.42 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13748.84 ms /    59 tokens\n",
      " 79%|███████▉  | 2750/3487 [7:52:03<2:03:15, 10.03s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1999.97 ms /     7 tokens (  285.71 ms per token,     3.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.77 ms /     3 runs   (  908.59 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4728.44 ms /    10 tokens\n",
      " 79%|███████▉  | 2751/3487 [7:52:07<1:43:36,  8.45s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4083.06 ms /    19 tokens (  214.90 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4152.86 ms /     3 runs   ( 1384.29 ms per token,     0.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    8237.82 ms /    22 tokens\n",
      " 79%|███████▉  | 2752/3487 [7:52:16<1:42:43,  8.39s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10360.43 ms /    40 tokens (  259.01 ms per token,     3.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3042.99 ms /     3 runs   ( 1014.33 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   13406.39 ms /    43 tokens\n",
      " 79%|███████▉  | 2753/3487 [7:52:29<2:01:03,  9.90s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7195.56 ms /    28 tokens (  256.98 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3453.26 ms /     3 runs   ( 1151.09 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =   10651.93 ms /    31 tokens\n",
      " 79%|███████▉  | 2754/3487 [7:52:40<2:03:42, 10.13s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6175.77 ms /    16 tokens (  385.99 ms per token,     2.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3164.38 ms /     3 runs   ( 1054.79 ms per token,     0.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    9343.42 ms /    19 tokens\n",
      " 79%|███████▉  | 2755/3487 [7:52:49<2:00:43,  9.89s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3329.88 ms /    13 tokens (  256.14 ms per token,     3.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2747.77 ms /     3 runs   (  915.92 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6080.38 ms /    16 tokens\n",
      " 79%|███████▉  | 2756/3487 [7:52:55<1:46:38,  8.75s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2662.38 ms /    11 tokens (  242.03 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.51 ms /     3 runs   (  901.84 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5370.16 ms /    14 tokens\n",
      " 79%|███████▉  | 2757/3487 [7:53:00<1:34:11,  7.74s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4649.53 ms /    20 tokens (  232.48 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.67 ms /     3 runs   (  890.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7322.95 ms /    23 tokens\n",
      " 79%|███████▉  | 2758/3487 [7:53:08<1:32:33,  7.62s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3056.34 ms /    13 tokens (  235.10 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.86 ms /     3 runs   (  898.62 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5754.19 ms /    16 tokens\n",
      " 79%|███████▉  | 2759/3487 [7:53:14<1:25:40,  7.06s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3026.87 ms /    13 tokens (  232.84 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.39 ms /     3 runs   (  892.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5706.86 ms /    16 tokens\n",
      " 79%|███████▉  | 2760/3487 [7:53:19<1:20:39,  6.66s/it]Llama.generate: 316 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3023.27 ms /    13 tokens (  232.56 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.23 ms /     3 runs   (  892.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5703.71 ms /    16 tokens\n",
      " 79%|███████▉  | 2761/3487 [7:53:25<1:17:07,  6.37s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2636.97 ms /    11 tokens (  239.72 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.08 ms /     3 runs   (  895.69 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5326.06 ms /    14 tokens\n",
      " 79%|███████▉  | 2762/3487 [7:53:30<1:13:14,  6.06s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3040.74 ms /    13 tokens (  233.90 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.97 ms /     3 runs   (  886.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5703.24 ms /    16 tokens\n",
      " 79%|███████▉  | 2763/3487 [7:53:36<1:11:52,  5.96s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3023.86 ms /    13 tokens (  232.60 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.89 ms /     3 runs   (  888.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5692.16 ms /    16 tokens\n",
      " 79%|███████▉  | 2764/3487 [7:53:42<1:10:50,  5.88s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3010.59 ms /    13 tokens (  231.58 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.59 ms /     3 runs   (  889.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5681.39 ms /    16 tokens\n",
      " 79%|███████▉  | 2765/3487 [7:53:47<1:10:03,  5.82s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4693.75 ms /    21 tokens (  223.51 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.69 ms /     3 runs   (  889.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7365.17 ms /    24 tokens\n",
      " 79%|███████▉  | 2766/3487 [7:53:55<1:15:33,  6.29s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3909.74 ms /    17 tokens (  229.98 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.48 ms /     3 runs   (  894.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6596.57 ms /    20 tokens\n",
      " 79%|███████▉  | 2767/3487 [7:54:01<1:16:35,  6.38s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3179.30 ms /    14 tokens (  227.09 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.30 ms /     3 runs   (  885.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5838.85 ms /    17 tokens\n",
      " 79%|███████▉  | 2768/3487 [7:54:07<1:14:33,  6.22s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3060.93 ms /    13 tokens (  235.46 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.67 ms /     3 runs   (  891.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5737.40 ms /    16 tokens\n",
      " 79%|███████▉  | 2769/3487 [7:54:13<1:12:44,  6.08s/it]Llama.generate: 316 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2628.78 ms /    11 tokens (  238.98 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.73 ms /     3 runs   (  893.58 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5312.55 ms /    14 tokens\n",
      " 79%|███████▉  | 2770/3487 [7:54:18<1:09:55,  5.85s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2035.90 ms /     7 tokens (  290.84 ms per token,     3.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.88 ms /     3 runs   (  897.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4732.21 ms /    10 tokens\n",
      " 79%|███████▉  | 2771/3487 [7:54:23<1:05:50,  5.52s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3153.07 ms /    14 tokens (  225.22 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2862.58 ms /     3 runs   (  954.19 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    6018.40 ms /    17 tokens\n",
      " 79%|███████▉  | 2772/3487 [7:54:29<1:07:34,  5.67s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6015.49 ms /    29 tokens (  207.43 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.33 ms /     3 runs   (  902.11 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8724.48 ms /    32 tokens\n",
      " 80%|███████▉  | 2773/3487 [7:54:38<1:18:24,  6.59s/it]Llama.generate: 316 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2233.44 ms /     4 tokens (  558.36 ms per token,     1.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2758.78 ms /     3 runs   (  919.59 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4994.99 ms /     7 tokens\n",
      " 80%|███████▉  | 2774/3487 [7:54:43<1:12:38,  6.11s/it]Llama.generate: 319 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3893.24 ms /     4 runs   (  973.31 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    3895.38 ms /     5 tokens\n",
      " 80%|███████▉  | 2775/3487 [7:54:47<1:04:40,  5.45s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3079.46 ms /    13 tokens (  236.88 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.49 ms /     3 runs   (  889.16 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5749.26 ms /    16 tokens\n",
      " 80%|███████▉  | 2776/3487 [7:54:52<1:05:40,  5.54s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5740.67 ms /    28 tokens (  205.02 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.76 ms /     3 runs   (  896.25 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8432.36 ms /    31 tokens\n",
      " 80%|███████▉  | 2777/3487 [7:55:01<1:15:52,  6.41s/it]Llama.generate: 316 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1453.53 ms /     4 tokens (  363.38 ms per token,     2.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2831.38 ms /     3 runs   (  943.79 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4287.81 ms /     7 tokens\n",
      " 80%|███████▉  | 2778/3487 [7:55:05<1:08:15,  5.78s/it]Llama.generate: 319 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3920.12 ms /     4 runs   (  980.03 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    3922.56 ms /     5 tokens\n",
      " 80%|███████▉  | 2779/3487 [7:55:09<1:01:38,  5.22s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2705.65 ms /    11 tokens (  245.97 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.34 ms /     3 runs   (  889.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5377.83 ms /    14 tokens\n",
      " 80%|███████▉  | 2780/3487 [7:55:14<1:02:07,  5.27s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5049.79 ms /    23 tokens (  219.56 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.57 ms /     3 runs   (  900.86 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7755.52 ms /    26 tokens\n",
      " 80%|███████▉  | 2781/3487 [7:55:22<1:10:50,  6.02s/it]Llama.generate: 316 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1368.39 ms /     4 tokens (  342.10 ms per token,     2.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2844.69 ms /     3 runs   (  948.23 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4215.67 ms /     7 tokens\n",
      " 80%|███████▉  | 2782/3487 [7:55:26<1:04:24,  5.48s/it]Llama.generate: 316 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4087.34 ms /    19 tokens (  215.12 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.59 ms /     3 runs   (  888.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6754.51 ms /    22 tokens\n",
      " 80%|███████▉  | 2783/3487 [7:55:33<1:08:49,  5.87s/it]Llama.generate: 316 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1404.19 ms /     4 tokens (  351.05 ms per token,     2.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2852.28 ms /     3 runs   (  950.76 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4259.14 ms /     7 tokens\n",
      " 80%|███████▉  | 2784/3487 [7:55:38<1:03:06,  5.39s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4365.67 ms /    21 tokens (  207.89 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.04 ms /     3 runs   (  887.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7030.31 ms /    24 tokens\n",
      " 80%|███████▉  | 2785/3487 [7:55:45<1:08:49,  5.88s/it]Llama.generate: 307 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   29090.48 ms /   103 tokens (  282.43 ms per token,     3.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3829.70 ms /     3 runs   ( 1276.57 ms per token,     0.78 tokens per second)\n",
      "llama_perf_context_print:       total time =   32924.38 ms /   106 tokens\n",
      " 80%|███████▉  | 2786/3487 [7:56:17<2:43:35, 14.00s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3975.88 ms /    13 tokens (  305.84 ms per token,     3.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3545.18 ms /     3 runs   ( 1181.73 ms per token,     0.85 tokens per second)\n",
      "llama_perf_context_print:       total time =    7525.77 ms /    16 tokens\n",
      " 80%|███████▉  | 2787/3487 [7:56:25<2:20:47, 12.07s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10776.68 ms /    43 tokens (  250.62 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3044.08 ms /     3 runs   ( 1014.69 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   13823.73 ms /    46 tokens\n",
      " 80%|███████▉  | 2788/3487 [7:56:39<2:26:46, 12.60s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2728.26 ms /    10 tokens (  272.83 ms per token,     3.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6754.33 ms /     3 runs   ( 2251.44 ms per token,     0.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    9486.92 ms /    13 tokens\n",
      " 80%|███████▉  | 2789/3487 [7:56:48<2:15:45, 11.67s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5521.49 ms /     7 tokens (  788.78 ms per token,     1.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3309.86 ms /     3 runs   ( 1103.29 ms per token,     0.91 tokens per second)\n",
      "llama_perf_context_print:       total time =    8835.53 ms /    10 tokens\n",
      " 80%|████████  | 2790/3487 [7:56:57<2:05:44, 10.82s/it]Llama.generate: 306 prefix-match hit, remaining 122 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   23932.99 ms /   122 tokens (  196.17 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.33 ms /     3 runs   (  902.78 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   26644.35 ms /   125 tokens\n",
      " 80%|████████  | 2791/3487 [7:57:24<3:00:38, 15.57s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7386.69 ms /    34 tokens (  217.26 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.85 ms /     3 runs   (  881.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10035.11 ms /    37 tokens\n",
      " 80%|████████  | 2792/3487 [7:57:34<2:41:10, 13.92s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11001.50 ms /    57 tokens (  193.01 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.60 ms /     3 runs   (  896.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13693.10 ms /    60 tokens\n",
      " 80%|████████  | 2793/3487 [7:57:48<2:40:12, 13.85s/it]Llama.generate: 306 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9852.93 ms /    51 tokens (  193.19 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.82 ms /     3 runs   (  885.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12513.56 ms /    54 tokens\n",
      " 80%|████████  | 2794/3487 [7:58:00<2:35:22, 13.45s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8848.24 ms /    45 tokens (  196.63 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.69 ms /     3 runs   (  887.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11514.19 ms /    48 tokens\n",
      " 80%|████████  | 2795/3487 [7:58:12<2:28:28, 12.87s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4792.92 ms /    20 tokens (  239.65 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.45 ms /     3 runs   (  911.82 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7531.02 ms /    23 tokens\n",
      " 80%|████████  | 2796/3487 [7:58:19<2:09:50, 11.27s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1362.30 ms /     4 tokens (  340.58 ms per token,     2.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2869.06 ms /     3 runs   (  956.35 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4234.00 ms /     7 tokens\n",
      " 80%|████████  | 2797/3487 [7:58:23<1:45:23,  9.16s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4289.63 ms /    21 tokens (  204.27 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.56 ms /     3 runs   (  883.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6943.88 ms /    24 tokens\n",
      " 80%|████████  | 2798/3487 [7:58:30<1:37:36,  8.50s/it]Llama.generate: 307 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9127.05 ms /    47 tokens (  194.19 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2872.87 ms /     3 runs   (  957.62 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   12002.23 ms /    50 tokens\n",
      " 80%|████████  | 2799/3487 [7:58:42<1:49:32,  9.55s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5080.90 ms /    25 tokens (  203.24 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.63 ms /     3 runs   (  885.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7739.64 ms /    28 tokens\n",
      " 80%|████████  | 2800/3487 [7:58:50<1:43:10,  9.01s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7295.46 ms /    33 tokens (  221.07 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.20 ms /     3 runs   (  893.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9977.86 ms /    36 tokens\n",
      " 80%|████████  | 2801/3487 [7:59:00<1:46:22,  9.30s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3039.09 ms /    13 tokens (  233.78 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.01 ms /     3 runs   (  883.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5691.63 ms /    16 tokens\n",
      " 80%|████████  | 2802/3487 [7:59:06<1:33:53,  8.22s/it]Llama.generate: 307 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17820.83 ms /    93 tokens (  191.62 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.15 ms /     3 runs   (  887.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20486.81 ms /    96 tokens\n",
      " 80%|████████  | 2803/3487 [7:59:26<2:15:43, 11.91s/it]Llama.generate: 307 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12939.83 ms /    66 tokens (  196.06 ms per token,     5.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.46 ms /     3 runs   (  890.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15612.87 ms /    69 tokens\n",
      " 80%|████████  | 2804/3487 [7:59:42<2:28:12, 13.02s/it]Llama.generate: 307 prefix-match hit, remaining 121 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   22424.89 ms /   121 tokens (  185.33 ms per token,     5.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.39 ms /     3 runs   (  881.46 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   25072.52 ms /   124 tokens\n",
      " 80%|████████  | 2805/3487 [8:00:07<3:09:07, 16.64s/it]Llama.generate: 307 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   20073.46 ms /   107 tokens (  187.60 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.18 ms /     3 runs   (  886.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   22734.39 ms /   110 tokens\n",
      " 80%|████████  | 2806/3487 [8:00:30<3:29:37, 18.47s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4070.92 ms /    19 tokens (  214.26 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.45 ms /     3 runs   (  880.48 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6714.81 ms /    22 tokens\n",
      " 80%|████████  | 2807/3487 [8:00:37<2:49:23, 14.95s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11401.24 ms /    59 tokens (  193.24 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2823.35 ms /     3 runs   (  941.12 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   14227.33 ms /    62 tokens\n",
      " 81%|████████  | 2808/3487 [8:00:51<2:46:43, 14.73s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4847.04 ms /    24 tokens (  201.96 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.54 ms /     3 runs   (  888.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7515.64 ms /    27 tokens\n",
      " 81%|████████  | 2809/3487 [8:00:58<2:22:02, 12.57s/it]Llama.generate: 307 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12374.45 ms /    63 tokens (  196.42 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.39 ms /     3 runs   (  881.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15021.65 ms /    66 tokens\n",
      " 81%|████████  | 2810/3487 [8:01:13<2:30:09, 13.31s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2696.54 ms /    12 tokens (  224.71 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.40 ms /     3 runs   (  882.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5346.20 ms /    15 tokens\n",
      " 81%|████████  | 2811/3487 [8:01:19<2:03:02, 10.92s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6156.66 ms /    31 tokens (  198.60 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.56 ms /     3 runs   (  885.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8815.92 ms /    34 tokens\n",
      " 81%|████████  | 2812/3487 [8:01:27<1:55:47, 10.29s/it]Llama.generate: 308 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2968.23 ms /    13 tokens (  228.33 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.32 ms /     3 runs   (  879.11 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5608.59 ms /    16 tokens\n",
      " 81%|████████  | 2813/3487 [8:01:33<1:39:51,  8.89s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2716.34 ms /    12 tokens (  226.36 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.53 ms /     3 runs   (  885.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5374.32 ms /    15 tokens\n",
      " 81%|████████  | 2814/3487 [8:01:38<1:27:54,  7.84s/it]Llama.generate: 310 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9351.33 ms /    47 tokens (  198.96 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.50 ms /     3 runs   (  880.50 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11994.94 ms /    50 tokens\n",
      " 81%|████████  | 2815/3487 [8:01:50<1:41:46,  9.09s/it]Llama.generate: 310 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2104.35 ms /     8 tokens (  263.04 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.67 ms /     3 runs   (  890.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4779.26 ms /    11 tokens\n",
      " 81%|████████  | 2816/3487 [8:01:55<1:27:11,  7.80s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9419.11 ms /    46 tokens (  204.76 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2795.46 ms /     3 runs   (  931.82 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12217.58 ms /    49 tokens\n",
      " 81%|████████  | 2817/3487 [8:02:08<1:41:54,  9.13s/it]Llama.generate: 306 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14146.20 ms /    73 tokens (  193.78 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.95 ms /     3 runs   (  881.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16795.00 ms /    76 tokens\n",
      " 81%|████████  | 2818/3487 [8:02:24<2:07:25, 11.43s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3796.33 ms /    18 tokens (  210.91 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.80 ms /     3 runs   (  881.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6443.57 ms /    21 tokens\n",
      " 81%|████████  | 2819/3487 [8:02:31<1:50:37,  9.94s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4812.12 ms /    24 tokens (  200.51 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.55 ms /     3 runs   (  882.85 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7462.77 ms /    27 tokens\n",
      " 81%|████████  | 2820/3487 [8:02:38<1:42:13,  9.20s/it]Llama.generate: 307 prefix-match hit, remaining 97 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19248.16 ms /    97 tokens (  198.43 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.94 ms /     3 runs   (  892.65 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   21928.77 ms /   100 tokens\n",
      " 81%|████████  | 2821/3487 [8:03:00<2:24:30, 13.02s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13765.10 ms /    72 tokens (  191.18 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.48 ms /     3 runs   (  878.49 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16402.97 ms /    75 tokens\n",
      " 81%|████████  | 2822/3487 [8:03:17<2:35:34, 14.04s/it]Llama.generate: 307 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15714.41 ms /    83 tokens (  189.33 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.43 ms /     3 runs   (  905.14 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   18432.43 ms /    86 tokens\n",
      " 81%|████████  | 2823/3487 [8:03:35<2:49:57, 15.36s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5496.40 ms /    27 tokens (  203.57 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.51 ms /     3 runs   (  894.50 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8182.11 ms /    30 tokens\n",
      " 81%|████████  | 2824/3487 [8:03:43<2:25:56, 13.21s/it]Llama.generate: 306 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13780.32 ms /    73 tokens (  188.77 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.94 ms /     3 runs   (  881.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16426.67 ms /    76 tokens\n",
      " 81%|████████  | 2825/3487 [8:04:00<2:36:24, 14.18s/it]Llama.generate: 306 prefix-match hit, remaining 116 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21970.40 ms /   116 tokens (  189.40 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.95 ms /     3 runs   (  885.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   24630.66 ms /   119 tokens\n",
      " 81%|████████  | 2826/3487 [8:04:24<3:10:44, 17.31s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5478.97 ms /    27 tokens (  202.92 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.36 ms /     3 runs   (  879.45 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8119.79 ms /    30 tokens\n",
      " 81%|████████  | 2827/3487 [8:04:32<2:40:08, 14.56s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3528.67 ms /    16 tokens (  220.54 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.52 ms /     3 runs   (  885.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6188.18 ms /    19 tokens\n",
      " 81%|████████  | 2828/3487 [8:04:39<2:12:21, 12.05s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6278.94 ms /    31 tokens (  202.55 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.49 ms /     3 runs   (  890.50 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8953.07 ms /    34 tokens\n",
      " 81%|████████  | 2829/3487 [8:04:48<2:01:59, 11.12s/it]Llama.generate: 307 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10387.61 ms /    54 tokens (  192.36 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2768.48 ms /     3 runs   (  922.83 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   13159.50 ms /    57 tokens\n",
      " 81%|████████  | 2830/3487 [8:05:01<2:08:30, 11.74s/it]Llama.generate: 306 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15964.23 ms /    84 tokens (  190.05 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.96 ms /     3 runs   (  879.99 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   18606.51 ms /    87 tokens\n",
      " 81%|████████  | 2831/3487 [8:05:19<2:30:52, 13.80s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7865.03 ms /    39 tokens (  201.67 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.45 ms /     3 runs   (  879.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10507.46 ms /    42 tokens\n",
      " 81%|████████  | 2832/3487 [8:05:30<2:19:53, 12.81s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5389.93 ms /    27 tokens (  199.63 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.86 ms /     3 runs   (  883.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8043.10 ms /    30 tokens\n",
      " 81%|████████  | 2833/3487 [8:05:38<2:04:05, 11.38s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5205.42 ms /    24 tokens (  216.89 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2623.41 ms /     3 runs   (  874.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7831.39 ms /    27 tokens\n",
      " 81%|████████▏ | 2834/3487 [8:05:46<1:52:19, 10.32s/it]Llama.generate: 307 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7807.19 ms /    37 tokens (  211.01 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2847.47 ms /     3 runs   (  949.16 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   10657.22 ms /    40 tokens\n",
      " 81%|████████▏ | 2835/3487 [8:05:56<1:53:16, 10.42s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8214.08 ms /    41 tokens (  200.34 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.49 ms /     3 runs   (  879.16 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10854.53 ms /    44 tokens\n",
      " 81%|████████▏ | 2836/3487 [8:06:07<1:54:32, 10.56s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5291.46 ms /    26 tokens (  203.52 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.61 ms /     3 runs   (  881.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7939.01 ms /    29 tokens\n",
      " 81%|████████▏ | 2837/3487 [8:06:15<1:45:52,  9.77s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5338.05 ms /    27 tokens (  197.71 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.06 ms /     3 runs   (  882.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7987.93 ms /    30 tokens\n",
      " 81%|████████▏ | 2838/3487 [8:06:23<1:39:57,  9.24s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4359.94 ms /    21 tokens (  207.62 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.95 ms /     3 runs   (  880.32 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7003.69 ms /    24 tokens\n",
      " 81%|████████▏ | 2839/3487 [8:06:30<1:32:34,  8.57s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3040.37 ms /    13 tokens (  233.87 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.61 ms /     3 runs   (  881.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5687.15 ms /    16 tokens\n",
      " 81%|████████▏ | 2840/3487 [8:06:36<1:23:07,  7.71s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2248.62 ms /     9 tokens (  249.85 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.18 ms /     3 runs   (  885.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4908.52 ms /    12 tokens\n",
      " 81%|████████▏ | 2841/3487 [8:06:41<1:13:59,  6.87s/it]Llama.generate: 307 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12412.19 ms /    61 tokens (  203.48 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2779.86 ms /     3 runs   (  926.62 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   15194.93 ms /    64 tokens\n",
      " 82%|████████▏ | 2842/3487 [8:06:56<1:40:44,  9.37s/it]Llama.generate: 312 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3306.57 ms /    14 tokens (  236.18 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.44 ms /     3 runs   (  902.81 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6018.03 ms /    17 tokens\n",
      " 82%|████████▏ | 2843/3487 [8:07:02<1:29:49,  8.37s/it]Llama.generate: 315 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1837.04 ms /     4 tokens (  459.26 ms per token,     2.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.16 ms /     3 runs   (  907.05 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4560.50 ms /     7 tokens\n",
      " 82%|████████▏ | 2844/3487 [8:07:07<1:17:27,  7.23s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4826.93 ms /    22 tokens (  219.41 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.26 ms /     3 runs   (  882.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7475.92 ms /    25 tokens\n",
      " 82%|████████▏ | 2845/3487 [8:07:14<1:18:10,  7.31s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8584.58 ms /    44 tokens (  195.10 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.78 ms /     3 runs   (  883.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11237.77 ms /    47 tokens\n",
      " 82%|████████▏ | 2846/3487 [8:07:25<1:30:40,  8.49s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7851.65 ms /    39 tokens (  201.32 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.93 ms /     3 runs   (  883.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10505.68 ms /    42 tokens\n",
      " 82%|████████▏ | 2847/3487 [8:07:36<1:37:01,  9.10s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7226.49 ms /    34 tokens (  212.54 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.36 ms /     3 runs   (  876.79 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9859.09 ms /    37 tokens\n",
      " 82%|████████▏ | 2848/3487 [8:07:46<1:39:20,  9.33s/it]Llama.generate: 307 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10051.47 ms /    52 tokens (  193.30 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.09 ms /     3 runs   (  880.70 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12696.36 ms /    55 tokens\n",
      " 82%|████████▏ | 2849/3487 [8:07:58<1:49:57, 10.34s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9883.55 ms /    49 tokens (  201.71 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.11 ms /     3 runs   (  885.37 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12541.61 ms /    52 tokens\n",
      " 82%|████████▏ | 2850/3487 [8:08:11<1:56:48, 11.00s/it]Llama.generate: 306 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13814.99 ms /    73 tokens (  189.25 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.99 ms /     3 runs   (  881.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16462.36 ms /    76 tokens\n",
      " 82%|████████▏ | 2851/3487 [8:08:27<2:14:01, 12.64s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1982.04 ms /     7 tokens (  283.15 ms per token,     3.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.15 ms /     3 runs   (  884.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4637.40 ms /    10 tokens\n",
      " 82%|████████▏ | 2852/3487 [8:08:32<1:48:25, 10.24s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3801.35 ms /    18 tokens (  211.19 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.92 ms /     3 runs   (  889.97 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6473.80 ms /    21 tokens\n",
      " 82%|████████▏ | 2853/3487 [8:08:39<1:36:19,  9.12s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5340.01 ms /    26 tokens (  205.39 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.07 ms /     3 runs   (  891.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8016.17 ms /    29 tokens\n",
      " 82%|████████▏ | 2854/3487 [8:08:47<1:32:43,  8.79s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5286.76 ms /    26 tokens (  203.34 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2636.52 ms /     3 runs   (  878.84 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7926.37 ms /    29 tokens\n",
      " 82%|████████▏ | 2855/3487 [8:08:55<1:29:52,  8.53s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2141.29 ms /     8 tokens (  267.66 ms per token,     3.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.41 ms /     3 runs   (  908.14 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4869.20 ms /    11 tokens\n",
      " 82%|████████▏ | 2856/3487 [8:08:59<1:18:12,  7.44s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7277.34 ms /    34 tokens (  214.04 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.66 ms /     3 runs   (  883.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9930.54 ms /    37 tokens\n",
      " 82%|████████▏ | 2857/3487 [8:09:09<1:25:57,  8.19s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4979.53 ms /    22 tokens (  226.34 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.98 ms /     3 runs   (  901.66 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7687.38 ms /    25 tokens\n",
      " 82%|████████▏ | 2858/3487 [8:09:17<1:24:17,  8.04s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4312.18 ms /    21 tokens (  205.34 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.50 ms /     3 runs   (  898.83 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7011.05 ms /    24 tokens\n",
      " 82%|████████▏ | 2859/3487 [8:09:24<1:20:56,  7.73s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4393.22 ms /    21 tokens (  209.20 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.58 ms /     3 runs   (  896.19 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7084.18 ms /    24 tokens\n",
      " 82%|████████▏ | 2860/3487 [8:09:31<1:18:48,  7.54s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3298.80 ms /    15 tokens (  219.92 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.42 ms /     3 runs   (  891.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5974.25 ms /    18 tokens\n",
      " 82%|████████▏ | 2861/3487 [8:09:37<1:13:47,  7.07s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5157.77 ms /    25 tokens (  206.31 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.67 ms /     3 runs   (  890.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7830.76 ms /    28 tokens\n",
      " 82%|████████▏ | 2862/3487 [8:09:45<1:16:04,  7.30s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1992.30 ms /     7 tokens (  284.61 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.23 ms /     3 runs   (  890.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4667.26 ms /    10 tokens\n",
      " 82%|████████▏ | 2863/3487 [8:09:50<1:07:44,  6.51s/it]Llama.generate: 306 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14407.90 ms /    72 tokens (  200.11 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.61 ms /     3 runs   (  887.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17073.36 ms /    75 tokens\n",
      " 82%|████████▏ | 2864/3487 [8:10:07<1:40:33,  9.68s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7798.47 ms /    36 tokens (  216.62 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.37 ms /     3 runs   (  888.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10465.44 ms /    39 tokens\n",
      " 82%|████████▏ | 2865/3487 [8:10:17<1:42:51,  9.92s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4271.90 ms /    19 tokens (  224.84 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.52 ms /     3 runs   (  891.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6950.08 ms /    22 tokens\n",
      " 82%|████████▏ | 2866/3487 [8:10:24<1:33:29,  9.03s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8203.68 ms /    41 tokens (  200.09 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.45 ms /     3 runs   (  890.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10877.19 ms /    44 tokens\n",
      " 82%|████████▏ | 2867/3487 [8:10:35<1:39:04,  9.59s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3593.08 ms /    16 tokens (  224.57 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.69 ms /     3 runs   (  899.90 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6295.94 ms /    19 tokens\n",
      " 82%|████████▏ | 2868/3487 [8:10:41<1:28:45,  8.60s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5798.51 ms /    28 tokens (  207.09 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.54 ms /     3 runs   (  889.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8471.02 ms /    31 tokens\n",
      " 82%|████████▏ | 2869/3487 [8:10:50<1:28:13,  8.57s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2533.68 ms /    10 tokens (  253.37 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2944.33 ms /     3 runs   (  981.44 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    5480.97 ms /    13 tokens\n",
      " 82%|████████▏ | 2870/3487 [8:10:55<1:18:35,  7.64s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1386.03 ms /     4 tokens (  346.51 ms per token,     2.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2864.86 ms /     3 runs   (  954.95 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4253.63 ms /     7 tokens\n",
      " 82%|████████▏ | 2871/3487 [8:11:00<1:08:03,  6.63s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5348.71 ms /    24 tokens (  222.86 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.88 ms /     3 runs   (  892.63 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8028.93 ms /    27 tokens\n",
      " 82%|████████▏ | 2872/3487 [8:11:08<1:12:16,  7.05s/it]Llama.generate: 307 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14349.71 ms /    75 tokens (  191.33 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.36 ms /     3 runs   (  887.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17014.33 ms /    78 tokens\n",
      " 82%|████████▏ | 2873/3487 [8:11:25<1:42:46, 10.04s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2164.97 ms /     8 tokens (  270.62 ms per token,     3.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.94 ms /     3 runs   (  889.98 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4837.04 ms /    11 tokens\n",
      " 82%|████████▏ | 2874/3487 [8:11:30<1:26:40,  8.48s/it]Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9416.40 ms /    47 tokens (  200.35 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2769.39 ms /     3 runs   (  923.13 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   12188.29 ms /    50 tokens\n",
      " 82%|████████▏ | 2875/3487 [8:11:42<1:37:53,  9.60s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9590.53 ms /    49 tokens (  195.73 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.89 ms /     3 runs   (  882.96 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12242.36 ms /    52 tokens\n",
      " 82%|████████▏ | 2876/3487 [8:11:54<1:45:50, 10.39s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2159.53 ms /     8 tokens (  269.94 ms per token,     3.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.96 ms /     3 runs   (  899.99 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4862.20 ms /    11 tokens\n",
      " 83%|████████▎ | 2877/3487 [8:11:59<1:28:49,  8.74s/it]Llama.generate: 307 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15217.91 ms /    78 tokens (  195.10 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.06 ms /     3 runs   (  905.02 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   17935.58 ms /    81 tokens\n",
      " 83%|████████▎ | 2878/3487 [8:12:17<1:56:43, 11.50s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8348.42 ms /    39 tokens (  214.06 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.92 ms /     3 runs   (  886.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11012.21 ms /    42 tokens\n",
      " 83%|████████▎ | 2879/3487 [8:12:28<1:55:04, 11.36s/it]Llama.generate: 307 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13670.14 ms /    71 tokens (  192.54 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.28 ms /     3 runs   (  904.09 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   16385.18 ms /    74 tokens\n",
      " 83%|████████▎ | 2880/3487 [8:12:44<2:10:10, 12.87s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8242.47 ms /    40 tokens (  206.06 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3459.31 ms /     3 runs   ( 1153.10 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =   11704.87 ms /    43 tokens\n",
      " 83%|████████▎ | 2881/3487 [8:12:56<2:06:28, 12.52s/it]Llama.generate: 307 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10786.59 ms /    50 tokens (  215.73 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2881.74 ms /     3 runs   (  960.58 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   13671.15 ms /    53 tokens\n",
      " 83%|████████▎ | 2882/3487 [8:13:10<2:09:46, 12.87s/it]Llama.generate: 307 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12126.78 ms /    55 tokens (  220.49 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.98 ms /     3 runs   (  908.33 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   14854.49 ms /    58 tokens\n",
      " 83%|████████▎ | 2883/3487 [8:13:24<2:15:34, 13.47s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2253.44 ms /     9 tokens (  250.38 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.88 ms /     3 runs   (  895.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4942.90 ms /    12 tokens\n",
      " 83%|████████▎ | 2884/3487 [8:13:29<1:49:40, 10.91s/it]Llama.generate: 307 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13058.85 ms /    66 tokens (  197.86 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.83 ms /     3 runs   (  883.28 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15711.08 ms /    69 tokens\n",
      " 83%|████████▎ | 2885/3487 [8:13:45<2:03:57, 12.36s/it]Llama.generate: 306 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13511.65 ms /    68 tokens (  198.70 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2718.42 ms /     3 runs   (  906.14 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   16231.98 ms /    71 tokens\n",
      " 83%|████████▎ | 2886/3487 [8:14:01<2:15:26, 13.52s/it]Llama.generate: 306 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12031.50 ms /    62 tokens (  194.06 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.49 ms /     3 runs   (  893.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14715.11 ms /    65 tokens\n",
      " 83%|████████▎ | 2887/3487 [8:14:16<2:18:49, 13.88s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8474.57 ms /    43 tokens (  197.08 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.64 ms /     3 runs   (  886.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11136.91 ms /    46 tokens\n",
      " 83%|████████▎ | 2888/3487 [8:14:27<2:10:23, 13.06s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2204.21 ms /     9 tokens (  244.91 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.55 ms /     3 runs   (  897.18 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4898.17 ms /    12 tokens\n",
      " 83%|████████▎ | 2889/3487 [8:14:32<1:45:47, 10.61s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3815.77 ms /    18 tokens (  211.99 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.63 ms /     3 runs   (  886.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6479.72 ms /    21 tokens\n",
      " 83%|████████▎ | 2890/3487 [8:14:39<1:33:17,  9.38s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7897.71 ms /    37 tokens (  213.45 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.36 ms /     3 runs   (  885.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10555.47 ms /    40 tokens\n",
      " 83%|████████▎ | 2891/3487 [8:14:49<1:36:41,  9.73s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3835.13 ms /    18 tokens (  213.06 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.06 ms /     3 runs   (  890.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6507.51 ms /    21 tokens\n",
      " 83%|████████▎ | 2892/3487 [8:14:56<1:26:57,  8.77s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3736.22 ms /    15 tokens (  249.08 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.02 ms /     3 runs   (  900.34 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6439.86 ms /    18 tokens\n",
      " 83%|████████▎ | 2893/3487 [8:15:02<1:19:55,  8.07s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3779.25 ms /    18 tokens (  209.96 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.22 ms /     3 runs   (  901.41 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6486.00 ms /    21 tokens\n",
      " 83%|████████▎ | 2894/3487 [8:15:09<1:15:06,  7.60s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5666.10 ms /    28 tokens (  202.36 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.57 ms /     3 runs   (  894.19 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8351.08 ms /    31 tokens\n",
      " 83%|████████▎ | 2895/3487 [8:15:17<1:17:13,  7.83s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4127.09 ms /    19 tokens (  217.22 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2876.61 ms /     3 runs   (  958.87 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    7006.36 ms /    22 tokens\n",
      " 83%|████████▎ | 2896/3487 [8:15:24<1:14:41,  7.58s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5454.10 ms /    26 tokens (  209.77 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.28 ms /     3 runs   (  889.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8124.32 ms /    29 tokens\n",
      " 83%|████████▎ | 2897/3487 [8:15:32<1:16:11,  7.75s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13183.29 ms /    65 tokens (  202.82 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.69 ms /     3 runs   (  886.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15845.92 ms /    68 tokens\n",
      " 83%|████████▎ | 2898/3487 [8:15:48<1:39:55, 10.18s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2631.04 ms /    11 tokens (  239.19 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.86 ms /     3 runs   (  894.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5317.63 ms /    14 tokens\n",
      " 83%|████████▎ | 2899/3487 [8:15:53<1:25:29,  8.72s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8555.54 ms /    39 tokens (  219.37 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.49 ms /     3 runs   (  885.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11213.27 ms /    42 tokens\n",
      " 83%|████████▎ | 2900/3487 [8:16:05<1:32:40,  9.47s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11242.72 ms /    59 tokens (  190.55 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.35 ms /     3 runs   (  891.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13919.12 ms /    62 tokens\n",
      " 83%|████████▎ | 2901/3487 [8:16:19<1:45:33, 10.81s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2754.22 ms /    12 tokens (  229.52 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.03 ms /     3 runs   (  896.34 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5445.45 ms /    15 tokens\n",
      " 83%|████████▎ | 2902/3487 [8:16:24<1:29:43,  9.20s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3134.35 ms /    14 tokens (  223.88 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.45 ms /     3 runs   (  888.49 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5802.02 ms /    17 tokens\n",
      " 83%|████████▎ | 2903/3487 [8:16:30<1:19:40,  8.19s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3021.70 ms /    13 tokens (  232.44 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.18 ms /     3 runs   (  899.06 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5720.99 ms /    16 tokens\n",
      " 83%|████████▎ | 2904/3487 [8:16:36<1:12:22,  7.45s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7212.35 ms /    33 tokens (  218.56 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.72 ms /     3 runs   (  881.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9859.78 ms /    36 tokens\n",
      " 83%|████████▎ | 2905/3487 [8:16:45<1:19:17,  8.17s/it]Llama.generate: 308 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10895.13 ms /    57 tokens (  191.14 ms per token,     5.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.78 ms /     3 runs   (  891.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13572.68 ms /    60 tokens\n",
      " 83%|████████▎ | 2906/3487 [8:16:59<1:34:51,  9.80s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3059.93 ms /    13 tokens (  235.38 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.82 ms /     3 runs   (  897.27 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5754.17 ms /    16 tokens\n",
      " 83%|████████▎ | 2907/3487 [8:17:05<1:22:59,  8.59s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4668.16 ms /    20 tokens (  233.41 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.37 ms /     3 runs   (  884.79 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7325.04 ms /    23 tokens\n",
      " 83%|████████▎ | 2908/3487 [8:17:12<1:19:13,  8.21s/it]Llama.generate: 306 prefix-match hit, remaining 99 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19610.42 ms /    99 tokens (  198.09 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.97 ms /     3 runs   (  908.32 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   22340.39 ms /   102 tokens\n",
      " 83%|████████▎ | 2909/3487 [8:17:34<1:59:57, 12.45s/it]Llama.generate: 309 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8154.84 ms /    39 tokens (  209.10 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.62 ms /     3 runs   (  886.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10817.09 ms /    42 tokens\n",
      " 83%|████████▎ | 2910/3487 [8:17:45<1:55:03, 11.96s/it]Llama.generate: 306 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8993.71 ms /    45 tokens (  199.86 ms per token,     5.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.03 ms /     3 runs   (  885.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11652.34 ms /    48 tokens\n",
      " 83%|████████▎ | 2911/3487 [8:17:57<1:53:59, 11.87s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5691.69 ms /    28 tokens (  203.27 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.39 ms /     3 runs   (  896.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8383.67 ms /    31 tokens\n",
      " 84%|████████▎ | 2912/3487 [8:18:05<1:43:47, 10.83s/it]Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7202.41 ms /    33 tokens (  218.25 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.50 ms /     3 runs   (  884.83 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9859.95 ms /    36 tokens\n",
      " 84%|████████▎ | 2913/3487 [8:18:15<1:40:50, 10.54s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3538.59 ms /    16 tokens (  221.16 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.98 ms /     3 runs   (  884.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6195.57 ms /    19 tokens\n",
      " 84%|████████▎ | 2914/3487 [8:18:21<1:28:14,  9.24s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5043.41 ms /    23 tokens (  219.28 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.10 ms /     3 runs   (  890.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7717.29 ms /    26 tokens\n",
      " 84%|████████▎ | 2915/3487 [8:18:29<1:23:45,  8.79s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2321.99 ms /     9 tokens (  258.00 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.88 ms /     3 runs   (  895.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5010.65 ms /    12 tokens\n",
      " 84%|████████▎ | 2916/3487 [8:18:34<1:12:51,  7.66s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3247.47 ms /    15 tokens (  216.50 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.34 ms /     3 runs   (  895.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5937.30 ms /    18 tokens\n",
      " 84%|████████▎ | 2917/3487 [8:18:40<1:07:51,  7.14s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4680.17 ms /    22 tokens (  212.74 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.78 ms /     3 runs   (  885.59 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7339.53 ms /    25 tokens\n",
      " 84%|████████▎ | 2918/3487 [8:18:47<1:08:19,  7.20s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2444.43 ms /    10 tokens (  244.44 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.24 ms /     3 runs   (  885.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5103.96 ms /    13 tokens\n",
      " 84%|████████▎ | 2919/3487 [8:18:53<1:02:15,  6.58s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4259.74 ms /    20 tokens (  212.99 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2783.10 ms /     3 runs   (  927.70 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7045.62 ms /    23 tokens\n",
      " 84%|████████▎ | 2920/3487 [8:19:00<1:03:30,  6.72s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4378.61 ms /    20 tokens (  218.93 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.86 ms /     3 runs   (  894.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7064.23 ms /    23 tokens\n",
      " 84%|████████▍ | 2921/3487 [8:19:07<1:04:23,  6.83s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5045.31 ms /    24 tokens (  210.22 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2751.32 ms /     3 runs   (  917.11 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7800.07 ms /    27 tokens\n",
      " 84%|████████▍ | 2922/3487 [8:19:14<1:07:03,  7.12s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2983.90 ms /    10 tokens (  298.39 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.27 ms /     3 runs   (  887.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5648.50 ms /    13 tokens\n",
      " 84%|████████▍ | 2923/3487 [8:19:20<1:02:48,  6.68s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3851.90 ms /    17 tokens (  226.58 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.43 ms /     3 runs   (  898.14 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6548.96 ms /    20 tokens\n",
      " 84%|████████▍ | 2924/3487 [8:19:27<1:02:20,  6.64s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2103.75 ms /     7 tokens (  300.54 ms per token,     3.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.88 ms /     3 runs   (  894.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4790.94 ms /    10 tokens\n",
      " 84%|████████▍ | 2925/3487 [8:19:31<57:03,  6.09s/it]  Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3621.79 ms /    16 tokens (  226.36 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.14 ms /     3 runs   (  890.38 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6295.48 ms /    19 tokens\n",
      " 84%|████████▍ | 2926/3487 [8:19:38<57:32,  6.15s/it]Llama.generate: 312 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2027.64 ms /     7 tokens (  289.66 ms per token,     3.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.44 ms /     3 runs   (  900.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4730.53 ms /    10 tokens\n",
      " 84%|████████▍ | 2927/3487 [8:19:43<53:28,  5.73s/it]Llama.generate: 312 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2525.41 ms /    10 tokens (  252.54 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.63 ms /     3 runs   (  885.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5185.46 ms /    13 tokens\n",
      " 84%|████████▍ | 2928/3487 [8:19:48<51:53,  5.57s/it]Llama.generate: 312 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4360.26 ms /    20 tokens (  218.01 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.53 ms /     3 runs   (  891.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7037.17 ms /    23 tokens\n",
      " 84%|████████▍ | 2929/3487 [8:19:55<55:54,  6.01s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13152.01 ms /    65 tokens (  202.34 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.73 ms /     3 runs   (  883.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   15804.97 ms /    68 tokens\n",
      " 84%|████████▍ | 2930/3487 [8:20:11<1:23:06,  8.95s/it]Llama.generate: 306 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8294.40 ms /    39 tokens (  212.68 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.00 ms /     3 runs   (  887.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10958.08 ms /    42 tokens\n",
      " 84%|████████▍ | 2931/3487 [8:20:22<1:28:33,  9.56s/it]Llama.generate: 306 prefix-match hit, remaining 88 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16457.35 ms /    88 tokens (  187.02 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2758.56 ms /     3 runs   (  919.52 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   19218.23 ms /    91 tokens\n",
      " 84%|████████▍ | 2932/3487 [8:20:41<1:55:14, 12.46s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7342.37 ms /    34 tokens (  215.95 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2855.26 ms /     3 runs   (  951.75 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   10200.27 ms /    37 tokens\n",
      " 84%|████████▍ | 2933/3487 [8:20:51<1:48:47, 11.78s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7659.77 ms /    38 tokens (  201.57 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2965.51 ms /     3 runs   (  988.50 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   10628.14 ms /    41 tokens\n",
      " 84%|████████▍ | 2934/3487 [8:21:02<1:45:25, 11.44s/it]Llama.generate: 306 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13738.26 ms /    72 tokens (  190.81 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.05 ms /     3 runs   (  894.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16422.46 ms /    75 tokens\n",
      " 84%|████████▍ | 2935/3487 [8:21:18<1:59:00, 12.94s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3633.48 ms /    16 tokens (  227.09 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.17 ms /     3 runs   (  886.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6296.11 ms /    19 tokens\n",
      " 84%|████████▍ | 2936/3487 [8:21:24<1:40:31, 10.95s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5676.64 ms /    28 tokens (  202.74 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.51 ms /     3 runs   (  885.17 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8334.73 ms /    31 tokens\n",
      " 84%|████████▍ | 2937/3487 [8:21:33<1:33:11, 10.17s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2774.29 ms /    12 tokens (  231.19 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.05 ms /     3 runs   (  895.68 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5464.42 ms /    15 tokens\n",
      " 84%|████████▍ | 2938/3487 [8:21:38<1:20:07,  8.76s/it]Llama.generate: 312 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3832.04 ms /    15 tokens (  255.47 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.05 ms /     3 runs   (  880.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6475.08 ms /    18 tokens\n",
      " 84%|████████▍ | 2939/3487 [8:21:45<1:13:45,  8.08s/it]Llama.generate: 311 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2146.38 ms /     8 tokens (  268.30 ms per token,     3.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.56 ms /     3 runs   (  887.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4811.61 ms /    11 tokens\n",
      " 84%|████████▍ | 2940/3487 [8:21:49<1:04:43,  7.10s/it]Llama.generate: 311 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2736.70 ms /    11 tokens (  248.79 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2833.02 ms /     3 runs   (  944.34 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5572.25 ms /    14 tokens\n",
      " 84%|████████▍ | 2941/3487 [8:21:55<1:00:27,  6.64s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4769.59 ms /    22 tokens (  216.80 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.57 ms /     3 runs   (  902.52 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7479.45 ms /    25 tokens\n",
      " 84%|████████▍ | 2942/3487 [8:22:03<1:02:38,  6.90s/it]Llama.generate: 306 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8174.02 ms /    41 tokens (  199.37 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.12 ms /     3 runs   (  883.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10827.59 ms /    44 tokens\n",
      " 84%|████████▍ | 2943/3487 [8:22:13<1:13:14,  8.08s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2531.17 ms /    10 tokens (  253.12 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2797.13 ms /     3 runs   (  932.38 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5330.96 ms /    13 tokens\n",
      " 84%|████████▍ | 2944/3487 [8:22:19<1:05:40,  7.26s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2993.13 ms /    12 tokens (  249.43 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.69 ms /     3 runs   (  886.23 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5654.77 ms /    15 tokens\n",
      " 84%|████████▍ | 2945/3487 [8:22:24<1:01:14,  6.78s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2602.04 ms /    10 tokens (  260.20 ms per token,     3.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.02 ms /     3 runs   (  887.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5266.72 ms /    13 tokens\n",
      " 84%|████████▍ | 2946/3487 [8:22:30<57:03,  6.33s/it]  Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3583.04 ms /    13 tokens (  275.62 ms per token,     3.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.16 ms /     3 runs   (  883.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6236.09 ms /    16 tokens\n",
      " 85%|████████▍ | 2947/3487 [8:22:36<56:43,  6.30s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2262.16 ms /     9 tokens (  251.35 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.04 ms /     3 runs   (  888.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4929.78 ms /    12 tokens\n",
      " 85%|████████▍ | 2948/3487 [8:22:41<52:56,  5.89s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5628.92 ms /    27 tokens (  208.48 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.60 ms /     3 runs   (  883.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8281.21 ms /    30 tokens\n",
      " 85%|████████▍ | 2949/3487 [8:22:49<59:17,  6.61s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2566.83 ms /    10 tokens (  256.68 ms per token,     3.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.75 ms /     3 runs   (  895.92 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5257.43 ms /    13 tokens\n",
      " 85%|████████▍ | 2950/3487 [8:22:54<55:34,  6.21s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9531.93 ms /    48 tokens (  198.58 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.32 ms /     3 runs   (  879.77 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12173.59 ms /    51 tokens\n",
      " 85%|████████▍ | 2951/3487 [8:23:07<1:11:28,  8.00s/it]Llama.generate: 306 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9101.25 ms /    46 tokens (  197.85 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.08 ms /     3 runs   (  878.36 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11739.97 ms /    49 tokens\n",
      " 85%|████████▍ | 2952/3487 [8:23:18<1:21:21,  9.12s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3574.38 ms /    16 tokens (  223.40 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.98 ms /     3 runs   (  885.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6234.42 ms /    19 tokens\n",
      " 85%|████████▍ | 2953/3487 [8:23:25<1:13:31,  8.26s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4306.50 ms /    21 tokens (  205.07 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.60 ms /     3 runs   (  883.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6958.34 ms /    24 tokens\n",
      " 85%|████████▍ | 2954/3487 [8:23:32<1:09:55,  7.87s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7593.25 ms /    33 tokens (  230.10 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.62 ms /     3 runs   (  888.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10260.59 ms /    36 tokens\n",
      " 85%|████████▍ | 2955/3487 [8:23:42<1:16:10,  8.59s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2246.81 ms /     9 tokens (  249.65 ms per token,     4.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.05 ms /     3 runs   (  882.68 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4897.70 ms /    12 tokens\n",
      " 85%|████████▍ | 2956/3487 [8:23:47<1:06:14,  7.49s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4627.43 ms /    22 tokens (  210.34 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.13 ms /     3 runs   (  880.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7271.37 ms /    25 tokens\n",
      " 85%|████████▍ | 2957/3487 [8:23:54<1:05:34,  7.42s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4166.80 ms /    19 tokens (  219.31 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.89 ms /     3 runs   (  898.96 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6866.07 ms /    22 tokens\n",
      " 85%|████████▍ | 2958/3487 [8:24:01<1:03:59,  7.26s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4460.39 ms /    21 tokens (  212.40 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2751.18 ms /     3 runs   (  917.06 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7214.08 ms /    24 tokens\n",
      " 85%|████████▍ | 2959/3487 [8:24:08<1:03:46,  7.25s/it]Llama.generate: 306 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   19514.29 ms /   103 tokens (  189.46 ms per token,     5.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.45 ms /     3 runs   (  896.82 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   22207.08 ms /   106 tokens\n",
      " 85%|████████▍ | 2960/3487 [8:24:30<1:43:06, 11.74s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7329.07 ms /    35 tokens (  209.40 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2873.03 ms /     3 runs   (  957.68 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   10204.95 ms /    38 tokens\n",
      " 85%|████████▍ | 2961/3487 [8:24:40<1:38:53, 11.28s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3389.31 ms /    13 tokens (  260.72 ms per token,     3.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.24 ms /     3 runs   (  895.75 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6079.64 ms /    16 tokens\n",
      " 85%|████████▍ | 2962/3487 [8:24:47<1:25:05,  9.72s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4932.06 ms /    22 tokens (  224.18 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.18 ms /     3 runs   (  887.06 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7596.02 ms /    25 tokens\n",
      " 85%|████████▍ | 2963/3487 [8:24:54<1:19:22,  9.09s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10940.84 ms /    56 tokens (  195.37 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.75 ms /     3 runs   (  881.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13587.34 ms /    59 tokens\n",
      " 85%|████████▌ | 2964/3487 [8:25:08<1:31:00, 10.44s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10767.08 ms /    56 tokens (  192.27 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.84 ms /     3 runs   (  881.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13417.07 ms /    59 tokens\n",
      " 85%|████████▌ | 2965/3487 [8:25:21<1:38:38, 11.34s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4321.95 ms /    21 tokens (  205.81 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.10 ms /     3 runs   (  894.70 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7008.66 ms /    24 tokens\n",
      " 85%|████████▌ | 2966/3487 [8:25:28<1:27:11, 10.04s/it]Llama.generate: 314 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1392.93 ms /     4 tokens (  348.23 ms per token,     2.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2859.75 ms /     3 runs   (  953.25 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4255.38 ms /     7 tokens\n",
      " 85%|████████▌ | 2967/3487 [8:25:32<1:11:59,  8.31s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8831.61 ms /    43 tokens (  205.39 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2810.12 ms /     3 runs   (  936.71 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   11644.37 ms /    46 tokens\n",
      " 85%|████████▌ | 2968/3487 [8:25:44<1:20:33,  9.31s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3394.70 ms /    15 tokens (  226.31 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.70 ms /     3 runs   (  903.23 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6106.79 ms /    18 tokens\n",
      " 85%|████████▌ | 2969/3487 [8:25:50<1:12:06,  8.35s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4986.10 ms /    24 tokens (  207.75 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.37 ms /     3 runs   (  894.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7671.32 ms /    27 tokens\n",
      " 85%|████████▌ | 2970/3487 [8:25:58<1:10:14,  8.15s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2719.23 ms /    11 tokens (  247.20 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.13 ms /     3 runs   (  900.71 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5423.91 ms /    14 tokens\n",
      " 85%|████████▌ | 2971/3487 [8:26:03<1:03:05,  7.34s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4957.35 ms /    24 tokens (  206.56 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2748.14 ms /     3 runs   (  916.05 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7707.48 ms /    27 tokens\n",
      " 85%|████████▌ | 2972/3487 [8:26:11<1:03:57,  7.45s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2842.84 ms /    11 tokens (  258.44 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.22 ms /     3 runs   (  880.41 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5488.32 ms /    14 tokens\n",
      " 85%|████████▌ | 2973/3487 [8:26:17<58:48,  6.87s/it]  Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7567.94 ms /    36 tokens (  210.22 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2759.82 ms /     3 runs   (  919.94 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10330.15 ms /    39 tokens\n",
      " 85%|████████▌ | 2974/3487 [8:26:27<1:07:36,  7.91s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4562.10 ms /    20 tokens (  228.10 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.66 ms /     3 runs   (  890.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7235.39 ms /    23 tokens\n",
      " 85%|████████▌ | 2975/3487 [8:26:34<1:05:46,  7.71s/it]Llama.generate: 313 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3278.06 ms /    14 tokens (  234.15 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.69 ms /     3 runs   (  897.56 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5973.91 ms /    17 tokens\n",
      " 85%|████████▌ | 2976/3487 [8:26:40<1:01:14,  7.19s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8190.44 ms /    41 tokens (  199.77 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.41 ms /     3 runs   (  880.47 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10834.04 ms /    44 tokens\n",
      " 85%|████████▌ | 2977/3487 [8:26:51<1:10:26,  8.29s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2657.93 ms /    11 tokens (  241.63 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.98 ms /     3 runs   (  892.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5339.70 ms /    14 tokens\n",
      " 85%|████████▌ | 2978/3487 [8:26:56<1:02:49,  7.41s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2849.83 ms /    12 tokens (  237.49 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.88 ms /     3 runs   (  898.29 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5546.94 ms /    15 tokens\n",
      " 85%|████████▌ | 2979/3487 [8:27:02<57:59,  6.85s/it]  Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2817.56 ms /    12 tokens (  234.80 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.76 ms /     3 runs   (  899.25 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5518.39 ms /    15 tokens\n",
      " 85%|████████▌ | 2980/3487 [8:27:07<54:32,  6.45s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4146.14 ms /    19 tokens (  218.22 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.53 ms /     3 runs   (  887.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6812.24 ms /    22 tokens\n",
      " 85%|████████▌ | 2981/3487 [8:27:14<55:21,  6.56s/it]Llama.generate: 307 prefix-match hit, remaining 226 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   42699.75 ms /   226 tokens (  188.94 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.47 ms /     3 runs   (  886.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   45363.03 ms /   229 tokens\n",
      " 86%|████████▌ | 2982/3487 [8:28:00<2:33:13, 18.21s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5236.43 ms /    24 tokens (  218.18 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.24 ms /     3 runs   (  888.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7904.23 ms /    27 tokens\n",
      " 86%|████████▌ | 2983/3487 [8:28:08<2:06:59, 15.12s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2186.51 ms /     8 tokens (  273.31 ms per token,     3.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.27 ms /     3 runs   (  890.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4859.13 ms /    11 tokens\n",
      " 86%|████████▌ | 2984/3487 [8:28:12<1:40:57, 12.04s/it]Llama.generate: 306 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8401.81 ms /    43 tokens (  195.39 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2818.68 ms /     3 runs   (  939.56 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   11223.05 ms /    46 tokens\n",
      " 86%|████████▌ | 2985/3487 [8:28:24<1:38:43, 11.80s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2273.02 ms /     9 tokens (  252.56 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.60 ms /     3 runs   (  898.20 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4970.32 ms /    12 tokens\n",
      " 86%|████████▌ | 2986/3487 [8:28:29<1:21:26,  9.75s/it]Llama.generate: 312 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2716.22 ms /    11 tokens (  246.93 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.71 ms /     3 runs   (  885.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5373.97 ms /    14 tokens\n",
      " 86%|████████▌ | 2987/3487 [8:28:34<1:10:20,  8.44s/it]Llama.generate: 307 prefix-match hit, remaining 153 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28399.33 ms /   153 tokens (  185.62 ms per token,     5.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.65 ms /     3 runs   (  881.55 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   31048.30 ms /   156 tokens\n",
      " 86%|████████▌ | 2988/3487 [8:29:05<2:06:37, 15.23s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11156.76 ms /    59 tokens (  189.10 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.47 ms /     3 runs   (  885.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13814.46 ms /    62 tokens\n",
      " 86%|████████▌ | 2989/3487 [8:29:19<2:02:52, 14.80s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6173.63 ms /    31 tokens (  199.15 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.70 ms /     3 runs   (  888.23 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8840.88 ms /    34 tokens\n",
      " 86%|████████▌ | 2990/3487 [8:29:28<1:47:50, 13.02s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4661.24 ms /    20 tokens (  233.06 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.20 ms /     3 runs   (  890.73 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7335.96 ms /    23 tokens\n",
      " 86%|████████▌ | 2991/3487 [8:29:35<1:33:32, 11.32s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5285.13 ms /    26 tokens (  203.27 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.04 ms /     3 runs   (  888.01 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7951.42 ms /    29 tokens\n",
      " 86%|████████▌ | 2992/3487 [8:29:43<1:25:02, 10.31s/it]Llama.generate: 306 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11607.07 ms /    61 tokens (  190.28 ms per token,     5.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.97 ms /     3 runs   (  881.99 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14256.34 ms /    64 tokens\n",
      " 86%|████████▌ | 2993/3487 [8:29:57<1:34:38, 11.50s/it]Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9969.77 ms /    52 tokens (  191.73 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.61 ms /     3 runs   (  888.54 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12638.48 ms /    55 tokens\n",
      " 86%|████████▌ | 2994/3487 [8:30:10<1:37:17, 11.84s/it]Llama.generate: 317 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13218.00 ms /    69 tokens (  191.57 ms per token,     5.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.05 ms /     3 runs   (  877.35 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   15852.82 ms /    72 tokens\n",
      " 86%|████████▌ | 2995/3487 [8:30:26<1:46:59, 13.05s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4297.49 ms /    21 tokens (  204.64 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.07 ms /     3 runs   (  880.69 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6942.83 ms /    24 tokens\n",
      " 86%|████████▌ | 2996/3487 [8:30:33<1:31:48, 11.22s/it]Llama.generate: 312 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1389.69 ms /     4 tokens (  347.42 ms per token,     2.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2808.30 ms /     3 runs   (  936.10 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4200.19 ms /     7 tokens\n",
      " 86%|████████▌ | 2997/3487 [8:30:37<1:14:26,  9.12s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4563.11 ms /    19 tokens (  240.16 ms per token,     4.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.05 ms /     3 runs   (  891.35 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7239.62 ms /    22 tokens\n",
      " 86%|████████▌ | 2998/3487 [8:30:44<1:09:43,  8.55s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4280.58 ms /    20 tokens (  214.03 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.52 ms /     3 runs   (  899.51 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6981.87 ms /    23 tokens\n",
      " 86%|████████▌ | 2999/3487 [8:30:51<1:05:45,  8.09s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2272.84 ms /     9 tokens (  252.54 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.48 ms /     3 runs   (  892.49 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4953.10 ms /    12 tokens\n",
      " 86%|████████▌ | 3000/3487 [8:30:56<58:01,  7.15s/it]  Llama.generate: 307 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7332.21 ms /    33 tokens (  222.19 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.53 ms /     3 runs   (  886.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9994.02 ms /    36 tokens\n",
      " 86%|████████▌ | 3001/3487 [8:31:06<1:04:50,  8.00s/it]Llama.generate: 313 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3580.18 ms /    16 tokens (  223.76 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.62 ms /     3 runs   (  890.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6255.57 ms /    19 tokens\n",
      " 86%|████████▌ | 3002/3487 [8:31:12<1:00:28,  7.48s/it]Llama.generate: 307 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2498.59 ms /     9 tokens (  277.62 ms per token,     3.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3625.16 ms /     4 runs   (  906.29 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6157.39 ms /    13 tokens\n",
      " 86%|████████▌ | 3003/3487 [8:31:19<57:10,  7.09s/it]  Llama.generate: 312 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2849.66 ms /    12 tokens (  237.47 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.95 ms /     3 runs   (  889.32 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5520.22 ms /    15 tokens\n",
      " 86%|████████▌ | 3004/3487 [8:31:24<53:17,  6.62s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5535.53 ms /    25 tokens (  221.42 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.93 ms /     3 runs   (  885.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8196.40 ms /    28 tokens\n",
      " 86%|████████▌ | 3005/3487 [8:31:32<57:00,  7.10s/it]Llama.generate: 306 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16809.99 ms /    90 tokens (  186.78 ms per token,     5.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.64 ms /     3 runs   (  879.21 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19450.18 ms /    93 tokens\n",
      " 86%|████████▌ | 3006/3487 [8:31:52<1:26:37, 10.80s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4353.97 ms /    20 tokens (  217.70 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.90 ms /     3 runs   (  880.97 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6999.20 ms /    23 tokens\n",
      " 86%|████████▌ | 3007/3487 [8:31:59<1:17:19,  9.67s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12530.47 ms /    37 tokens (  338.66 ms per token,     2.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3041.17 ms /     3 runs   ( 1013.72 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   15574.57 ms /    40 tokens\n",
      " 86%|████████▋ | 3008/3487 [8:32:14<1:31:20, 11.44s/it]Llama.generate: 306 prefix-match hit, remaining 136 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   26606.59 ms /   136 tokens (  195.64 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.17 ms /     3 runs   (  881.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   29254.32 ms /   139 tokens\n",
      " 86%|████████▋ | 3009/3487 [8:32:44<2:13:44, 16.79s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3313.22 ms /    15 tokens (  220.88 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2748.10 ms /     3 runs   (  916.03 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6063.96 ms /    18 tokens\n",
      " 86%|████████▋ | 3010/3487 [8:32:50<1:47:54, 13.57s/it]Llama.generate: 307 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14846.35 ms /    74 tokens (  200.63 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.91 ms /     3 runs   (  910.64 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   17581.04 ms /    77 tokens\n",
      " 86%|████████▋ | 3011/3487 [8:33:07<1:57:14, 14.78s/it]Llama.generate: 307 prefix-match hit, remaining 92 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   21240.00 ms /    92 tokens (  230.87 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2976.94 ms /     3 runs   (  992.31 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   24219.51 ms /    95 tokens\n",
      " 86%|████████▋ | 3012/3487 [8:33:32<2:19:26, 17.61s/it]Llama.generate: 306 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10805.06 ms /    55 tokens (  196.46 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.35 ms /     3 runs   (  882.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13456.01 ms /    58 tokens\n",
      " 86%|████████▋ | 3013/3487 [8:33:45<2:09:18, 16.37s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5754.17 ms /    29 tokens (  198.42 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.05 ms /     3 runs   (  890.68 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8428.30 ms /    32 tokens\n",
      " 86%|████████▋ | 3014/3487 [8:33:53<1:50:16, 13.99s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4539.48 ms /    21 tokens (  216.17 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.83 ms /     3 runs   (  902.28 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7248.63 ms /    24 tokens\n",
      " 86%|████████▋ | 3015/3487 [8:34:01<1:34:09, 11.97s/it]Llama.generate: 306 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16725.68 ms /    82 tokens (  203.97 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.21 ms /     3 runs   (  913.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   19468.16 ms /    85 tokens\n",
      " 86%|████████▋ | 3016/3487 [8:34:20<1:51:38, 14.22s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7050.40 ms /    32 tokens (  220.33 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.54 ms /     3 runs   (  905.85 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    9770.65 ms /    35 tokens\n",
      " 87%|████████▋ | 3017/3487 [8:34:30<1:40:57, 12.89s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8351.55 ms /    39 tokens (  214.14 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.31 ms /     3 runs   (  900.77 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   11056.99 ms /    42 tokens\n",
      " 87%|████████▋ | 3018/3487 [8:34:41<1:36:28, 12.34s/it]Llama.generate: 310 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7383.64 ms /    34 tokens (  217.17 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.42 ms /     3 runs   (  889.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10053.79 ms /    37 tokens\n",
      " 87%|████████▋ | 3019/3487 [8:34:51<1:30:55, 11.66s/it]Llama.generate: 310 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7880.17 ms /    36 tokens (  218.89 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.15 ms /     3 runs   (  889.72 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10551.62 ms /    39 tokens\n",
      " 87%|████████▋ | 3020/3487 [8:35:02<1:28:10, 11.33s/it]Llama.generate: 306 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2104.01 ms /     7 tokens (  300.57 ms per token,     3.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.07 ms /     3 runs   (  884.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4758.94 ms /    10 tokens\n",
      " 87%|████████▋ | 3021/3487 [8:35:06<1:12:41,  9.36s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3692.28 ms /    16 tokens (  230.77 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.64 ms /     3 runs   (  894.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6378.41 ms /    19 tokens\n",
      " 87%|████████▋ | 3022/3487 [8:35:13<1:05:37,  8.47s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3177.70 ms /    14 tokens (  226.98 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2742.44 ms /     3 runs   (  914.15 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5922.85 ms /    17 tokens\n",
      " 87%|████████▋ | 3023/3487 [8:35:19<59:36,  7.71s/it]  Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11548.22 ms /    57 tokens (  202.60 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2875.04 ms /     3 runs   (  958.35 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   14425.77 ms /    60 tokens\n",
      " 87%|████████▋ | 3024/3487 [8:35:33<1:15:03,  9.73s/it]Llama.generate: 307 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14226.65 ms /    72 tokens (  197.59 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.60 ms /     3 runs   (  884.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16881.79 ms /    75 tokens\n",
      " 87%|████████▋ | 3025/3487 [8:35:50<1:31:26, 11.88s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7702.35 ms /    36 tokens (  213.95 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.34 ms /     3 runs   (  885.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10360.80 ms /    39 tokens\n",
      " 87%|████████▋ | 3026/3487 [8:36:00<1:27:46, 11.42s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6223.82 ms /    29 tokens (  214.61 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.18 ms /     3 runs   (  887.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8889.08 ms /    32 tokens\n",
      " 87%|████████▋ | 3027/3487 [8:36:09<1:21:46, 10.67s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2271.13 ms /     9 tokens (  252.35 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.71 ms /     3 runs   (  900.57 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4975.78 ms /    12 tokens\n",
      " 87%|████████▋ | 3028/3487 [8:36:14<1:08:32,  8.96s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3679.46 ms /    15 tokens (  245.30 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.89 ms /     3 runs   (  880.96 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6324.68 ms /    18 tokens\n",
      " 87%|████████▋ | 3029/3487 [8:36:21<1:02:22,  8.17s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2680.72 ms /    11 tokens (  243.70 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.66 ms /     3 runs   (  886.89 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5343.70 ms /    14 tokens\n",
      " 87%|████████▋ | 3030/3487 [8:36:26<55:48,  7.33s/it]  Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2295.30 ms /     9 tokens (  255.03 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2887.44 ms /     3 runs   (  962.48 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    5185.42 ms /    12 tokens\n",
      " 87%|████████▋ | 3031/3487 [8:36:31<50:48,  6.69s/it]Llama.generate: 311 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2656.92 ms /    10 tokens (  265.69 ms per token,     3.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3133.26 ms /     3 runs   ( 1044.42 ms per token,     0.96 tokens per second)\n",
      "llama_perf_context_print:       total time =    5793.04 ms /    13 tokens\n",
      " 87%|████████▋ | 3032/3487 [8:36:37<48:41,  6.42s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3276.04 ms /    13 tokens (  252.00 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.08 ms /     3 runs   (  878.36 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5913.70 ms /    16 tokens\n",
      " 87%|████████▋ | 3033/3487 [8:36:43<47:27,  6.27s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3214.65 ms /    15 tokens (  214.31 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2789.43 ms /     3 runs   (  929.81 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6006.65 ms /    18 tokens\n",
      " 87%|████████▋ | 3034/3487 [8:36:49<46:45,  6.19s/it]Llama.generate: 308 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2648.58 ms /     7 tokens (  378.37 ms per token,     2.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.45 ms /     3 runs   (  890.15 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5321.74 ms /    10 tokens\n",
      " 87%|████████▋ | 3035/3487 [8:36:54<44:42,  5.93s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2972.44 ms /    11 tokens (  270.22 ms per token,     3.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3081.95 ms /     3 runs   ( 1027.32 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    6057.49 ms /    14 tokens\n",
      " 87%|████████▋ | 3036/3487 [8:37:00<44:54,  5.97s/it]Llama.generate: 316 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3993.08 ms /     4 runs   (  998.27 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    3995.35 ms /     5 tokens\n",
      " 87%|████████▋ | 3037/3487 [8:37:04<40:22,  5.38s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3256.28 ms /    13 tokens (  250.48 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.64 ms /     3 runs   (  883.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5910.68 ms /    16 tokens\n",
      " 87%|████████▋ | 3038/3487 [8:37:10<41:29,  5.54s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2250.84 ms /     9 tokens (  250.09 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.61 ms /     3 runs   (  886.87 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4913.97 ms /    12 tokens\n",
      " 87%|████████▋ | 3039/3487 [8:37:15<40:00,  5.36s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2772.26 ms /    11 tokens (  252.02 ms per token,     3.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.35 ms /     3 runs   (  884.78 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5428.79 ms /    14 tokens\n",
      " 87%|████████▋ | 3040/3487 [8:37:21<40:05,  5.38s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7338.94 ms /    35 tokens (  209.68 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.37 ms /     3 runs   (  887.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10003.14 ms /    38 tokens\n",
      " 87%|████████▋ | 3041/3487 [8:37:31<50:19,  6.77s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7601.82 ms /    33 tokens (  230.36 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.13 ms /     3 runs   (  884.04 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10256.36 ms /    36 tokens\n",
      " 87%|████████▋ | 3042/3487 [8:37:41<57:59,  7.82s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7882.29 ms /    39 tokens (  202.11 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.20 ms /     3 runs   (  877.07 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10516.52 ms /    42 tokens\n",
      " 87%|████████▋ | 3043/3487 [8:37:51<1:03:52,  8.63s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6312.24 ms /    32 tokens (  197.26 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.51 ms /     3 runs   (  879.84 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8953.41 ms /    35 tokens\n",
      " 87%|████████▋ | 3044/3487 [8:38:00<1:04:27,  8.73s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4870.92 ms /    22 tokens (  221.41 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.58 ms /     3 runs   (  878.19 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7507.86 ms /    25 tokens\n",
      " 87%|████████▋ | 3045/3487 [8:38:08<1:01:37,  8.37s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4037.52 ms /    18 tokens (  224.31 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2733.09 ms /     3 runs   (  911.03 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6772.83 ms /    21 tokens\n",
      " 87%|████████▋ | 3046/3487 [8:38:15<57:59,  7.89s/it]  Llama.generate: 306 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10332.37 ms /    47 tokens (  219.84 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.78 ms /     3 runs   (  881.93 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12980.86 ms /    50 tokens\n",
      " 87%|████████▋ | 3047/3487 [8:38:28<1:09:05,  9.42s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2324.91 ms /     9 tokens (  258.32 ms per token,     3.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.91 ms /     3 runs   (  896.30 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5016.49 ms /    12 tokens\n",
      " 87%|████████▋ | 3048/3487 [8:38:33<59:16,  8.10s/it]  Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14719.26 ms /    42 tokens (  350.46 ms per token,     2.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14794.67 ms /     3 runs   ( 4931.56 ms per token,     0.20 tokens per second)\n",
      "llama_perf_context_print:       total time =   29521.34 ms /    45 tokens\n",
      " 87%|████████▋ | 3049/3487 [8:39:02<1:46:06, 14.54s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10952.35 ms /    44 tokens (  248.92 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3453.36 ms /     3 runs   ( 1151.12 ms per token,     0.87 tokens per second)\n",
      "llama_perf_context_print:       total time =   14410.20 ms /    47 tokens\n",
      " 87%|████████▋ | 3050/3487 [8:39:17<1:45:39, 14.51s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13420.36 ms /    48 tokens (  279.59 ms per token,     3.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3497.64 ms /     3 runs   ( 1165.88 ms per token,     0.86 tokens per second)\n",
      "llama_perf_context_print:       total time =   16920.96 ms /    51 tokens\n",
      " 87%|████████▋ | 3051/3487 [8:39:34<1:50:42, 15.24s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3511.76 ms /    13 tokens (  270.14 ms per token,     3.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2974.16 ms /     3 runs   (  991.39 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    6489.47 ms /    16 tokens\n",
      " 88%|████████▊ | 3052/3487 [8:39:40<1:31:27, 12.61s/it]Llama.generate: 307 prefix-match hit, remaining 95 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17958.62 ms /    95 tokens (  189.04 ms per token,     5.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.44 ms /     3 runs   (  881.48 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20605.38 ms /    98 tokens\n",
      " 88%|████████▊ | 3053/3487 [8:40:01<1:48:36, 15.02s/it]Llama.generate: 307 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11498.21 ms /    57 tokens (  201.72 ms per token,     4.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.58 ms /     3 runs   (  895.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14187.19 ms /    60 tokens\n",
      " 88%|████████▊ | 3054/3487 [8:40:15<1:46:35, 14.77s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13530.22 ms /    64 tokens (  211.41 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2823.62 ms /     3 runs   (  941.21 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   16356.60 ms /    67 tokens\n",
      " 88%|████████▊ | 3055/3487 [8:40:31<1:49:47, 15.25s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4958.80 ms /    23 tokens (  215.60 ms per token,     4.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2753.53 ms /     3 runs   (  917.84 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7715.19 ms /    26 tokens\n",
      " 88%|████████▊ | 3056/3487 [8:40:39<1:33:19, 12.99s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3996.92 ms /    17 tokens (  235.11 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.91 ms /     3 runs   (  896.97 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6690.33 ms /    20 tokens\n",
      " 88%|████████▊ | 3057/3487 [8:40:46<1:19:34, 11.10s/it]Llama.generate: 307 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13560.91 ms /    65 tokens (  208.63 ms per token,     4.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.01 ms /     3 runs   (  886.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16220.93 ms /    68 tokens\n",
      " 88%|████████▊ | 3058/3487 [8:41:02<1:30:23, 12.64s/it]Llama.generate: 312 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2270.40 ms /     9 tokens (  252.27 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.22 ms /     3 runs   (  907.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    4994.34 ms /    12 tokens\n",
      " 88%|████████▊ | 3059/3487 [8:41:07<1:13:49, 10.35s/it]Llama.generate: 317 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4868.87 ms /    22 tokens (  221.31 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.02 ms /     3 runs   (  881.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7515.50 ms /    25 tokens\n",
      " 88%|████████▊ | 3060/3487 [8:41:14<1:07:37,  9.50s/it]Llama.generate: 312 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2313.36 ms /     9 tokens (  257.04 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.89 ms /     3 runs   (  908.63 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5041.58 ms /    12 tokens\n",
      " 88%|████████▊ | 3061/3487 [8:41:20<57:59,  8.17s/it]  Llama.generate: 320 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4554.77 ms /     4 runs   ( 1138.69 ms per token,     0.88 tokens per second)\n",
      "llama_perf_context_print:       total time =    4557.40 ms /     5 tokens\n",
      " 88%|████████▊ | 3062/3487 [8:41:24<50:11,  7.09s/it]Llama.generate: 307 prefix-match hit, remaining 85 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16049.40 ms /    85 tokens (  188.82 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.85 ms /     3 runs   (  885.95 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18710.01 ms /    88 tokens\n",
      " 88%|████████▊ | 3063/3487 [8:41:43<1:14:44, 10.58s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2638.60 ms /    11 tokens (  239.87 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.80 ms /     3 runs   (  892.60 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5319.32 ms /    14 tokens\n",
      " 88%|████████▊ | 3064/3487 [8:41:48<1:03:27,  9.00s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3646.38 ms /    16 tokens (  227.90 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.00 ms /     3 runs   (  888.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6313.00 ms /    19 tokens\n",
      " 88%|████████▊ | 3065/3487 [8:41:54<57:39,  8.20s/it]  Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4130.56 ms /    18 tokens (  229.48 ms per token,     4.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.28 ms /     3 runs   (  894.43 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6817.23 ms /    21 tokens\n",
      " 88%|████████▊ | 3066/3487 [8:42:01<54:37,  7.79s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5736.03 ms /    28 tokens (  204.86 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.58 ms /     3 runs   (  878.53 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8373.68 ms /    31 tokens\n",
      " 88%|████████▊ | 3067/3487 [8:42:10<55:45,  7.96s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9424.94 ms /    48 tokens (  196.35 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.89 ms /     3 runs   (  882.30 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12073.89 ms /    51 tokens\n",
      " 88%|████████▊ | 3068/3487 [8:42:22<1:04:14,  9.20s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2566.44 ms /     8 tokens (  320.80 ms per token,     3.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.59 ms /     3 runs   (  881.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5213.88 ms /    11 tokens\n",
      " 88%|████████▊ | 3069/3487 [8:42:27<55:46,  8.01s/it]  Llama.generate: 306 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10026.39 ms /    52 tokens (  192.82 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.08 ms /     3 runs   (  884.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12683.01 ms /    55 tokens\n",
      " 88%|████████▊ | 3070/3487 [8:42:40<1:05:24,  9.41s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4850.06 ms /    23 tokens (  210.87 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.58 ms /     3 runs   (  904.19 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7564.65 ms /    26 tokens\n",
      " 88%|████████▊ | 3071/3487 [8:42:47<1:01:26,  8.86s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3251.06 ms /    14 tokens (  232.22 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.11 ms /     3 runs   (  897.70 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5946.68 ms /    17 tokens\n",
      " 88%|████████▊ | 3072/3487 [8:42:53<55:15,  7.99s/it]  Llama.generate: 307 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17338.28 ms /    90 tokens (  192.65 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.95 ms /     3 runs   (  892.65 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   20018.83 ms /    93 tokens\n",
      " 88%|████████▊ | 3073/3487 [8:43:13<1:20:02, 11.60s/it]Llama.generate: 307 prefix-match hit, remaining 155 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   28813.28 ms /   155 tokens (  185.89 ms per token,     5.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.47 ms /     3 runs   (  884.16 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   31468.17 ms /   158 tokens\n",
      " 88%|████████▊ | 3074/3487 [8:43:45<2:00:53, 17.56s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2216.59 ms /     8 tokens (  277.07 ms per token,     3.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.81 ms /     3 runs   (  886.27 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4878.07 ms /    11 tokens\n",
      " 88%|████████▊ | 3075/3487 [8:43:50<1:34:29, 13.76s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2217.74 ms /     6 tokens (  369.62 ms per token,     2.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.00 ms /     3 runs   (  883.67 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4871.89 ms /     9 tokens\n",
      " 88%|████████▊ | 3076/3487 [8:43:54<1:16:00, 11.10s/it]Llama.generate: 306 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13433.66 ms /    69 tokens (  194.69 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.88 ms /     3 runs   (  886.63 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   16096.34 ms /    72 tokens\n",
      " 88%|████████▊ | 3077/3487 [8:44:11<1:26:05, 12.60s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7535.79 ms /    36 tokens (  209.33 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.77 ms /     3 runs   (  884.92 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10193.53 ms /    39 tokens\n",
      " 88%|████████▊ | 3078/3487 [8:44:21<1:20:58, 11.88s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7909.64 ms /    34 tokens (  232.64 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2955.01 ms /     3 runs   (  985.00 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =   10867.58 ms /    37 tokens\n",
      " 88%|████████▊ | 3079/3487 [8:44:32<1:18:44, 11.58s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7940.84 ms /    34 tokens (  233.55 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.59 ms /     3 runs   (  900.53 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10645.57 ms /    37 tokens\n",
      " 88%|████████▊ | 3080/3487 [8:44:42<1:16:39, 11.30s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3173.14 ms /    13 tokens (  244.09 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.38 ms /     3 runs   (  891.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5851.94 ms /    16 tokens\n",
      " 88%|████████▊ | 3081/3487 [8:44:48<1:05:25,  9.67s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8329.88 ms /    39 tokens (  213.59 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.98 ms /     3 runs   (  890.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11005.99 ms /    42 tokens\n",
      " 88%|████████▊ | 3082/3487 [8:44:59<1:07:59, 10.07s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2178.79 ms /     8 tokens (  272.35 ms per token,     3.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.76 ms /     3 runs   (  899.92 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4880.91 ms /    11 tokens\n",
      " 88%|████████▊ | 3083/3487 [8:45:04<57:21,  8.52s/it]  Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2725.76 ms /    10 tokens (  272.58 ms per token,     3.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.26 ms /     3 runs   (  902.75 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5437.08 ms /    13 tokens\n",
      " 88%|████████▊ | 3084/3487 [8:45:09<51:01,  7.60s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2815.68 ms /    12 tokens (  234.64 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.33 ms /     3 runs   (  897.44 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5510.05 ms /    15 tokens\n",
      " 88%|████████▊ | 3085/3487 [8:45:15<46:42,  6.97s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2350.37 ms /     8 tokens (  293.80 ms per token,     3.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.66 ms /     3 runs   (  891.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5027.49 ms /    11 tokens\n",
      " 89%|████████▊ | 3086/3487 [8:45:20<42:42,  6.39s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7451.63 ms /    34 tokens (  219.17 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2752.11 ms /     3 runs   (  917.37 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10206.86 ms /    37 tokens\n",
      " 89%|████████▊ | 3087/3487 [8:45:30<50:15,  7.54s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2941.25 ms /    12 tokens (  245.10 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.60 ms /     3 runs   (  894.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5626.41 ms /    15 tokens\n",
      " 89%|████████▊ | 3088/3487 [8:45:36<46:19,  6.97s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2701.93 ms /     9 tokens (  300.21 ms per token,     3.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.15 ms /     3 runs   (  894.72 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5388.80 ms /    12 tokens\n",
      " 89%|████████▊ | 3089/3487 [8:45:41<43:05,  6.50s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2701.77 ms /    11 tokens (  245.62 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.43 ms /     3 runs   (  887.81 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5367.87 ms /    14 tokens\n",
      " 89%|████████▊ | 3090/3487 [8:45:47<40:45,  6.16s/it]Llama.generate: 306 prefix-match hit, remaining 85 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16516.01 ms /    85 tokens (  194.31 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.39 ms /     3 runs   (  898.46 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   19213.75 ms /    88 tokens\n",
      " 89%|████████▊ | 3091/3487 [8:46:06<1:06:31, 10.08s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3068.81 ms /    13 tokens (  236.06 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.40 ms /     3 runs   (  886.80 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5731.83 ms /    16 tokens\n",
      " 89%|████████▊ | 3092/3487 [8:46:12<57:47,  8.78s/it]  Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5422.15 ms /    27 tokens (  200.82 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.94 ms /     3 runs   (  883.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8075.71 ms /    30 tokens\n",
      " 89%|████████▊ | 3093/3487 [8:46:20<56:16,  8.57s/it]Llama.generate: 307 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6324.85 ms /    30 tokens (  210.83 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.02 ms /     3 runs   (  887.01 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8988.38 ms /    33 tokens\n",
      " 89%|████████▊ | 3094/3487 [8:46:29<56:58,  8.70s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3789.49 ms /    17 tokens (  222.91 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.60 ms /     3 runs   (  889.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6460.44 ms /    20 tokens\n",
      " 89%|████████▉ | 3095/3487 [8:46:35<52:27,  8.03s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10109.84 ms /    49 tokens (  206.32 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2795.20 ms /     3 runs   (  931.73 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12907.94 ms /    52 tokens\n",
      " 89%|████████▉ | 3096/3487 [8:46:48<1:01:52,  9.50s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10132.67 ms /    51 tokens (  198.68 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.77 ms /     3 runs   (  891.26 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12808.56 ms /    54 tokens\n",
      " 89%|████████▉ | 3097/3487 [8:47:01<1:08:12, 10.49s/it]Llama.generate: 307 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1657.31 ms /     5 tokens (  331.46 ms per token,     3.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2824.59 ms /     3 runs   (  941.53 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4485.46 ms /     8 tokens\n",
      " 89%|████████▉ | 3098/3487 [8:47:05<56:21,  8.69s/it]  Llama.generate: 308 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1711.94 ms /     5 tokens (  342.39 ms per token,     2.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.15 ms /     3 runs   (  884.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4369.14 ms /     8 tokens\n",
      " 89%|████████▉ | 3099/3487 [8:47:10<47:50,  7.40s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1485.77 ms /     5 tokens (  297.15 ms per token,     3.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2827.37 ms /     3 runs   (  942.46 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4315.58 ms /     8 tokens\n",
      " 89%|████████▉ | 3100/3487 [8:47:14<41:46,  6.48s/it]Llama.generate: 306 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16414.68 ms /    87 tokens (  188.67 ms per token,     5.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.14 ms /     3 runs   (  884.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19069.14 ms /    90 tokens\n",
      " 89%|████████▉ | 3101/3487 [8:47:33<1:05:58, 10.26s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3686.23 ms /    16 tokens (  230.39 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.38 ms /     3 runs   (  897.79 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6382.21 ms /    19 tokens\n",
      " 89%|████████▉ | 3102/3487 [8:47:40<58:22,  9.10s/it]  Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5599.22 ms /    25 tokens (  223.97 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.57 ms /     3 runs   (  886.19 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8260.25 ms /    28 tokens\n",
      " 89%|████████▉ | 3103/3487 [8:47:48<56:37,  8.85s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4900.84 ms /    24 tokens (  204.20 ms per token,     4.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.42 ms /     3 runs   (  887.81 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7566.70 ms /    27 tokens\n",
      " 89%|████████▉ | 3104/3487 [8:47:55<54:02,  8.47s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5329.47 ms /    26 tokens (  204.98 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.37 ms /     3 runs   (  889.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8000.38 ms /    29 tokens\n",
      " 89%|████████▉ | 3105/3487 [8:48:03<53:01,  8.33s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7418.93 ms /    35 tokens (  211.97 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.78 ms /     3 runs   (  895.26 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10106.66 ms /    38 tokens\n",
      " 89%|████████▉ | 3106/3487 [8:48:14<56:17,  8.86s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4909.06 ms /    24 tokens (  204.54 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.36 ms /     3 runs   (  895.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7596.52 ms /    27 tokens\n",
      " 89%|████████▉ | 3107/3487 [8:48:21<53:44,  8.49s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3619.89 ms /    16 tokens (  226.24 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.64 ms /     3 runs   (  892.21 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6299.10 ms /    19 tokens\n",
      " 89%|████████▉ | 3108/3487 [8:48:27<49:28,  7.83s/it]Llama.generate: 307 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10019.01 ms /    51 tokens (  196.45 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.72 ms /     3 runs   (  895.57 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12707.82 ms /    54 tokens\n",
      " 89%|████████▉ | 3109/3487 [8:48:40<58:34,  9.30s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3159.98 ms /    12 tokens (  263.33 ms per token,     3.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.69 ms /     3 runs   (  888.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5828.18 ms /    15 tokens\n",
      " 89%|████████▉ | 3110/3487 [8:48:46<51:53,  8.26s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2875.44 ms /    12 tokens (  239.62 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2685.28 ms /     3 runs   (  895.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5564.19 ms /    15 tokens\n",
      " 89%|████████▉ | 3111/3487 [8:48:52<46:42,  7.45s/it]Llama.generate: 307 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3457.84 ms /    15 tokens (  230.52 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2727.31 ms /     3 runs   (  909.10 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6187.22 ms /    18 tokens\n",
      " 89%|████████▉ | 3112/3487 [8:48:58<44:13,  7.08s/it]Llama.generate: 306 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13346.69 ms /    66 tokens (  202.22 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.18 ms /     3 runs   (  889.39 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16017.38 ms /    69 tokens\n",
      " 89%|████████▉ | 3113/3487 [8:49:14<1:00:50,  9.76s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3725.51 ms /    17 tokens (  219.15 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.99 ms /     3 runs   (  898.66 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6424.14 ms /    20 tokens\n",
      " 89%|████████▉ | 3114/3487 [8:49:20<54:28,  8.76s/it]  Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4356.78 ms /    20 tokens (  217.84 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.73 ms /     3 runs   (  889.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7026.79 ms /    23 tokens\n",
      " 89%|████████▉ | 3115/3487 [8:49:27<51:06,  8.24s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3080.09 ms /    13 tokens (  236.93 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.45 ms /     3 runs   (  898.15 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5777.25 ms /    16 tokens\n",
      " 89%|████████▉ | 3116/3487 [8:49:33<46:24,  7.51s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7983.87 ms /    33 tokens (  241.94 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.36 ms /     3 runs   (  882.12 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10632.72 ms /    36 tokens\n",
      " 89%|████████▉ | 3117/3487 [8:49:44<52:05,  8.45s/it]Llama.generate: 307 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14654.35 ms /    74 tokens (  198.03 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.43 ms /     3 runs   (  894.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   17339.33 ms /    77 tokens\n",
      " 89%|████████▉ | 3118/3487 [8:50:01<1:08:21, 11.12s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3768.77 ms /    17 tokens (  221.69 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.59 ms /     3 runs   (  891.20 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6445.00 ms /    20 tokens\n",
      " 89%|████████▉ | 3119/3487 [8:50:08<59:35,  9.72s/it]  Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3147.79 ms /    13 tokens (  242.14 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.78 ms /     3 runs   (  891.59 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5825.57 ms /    16 tokens\n",
      " 89%|████████▉ | 3120/3487 [8:50:13<52:18,  8.55s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3224.35 ms /    14 tokens (  230.31 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.07 ms /     3 runs   (  891.36 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5901.11 ms /    17 tokens\n",
      " 90%|████████▉ | 3121/3487 [8:50:19<47:20,  7.76s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6444.98 ms /    31 tokens (  207.90 ms per token,     4.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.70 ms /     3 runs   (  893.23 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    9127.74 ms /    34 tokens\n",
      " 90%|████████▉ | 3122/3487 [8:50:28<49:43,  8.17s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3846.76 ms /    18 tokens (  213.71 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.66 ms /     3 runs   (  882.89 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6498.71 ms /    21 tokens\n",
      " 90%|████████▉ | 3123/3487 [8:50:35<46:33,  7.67s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9221.30 ms /    43 tokens (  214.45 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.13 ms /     3 runs   (  887.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11887.03 ms /    46 tokens\n",
      " 90%|████████▉ | 3124/3487 [8:50:47<54:05,  8.94s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2175.56 ms /     8 tokens (  271.94 ms per token,     3.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.03 ms /     3 runs   (  893.68 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4858.69 ms /    11 tokens\n",
      " 90%|████████▉ | 3125/3487 [8:50:52<46:33,  7.72s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2343.83 ms /     9 tokens (  260.43 ms per token,     3.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.17 ms /     3 runs   (  883.72 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4997.17 ms /    12 tokens\n",
      " 90%|████████▉ | 3126/3487 [8:50:57<41:32,  6.90s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5785.88 ms /    28 tokens (  206.64 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.41 ms /     3 runs   (  887.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8449.61 ms /    31 tokens\n",
      " 90%|████████▉ | 3127/3487 [8:51:05<44:13,  7.37s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4282.57 ms /    19 tokens (  225.40 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.08 ms /     3 runs   (  884.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6938.99 ms /    22 tokens\n",
      " 90%|████████▉ | 3128/3487 [8:51:12<43:20,  7.24s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5519.78 ms /    27 tokens (  204.44 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.54 ms /     3 runs   (  902.85 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8231.33 ms /    30 tokens\n",
      " 90%|████████▉ | 3129/3487 [8:51:20<45:00,  7.54s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2273.83 ms /     9 tokens (  252.65 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2923.91 ms /     3 runs   (  974.64 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    5200.40 ms /    12 tokens\n",
      " 90%|████████▉ | 3130/3487 [8:51:26<40:42,  6.84s/it]Llama.generate: 308 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3997.32 ms /    16 tokens (  249.83 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.28 ms /     3 runs   (  889.76 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6669.78 ms /    19 tokens\n",
      " 90%|████████▉ | 3131/3487 [8:51:32<40:18,  6.79s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2759.39 ms /    11 tokens (  250.85 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.70 ms /     3 runs   (  888.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5427.50 ms /    14 tokens\n",
      " 90%|████████▉ | 3132/3487 [8:51:38<37:47,  6.39s/it]Llama.generate: 313 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10304.70 ms /    53 tokens (  194.43 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.93 ms /     3 runs   (  882.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12954.34 ms /    56 tokens\n",
      " 90%|████████▉ | 3133/3487 [8:51:51<49:19,  8.36s/it]Llama.generate: 313 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1406.29 ms /     4 tokens (  351.57 ms per token,     2.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2874.24 ms /     3 runs   (  958.08 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4283.34 ms /     7 tokens\n",
      " 90%|████████▉ | 3134/3487 [8:51:55<42:00,  7.14s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6012.60 ms /    28 tokens (  214.74 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2717.86 ms /     3 runs   (  905.95 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8733.22 ms /    31 tokens\n",
      " 90%|████████▉ | 3135/3487 [8:52:04<44:42,  7.62s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5398.32 ms /    25 tokens (  215.93 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2736.81 ms /     3 runs   (  912.27 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8137.59 ms /    28 tokens\n",
      " 90%|████████▉ | 3136/3487 [8:52:12<45:30,  7.78s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7584.91 ms /    36 tokens (  210.69 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.89 ms /     3 runs   (  886.96 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10248.41 ms /    39 tokens\n",
      " 90%|████████▉ | 3137/3487 [8:52:22<49:42,  8.52s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16819.21 ms /    86 tokens (  195.57 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2784.59 ms /     3 runs   (  928.20 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   19606.45 ms /    89 tokens\n",
      " 90%|████████▉ | 3138/3487 [8:52:42<1:08:55, 11.85s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3948.49 ms /    16 tokens (  246.78 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2748.46 ms /     3 runs   (  916.15 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6699.31 ms /    19 tokens\n",
      " 90%|█████████ | 3139/3487 [8:52:48<59:50, 10.32s/it]  Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2780.39 ms /    11 tokens (  252.76 ms per token,     3.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2689.32 ms /     3 runs   (  896.44 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5472.59 ms /    14 tokens\n",
      " 90%|█████████ | 3140/3487 [8:52:54<51:16,  8.87s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3678.99 ms /    16 tokens (  229.94 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.61 ms /     3 runs   (  901.54 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6386.35 ms /    19 tokens\n",
      " 90%|█████████ | 3141/3487 [8:53:00<46:51,  8.12s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4805.32 ms /    22 tokens (  218.42 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.07 ms /     3 runs   (  899.02 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7535.96 ms /    25 tokens\n",
      " 90%|█████████ | 3142/3487 [8:53:08<45:42,  7.95s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7700.86 ms /    35 tokens (  220.02 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.24 ms /     3 runs   (  890.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10374.60 ms /    38 tokens\n",
      " 90%|█████████ | 3143/3487 [8:53:18<49:46,  8.68s/it]Llama.generate: 315 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1368.54 ms /     4 tokens (  342.13 ms per token,     2.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2819.87 ms /     3 runs   (  939.96 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4191.42 ms /     7 tokens\n",
      " 90%|█████████ | 3144/3487 [8:53:22<41:56,  7.34s/it]Llama.generate: 315 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4984.02 ms /    22 tokens (  226.55 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.10 ms /     3 runs   (  883.70 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7637.48 ms /    25 tokens\n",
      " 90%|█████████ | 3145/3487 [8:53:30<42:20,  7.43s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3081.14 ms /    13 tokens (  237.01 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.09 ms /     3 runs   (  887.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5745.49 ms /    16 tokens\n",
      " 90%|█████████ | 3146/3487 [8:53:36<39:21,  6.93s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5233.63 ms /    25 tokens (  209.35 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.66 ms /     3 runs   (  897.89 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7929.86 ms /    28 tokens\n",
      " 90%|█████████ | 3147/3487 [8:53:44<40:58,  7.23s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2247.26 ms /     9 tokens (  249.70 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.07 ms /     3 runs   (  890.02 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4919.79 ms /    12 tokens\n",
      " 90%|█████████ | 3148/3487 [8:53:49<37:00,  6.55s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3145.16 ms /    13 tokens (  241.94 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.87 ms /     3 runs   (  896.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5837.05 ms /    16 tokens\n",
      " 90%|█████████ | 3149/3487 [8:53:55<35:42,  6.34s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2284.06 ms /     9 tokens (  253.78 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.17 ms /     3 runs   (  907.39 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5008.82 ms /    12 tokens\n",
      " 90%|█████████ | 3150/3487 [8:54:00<33:22,  5.94s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3022.24 ms /    13 tokens (  232.48 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2854.47 ms /     3 runs   (  951.49 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    5879.54 ms /    16 tokens\n",
      " 90%|█████████ | 3151/3487 [8:54:05<33:10,  5.92s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3093.08 ms /    11 tokens (  281.19 ms per token,     3.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.53 ms /     3 runs   (  890.18 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5766.05 ms /    14 tokens\n",
      " 90%|█████████ | 3152/3487 [8:54:11<32:49,  5.88s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5368.04 ms /    25 tokens (  214.72 ms per token,     4.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.82 ms /     3 runs   (  884.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8025.05 ms /    28 tokens\n",
      " 90%|█████████ | 3153/3487 [8:54:19<36:19,  6.53s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2289.93 ms /     9 tokens (  254.44 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.68 ms /     3 runs   (  892.56 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4969.91 ms /    12 tokens\n",
      " 90%|█████████ | 3154/3487 [8:54:24<33:38,  6.06s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2653.51 ms /    10 tokens (  265.35 ms per token,     3.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.57 ms /     3 runs   (  889.52 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5325.07 ms /    13 tokens\n",
      " 90%|█████████ | 3155/3487 [8:54:30<32:19,  5.84s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11347.53 ms /    57 tokens (  199.08 ms per token,     5.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2877.37 ms /     3 runs   (  959.12 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   14229.68 ms /    60 tokens\n",
      " 91%|█████████ | 3156/3487 [8:54:44<46:07,  8.36s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1900.13 ms /     6 tokens (  316.69 ms per token,     3.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.99 ms /     3 runs   (  897.00 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4593.87 ms /     9 tokens\n",
      " 91%|█████████ | 3157/3487 [8:54:48<39:47,  7.23s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3684.67 ms /    16 tokens (  230.29 ms per token,     4.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.57 ms /     3 runs   (  891.19 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6360.79 ms /    19 tokens\n",
      " 91%|█████████ | 3158/3487 [8:54:55<38:14,  6.97s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12259.93 ms /    60 tokens (  204.33 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.70 ms /     3 runs   (  888.90 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14929.37 ms /    63 tokens\n",
      " 91%|█████████ | 3159/3487 [8:55:10<51:11,  9.36s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6421.35 ms /    31 tokens (  207.14 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.63 ms /     3 runs   (  883.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9075.16 ms /    34 tokens\n",
      " 91%|█████████ | 3160/3487 [8:55:19<50:34,  9.28s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2805.36 ms /    12 tokens (  233.78 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.54 ms /     3 runs   (  883.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5458.71 ms /    15 tokens\n",
      " 91%|█████████ | 3161/3487 [8:55:24<44:12,  8.14s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7947.26 ms /    40 tokens (  198.68 ms per token,     5.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.34 ms /     3 runs   (  894.45 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10633.11 ms /    43 tokens\n",
      " 91%|█████████ | 3162/3487 [8:55:35<48:08,  8.89s/it]Llama.generate: 316 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1402.47 ms /     4 tokens (  350.62 ms per token,     2.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2876.61 ms /     3 runs   (  958.87 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4281.45 ms /     7 tokens\n",
      " 91%|█████████ | 3163/3487 [8:55:39<40:32,  7.51s/it]Llama.generate: 306 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12464.23 ms /    64 tokens (  194.75 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.54 ms /     3 runs   (  889.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15136.56 ms /    67 tokens\n",
      " 91%|█████████ | 3164/3487 [8:55:54<52:45,  9.80s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3863.77 ms /    15 tokens (  257.58 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.09 ms /     3 runs   (  885.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6522.26 ms /    18 tokens\n",
      " 91%|█████████ | 3165/3487 [8:56:01<47:19,  8.82s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4346.30 ms /    21 tokens (  206.97 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.47 ms /     3 runs   (  888.49 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7014.84 ms /    24 tokens\n",
      " 91%|█████████ | 3166/3487 [8:56:08<44:17,  8.28s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3063.87 ms /    13 tokens (  235.68 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.02 ms /     3 runs   (  887.34 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5728.24 ms /    16 tokens\n",
      " 91%|█████████ | 3167/3487 [8:56:14<40:05,  7.52s/it]Llama.generate: 310 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2633.51 ms /    11 tokens (  239.41 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.41 ms /     3 runs   (  882.14 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5282.55 ms /    14 tokens\n",
      " 91%|█████████ | 3168/3487 [8:56:19<36:24,  6.85s/it]Llama.generate: 310 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2695.36 ms /    10 tokens (  269.54 ms per token,     3.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.62 ms /     3 runs   (  881.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5342.90 ms /    13 tokens\n",
      " 91%|█████████ | 3169/3487 [8:56:24<33:55,  6.40s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8152.16 ms /    40 tokens (  203.80 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2867.72 ms /     3 runs   (  955.91 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   11021.91 ms /    43 tokens\n",
      " 91%|█████████ | 3170/3487 [8:56:35<41:09,  7.79s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3186.82 ms /    14 tokens (  227.63 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.07 ms /     3 runs   (  901.69 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5894.15 ms /    17 tokens\n",
      " 91%|█████████ | 3171/3487 [8:56:41<38:02,  7.22s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4718.84 ms /    20 tokens (  235.94 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2637.41 ms /     3 runs   (  879.14 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7358.74 ms /    23 tokens\n",
      " 91%|█████████ | 3172/3487 [8:56:49<38:08,  7.27s/it]Llama.generate: 306 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11813.20 ms /    60 tokens (  196.89 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.60 ms /     3 runs   (  895.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14503.13 ms /    63 tokens\n",
      " 91%|█████████ | 3173/3487 [8:57:03<49:24,  9.44s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7601.10 ms /    36 tokens (  211.14 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.30 ms /     3 runs   (  884.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10257.46 ms /    39 tokens\n",
      " 91%|█████████ | 3174/3487 [8:57:13<50:32,  9.69s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7790.80 ms /    38 tokens (  205.02 ms per token,     4.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2822.05 ms /     3 runs   (  940.68 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   10615.85 ms /    41 tokens\n",
      " 91%|█████████ | 3175/3487 [8:57:24<51:50,  9.97s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2913.86 ms /    12 tokens (  242.82 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.52 ms /     3 runs   (  889.51 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5585.57 ms /    15 tokens\n",
      " 91%|█████████ | 3176/3487 [8:57:30<44:52,  8.66s/it]Llama.generate: 314 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2207.55 ms /     8 tokens (  275.94 ms per token,     3.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.66 ms /     3 runs   (  890.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4881.51 ms /    11 tokens\n",
      " 91%|█████████ | 3177/3487 [8:57:34<38:53,  7.53s/it]Llama.generate: 314 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7674.59 ms /    36 tokens (  213.18 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.33 ms /     3 runs   (  878.44 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10313.18 ms /    39 tokens\n",
      " 91%|█████████ | 3178/3487 [8:57:45<43:04,  8.37s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2175.83 ms /     5 tokens (  435.17 ms per token,     2.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2631.28 ms /     3 runs   (  877.09 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4809.53 ms /     8 tokens\n",
      " 91%|█████████ | 3179/3487 [8:57:50<37:28,  7.30s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4840.13 ms /    22 tokens (  220.01 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.84 ms /     3 runs   (  884.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7496.05 ms /    25 tokens\n",
      " 91%|█████████ | 3180/3487 [8:57:57<37:40,  7.36s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3907.14 ms /    18 tokens (  217.06 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.72 ms /     3 runs   (  881.57 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6554.10 ms /    21 tokens\n",
      " 91%|█████████ | 3181/3487 [8:58:04<36:19,  7.12s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5277.75 ms /    26 tokens (  202.99 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.23 ms /     3 runs   (  876.74 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7910.38 ms /    29 tokens\n",
      " 91%|█████████▏| 3182/3487 [8:58:12<37:25,  7.36s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6709.14 ms /    32 tokens (  209.66 ms per token,     4.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.27 ms /     3 runs   (  882.76 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9360.54 ms /    35 tokens\n",
      " 91%|█████████▏| 3183/3487 [8:58:21<40:21,  7.96s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3900.61 ms /    18 tokens (  216.70 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2945.94 ms /     3 runs   (  981.98 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    6849.21 ms /    21 tokens\n",
      " 91%|█████████▏| 3184/3487 [8:58:28<38:32,  7.63s/it]Llama.generate: 323 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4822.32 ms /     4 runs   ( 1205.58 ms per token,     0.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    4825.56 ms /     5 tokens\n",
      " 91%|█████████▏| 3185/3487 [8:58:33<34:11,  6.79s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6862.77 ms /    30 tokens (  228.76 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.65 ms /     3 runs   (  904.22 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9577.90 ms /    33 tokens\n",
      " 91%|█████████▏| 3186/3487 [8:58:42<38:16,  7.63s/it]Llama.generate: 306 prefix-match hit, remaining 161 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   31224.90 ms /   161 tokens (  193.94 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.63 ms /     3 runs   (  885.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   33885.49 ms /   164 tokens\n",
      " 91%|█████████▏| 3187/3487 [8:59:16<1:17:33, 15.51s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3196.09 ms /    14 tokens (  228.29 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2696.78 ms /     3 runs   (  898.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5895.78 ms /    17 tokens\n",
      " 91%|█████████▏| 3188/3487 [8:59:22<1:02:55, 12.63s/it]Llama.generate: 309 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7452.13 ms /    35 tokens (  212.92 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.13 ms /     3 runs   (  895.71 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10141.80 ms /    38 tokens\n",
      " 91%|█████████▏| 3189/3487 [8:59:32<59:04, 11.89s/it]  Llama.generate: 309 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2806.83 ms /    11 tokens (  255.17 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2738.65 ms /     3 runs   (  912.88 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5548.01 ms /    14 tokens\n",
      " 91%|█████████▏| 3190/3487 [8:59:38<49:27,  9.99s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2207.31 ms /     8 tokens (  275.91 ms per token,     3.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.75 ms /     3 runs   (  890.25 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4880.74 ms /    11 tokens\n",
      " 92%|█████████▏| 3191/3487 [8:59:43<41:44,  8.46s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2844.99 ms /    12 tokens (  237.08 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2715.24 ms /     3 runs   (  905.08 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5562.90 ms /    15 tokens\n",
      " 92%|█████████▏| 3192/3487 [8:59:48<37:20,  7.59s/it]Llama.generate: 315 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2156.75 ms /     5 tokens (  431.35 ms per token,     2.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2816.65 ms /     3 runs   (  938.88 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4976.38 ms /     8 tokens\n",
      " 92%|█████████▏| 3193/3487 [8:59:53<33:22,  6.81s/it]Llama.generate: 307 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   27499.74 ms /   105 tokens (  261.90 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2968.04 ms /     3 runs   (  989.35 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   30470.38 ms /   108 tokens\n",
      " 92%|█████████▏| 3194/3487 [9:00:24<1:07:56, 13.91s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2685.82 ms /    10 tokens (  268.58 ms per token,     3.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2756.34 ms /     3 runs   (  918.78 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5444.89 ms /    13 tokens\n",
      " 92%|█████████▏| 3195/3487 [9:00:29<55:21, 11.37s/it]  Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2781.97 ms /    11 tokens (  252.91 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.73 ms /     3 runs   (  911.91 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5520.91 ms /    14 tokens\n",
      " 92%|█████████▏| 3196/3487 [9:00:35<46:39,  9.62s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2767.36 ms /    10 tokens (  276.74 ms per token,     3.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.26 ms /     3 runs   (  884.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5423.29 ms /    13 tokens\n",
      " 92%|█████████▏| 3197/3487 [9:00:40<40:25,  8.36s/it]Llama.generate: 306 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17456.68 ms /    90 tokens (  193.96 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.03 ms /     3 runs   (  901.34 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   20163.36 ms /    93 tokens\n",
      " 92%|█████████▏| 3198/3487 [9:01:00<57:20, 11.91s/it]Llama.generate: 307 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8802.34 ms /    43 tokens (  204.71 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.22 ms /     3 runs   (  889.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11473.99 ms /    46 tokens\n",
      " 92%|█████████▏| 3199/3487 [9:01:12<56:32, 11.78s/it]Llama.generate: 307 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5745.21 ms /    26 tokens (  220.97 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.71 ms /     3 runs   (  885.24 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8403.75 ms /    29 tokens\n",
      " 92%|█████████▏| 3200/3487 [9:01:20<51:30, 10.77s/it]Llama.generate: 307 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6288.66 ms /    31 tokens (  202.86 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.14 ms /     3 runs   (  888.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8955.02 ms /    34 tokens\n",
      " 92%|█████████▏| 3201/3487 [9:01:29<48:44, 10.23s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5079.64 ms /    23 tokens (  220.85 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.60 ms /     3 runs   (  899.20 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7779.74 ms /    26 tokens\n",
      " 92%|█████████▏| 3202/3487 [9:01:37<45:06,  9.50s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2444.35 ms /     8 tokens (  305.54 ms per token,     3.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2965.54 ms /     3 runs   (  988.51 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    5412.50 ms /    11 tokens\n",
      " 92%|█████████▏| 3203/3487 [9:01:42<39:09,  8.27s/it]Llama.generate: 306 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11498.45 ms /    56 tokens (  205.33 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2728.59 ms /     3 runs   (  909.53 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   14230.27 ms /    59 tokens\n",
      " 92%|█████████▏| 3204/3487 [9:01:57<47:28, 10.06s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9213.10 ms /    42 tokens (  219.36 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2809.11 ms /     3 runs   (  936.37 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   12024.56 ms /    45 tokens\n",
      " 92%|█████████▏| 3205/3487 [9:02:09<50:04, 10.65s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8912.26 ms /    45 tokens (  198.05 ms per token,     5.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2769.78 ms /     3 runs   (  923.26 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   11684.51 ms /    48 tokens\n",
      " 92%|█████████▏| 3206/3487 [9:02:20<51:21, 10.97s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2715.92 ms /     8 tokens (  339.49 ms per token,     2.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.45 ms /     3 runs   (  880.82 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5360.24 ms /    11 tokens\n",
      " 92%|█████████▏| 3207/3487 [9:02:26<43:20,  9.29s/it]Llama.generate: 307 prefix-match hit, remaining 81 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15817.20 ms /    81 tokens (  195.27 ms per token,     5.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.57 ms /     3 runs   (  886.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   18480.27 ms /    84 tokens\n",
      " 92%|█████████▏| 3208/3487 [9:02:44<56:01, 12.05s/it]Llama.generate: 307 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5927.54 ms /    28 tokens (  211.70 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2750.76 ms /     3 runs   (  916.92 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8680.82 ms /    31 tokens\n",
      " 92%|█████████▏| 3209/3487 [9:02:53<51:09, 11.04s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4209.69 ms /    18 tokens (  233.87 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.71 ms /     3 runs   (  894.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6895.48 ms /    21 tokens\n",
      " 92%|█████████▏| 3210/3487 [9:03:00<45:16,  9.81s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3320.47 ms /    13 tokens (  255.42 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.60 ms /     3 runs   (  889.87 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5993.89 ms /    16 tokens\n",
      " 92%|█████████▏| 3211/3487 [9:03:06<39:52,  8.67s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2295.27 ms /     9 tokens (  255.03 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.35 ms /     3 runs   (  898.45 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4993.38 ms /    12 tokens\n",
      " 92%|█████████▏| 3212/3487 [9:03:11<34:41,  7.57s/it]Llama.generate: 306 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7510.49 ms /    34 tokens (  220.90 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.53 ms /     3 runs   (  882.84 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10161.44 ms /    37 tokens\n",
      " 92%|█████████▏| 3213/3487 [9:03:21<38:07,  8.35s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8102.64 ms /    36 tokens (  225.07 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.18 ms /     3 runs   (  880.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   10745.86 ms /    39 tokens\n",
      " 92%|█████████▏| 3214/3487 [9:03:32<41:16,  9.07s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2828.55 ms /    11 tokens (  257.14 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.90 ms /     3 runs   (  885.97 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5488.58 ms /    14 tokens\n",
      " 92%|█████████▏| 3215/3487 [9:03:37<36:15,  8.00s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3175.44 ms /    13 tokens (  244.26 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.08 ms /     3 runs   (  884.03 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5830.21 ms /    16 tokens\n",
      " 92%|█████████▏| 3216/3487 [9:03:43<33:11,  7.35s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5901.85 ms /    28 tokens (  210.78 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.21 ms /     3 runs   (  900.74 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8606.37 ms /    31 tokens\n",
      " 92%|█████████▏| 3217/3487 [9:03:52<34:46,  7.73s/it]Llama.generate: 306 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8656.12 ms /    44 tokens (  196.73 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.22 ms /     3 runs   (  881.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11303.80 ms /    47 tokens\n",
      " 92%|█████████▏| 3218/3487 [9:04:03<39:28,  8.80s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2674.71 ms /    11 tokens (  243.16 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.79 ms /     3 runs   (  889.60 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5345.84 ms /    14 tokens\n",
      " 92%|█████████▏| 3219/3487 [9:04:08<34:41,  7.77s/it]Llama.generate: 313 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3227.26 ms /    13 tokens (  248.25 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.21 ms /     3 runs   (  913.07 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5969.32 ms /    16 tokens\n",
      " 92%|█████████▏| 3220/3487 [9:04:14<32:10,  7.23s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3828.58 ms /    15 tokens (  255.24 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.03 ms /     3 runs   (  879.34 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6469.43 ms /    18 tokens\n",
      " 92%|█████████▏| 3221/3487 [9:04:21<31:03,  7.01s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2564.61 ms /    10 tokens (  256.46 ms per token,     3.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.49 ms /     3 runs   (  891.50 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5241.56 ms /    13 tokens\n",
      " 92%|█████████▏| 3222/3487 [9:04:26<28:36,  6.48s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3243.84 ms /    14 tokens (  231.70 ms per token,     4.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.49 ms /     3 runs   (  879.50 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5884.38 ms /    17 tokens\n",
      " 92%|█████████▏| 3223/3487 [9:04:32<27:43,  6.30s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2292.22 ms /     9 tokens (  254.69 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.24 ms /     3 runs   (  891.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4968.68 ms /    12 tokens\n",
      " 92%|█████████▏| 3224/3487 [9:04:37<25:52,  5.90s/it]Llama.generate: 314 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4098.90 ms /     4 runs   ( 1024.73 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    4101.68 ms /     5 tokens\n",
      " 92%|█████████▏| 3225/3487 [9:04:41<23:25,  5.37s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3087.40 ms /    13 tokens (  237.49 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.14 ms /     3 runs   (  893.71 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5771.34 ms /    16 tokens\n",
      " 93%|█████████▎| 3226/3487 [9:04:47<23:53,  5.49s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3907.15 ms /    18 tokens (  217.06 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.05 ms /     3 runs   (  899.68 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6609.17 ms /    21 tokens\n",
      " 93%|█████████▎| 3227/3487 [9:04:53<25:15,  5.83s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5307.85 ms /    24 tokens (  221.16 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.05 ms /     3 runs   (  893.35 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7990.34 ms /    27 tokens\n",
      " 93%|█████████▎| 3228/3487 [9:05:01<27:58,  6.48s/it]Llama.generate: 315 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1407.91 ms /     4 tokens (  351.98 ms per token,     2.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2856.61 ms /     3 runs   (  952.20 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4267.02 ms /     7 tokens\n",
      " 93%|█████████▎| 3229/3487 [9:05:06<25:01,  5.82s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4540.27 ms /    21 tokens (  216.20 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.23 ms /     3 runs   (  881.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7188.21 ms /    24 tokens\n",
      " 93%|█████████▎| 3230/3487 [9:05:13<26:41,  6.23s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2881.31 ms /    11 tokens (  261.94 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2761.09 ms /     3 runs   (  920.36 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5644.63 ms /    14 tokens\n",
      " 93%|█████████▎| 3231/3487 [9:05:19<25:50,  6.06s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4926.16 ms /    24 tokens (  205.26 ms per token,     4.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.88 ms /     3 runs   (  889.96 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7598.39 ms /    27 tokens\n",
      " 93%|█████████▎| 3232/3487 [9:05:26<27:43,  6.52s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2907.86 ms /    11 tokens (  264.35 ms per token,     3.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.37 ms /     3 runs   (  892.46 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5587.67 ms /    14 tokens\n",
      " 93%|█████████▎| 3233/3487 [9:05:32<26:26,  6.24s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4644.80 ms /    22 tokens (  211.13 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.47 ms /     3 runs   (  884.82 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7302.29 ms /    25 tokens\n",
      " 93%|█████████▎| 3234/3487 [9:05:39<27:40,  6.56s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2750.47 ms /     9 tokens (  305.61 ms per token,     3.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.81 ms /     3 runs   (  886.60 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5412.89 ms /    12 tokens\n",
      " 93%|█████████▎| 3235/3487 [9:05:44<26:07,  6.22s/it]Llama.generate: 311 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3556.99 ms /    15 tokens (  237.13 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.78 ms /     3 runs   (  889.26 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6227.10 ms /    18 tokens\n",
      " 93%|█████████▎| 3236/3487 [9:05:51<26:02,  6.23s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3170.37 ms /    12 tokens (  264.20 ms per token,     3.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.39 ms /     3 runs   (  895.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5859.89 ms /    15 tokens\n",
      " 93%|█████████▎| 3237/3487 [9:05:57<25:29,  6.12s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6306.94 ms /    30 tokens (  210.23 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2814.13 ms /     3 runs   (  938.04 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    9123.62 ms /    33 tokens\n",
      " 93%|█████████▎| 3238/3487 [9:06:06<29:10,  7.03s/it]Llama.generate: 313 prefix-match hit, remaining 185 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   34718.56 ms /   185 tokens (  187.67 ms per token,     5.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.39 ms /     3 runs   (  896.80 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   37411.18 ms /   188 tokens\n",
      " 93%|█████████▎| 3239/3487 [9:06:43<1:06:44, 16.15s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3292.12 ms /    13 tokens (  253.24 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.54 ms /     3 runs   (  907.18 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6015.73 ms /    16 tokens\n",
      " 93%|█████████▎| 3240/3487 [9:06:49<53:58, 13.11s/it]  Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6214.75 ms /    30 tokens (  207.16 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.57 ms /     3 runs   (  886.86 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8877.44 ms /    33 tokens\n",
      " 93%|█████████▎| 3241/3487 [9:06:58<48:33, 11.84s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3623.70 ms /    13 tokens (  278.75 ms per token,     3.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2878.14 ms /     3 runs   (  959.38 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    6504.59 ms /    16 tokens\n",
      " 93%|█████████▎| 3242/3487 [9:07:05<41:50, 10.24s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6484.93 ms /    31 tokens (  209.19 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.63 ms /     3 runs   (  884.88 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9141.68 ms /    34 tokens\n",
      " 93%|█████████▎| 3243/3487 [9:07:14<40:19,  9.92s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5052.43 ms /    24 tokens (  210.52 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.66 ms /     3 runs   (  900.55 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7756.05 ms /    27 tokens\n",
      " 93%|█████████▎| 3244/3487 [9:07:21<37:32,  9.27s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3023.88 ms /    13 tokens (  232.61 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.61 ms /     3 runs   (  895.54 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5713.18 ms /    16 tokens\n",
      " 93%|█████████▎| 3245/3487 [9:07:27<33:05,  8.21s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2667.83 ms /    11 tokens (  242.53 ms per token,     4.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.86 ms /     3 runs   (  886.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5330.18 ms /    14 tokens\n",
      " 93%|█████████▎| 3246/3487 [9:07:33<29:30,  7.35s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2142.24 ms /     8 tokens (  267.78 ms per token,     3.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.35 ms /     3 runs   (  894.12 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4827.04 ms /    11 tokens\n",
      " 93%|█████████▎| 3247/3487 [9:07:37<26:22,  6.59s/it]Llama.generate: 307 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8237.49 ms /    41 tokens (  200.91 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2645.23 ms /     3 runs   (  881.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10886.38 ms /    44 tokens\n",
      " 93%|█████████▎| 3248/3487 [9:07:48<31:24,  7.88s/it]Llama.generate: 307 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8885.28 ms /    42 tokens (  211.55 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.83 ms /     3 runs   (  883.61 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11538.41 ms /    45 tokens\n",
      " 93%|█████████▎| 3249/3487 [9:08:00<35:37,  8.98s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3165.63 ms /    14 tokens (  226.12 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.83 ms /     3 runs   (  878.28 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5802.08 ms /    17 tokens\n",
      " 93%|█████████▎| 3250/3487 [9:08:06<31:43,  8.03s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3661.91 ms /    16 tokens (  228.87 ms per token,     4.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.28 ms /     3 runs   (  893.09 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6343.50 ms /    19 tokens\n",
      " 93%|█████████▎| 3251/3487 [9:08:12<29:36,  7.53s/it]Llama.generate: 307 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1994.96 ms /     7 tokens (  284.99 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.05 ms /     3 runs   (  880.68 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4639.65 ms /    10 tokens\n",
      " 93%|█████████▎| 3252/3487 [9:08:17<26:05,  6.66s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9053.64 ms /    46 tokens (  196.82 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2799.58 ms /     3 runs   (  933.19 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   11855.91 ms /    49 tokens\n",
      " 93%|█████████▎| 3253/3487 [9:08:29<32:04,  8.22s/it]Llama.generate: 307 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8059.36 ms /    39 tokens (  206.65 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.52 ms /     3 runs   (  885.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10718.70 ms /    42 tokens\n",
      " 93%|█████████▎| 3254/3487 [9:08:39<34:51,  8.97s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5597.16 ms /    27 tokens (  207.30 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.22 ms /     3 runs   (  907.74 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8323.12 ms /    30 tokens\n",
      " 93%|█████████▎| 3255/3487 [9:08:48<33:57,  8.78s/it]Llama.generate: 307 prefix-match hit, remaining 567 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =  105784.71 ms /   567 tokens (  186.57 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2699.80 ms /     3 runs   (  899.93 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =  108488.08 ms /   570 tokens\n",
      " 93%|█████████▎| 3256/3487 [9:10:36<2:28:59, 38.70s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2287.81 ms /     8 tokens (  285.98 ms per token,     3.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2749.06 ms /     3 runs   (  916.35 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5039.24 ms /    11 tokens\n",
      " 93%|█████████▎| 3257/3487 [9:10:41<1:49:38, 28.60s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3772.66 ms /    17 tokens (  221.92 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.89 ms /     3 runs   (  890.63 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6447.06 ms /    20 tokens\n",
      " 93%|█████████▎| 3258/3487 [9:10:48<1:23:48, 21.96s/it]Llama.generate: 312 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2952.50 ms /    12 tokens (  246.04 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.31 ms /     3 runs   (  891.10 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5628.05 ms /    15 tokens\n",
      " 93%|█████████▎| 3259/3487 [9:10:53<1:04:50, 17.06s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6459.65 ms /    31 tokens (  208.38 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.09 ms /     3 runs   (  906.70 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    9182.67 ms /    34 tokens\n",
      " 93%|█████████▎| 3260/3487 [9:11:02<55:37, 14.70s/it]  Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5491.61 ms /    26 tokens (  211.22 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2683.57 ms /     3 runs   (  894.52 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8177.14 ms /    29 tokens\n",
      " 94%|█████████▎| 3261/3487 [9:11:11<48:00, 12.75s/it]Llama.generate: 308 prefix-match hit, remaining 92 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17920.70 ms /    92 tokens (  194.79 ms per token,     5.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.24 ms /     3 runs   (  881.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   20567.61 ms /    95 tokens\n",
      " 94%|█████████▎| 3262/3487 [9:11:31<56:36, 15.10s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4797.98 ms /    22 tokens (  218.09 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.76 ms /     3 runs   (  894.92 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7485.50 ms /    25 tokens\n",
      " 94%|█████████▎| 3263/3487 [9:11:39<47:50, 12.81s/it]Llama.generate: 307 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5121.78 ms /    24 tokens (  213.41 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.10 ms /     3 runs   (  886.37 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7784.07 ms /    27 tokens\n",
      " 94%|█████████▎| 3264/3487 [9:11:46<42:01, 11.31s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2877.42 ms /    11 tokens (  261.58 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.51 ms /     3 runs   (  893.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5561.79 ms /    14 tokens\n",
      " 94%|█████████▎| 3265/3487 [9:11:52<35:28,  9.59s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3549.38 ms /    14 tokens (  253.53 ms per token,     3.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.16 ms /     3 runs   (  884.39 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6205.34 ms /    17 tokens\n",
      " 94%|█████████▎| 3266/3487 [9:11:58<31:35,  8.57s/it]Llama.generate: 306 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7518.64 ms /    33 tokens (  227.84 ms per token,     4.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.74 ms /     3 runs   (  891.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10196.66 ms /    36 tokens\n",
      " 94%|█████████▎| 3267/3487 [9:12:08<33:14,  9.06s/it]Llama.generate: 307 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9469.62 ms /    46 tokens (  205.86 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2741.35 ms /     3 runs   (  913.78 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   12213.77 ms /    49 tokens\n",
      " 94%|█████████▎| 3268/3487 [9:12:21<36:32, 10.01s/it]Llama.generate: 307 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8281.97 ms /    40 tokens (  207.05 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.76 ms /     3 runs   (  889.25 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10952.59 ms /    43 tokens\n",
      " 94%|█████████▎| 3269/3487 [9:12:32<37:24, 10.30s/it]Llama.generate: 306 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10571.77 ms /    54 tokens (  195.77 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2647.33 ms /     3 runs   (  882.44 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13221.96 ms /    57 tokens\n",
      " 94%|█████████▍| 3270/3487 [9:12:45<40:25, 11.18s/it]Llama.generate: 306 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9666.02 ms /    50 tokens (  193.32 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.30 ms /     3 runs   (  892.43 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12345.73 ms /    53 tokens\n",
      " 94%|█████████▍| 3271/3487 [9:12:57<41:30, 11.53s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2550.99 ms /    10 tokens (  255.10 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.31 ms /     3 runs   (  891.77 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5228.91 ms /    13 tokens\n",
      " 94%|█████████▍| 3272/3487 [9:13:02<34:33,  9.64s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2939.31 ms /    12 tokens (  244.94 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.49 ms /     3 runs   (  890.83 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5614.64 ms /    15 tokens\n",
      " 94%|█████████▍| 3273/3487 [9:13:08<30:05,  8.44s/it]Llama.generate: 315 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8209.52 ms /    38 tokens (  216.04 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.14 ms /     3 runs   (  883.71 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10862.92 ms /    41 tokens\n",
      " 94%|█████████▍| 3274/3487 [9:13:19<32:32,  9.17s/it]Llama.generate: 328 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11329.69 ms /    56 tokens (  202.32 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.30 ms /     3 runs   (  884.77 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13986.36 ms /    59 tokens\n",
      " 94%|█████████▍| 3275/3487 [9:13:33<37:30, 10.62s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4333.24 ms /    20 tokens (  216.66 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.40 ms /     3 runs   (  902.13 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7041.70 ms /    23 tokens\n",
      " 94%|█████████▍| 3276/3487 [9:13:40<33:34,  9.55s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1435.82 ms /     4 tokens (  358.95 ms per token,     2.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2829.88 ms /     3 runs   (  943.29 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4268.52 ms /     7 tokens\n",
      " 94%|█████████▍| 3277/3487 [9:13:44<27:52,  7.96s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2833.43 ms /    11 tokens (  257.58 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.59 ms /     3 runs   (  883.53 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5485.60 ms /    14 tokens\n",
      " 94%|█████████▍| 3278/3487 [9:13:50<25:09,  7.22s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5172.40 ms /    25 tokens (  206.90 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.28 ms /     3 runs   (  907.76 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7897.81 ms /    28 tokens\n",
      " 94%|█████████▍| 3279/3487 [9:13:58<25:45,  7.43s/it]Llama.generate: 312 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3221.88 ms /    14 tokens (  230.13 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.66 ms /     3 runs   (  893.55 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5905.55 ms /    17 tokens\n",
      " 94%|█████████▍| 3280/3487 [9:14:04<24:03,  6.97s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2034.17 ms /     4 tokens (  508.54 ms per token,     1.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2801.54 ms /     3 runs   (  933.85 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4838.14 ms /     7 tokens\n",
      " 94%|█████████▍| 3281/3487 [9:14:08<21:45,  6.34s/it]Llama.generate: 311 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3391.72 ms /    14 tokens (  242.27 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2670.08 ms /     3 runs   (  890.03 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6064.29 ms /    17 tokens\n",
      " 94%|█████████▍| 3282/3487 [9:14:14<21:22,  6.26s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3295.02 ms /    13 tokens (  253.46 ms per token,     3.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.17 ms /     3 runs   (  902.06 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6003.59 ms /    16 tokens\n",
      " 94%|█████████▍| 3283/3487 [9:14:20<21:01,  6.18s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2310.06 ms /     9 tokens (  256.67 ms per token,     3.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.85 ms /     3 runs   (  900.95 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5015.58 ms /    12 tokens\n",
      " 94%|█████████▍| 3284/3487 [9:14:26<19:44,  5.84s/it]Llama.generate: 314 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3899.89 ms /     4 runs   (  974.97 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    3902.50 ms /     5 tokens\n",
      " 94%|█████████▍| 3285/3487 [9:14:29<17:42,  5.26s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7878.74 ms /    37 tokens (  212.94 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.78 ms /     3 runs   (  901.59 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   10586.13 ms /    40 tokens\n",
      " 94%|█████████▍| 3286/3487 [9:14:40<22:58,  6.86s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3496.43 ms /    15 tokens (  233.10 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2723.81 ms /     3 runs   (  907.94 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6223.39 ms /    18 tokens\n",
      " 94%|█████████▍| 3287/3487 [9:14:46<22:14,  6.67s/it]Llama.generate: 314 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3320.61 ms /    12 tokens (  276.72 ms per token,     3.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.59 ms /     3 runs   (  887.20 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5984.12 ms /    15 tokens\n",
      " 94%|█████████▍| 3288/3487 [9:14:52<21:27,  6.47s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3261.58 ms /    13 tokens (  250.89 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.35 ms /     3 runs   (  888.45 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5929.87 ms /    16 tokens\n",
      " 94%|█████████▍| 3289/3487 [9:14:58<20:49,  6.31s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2765.83 ms /    11 tokens (  251.44 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2775.08 ms /     3 runs   (  925.03 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5543.53 ms /    14 tokens\n",
      " 94%|█████████▍| 3290/3487 [9:15:04<19:57,  6.08s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3466.29 ms /    15 tokens (  231.09 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2736.10 ms /     3 runs   (  912.03 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6205.18 ms /    18 tokens\n",
      " 94%|█████████▍| 3291/3487 [9:15:10<19:59,  6.12s/it]Llama.generate: 311 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1460.70 ms /     4 tokens (  365.18 ms per token,     2.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2844.63 ms /     3 runs   (  948.21 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4308.00 ms /     7 tokens\n",
      " 94%|█████████▍| 3292/3487 [9:15:14<18:08,  5.58s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2698.85 ms /    11 tokens (  245.35 ms per token,     4.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3233.84 ms /     3 runs   ( 1077.95 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    5934.50 ms /    14 tokens\n",
      " 94%|█████████▍| 3293/3487 [9:15:20<18:23,  5.69s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4276.03 ms /     9 tokens (  475.11 ms per token,     2.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4456.84 ms /     3 runs   ( 1485.61 ms per token,     0.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    8736.06 ms /    12 tokens\n",
      " 94%|█████████▍| 3294/3487 [9:15:29<21:14,  6.61s/it]Llama.generate: 306 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9061.12 ms /    38 tokens (  238.45 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2895.03 ms /     3 runs   (  965.01 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   11959.33 ms /    41 tokens\n",
      " 94%|█████████▍| 3295/3487 [9:15:41<26:17,  8.21s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2712.52 ms /    10 tokens (  271.25 ms per token,     3.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2792.74 ms /     3 runs   (  930.91 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5507.98 ms /    13 tokens\n",
      " 95%|█████████▍| 3296/3487 [9:15:46<23:34,  7.40s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4014.23 ms /    17 tokens (  236.13 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.63 ms /     3 runs   (  889.21 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6684.09 ms /    20 tokens\n",
      " 95%|█████████▍| 3297/3487 [9:15:53<22:46,  7.19s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2299.10 ms /     9 tokens (  255.46 ms per token,     3.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2740.17 ms /     3 runs   (  913.39 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5042.16 ms /    12 tokens\n",
      " 95%|█████████▍| 3298/3487 [9:15:58<20:37,  6.55s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10111.59 ms /    49 tokens (  206.36 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.20 ms /     3 runs   (  887.73 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12777.49 ms /    52 tokens\n",
      " 95%|█████████▍| 3299/3487 [9:16:11<26:23,  8.42s/it]Llama.generate: 307 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13501.62 ms /    68 tokens (  198.55 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.66 ms /     3 runs   (  890.89 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16177.24 ms /    71 tokens\n",
      " 95%|█████████▍| 3300/3487 [9:16:27<33:30, 10.75s/it]Llama.generate: 308 prefix-match hit, remaining 89 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   17285.87 ms /    89 tokens (  194.22 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.42 ms /     3 runs   (  887.81 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19952.24 ms /    92 tokens\n",
      " 95%|█████████▍| 3301/3487 [9:16:47<41:53, 13.51s/it]Llama.generate: 306 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4770.61 ms /    23 tokens (  207.42 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2716.47 ms /     3 runs   (  905.49 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    7489.58 ms /    26 tokens\n",
      " 95%|█████████▍| 3302/3487 [9:16:55<36:06, 11.71s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4937.15 ms /    24 tokens (  205.71 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2916.14 ms /     3 runs   (  972.05 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    7855.79 ms /    27 tokens\n",
      " 95%|█████████▍| 3303/3487 [9:17:02<32:22, 10.55s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3256.05 ms /    14 tokens (  232.57 ms per token,     4.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.84 ms /     3 runs   (  902.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5966.47 ms /    17 tokens\n",
      " 95%|█████████▍| 3304/3487 [9:17:08<28:00,  9.18s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5245.18 ms /    22 tokens (  238.42 ms per token,     4.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.20 ms /     3 runs   (  900.73 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7950.16 ms /    25 tokens\n",
      " 95%|█████████▍| 3305/3487 [9:17:16<26:44,  8.81s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2832.63 ms /    11 tokens (  257.51 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2764.49 ms /     3 runs   (  921.50 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5599.69 ms /    14 tokens\n",
      " 95%|█████████▍| 3306/3487 [9:17:22<23:41,  7.85s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1954.49 ms /     5 tokens (  390.90 ms per token,     2.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.32 ms /     3 runs   (  892.11 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4633.99 ms /     8 tokens\n",
      " 95%|█████████▍| 3307/3487 [9:17:27<20:40,  6.89s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2147.49 ms /     5 tokens (  429.50 ms per token,     2.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3083.55 ms /     3 runs   ( 1027.85 ms per token,     0.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    5233.47 ms /     8 tokens\n",
      " 95%|█████████▍| 3308/3487 [9:17:32<19:04,  6.40s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2740.63 ms /     5 tokens (  548.13 ms per token,     1.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2829.94 ms /     3 runs   (  943.31 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5574.11 ms /     8 tokens\n",
      " 95%|█████████▍| 3309/3487 [9:17:37<18:15,  6.15s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2633.26 ms /     8 tokens (  329.16 ms per token,     3.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2893.91 ms /     3 runs   (  964.64 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    5529.83 ms /    11 tokens\n",
      " 95%|█████████▍| 3310/3487 [9:17:43<17:36,  5.97s/it]Llama.generate: 308 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4966.59 ms /    19 tokens (  261.40 ms per token,     3.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2801.42 ms /     3 runs   (  933.81 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7770.51 ms /    22 tokens\n",
      " 95%|█████████▍| 3311/3487 [9:17:51<19:06,  6.51s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8660.70 ms /    34 tokens (  254.73 ms per token,     3.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.04 ms /     3 runs   (  908.35 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   11388.67 ms /    37 tokens\n",
      " 95%|█████████▍| 3312/3487 [9:18:02<23:16,  7.98s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5317.16 ms /    24 tokens (  221.55 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2756.83 ms /     3 runs   (  918.94 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8076.20 ms /    27 tokens\n",
      " 95%|█████████▌| 3313/3487 [9:18:10<23:13,  8.01s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4152.75 ms /    18 tokens (  230.71 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.24 ms /     3 runs   (  892.75 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6833.37 ms /    21 tokens\n",
      " 95%|█████████▌| 3314/3487 [9:18:17<22:05,  7.66s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2440.15 ms /     6 tokens (  406.69 ms per token,     2.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.04 ms /     3 runs   (  888.35 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5107.48 ms /     9 tokens\n",
      " 95%|█████████▌| 3315/3487 [9:18:22<19:46,  6.90s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3807.23 ms /    17 tokens (  223.95 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2686.87 ms /     3 runs   (  895.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6496.07 ms /    20 tokens\n",
      " 95%|█████████▌| 3316/3487 [9:18:29<19:19,  6.78s/it]Llama.generate: 306 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9790.10 ms /    49 tokens (  199.80 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.52 ms /     3 runs   (  889.84 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   12462.02 ms /    52 tokens\n",
      " 95%|█████████▌| 3317/3487 [9:18:41<24:02,  8.49s/it]Llama.generate: 306 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14676.77 ms /    76 tokens (  193.12 ms per token,     5.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.22 ms /     3 runs   (  884.41 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   17333.06 ms /    79 tokens\n",
      " 95%|█████████▌| 3318/3487 [9:18:59<31:22, 11.14s/it]Llama.generate: 307 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12423.53 ms /    64 tokens (  194.12 ms per token,     5.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.92 ms /     3 runs   (  897.31 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   15117.41 ms /    67 tokens\n",
      " 95%|█████████▌| 3319/3487 [9:19:14<34:32, 12.34s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3224.21 ms /    13 tokens (  248.02 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.88 ms /     3 runs   (  898.63 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5922.43 ms /    16 tokens\n",
      " 95%|█████████▌| 3320/3487 [9:19:20<28:59, 10.41s/it]Llama.generate: 306 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16372.59 ms /    86 tokens (  190.38 ms per token,     5.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.52 ms /     3 runs   (  888.51 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19040.61 ms /    89 tokens\n",
      " 95%|█████████▌| 3321/3487 [9:19:39<35:58, 13.00s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6339.90 ms /    29 tokens (  218.62 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.28 ms /     3 runs   (  886.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9000.38 ms /    32 tokens\n",
      " 95%|█████████▌| 3322/3487 [9:19:48<32:27, 11.81s/it]Llama.generate: 335 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4067.67 ms /     4 runs   ( 1016.92 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    4070.55 ms /     5 tokens\n",
      " 95%|█████████▌| 3323/3487 [9:19:52<25:56,  9.49s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4875.77 ms /    23 tokens (  211.99 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.73 ms /     3 runs   (  893.24 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7557.95 ms /    26 tokens\n",
      " 95%|█████████▌| 3324/3487 [9:19:59<24:12,  8.91s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3237.71 ms /    13 tokens (  249.05 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2684.97 ms /     3 runs   (  894.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5925.23 ms /    16 tokens\n",
      " 95%|█████████▌| 3325/3487 [9:20:05<21:38,  8.02s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2310.18 ms /     8 tokens (  288.77 ms per token,     3.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2704.82 ms /     3 runs   (  901.61 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5017.29 ms /    11 tokens\n",
      " 95%|█████████▌| 3326/3487 [9:20:10<19:06,  7.12s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7779.79 ms /    36 tokens (  216.11 ms per token,     4.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.73 ms /     3 runs   (  883.91 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10433.94 ms /    39 tokens\n",
      " 95%|█████████▌| 3327/3487 [9:20:21<21:38,  8.12s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2688.69 ms /    10 tokens (  268.87 ms per token,     3.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.95 ms /     3 runs   (  898.32 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5386.43 ms /    13 tokens\n",
      " 95%|█████████▌| 3328/3487 [9:20:26<19:20,  7.30s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5259.51 ms /    22 tokens (  239.07 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2657.23 ms /     3 runs   (  885.74 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7918.77 ms /    25 tokens\n",
      " 95%|█████████▌| 3329/3487 [9:20:34<19:43,  7.49s/it]Llama.generate: 306 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3771.35 ms /    14 tokens (  269.38 ms per token,     3.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3234.22 ms /     3 runs   ( 1078.08 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    7008.75 ms /    17 tokens\n",
      " 95%|█████████▌| 3330/3487 [9:20:41<19:13,  7.35s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3374.17 ms /    10 tokens (  337.42 ms per token,     2.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3213.14 ms /     3 runs   ( 1071.05 ms per token,     0.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    6590.68 ms /    13 tokens\n",
      " 96%|█████████▌| 3331/3487 [9:20:48<18:31,  7.12s/it]Llama.generate: 306 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6360.59 ms /    30 tokens (  212.02 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.24 ms /     3 runs   (  888.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9029.55 ms /    33 tokens\n",
      " 96%|█████████▌| 3332/3487 [9:20:57<19:53,  7.70s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2647.98 ms /    10 tokens (  264.80 ms per token,     3.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2675.98 ms /     3 runs   (  891.99 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5326.58 ms /    13 tokens\n",
      " 96%|█████████▌| 3333/3487 [9:21:02<17:56,  6.99s/it]Llama.generate: 306 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   13620.44 ms /    67 tokens (  203.29 ms per token,     4.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.23 ms /     3 runs   (  893.41 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   16303.39 ms /    70 tokens\n",
      " 96%|█████████▌| 3334/3487 [9:21:18<24:57,  9.79s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2659.64 ms /    10 tokens (  265.96 ms per token,     3.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.83 ms /     3 runs   (  892.94 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5340.77 ms /    13 tokens\n",
      " 96%|█████████▌| 3335/3487 [9:21:24<21:25,  8.46s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3415.56 ms /    12 tokens (  284.63 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.68 ms /     3 runs   (  880.56 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6059.68 ms /    15 tokens\n",
      " 96%|█████████▌| 3336/3487 [9:21:30<19:28,  7.74s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2830.26 ms /    11 tokens (  257.30 ms per token,     3.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.11 ms /     3 runs   (  891.37 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5507.48 ms /    14 tokens\n",
      " 96%|█████████▌| 3337/3487 [9:21:35<17:40,  7.07s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4863.12 ms /    24 tokens (  202.63 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.74 ms /     3 runs   (  886.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7524.25 ms /    27 tokens\n",
      " 96%|█████████▌| 3338/3487 [9:21:43<17:54,  7.21s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2903.75 ms /    12 tokens (  241.98 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.63 ms /     3 runs   (  888.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5571.38 ms /    15 tokens\n",
      " 96%|█████████▌| 3339/3487 [9:21:48<16:34,  6.72s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4601.17 ms /    21 tokens (  219.10 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.57 ms /     3 runs   (  883.52 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7254.27 ms /    24 tokens\n",
      " 96%|█████████▌| 3340/3487 [9:21:56<16:51,  6.88s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3778.60 ms /    17 tokens (  222.27 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.56 ms /     3 runs   (  895.85 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6468.66 ms /    20 tokens\n",
      " 96%|█████████▌| 3341/3487 [9:22:02<16:27,  6.76s/it]Llama.generate: 307 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2970.65 ms /    10 tokens (  297.06 ms per token,     3.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.97 ms /     3 runs   (  894.32 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5656.03 ms /    13 tokens\n",
      " 96%|█████████▌| 3342/3487 [9:22:08<15:32,  6.43s/it]Llama.generate: 306 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11439.39 ms /    57 tokens (  200.69 ms per token,     4.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.74 ms /     3 runs   (  895.91 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   14129.96 ms /    60 tokens\n",
      " 96%|█████████▌| 3343/3487 [9:22:22<20:59,  8.74s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2897.34 ms /    12 tokens (  241.44 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2732.28 ms /     3 runs   (  910.76 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5633.21 ms /    15 tokens\n",
      " 96%|█████████▌| 3344/3487 [9:22:28<18:37,  7.81s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2207.12 ms /     8 tokens (  275.89 ms per token,     3.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.69 ms /     3 runs   (  881.56 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    4854.37 ms /    11 tokens\n",
      " 96%|█████████▌| 3345/3487 [9:22:32<16:23,  6.93s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1796.42 ms /     6 tokens (  299.40 ms per token,     3.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.93 ms /     3 runs   (  894.31 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4482.39 ms /     9 tokens\n",
      " 96%|█████████▌| 3346/3487 [9:22:37<14:33,  6.20s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3614.57 ms /    16 tokens (  225.91 ms per token,     4.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.44 ms /     3 runs   (  901.81 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6323.04 ms /    19 tokens\n",
      " 96%|█████████▌| 3347/3487 [9:22:43<14:33,  6.24s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2658.84 ms /    10 tokens (  265.88 ms per token,     3.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2739.88 ms /     3 runs   (  913.29 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5401.55 ms /    13 tokens\n",
      " 96%|█████████▌| 3348/3487 [9:22:49<13:52,  5.99s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4320.91 ms /    19 tokens (  227.42 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2648.06 ms /     3 runs   (  882.69 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6971.75 ms /    22 tokens\n",
      " 96%|█████████▌| 3349/3487 [9:22:56<14:27,  6.29s/it]Llama.generate: 313 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5582.30 ms /    25 tokens (  223.29 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.93 ms /     3 runs   (  887.31 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8247.60 ms /    28 tokens\n",
      " 96%|█████████▌| 3350/3487 [9:23:04<15:42,  6.88s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5458.88 ms /    27 tokens (  202.18 ms per token,     4.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2698.75 ms /     3 runs   (  899.58 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8160.19 ms /    30 tokens\n",
      " 96%|█████████▌| 3351/3487 [9:23:12<16:28,  7.27s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2315.04 ms /     8 tokens (  289.38 ms per token,     3.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.22 ms /     3 runs   (  890.74 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4989.79 ms /    11 tokens\n",
      " 96%|█████████▌| 3352/3487 [9:23:17<14:49,  6.59s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4919.20 ms /    23 tokens (  213.88 ms per token,     4.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.50 ms /     3 runs   (  879.83 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7560.80 ms /    26 tokens\n",
      " 96%|█████████▌| 3353/3487 [9:23:25<15:21,  6.88s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5118.72 ms /    24 tokens (  213.28 ms per token,     4.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.68 ms /     3 runs   (  898.56 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7816.81 ms /    27 tokens\n",
      " 96%|█████████▌| 3354/3487 [9:23:32<15:52,  7.16s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3268.15 ms /    13 tokens (  251.40 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2680.19 ms /     3 runs   (  893.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5950.94 ms /    16 tokens\n",
      " 96%|█████████▌| 3355/3487 [9:23:38<14:57,  6.80s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4793.23 ms /    23 tokens (  208.40 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.51 ms /     3 runs   (  893.17 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7475.91 ms /    26 tokens\n",
      " 96%|█████████▌| 3356/3487 [9:23:46<15:17,  7.01s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3120.73 ms /    10 tokens (  312.07 ms per token,     3.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2630.27 ms /     3 runs   (  876.76 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5753.75 ms /    13 tokens\n",
      " 96%|█████████▋| 3357/3487 [9:23:52<14:22,  6.63s/it]Llama.generate: 306 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3797.21 ms /    17 tokens (  223.37 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.55 ms /     3 runs   (  894.18 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6481.99 ms /    20 tokens\n",
      " 96%|█████████▋| 3358/3487 [9:23:58<14:10,  6.59s/it]Llama.generate: 322 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4068.96 ms /     4 runs   ( 1017.24 ms per token,     0.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    4071.73 ms /     5 tokens\n",
      " 96%|█████████▋| 3359/3487 [9:24:02<12:27,  5.84s/it]Llama.generate: 307 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9129.94 ms /    45 tokens (  202.89 ms per token,     4.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.97 ms /     3 runs   (  884.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   11786.90 ms /    48 tokens\n",
      " 96%|█████████▋| 3360/3487 [9:24:14<16:08,  7.62s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3729.64 ms /    16 tokens (  233.10 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.63 ms /     3 runs   (  906.88 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6453.26 ms /    19 tokens\n",
      " 96%|█████████▋| 3361/3487 [9:24:21<15:16,  7.28s/it]Llama.generate: 322 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4053.40 ms /     4 runs   ( 1013.35 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    4055.91 ms /     5 tokens\n",
      " 96%|█████████▋| 3362/3487 [9:24:25<13:09,  6.31s/it]Llama.generate: 307 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6169.03 ms /    29 tokens (  212.73 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2977.20 ms /     3 runs   (  992.40 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    9149.62 ms /    32 tokens\n",
      " 96%|█████████▋| 3363/3487 [9:24:34<14:48,  7.17s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4266.76 ms /    19 tokens (  224.57 ms per token,     4.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2797.52 ms /     3 runs   (  932.51 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    7066.86 ms /    22 tokens\n",
      " 96%|█████████▋| 3364/3487 [9:24:41<14:38,  7.14s/it]Llama.generate: 318 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1549.11 ms /     5 tokens (  309.82 ms per token,     3.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2831.25 ms /     3 runs   (  943.75 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4383.16 ms /     8 tokens\n",
      " 97%|█████████▋| 3365/3487 [9:24:45<12:50,  6.32s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3979.53 ms /    18 tokens (  221.09 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.66 ms /     3 runs   (  889.22 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6650.45 ms /    21 tokens\n",
      " 97%|█████████▋| 3366/3487 [9:24:52<12:56,  6.42s/it]Llama.generate: 307 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3904.30 ms /    16 tokens (  244.02 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2718.25 ms /     3 runs   (  906.08 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6625.10 ms /    19 tokens\n",
      " 97%|█████████▋| 3367/3487 [9:24:58<12:57,  6.48s/it]Llama.generate: 307 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9115.03 ms /    44 tokens (  207.16 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2834.02 ms /     3 runs   (  944.67 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   11951.77 ms /    47 tokens\n",
      " 97%|█████████▋| 3368/3487 [9:25:10<16:07,  8.13s/it]Llama.generate: 318 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3351.05 ms /    12 tokens (  279.25 ms per token,     3.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2710.87 ms /     3 runs   (  903.62 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6064.39 ms /    15 tokens\n",
      " 97%|█████████▋| 3369/3487 [9:25:17<14:46,  7.51s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4387.18 ms /    19 tokens (  230.90 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.41 ms /     3 runs   (  891.47 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7064.62 ms /    22 tokens\n",
      " 97%|█████████▋| 3370/3487 [9:25:24<14:23,  7.38s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5389.14 ms /    26 tokens (  207.27 ms per token,     4.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.20 ms /     3 runs   (  889.40 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8059.27 ms /    29 tokens\n",
      " 97%|█████████▋| 3371/3487 [9:25:32<14:39,  7.59s/it]Llama.generate: 317 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1561.62 ms /     4 tokens (  390.41 ms per token,     2.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2895.74 ms /     3 runs   (  965.25 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4459.62 ms /     7 tokens\n",
      " 97%|█████████▋| 3372/3487 [9:25:36<12:44,  6.65s/it]Llama.generate: 307 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3000.17 ms /    12 tokens (  250.01 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.55 ms /     3 runs   (  888.18 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5667.31 ms /    15 tokens\n",
      " 97%|█████████▋| 3373/3487 [9:25:42<12:04,  6.36s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3403.29 ms /    14 tokens (  243.09 ms per token,     4.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2722.72 ms /     3 runs   (  907.57 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6128.55 ms /    17 tokens\n",
      " 97%|█████████▋| 3374/3487 [9:25:48<11:51,  6.29s/it]Llama.generate: 307 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4117.93 ms /    17 tokens (  242.23 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2655.25 ms /     3 runs   (  885.08 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6775.78 ms /    20 tokens\n",
      " 97%|█████████▋| 3375/3487 [9:25:55<12:01,  6.44s/it]Llama.generate: 314 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1397.78 ms /     4 tokens (  349.45 ms per token,     2.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2904.43 ms /     3 runs   (  968.14 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    4304.70 ms /     7 tokens\n",
      " 97%|█████████▋| 3376/3487 [9:25:59<10:44,  5.80s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5481.65 ms /    26 tokens (  210.83 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2977.76 ms /     3 runs   (  992.59 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    8463.32 ms /    29 tokens\n",
      " 97%|█████████▋| 3377/3487 [9:26:08<12:06,  6.60s/it]Llama.generate: 306 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4409.14 ms /    20 tokens (  220.46 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.33 ms /     3 runs   (  888.11 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7075.86 ms /    23 tokens\n",
      " 97%|█████████▋| 3378/3487 [9:26:15<12:15,  6.75s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1573.22 ms /     5 tokens (  314.64 ms per token,     3.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2872.03 ms /     3 runs   (  957.34 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4448.10 ms /     8 tokens\n",
      " 97%|█████████▋| 3379/3487 [9:26:19<10:54,  6.06s/it]Llama.generate: 306 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7496.81 ms /    36 tokens (  208.24 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.80 ms /     3 runs   (  893.93 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10181.32 ms /    39 tokens\n",
      " 97%|█████████▋| 3380/3487 [9:26:29<13:00,  7.30s/it]Llama.generate: 306 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5053.07 ms /    22 tokens (  229.69 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2682.17 ms /     3 runs   (  894.06 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7737.77 ms /    25 tokens\n",
      " 97%|█████████▋| 3381/3487 [9:26:37<13:07,  7.43s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3635.36 ms /    16 tokens (  227.21 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2678.36 ms /     3 runs   (  892.79 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6316.65 ms /    19 tokens\n",
      " 97%|█████████▋| 3382/3487 [9:26:43<12:25,  7.10s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7772.24 ms /    38 tokens (  204.53 ms per token,     4.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.96 ms /     3 runs   (  883.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10426.09 ms /    41 tokens\n",
      " 97%|█████████▋| 3383/3487 [9:26:54<14:02,  8.10s/it]Llama.generate: 307 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7684.85 ms /    38 tokens (  202.23 ms per token,     4.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2871.60 ms /     3 runs   (  957.20 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   10559.31 ms /    41 tokens\n",
      " 97%|█████████▋| 3384/3487 [9:27:04<15:10,  8.84s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4623.94 ms /    20 tokens (  231.20 ms per token,     4.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3136.70 ms /     3 runs   ( 1045.57 ms per token,     0.96 tokens per second)\n",
      "llama_perf_context_print:       total time =    7763.00 ms /    23 tokens\n",
      " 97%|█████████▋| 3385/3487 [9:27:12<14:28,  8.52s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5473.69 ms /    24 tokens (  228.07 ms per token,     4.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.75 ms /     3 runs   (  897.92 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    8169.90 ms /    27 tokens\n",
      " 97%|█████████▋| 3386/3487 [9:27:20<14:10,  8.42s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3513.74 ms /    15 tokens (  234.25 ms per token,     4.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2693.50 ms /     3 runs   (  897.83 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6209.80 ms /    18 tokens\n",
      " 97%|█████████▋| 3387/3487 [9:27:26<12:55,  7.76s/it]Llama.generate: 306 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6243.85 ms /    28 tokens (  222.99 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.29 ms /     3 runs   (  883.43 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8896.54 ms /    31 tokens\n",
      " 97%|█████████▋| 3388/3487 [9:27:35<13:22,  8.10s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3449.12 ms /    15 tokens (  229.94 ms per token,     4.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2690.14 ms /     3 runs   (  896.71 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6141.37 ms /    18 tokens\n",
      " 97%|█████████▋| 3389/3487 [9:27:42<12:16,  7.52s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3094.01 ms /    13 tokens (  238.00 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2709.79 ms /     3 runs   (  903.26 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5806.74 ms /    16 tokens\n",
      " 97%|█████████▋| 3390/3487 [9:27:47<11:19,  7.01s/it]Llama.generate: 306 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5348.88 ms /    25 tokens (  213.96 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.14 ms /     3 runs   (  879.38 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7989.47 ms /    28 tokens\n",
      " 97%|█████████▋| 3391/3487 [9:27:55<11:41,  7.30s/it]Llama.generate: 306 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3139.30 ms /    13 tokens (  241.48 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2824.31 ms /     3 runs   (  941.44 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5966.21 ms /    16 tokens\n",
      " 97%|█████████▋| 3392/3487 [9:28:01<10:55,  6.90s/it]Llama.generate: 306 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3870.05 ms /    16 tokens (  241.88 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2667.49 ms /     3 runs   (  889.16 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6541.74 ms /    19 tokens\n",
      " 97%|█████████▋| 3393/3487 [9:28:08<10:39,  6.80s/it]Llama.generate: 314 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1492.13 ms /     4 tokens (  373.03 ms per token,     2.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2861.17 ms /     3 runs   (  953.72 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4355.62 ms /     7 tokens\n",
      " 97%|█████████▋| 3394/3487 [9:28:12<09:24,  6.07s/it]Llama.generate: 307 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7948.41 ms /    36 tokens (  220.79 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.77 ms /     3 runs   (  884.26 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10603.65 ms /    39 tokens\n",
      " 97%|█████████▋| 3395/3487 [9:28:23<11:23,  7.43s/it]Llama.generate: 307 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2684.54 ms /    11 tokens (  244.05 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2706.29 ms /     3 runs   (  902.10 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5393.47 ms /    14 tokens\n",
      " 97%|█████████▋| 3396/3487 [9:28:28<10:20,  6.82s/it]Llama.generate: 317 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3852.85 ms /     4 runs   (  963.21 ms per token,     1.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    3855.41 ms /     5 tokens\n",
      " 97%|█████████▋| 3397/3487 [9:28:32<08:54,  5.94s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4832.09 ms /    22 tokens (  219.64 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.21 ms /     3 runs   (  884.40 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7488.10 ms /    25 tokens\n",
      " 97%|█████████▋| 3398/3487 [9:28:40<09:29,  6.40s/it]Llama.generate: 317 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1440.80 ms /     4 tokens (  360.20 ms per token,     2.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2803.76 ms /     3 runs   (  934.59 ms per token,     1.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    4246.78 ms /     7 tokens\n",
      " 97%|█████████▋| 3399/3487 [9:28:44<08:26,  5.76s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4513.83 ms /    21 tokens (  214.94 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.26 ms /     3 runs   (  881.09 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7159.76 ms /    24 tokens\n",
      " 98%|█████████▊| 3400/3487 [9:28:51<08:57,  6.18s/it]Llama.generate: 307 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6442.47 ms /    32 tokens (  201.33 ms per token,     4.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2777.14 ms /     3 runs   (  925.71 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    9221.89 ms /    35 tokens\n",
      " 98%|█████████▊| 3401/3487 [9:29:00<10:10,  7.10s/it]Llama.generate: 306 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4709.51 ms /    19 tokens (  247.87 ms per token,     4.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2626.79 ms /     3 runs   (  875.60 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7339.04 ms /    22 tokens\n",
      " 98%|█████████▊| 3402/3487 [9:29:08<10:09,  7.17s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5062.36 ms /    24 tokens (  210.93 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2691.13 ms /     3 runs   (  897.04 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    7756.23 ms /    27 tokens\n",
      " 98%|█████████▊| 3403/3487 [9:29:15<10:17,  7.35s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1740.27 ms /     6 tokens (  290.05 ms per token,     3.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2830.24 ms /     3 runs   (  943.41 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    4572.95 ms /     9 tokens\n",
      " 98%|█████████▊| 3404/3487 [9:29:20<09:01,  6.52s/it]Llama.generate: 306 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12491.92 ms /    42 tokens (  297.43 ms per token,     3.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3976.23 ms /     4 runs   (  994.06 ms per token,     1.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   16502.94 ms /    46 tokens\n",
      " 98%|█████████▊| 3405/3487 [9:29:36<13:00,  9.52s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2600.55 ms /     8 tokens (  325.07 ms per token,     3.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2843.05 ms /     3 runs   (  947.68 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5446.57 ms /    11 tokens\n",
      " 98%|█████████▊| 3406/3487 [9:29:42<11:12,  8.30s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2804.87 ms /    10 tokens (  280.49 ms per token,     3.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3153.84 ms /     3 runs   ( 1051.28 ms per token,     0.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    5961.45 ms /    13 tokens\n",
      " 98%|█████████▊| 3407/3487 [9:29:48<10:07,  7.60s/it]Llama.generate: 306 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9054.64 ms /    31 tokens (  292.08 ms per token,     3.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3155.33 ms /     3 runs   ( 1051.78 ms per token,     0.95 tokens per second)\n",
      "llama_perf_context_print:       total time =   12212.74 ms /    34 tokens\n",
      " 98%|█████████▊| 3408/3487 [9:30:00<11:49,  8.99s/it]Llama.generate: 306 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4033.55 ms /     9 tokens (  448.17 ms per token,     2.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3391.59 ms /     3 runs   ( 1130.53 ms per token,     0.88 tokens per second)\n",
      "llama_perf_context_print:       total time =    7428.59 ms /    12 tokens\n",
      " 98%|█████████▊| 3409/3487 [9:30:08<11:04,  8.52s/it]Llama.generate: 310 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1985.72 ms /     4 tokens (  496.43 ms per token,     2.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2844.23 ms /     3 runs   (  948.08 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4833.11 ms /     7 tokens\n",
      " 98%|█████████▊| 3410/3487 [9:30:12<09:31,  7.42s/it]Llama.generate: 306 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6355.55 ms /    29 tokens (  219.16 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2724.68 ms /     3 runs   (  908.23 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    9082.35 ms /    32 tokens\n",
      " 98%|█████████▊| 3411/3487 [9:30:21<10:01,  7.92s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5864.60 ms /    27 tokens (  217.21 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.42 ms /     3 runs   (  893.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8547.57 ms /    30 tokens\n",
      " 98%|█████████▊| 3412/3487 [9:30:30<10:08,  8.11s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3479.54 ms /    14 tokens (  248.54 ms per token,     4.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.87 ms /     3 runs   (  892.62 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6159.73 ms /    17 tokens\n",
      " 98%|█████████▊| 3413/3487 [9:30:36<09:17,  7.53s/it]Llama.generate: 306 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1919.58 ms /     6 tokens (  319.93 ms per token,     3.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2695.25 ms /     3 runs   (  898.42 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    4617.32 ms /     9 tokens\n",
      " 98%|█████████▊| 3414/3487 [9:30:41<08:05,  6.66s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3829.18 ms /    15 tokens (  255.28 ms per token,     3.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2708.47 ms /     3 runs   (  902.82 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    6540.08 ms /    18 tokens\n",
      " 98%|█████████▊| 3415/3487 [9:30:47<07:56,  6.62s/it]Llama.generate: 307 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7519.42 ms /    35 tokens (  214.84 ms per token,     4.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.14 ms /     3 runs   (  886.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10180.75 ms /    38 tokens\n",
      " 98%|█████████▊| 3416/3487 [9:30:58<09:06,  7.69s/it]Llama.generate: 307 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4464.81 ms /    21 tokens (  212.61 ms per token,     4.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4207.88 ms /     3 runs   ( 1402.62 ms per token,     0.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    8675.52 ms /    24 tokens\n",
      " 98%|█████████▊| 3417/3487 [9:31:06<09:19,  7.99s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3771.25 ms /    10 tokens (  377.13 ms per token,     2.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3257.55 ms /     3 runs   ( 1085.85 ms per token,     0.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    7031.39 ms /    13 tokens\n",
      " 98%|█████████▊| 3418/3487 [9:31:13<08:51,  7.71s/it]Llama.generate: 306 prefix-match hit, remaining 235 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   44857.47 ms /   235 tokens (  190.88 ms per token,     5.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.42 ms /     3 runs   (  885.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   47516.25 ms /   238 tokens\n",
      " 98%|█████████▊| 3419/3487 [9:32:01<22:16, 19.65s/it]Llama.generate: 306 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14490.16 ms /    74 tokens (  195.81 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2904.74 ms /     3 runs   (  968.25 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   17397.59 ms /    77 tokens\n",
      " 98%|█████████▊| 3420/3487 [9:32:18<21:11, 18.98s/it]Llama.generate: 306 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    1528.87 ms /     5 tokens (  305.77 ms per token,     3.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2865.14 ms /     3 runs   (  955.05 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4396.02 ms /     8 tokens\n",
      " 98%|█████████▊| 3421/3487 [9:32:23<16:04, 14.61s/it]Llama.generate: 306 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   16365.31 ms /    83 tokens (  197.17 ms per token,     5.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2641.49 ms /     3 runs   (  880.50 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   19009.55 ms /    86 tokens\n",
      " 98%|█████████▊| 3422/3487 [9:32:42<17:15, 15.93s/it]Llama.generate: 306 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5377.23 ms /    26 tokens (  206.82 ms per token,     4.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2725.57 ms /     3 runs   (  908.52 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    8105.53 ms /    29 tokens\n",
      " 98%|█████████▊| 3423/3487 [9:32:50<14:29, 13.58s/it]Llama.generate: 306 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9578.26 ms /    48 tokens (  199.55 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2634.06 ms /     3 runs   (  878.02 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   12214.18 ms /    51 tokens\n",
      " 98%|█████████▊| 3424/3487 [9:33:02<13:50, 13.18s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4640.25 ms /    22 tokens (  210.92 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2673.10 ms /     3 runs   (  891.03 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7315.95 ms /    25 tokens\n",
      " 98%|█████████▊| 3425/3487 [9:33:09<11:48, 11.42s/it]Llama.generate: 307 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7475.89 ms /    34 tokens (  219.88 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.60 ms /     3 runs   (  890.53 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   10149.93 ms /    37 tokens\n",
      " 98%|█████████▊| 3426/3487 [9:33:19<11:13, 11.04s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3170.30 ms /    13 tokens (  243.87 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2731.66 ms /     3 runs   (  910.55 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5904.42 ms /    16 tokens\n",
      " 98%|█████████▊| 3427/3487 [9:33:25<09:30,  9.50s/it]Llama.generate: 308 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3484.25 ms /    15 tokens (  232.28 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2643.63 ms /     3 runs   (  881.21 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6130.37 ms /    18 tokens\n",
      " 98%|█████████▊| 3428/3487 [9:33:32<08:21,  8.49s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3708.05 ms /    13 tokens (  285.23 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2654.95 ms /     3 runs   (  884.98 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6364.95 ms /    16 tokens\n",
      " 98%|█████████▊| 3429/3487 [9:33:38<07:35,  7.86s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3082.16 ms /    13 tokens (  237.09 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2650.27 ms /     3 runs   (  883.42 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5734.91 ms /    16 tokens\n",
      " 98%|█████████▊| 3430/3487 [9:33:44<06:51,  7.22s/it]Llama.generate: 307 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    9787.04 ms /    49 tokens (  199.74 ms per token,     5.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.91 ms /     3 runs   (  881.64 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12434.59 ms /    52 tokens\n",
      " 98%|█████████▊| 3431/3487 [9:33:56<08:12,  8.79s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3268.10 ms /    13 tokens (  251.39 ms per token,     3.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.11 ms /     3 runs   (  904.04 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5982.34 ms /    16 tokens\n",
      " 98%|█████████▊| 3432/3487 [9:34:02<07:17,  7.95s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4163.97 ms /    19 tokens (  219.16 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.03 ms /     3 runs   (  889.34 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6834.46 ms /    22 tokens\n",
      " 98%|█████████▊| 3433/3487 [9:34:09<06:51,  7.62s/it]Llama.generate: 306 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2735.01 ms /    10 tokens (  273.50 ms per token,     3.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.42 ms /     3 runs   (  896.14 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5425.95 ms /    13 tokens\n",
      " 98%|█████████▊| 3434/3487 [9:34:14<06:09,  6.96s/it]Llama.generate: 306 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5068.61 ms /    24 tokens (  211.19 ms per token,     4.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.76 ms /     3 runs   (  880.92 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7714.00 ms /    27 tokens\n",
      " 99%|█████████▊| 3435/3487 [9:34:22<06:13,  7.19s/it]Llama.generate: 309 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3135.34 ms /    11 tokens (  285.03 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2646.00 ms /     3 runs   (  882.00 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5783.44 ms /    14 tokens\n",
      " 99%|█████████▊| 3436/3487 [9:34:28<05:45,  6.77s/it]Llama.generate: 319 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3903.02 ms /     4 runs   (  975.76 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    3906.27 ms /     5 tokens\n",
      " 99%|█████████▊| 3437/3487 [9:34:32<04:55,  5.91s/it]Llama.generate: 319 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3868.79 ms /     4 runs   (  967.20 ms per token,     1.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    3871.30 ms /     5 tokens\n",
      " 99%|█████████▊| 3438/3487 [9:34:36<04:19,  5.30s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3199.32 ms /    13 tokens (  246.10 ms per token,     4.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2755.19 ms /     3 runs   (  918.40 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5957.41 ms /    16 tokens\n",
      " 99%|█████████▊| 3439/3487 [9:34:42<04:24,  5.50s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3253.09 ms /    13 tokens (  250.24 ms per token,     4.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2653.15 ms /     3 runs   (  884.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5909.11 ms /    16 tokens\n",
      " 99%|█████████▊| 3440/3487 [9:34:48<04:24,  5.63s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3173.94 ms /    13 tokens (  244.15 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2713.42 ms /     3 runs   (  904.47 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5889.62 ms /    16 tokens\n",
      " 99%|█████████▊| 3441/3487 [9:34:53<04:22,  5.71s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3095.18 ms /    13 tokens (  238.09 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2694.87 ms /     3 runs   (  898.29 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5793.13 ms /    16 tokens\n",
      " 99%|█████████▊| 3442/3487 [9:34:59<04:18,  5.74s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3484.69 ms /    13 tokens (  268.05 ms per token,     3.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.74 ms /     3 runs   (  879.91 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6127.23 ms /    16 tokens\n",
      " 99%|█████████▊| 3443/3487 [9:35:05<04:17,  5.86s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11485.15 ms /    59 tokens (  194.66 ms per token,     5.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2638.92 ms /     3 runs   (  879.64 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14126.98 ms /    62 tokens\n",
      " 99%|█████████▉| 3444/3487 [9:35:20<05:58,  8.34s/it]Llama.generate: 307 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5564.89 ms /    27 tokens (  206.11 ms per token,     4.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.87 ms /     3 runs   (  892.29 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8244.92 ms /    30 tokens\n",
      " 99%|█████████▉| 3445/3487 [9:35:28<05:49,  8.31s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3146.76 ms /    13 tokens (  242.06 ms per token,     4.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2676.84 ms /     3 runs   (  892.28 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5825.82 ms /    16 tokens\n",
      " 99%|█████████▉| 3446/3487 [9:35:34<05:10,  7.57s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3208.81 ms /    13 tokens (  246.83 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.18 ms /     3 runs   (  878.39 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5846.54 ms /    16 tokens\n",
      " 99%|█████████▉| 3447/3487 [9:35:39<04:42,  7.06s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3303.12 ms /    14 tokens (  235.94 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2660.69 ms /     3 runs   (  886.90 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5966.68 ms /    17 tokens\n",
      " 99%|█████████▉| 3448/3487 [9:35:45<04:22,  6.73s/it]Llama.generate: 313 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4814.69 ms /    23 tokens (  209.33 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2671.89 ms /     3 runs   (  890.63 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7489.31 ms /    26 tokens\n",
      " 99%|█████████▉| 3449/3487 [9:35:53<04:24,  6.96s/it]Llama.generate: 316 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2138.46 ms /     4 tokens (  534.61 ms per token,     1.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2639.18 ms /     3 runs   (  879.73 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    4780.82 ms /     7 tokens\n",
      " 99%|█████████▉| 3450/3487 [9:35:58<03:53,  6.31s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3171.64 ms /    13 tokens (  243.97 ms per token,     4.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.86 ms /     3 runs   (  887.62 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5837.71 ms /    16 tokens\n",
      " 99%|█████████▉| 3451/3487 [9:36:04<03:42,  6.17s/it]Llama.generate: 307 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4858.20 ms /    22 tokens (  220.83 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2836.71 ms /     3 runs   (  945.57 ms per token,     1.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    7698.18 ms /    25 tokens\n",
      " 99%|█████████▉| 3452/3487 [9:36:11<03:52,  6.63s/it]Llama.generate: 306 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2388.98 ms /     8 tokens (  298.62 ms per token,     3.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2737.62 ms /     3 runs   (  912.54 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5129.43 ms /    11 tokens\n",
      " 99%|█████████▉| 3453/3487 [9:36:16<03:30,  6.18s/it]Llama.generate: 306 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    6577.81 ms /    32 tokens (  205.56 ms per token,     4.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2665.13 ms /     3 runs   (  888.38 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9245.75 ms /    35 tokens\n",
      " 99%|█████████▉| 3454/3487 [9:36:26<03:54,  7.10s/it]Llama.generate: 307 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11102.02 ms /    56 tokens (  198.25 ms per token,     5.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.99 ms /     3 runs   (  881.66 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   13750.07 ms /    59 tokens\n",
      " 99%|█████████▉| 3455/3487 [9:36:39<04:51,  9.10s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2835.35 ms /    12 tokens (  236.28 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2663.26 ms /     3 runs   (  887.75 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5500.69 ms /    15 tokens\n",
      " 99%|█████████▉| 3456/3487 [9:36:45<04:08,  8.02s/it]Llama.generate: 306 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7928.40 ms /    35 tokens (  226.53 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2651.82 ms /     3 runs   (  883.94 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   10582.42 ms /    38 tokens\n",
      " 99%|█████████▉| 3457/3487 [9:36:56<04:23,  8.79s/it]Llama.generate: 306 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3358.55 ms /    15 tokens (  223.90 ms per token,     4.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.81 ms /     3 runs   (  889.60 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6029.70 ms /    18 tokens\n",
      " 99%|█████████▉| 3458/3487 [9:37:02<03:51,  7.97s/it]Llama.generate: 306 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   11369.90 ms /    59 tokens (  192.71 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.41 ms /     3 runs   (  881.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14017.25 ms /    62 tokens\n",
      " 99%|█████████▉| 3459/3487 [9:37:16<04:33,  9.78s/it]Llama.generate: 306 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3248.55 ms /    11 tokens (  295.32 ms per token,     3.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2668.99 ms /     3 runs   (  889.66 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5920.44 ms /    14 tokens\n",
      " 99%|█████████▉| 3460/3487 [9:37:22<03:52,  8.63s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2959.93 ms /    12 tokens (  246.66 ms per token,     4.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.07 ms /     3 runs   (  887.36 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5624.45 ms /    15 tokens\n",
      " 99%|█████████▉| 3461/3487 [9:37:27<03:20,  7.73s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2800.38 ms /    12 tokens (  233.36 ms per token,     4.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2674.28 ms /     3 runs   (  891.43 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5477.16 ms /    15 tokens\n",
      " 99%|█████████▉| 3462/3487 [9:37:33<02:56,  7.06s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2784.36 ms /    12 tokens (  232.03 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2672.65 ms /     3 runs   (  890.88 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5459.83 ms /    15 tokens\n",
      " 99%|█████████▉| 3463/3487 [9:37:38<02:37,  6.58s/it]Llama.generate: 306 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4987.39 ms /    21 tokens (  237.49 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.23 ms /     3 runs   (  878.41 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7624.43 ms /    24 tokens\n",
      " 99%|█████████▉| 3464/3487 [9:37:46<02:38,  6.89s/it]Llama.generate: 307 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   14471.20 ms /    74 tokens (  195.56 ms per token,     5.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2707.27 ms /     3 runs   (  902.42 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   17180.50 ms /    77 tokens\n",
      " 99%|█████████▉| 3465/3487 [9:38:03<03:39,  9.98s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2824.60 ms /    12 tokens (  235.38 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2703.78 ms /     3 runs   (  901.26 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5530.86 ms /    15 tokens\n",
      " 99%|█████████▉| 3466/3487 [9:38:08<03:01,  8.65s/it]Llama.generate: 310 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3478.61 ms /    15 tokens (  231.91 ms per token,     4.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.34 ms /     3 runs   (  893.78 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6162.25 ms /    18 tokens\n",
      " 99%|█████████▉| 3467/3487 [9:38:15<02:38,  7.91s/it]Llama.generate: 306 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4036.51 ms /    18 tokens (  224.25 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2688.39 ms /     3 runs   (  896.13 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6727.38 ms /    21 tokens\n",
      " 99%|█████████▉| 3468/3487 [9:38:21<02:23,  7.56s/it]Llama.generate: 306 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2880.17 ms /    12 tokens (  240.01 ms per token,     4.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.14 ms /     3 runs   (  883.05 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    5531.66 ms /    15 tokens\n",
      " 99%|█████████▉| 3469/3487 [9:38:27<02:05,  6.95s/it]Llama.generate: 317 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3819.83 ms /     4 runs   (  954.96 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    3822.95 ms /     5 tokens\n",
      "100%|█████████▉| 3470/3487 [9:38:31<01:42,  6.01s/it]Llama.generate: 306 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    8485.08 ms /    40 tokens (  212.13 ms per token,     4.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2669.32 ms /     3 runs   (  889.77 ms per token,     1.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   11157.09 ms /    43 tokens\n",
      "100%|█████████▉| 3471/3487 [9:38:42<02:00,  7.56s/it]Llama.generate: 307 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4986.08 ms /    23 tokens (  216.79 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2649.67 ms /     3 runs   (  883.22 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7638.35 ms /    26 tokens\n",
      "100%|█████████▉| 3472/3487 [9:38:50<01:53,  7.59s/it]Llama.generate: 307 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4314.70 ms /    19 tokens (  227.09 ms per token,     4.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.73 ms /     3 runs   (  885.58 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6973.45 ms /    22 tokens\n",
      "100%|█████████▉| 3473/3487 [9:38:57<01:43,  7.40s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4531.25 ms /    20 tokens (  226.56 ms per token,     4.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2661.75 ms /     3 runs   (  887.25 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7195.91 ms /    23 tokens\n",
      "100%|█████████▉| 3474/3487 [9:39:04<01:35,  7.34s/it]Llama.generate: 307 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    4406.44 ms /    20 tokens (  220.32 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.31 ms /     3 runs   (  888.10 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    7073.31 ms /    23 tokens\n",
      "100%|█████████▉| 3475/3487 [9:39:11<01:27,  7.27s/it]Llama.generate: 306 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5584.77 ms /    27 tokens (  206.84 ms per token,     4.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.42 ms /     3 runs   (  885.47 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8243.54 ms /    30 tokens\n",
      "100%|█████████▉| 3476/3487 [9:39:19<01:23,  7.56s/it]Llama.generate: 306 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   10816.08 ms /    55 tokens (  196.66 ms per token,     5.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2857.08 ms /     3 runs   (  952.36 ms per token,     1.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   13675.09 ms /    58 tokens\n",
      "100%|█████████▉| 3477/3487 [9:39:33<01:33,  9.40s/it]Llama.generate: 307 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3174.78 ms /    13 tokens (  244.21 ms per token,     4.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2735.68 ms /     3 runs   (  911.89 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5912.98 ms /    16 tokens\n",
      "100%|█████████▉| 3478/3487 [9:39:39<01:15,  8.35s/it]Llama.generate: 307 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    5419.21 ms /    25 tokens (  216.77 ms per token,     4.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2632.71 ms /     3 runs   (  877.57 ms per token,     1.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    8054.49 ms /    28 tokens\n",
      "100%|█████████▉| 3479/3487 [9:39:47<01:06,  8.27s/it]Llama.generate: 307 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3969.93 ms /    18 tokens (  220.55 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.94 ms /     3 runs   (  887.65 ms per token,     1.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6635.47 ms /    21 tokens\n",
      "100%|█████████▉| 3480/3487 [9:39:53<00:54,  7.78s/it]Llama.generate: 324 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4044.65 ms /     4 runs   ( 1011.16 ms per token,     0.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    4046.98 ms /     5 tokens\n",
      "100%|█████████▉| 3481/3487 [9:39:57<00:39,  6.66s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3305.81 ms /    14 tokens (  236.13 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2755.36 ms /     3 runs   (  918.45 ms per token,     1.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    6063.72 ms /    17 tokens\n",
      "100%|█████████▉| 3482/3487 [9:40:03<00:32,  6.49s/it]Llama.generate: 307 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   12628.89 ms /    59 tokens (  214.05 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.80 ms /     3 runs   (  906.93 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   15352.51 ms /    62 tokens\n",
      "100%|█████████▉| 3483/3487 [9:40:19<00:36,  9.15s/it]Llama.generate: 307 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    3512.88 ms /    14 tokens (  250.92 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2773.64 ms /     3 runs   (  924.55 ms per token,     1.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    6289.26 ms /    17 tokens\n",
      "100%|█████████▉| 3484/3487 [9:40:25<00:24,  8.29s/it]Llama.generate: 320 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3995.72 ms /     4 runs   (  998.93 ms per token,     1.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    3997.91 ms /     5 tokens\n",
      "100%|█████████▉| 3485/3487 [9:40:29<00:14,  7.01s/it]Llama.generate: 306 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    7769.66 ms /    37 tokens (  209.99 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4197.83 ms /     3 runs   ( 1399.28 ms per token,     0.71 tokens per second)\n",
      "llama_perf_context_print:       total time =   11970.23 ms /    40 tokens\n",
      "100%|█████████▉| 3486/3487 [9:40:41<00:08,  8.50s/it]Llama.generate: 306 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =   15315.52 ms /    65 tokens (  235.62 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2692.22 ms /     3 runs   (  897.41 ms per token,     1.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   18010.56 ms /    68 tokens\n",
      "100%|██████████| 3487/3487 [9:40:59<00:00, 11.36s/it]Llama.generate: 307 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =  134621.40 ms\n",
      "llama_perf_context_print: prompt eval time =    2363.00 ms /     8 tokens (  295.37 ms per token,     3.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.40 ms /     3 runs   (  907.13 ms per token,     1.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5086.45 ms /    11 tokens\n",
      "100%|██████████| 3487/3487 [9:41:04<00:00, 10.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# 📌 Apply Sentiment Classification with Progress Bar\n",
    "tqdm.pandas()\n",
    "comments_df[\"Sentiment_Predicted\"] = comments_df[\"Comments\"].progress_apply(classify_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sentiment annotation completed! Results saved to Results/Comments_Annotated_Mistral-7B.csv\n"
     ]
    }
   ],
   "source": [
    "# 📌 Save the Annotated Data\n",
    "output_path = \"Results/Comments_Annotated_Mistral-7B.csv\"\n",
    "comments_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Sentiment annotation completed! Results saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
